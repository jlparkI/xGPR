"""Contains useful functions for testing convolution-based operations.
We test generally by comparing to the simplest and most idiot-proof
(i.e. verbose and slow) way of doing the operation in question
to the output from the wrapped C / Cuda modules."""
from math import ceil

import numpy as np

from cpu_rf_gen_module import cpuFastHadamardTransform as cFHT


def get_initial_matrices_fht(ndatapoints, kernel_width, aa_dim, num_aas,
            num_freqs, mode, precision = "double"):
    """Supplies the initial matrices that the C / Cuda modules will use.
    Note that this function uses stride_tricks, which is a (moderately)
    unsafe numpy / cupy tool, while the pure Python approach does NOT
    use stride tricks -- by cross-checking the results from both
    we can double-check that stride_tricks is being used correctly."""
    dim2 = 2**ceil(np.log2(kernel_width * aa_dim))
    num_blocks = num_aas - kernel_width + 1
    dim2_no_pad = aa_dim * kernel_width

    radem_array = np.asarray([-1,1], dtype=np.int8)
    radem_size = ceil(num_freqs / dim2) * dim2
    random_seed = 123
    rng = np.random.default_rng(random_seed)
    xdata = rng.uniform(low=-10.0,high=10.0, size=(ndatapoints, num_aas, aa_dim))

    if mode.startswith("maxpool"):
        features = np.zeros((ndatapoints, radem_size))
        s_mat = rng.uniform(size=(radem_size))
    elif mode.startswith("arccos"):
        features = np.zeros((ndatapoints, num_freqs))
        s_mat = rng.uniform(size=(num_freqs))
    else:
        features = np.zeros((ndatapoints, 2 * num_freqs))
        s_mat = rng.uniform(size=(num_freqs))
    radem = rng.choice(radem_array, size=(3, 1, radem_size), replace=True)

    reshaped_x = np.zeros((xdata.shape[0], num_blocks, dim2))
    x_strided = np.lib.stride_tricks.as_strided(xdata,
                    shape=(xdata.shape[0], num_blocks, dim2_no_pad),
                    strides=(xdata.strides[0], xdata.shape[2] * 8, 8))
    reshaped_x[:,:,:dim2_no_pad] = np.ascontiguousarray(x_strided)
    if precision == "float":
        return dim2, num_blocks, xdata.astype(np.float32), reshaped_x.astype(np.float32),\
                features, s_mat.astype(np.float32), radem
    return dim2, num_blocks, xdata, reshaped_x, features, s_mat, radem



def get_reshaped_x(xdata, kernel_width, dim2, radem, num_blocks,
                    repeat_num, precision = "double"):
    """This is the slow / simple / stupid way to generate the results of
    FHT-based convolution, for comparison with the output from the wrapped
    CPU / Cuda modules. The latter will be faster, but by using this
    straightforward approach we can ensure the former is correct."""

    norm_constant = np.log2(dim2) / 2
    norm_constant = 1 / (2**norm_constant)

    reshaped_x = np.zeros((xdata.shape[0], num_blocks, dim2))
    fht_func = cFHT
    if precision == "float":
        reshaped_x = reshaped_x.astype(np.float32)

    window_size = xdata.shape[2] * kernel_width
    start = repeat_num * reshaped_x.shape[2]
    end = start + reshaped_x.shape[2]
    for i in range(xdata.shape[1] - kernel_width + 1):
        window = xdata[:,i:i+kernel_width,:]
        reshaped_x[:,i,:window_size] = window.reshape((window.shape[0],
                        window.shape[1] * window.shape[2]))

    reshaped_x *= radem[0:1,:,start:end] * norm_constant
    fht_func(reshaped_x, 1)
    reshaped_x *= radem[1:2,:,start:end] * norm_constant
    fht_func(reshaped_x, 1)
    reshaped_x *= radem[2:3,:,start:end] * norm_constant
    fht_func(reshaped_x, 1)

    return reshaped_x


def get_features(xdata, kernel_width, dim2,
            radem, s_mat, num_freqs, num_blocks, sigma,
            precision = "double", fit_intercept = False):
    """Builds the ground truth features using an inefficient
    but easy to troubleshoot approach, for comparison with
    the features generated by the extensions."""
    num_repeats = ceil(num_freqs / dim2)
    counter = 0
    features = np.zeros((xdata.shape[0], 2 * num_freqs))
    for i in range(num_repeats):
        reshaped_x = get_reshaped_x(xdata, kernel_width, dim2, radem,
                                num_blocks, i, precision)
        end_position = min((i + 1) * dim2, num_freqs)
        end_position -= i * dim2
        counter = i * dim2
        for j in range(end_position):
            temp = reshaped_x[:,:,j] * s_mat[counter] * sigma
            features[:,2 * counter] = np.sum(np.cos(temp), axis=1)
            features[:,2 * counter + 1] = np.sum(np.sin(temp), axis=1)
            counter += 1

    if fit_intercept:
        features = features * np.sqrt(2 / (float(num_freqs)-0.5))
        features[:,0] = 1
    else:
        features = features * np.sqrt(2 / float(num_freqs))
    return features


def get_features_with_gradient(xdata, kernel_width, dim2,
            radem, s_mat, num_freqs, num_blocks, sigma,
            precision = "double", fit_intercept = False):
    """Builds the ground truth features and gradient using an inefficient
    but easy to troubleshoot approach, for comparison with
    the features generated by the extensions."""
    num_repeats = ceil(num_freqs / dim2)
    counter = 0
    features = np.zeros((xdata.shape[0], 2 * num_freqs))
    gradient = np.zeros(features.shape)

    for i in range(num_repeats):
        reshaped_x = get_reshaped_x(xdata, kernel_width, dim2, radem,
                                num_blocks, i, precision)
        end_position = min((i + 1) * dim2, num_freqs)
        end_position -= i * dim2
        counter = i * dim2
        for j in range(end_position):
            reshaped_x[:,:,j] *= s_mat[counter]
            temp_arr = reshaped_x[:,:,j] * sigma
            gradient[:,2 * counter] = np.sum(-np.sin(temp_arr) * reshaped_x[:,:,j],
                                    axis = 1)
            features[:,2 * counter] = np.sum(np.cos(temp_arr), axis = 1)

            gradient[:,2 * counter + 1] = np.sum(np.cos(temp_arr) * reshaped_x[:,:,j],
                                    axis = 1)
            features[:,2 * counter + 1] = np.sum(np.sin(temp_arr), axis = 1)
            counter += 1

    if fit_intercept:
        features *= np.sqrt(2 / (num_freqs-0.5))
        features[:,0] = 1
        gradient[:,0] = 0
        gradient *= np.sqrt(2 / (num_freqs-0.5))
    else:
        gradient *= np.sqrt(2 / num_freqs)
        features *= np.sqrt(2 / num_freqs)
    return features, gradient



def get_features_maxpool(xdata, kernel_width, dim2,
            radem, s_mat, num_rffs, num_blocks, precision = "double"):
    """Builds the ground truth features for maxpooling using an inefficient
    but easy to troubleshoot approach, for comparison with
    the features generated by the extensions."""
    num_repeats = ceil(num_rffs / dim2)
    features = np.zeros((xdata.shape[0], radem.shape[2]))
    if precision == "float":
        features = features.astype(np.float32)

    for i in range(num_repeats):
        reshaped_x = get_reshaped_x(xdata, kernel_width, dim2, radem,
                                num_blocks, i)
        start, end = i * dim2, (i + 1) * dim2
        reshaped_x = s_mat[None, None, start:end] * reshaped_x
        features[:,start:end] = reshaped_x.max(axis=1)
    return features[:,:num_rffs]



def get_features_arccos(xdata, kernel_width, dim2,
            radem, s_mat, num_freqs, num_blocks, precision = "double",
            fit_intercept = False):
    """Builds the ground truth features for the arc-cosine variant
    of the convolution kernel, using an inefficient
    but easy to troubleshoot approach, for comparison with
    the features generated by the extensions."""
    num_repeats = ceil(num_freqs / dim2)
    counter = 0
    features = np.zeros((xdata.shape[0], num_freqs))
    for i in range(num_repeats):
        reshaped_x = get_reshaped_x(xdata, kernel_width, dim2, radem,
                                num_blocks, i, precision)
        end_position = min((i + 1) * dim2, num_freqs)
        end_position -= i * dim2
        counter = i * dim2
        for j in range(end_position):
            temp = reshaped_x[:,:,j] * s_mat[counter]
            features[:,counter] = np.sum(temp.clip(min=0), axis=1)
            counter += 1

    if fit_intercept:
        features = features * np.sqrt(1 / float(num_freqs-1))
        features[:,0] = 1
    else:
        features = features * np.sqrt(1 / float(num_freqs))
    return features
