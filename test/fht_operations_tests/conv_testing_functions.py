"""Contains useful functions for testing convolution-based operations.
We test generally by comparing to the simplest and most idiot-proof
(i.e. verbose and slow) way of doing the operation in question
to the output from the wrapped C / Cuda modules."""
from math import ceil

import numpy as np

from cpu_basic_hadamard_operations import doubleCpuFastHadamardTransform as dFHT
from cpu_basic_hadamard_operations import floatCpuFastHadamardTransform as fFHT


def get_initial_matrices_fht(ndatapoints, kernel_width, aa_dim, num_aas,
            num_freqs, mode, precision = "double"):
    """Supplies the initial matrices that the C / Cuda modules will use.
    Note that this function uses stride_tricks, which is a (moderately)
    unsafe numpy / cupy tool, while the pure Python approach does NOT
    use stride tricks -- by cross-checking the results from both
    we can double-check that stride_tricks is being used correctly."""
    dim2 = 2**ceil(np.log2(kernel_width * aa_dim))
    num_blocks = num_aas - kernel_width + 1
    dim2_no_pad = aa_dim * kernel_width

    radem_array = np.asarray([-1,1], dtype=np.int8)
    radem_size = ceil(num_freqs / dim2) * dim2
    random_seed = 123
    rng = np.random.default_rng(random_seed)
    xdata = rng.uniform(low=-10.0,high=10.0, size=(ndatapoints, num_aas, aa_dim))

    if not mode.startswith("maxpool"):
        features = np.zeros((ndatapoints, 2 * radem_size))
    else:
        features = np.zeros((ndatapoints, radem_size))
    s_mat = rng.uniform(size=(radem_size))
    radem = rng.choice(radem_array, size=(3, 1, radem_size), replace=True)

    reshaped_x = np.zeros((xdata.shape[0], num_blocks, dim2))
    x_strided = np.lib.stride_tricks.as_strided(xdata,
                    shape=(xdata.shape[0], num_blocks, dim2_no_pad),
                    strides=(xdata.strides[0], xdata.shape[2] * 8, 8))
    reshaped_x[:,:,:dim2_no_pad] = np.ascontiguousarray(x_strided)
    if precision == "float":
        return dim2, num_blocks, xdata.astype(np.float32), reshaped_x.astype(np.float32),\
                features, s_mat.astype(np.float32), radem
    return dim2, num_blocks, xdata, reshaped_x, features, s_mat, radem



def get_reshaped_x(xdata, kernel_width, dim2, radem, num_blocks,
                    repeat_num, precision = "double"):
    """This is the slow / simple / stupid way to generate the results of
    FHT-based convolution, for comparison with the output from the wrapped
    CPU / Cuda modules. The latter will be faster, but by using this
    straightforward approach we can ensure the former is correct."""

    norm_constant = np.log2(dim2) / 2
    norm_constant = 1 / (2**norm_constant)

    reshaped_x = np.zeros((xdata.shape[0], num_blocks, dim2))
    fht_func = dFHT
    if precision == "float":
        reshaped_x = reshaped_x.astype(np.float32)
        fht_func = fFHT

    window_size = xdata.shape[2] * kernel_width
    start = repeat_num * reshaped_x.shape[2]
    end = start + reshaped_x.shape[2]
    for i in range(xdata.shape[1] - kernel_width + 1):
        window = xdata[:,i:i+kernel_width,:]
        reshaped_x[:,i,:window_size] = window.reshape((window.shape[0],
                        window.shape[1] * window.shape[2]))

    reshaped_x *= radem[0:1,:,start:end] * norm_constant
    fht_func(reshaped_x, 1)
    reshaped_x *= radem[1:2,:,start:end] * norm_constant
    fht_func(reshaped_x, 1)
    reshaped_x *= radem[2:3,:,start:end] * norm_constant
    fht_func(reshaped_x, 1)

    return reshaped_x


def get_features(xdata, kernel_width, dim2,
            radem, s_mat, num_freqs, num_blocks, sigma,
            precision = "double"):
    """Builds the ground truth features using an inefficient
    but easy to troubleshoot approach, for comparison with
    the features generated by the extensions."""
    num_repeats = ceil(num_freqs / dim2)
    counter, s_counter = 0, 0
    features = np.zeros((xdata.shape[0], 2 * radem.shape[2]))

    for i in range(num_repeats):
        reshaped_x = get_reshaped_x(xdata, kernel_width, dim2, radem,
                                num_blocks, i, precision)
        for j in range(dim2):
            reshaped_x[:,:,j] *= s_mat[s_counter] * sigma
            features[:,counter] = np.sum(np.cos(reshaped_x[:,:,j]), axis=1)
            features[:,counter+dim2] = np.sum(np.sin(reshaped_x[:,:,j]), axis=1)
            counter += 1
            s_counter += 1
        counter += dim2
    features *= np.sqrt(1 / radem.shape[2])
    return features[:,:(2 * num_freqs)]


def get_features_with_gradient(xdata, kernel_width, dim2,
            radem, s_mat, num_freqs, num_blocks, sigma,
            precision = "double"):
    """Builds the ground truth features and gradient using an inefficient
    but easy to troubleshoot approach, for comparison with
    the features generated by the extensions."""
    num_repeats = ceil(num_freqs / dim2)
    counter, s_counter = 0, 0
    features = np.zeros((xdata.shape[0], 2 * radem.shape[2]))
    gradient = np.zeros(features.shape)

    for i in range(num_repeats):
        reshaped_x = get_reshaped_x(xdata, kernel_width, dim2, radem,
                                num_blocks, i, precision)
        for j in range(dim2):
            reshaped_x[:,:,j] *= s_mat[s_counter]
            temp_arr = reshaped_x[:,:,j] * sigma
            gradient[:,counter] = np.sum(-np.sin(temp_arr) * reshaped_x[:,:,j],
                                    axis = 1)
            features[:,counter] = np.sum(np.cos(temp_arr), axis = 1)

            gradient[:,counter+dim2] = np.sum(np.cos(temp_arr) * reshaped_x[:,:,j],
                                    axis = 1)
            features[:,counter+dim2] = np.sum(np.sin(temp_arr), axis = 1)
            counter += 1
            s_counter += 1
        counter += dim2
    gradient *= np.sqrt(1 / radem.shape[2])
    features *= np.sqrt(1 / radem.shape[2])
    return features[:,:(2 * num_freqs)], gradient[:,:(2 * num_freqs)]



def get_features_maxpool(xdata, kernel_width, dim2,
            radem, s_mat, num_rffs, num_blocks, mode = "maxpool",
            precision = "double"):
    """Builds the ground truth features for maxpooling using an inefficient
    but easy to troubleshoot approach, for comparison with
    the features generated by the extensions."""
    num_repeats = ceil(num_rffs / dim2)
    features = np.zeros((xdata.shape[0], radem.shape[2]))
    if precision == "float":
        features = features.astype(np.float32)

    for i in range(num_repeats):
        reshaped_x = get_reshaped_x(xdata, kernel_width, dim2, radem,
                                num_blocks, i)
        start, end = i * dim2, (i + 1) * dim2
        reshaped_x = s_mat[None, None, start:end] * reshaped_x
        features[:,start:end] = reshaped_x.max(axis=1)
        if mode == "maxpool_loc":
            features[:,start:end] -= reshaped_x.mean(axis=1)
    return features[:,:num_rffs]
