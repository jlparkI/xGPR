{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41f0fa12",
   "metadata": {},
   "source": [
    "## Example: Sequence Data\n",
    "\n",
    "Next, let's consider the AAV dataset, designed vs mutant split, \n",
    "from the FLIP benchmark suite. For this dataset, we train on 200,000\n",
    "length 57 amino acid sequences and try to predict the fitness\n",
    "of a pre-specified test set. Dallago et al. report that a standard\n",
    "1d-CNN trained on this achieves a Spearman's r of 0.75, while\n",
    "a 750-million parameter pretrained model that took 50 GPU-days of\n",
    "time to train achieves Spearman's r of 0.71.\n",
    "\n",
    "We'll evaluate a convolution kernel and show that we can easily\n",
    "match or outperform the deep learning baselines without too\n",
    "much effort.\n",
    "\n",
    "This was originally run using xGPR v0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9a773dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd1/Documents/gp_proteins/venv_testing/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import math\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xGPR import xGPRegression as xGPReg\n",
    "from xGPR import build_regression_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42875b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'FLIP'...\n"
     ]
    }
   ],
   "source": [
    "#This may take a minute...\n",
    "subprocess.run([\"git\", \"clone\", \"https://github.com/J-SNACKKB/FLIP\"])\n",
    "\n",
    "shutil.move(os.path.join(\"FLIP\", \"splits\", \"aav\", \"full_data.csv.zip\"), \"full_data.csv.zip\")\n",
    "fname = \"full_data.csv.zip\"\n",
    "\n",
    "with zipfile.ZipFile(fname, \"r\") as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "\n",
    "os.remove(\"full_data.csv.zip\")\n",
    "\n",
    "\n",
    "shutil.rmtree(\"FLIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e5dc401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_224782/4195622896.py:1: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = pd.read_csv(\"full_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"full_data.csv\")\n",
    "os.remove(\"full_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80ee02b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[\"input_seq\"] = [f.upper().replace(\"*\", \"\") for f in raw_data[\"mutated_region\"].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fef6ad7",
   "metadata": {},
   "source": [
    "We'll use simple one-hot encoding for the sequences. This may take a minute to set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98745fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(input_seq_list, y_values, chunk_size, ftype = \"train\"):\n",
    "    aas = [\"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\",\n",
    "               \"K\", \"L\", \"M\", \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\",\n",
    "               \"V\", \"W\", \"Y\", \"-\"]\n",
    "    output_x, output_y = [], []\n",
    "    xfiles, yfiles = [], []\n",
    "    fcounter = 0\n",
    "    \n",
    "    for seq, y_value in zip(input_seq_list, y_values):\n",
    "        encoded_x = np.zeros((1,57,21), dtype = np.uint8)\n",
    "        for i, letter in enumerate(seq):\n",
    "            encoded_x[0, i, aas.index(letter)] = 1\n",
    "\n",
    "        output_x.append(encoded_x)\n",
    "        output_y.append(y_value)\n",
    "\n",
    "        if len(output_x) >= chunk_size:\n",
    "            xfiles.append(f\"{fcounter}_{ftype}_xblock.npy\")\n",
    "            yfiles.append(f\"{fcounter}_{ftype}_yblock.npy\")\n",
    "            np.save(xfiles[-1], np.vstack(output_x))\n",
    "            np.save(yfiles[-1], np.asarray(output_y))\n",
    "            fcounter += 1\n",
    "            output_x, output_y = [], []\n",
    "            print(f\"Encoded file {fcounter}\")\n",
    "    return xfiles, yfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18d97977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded file 1\n",
      "Encoded file 2\n",
      "Encoded file 3\n",
      "Encoded file 4\n",
      "Encoded file 5\n",
      "Encoded file 6\n",
      "Encoded file 7\n",
      "Encoded file 8\n",
      "Encoded file 9\n",
      "Encoded file 10\n",
      "Encoded file 11\n",
      "Encoded file 12\n",
      "Encoded file 13\n",
      "Encoded file 14\n",
      "Encoded file 15\n",
      "Encoded file 16\n",
      "Encoded file 17\n",
      "Encoded file 18\n",
      "Encoded file 19\n",
      "Encoded file 20\n",
      "Encoded file 21\n",
      "Encoded file 22\n",
      "Encoded file 23\n",
      "Encoded file 24\n",
      "Encoded file 25\n",
      "Encoded file 26\n",
      "Encoded file 27\n",
      "Encoded file 28\n",
      "Encoded file 29\n",
      "Encoded file 30\n",
      "Encoded file 31\n",
      "Encoded file 32\n",
      "Encoded file 33\n",
      "Encoded file 34\n",
      "Encoded file 35\n",
      "Encoded file 36\n",
      "Encoded file 37\n",
      "Encoded file 38\n",
      "Encoded file 39\n",
      "Encoded file 40\n",
      "Encoded file 41\n",
      "Encoded file 42\n",
      "Encoded file 43\n",
      "Encoded file 44\n",
      "Encoded file 45\n",
      "Encoded file 46\n",
      "Encoded file 47\n",
      "Encoded file 48\n",
      "Encoded file 49\n",
      "Encoded file 50\n",
      "Encoded file 51\n",
      "Encoded file 52\n",
      "Encoded file 53\n",
      "Encoded file 54\n",
      "Encoded file 55\n",
      "Encoded file 56\n",
      "Encoded file 57\n",
      "Encoded file 58\n",
      "Encoded file 59\n",
      "Encoded file 60\n",
      "Encoded file 61\n",
      "Encoded file 62\n",
      "Encoded file 63\n",
      "Encoded file 64\n",
      "Encoded file 65\n",
      "Encoded file 66\n",
      "Encoded file 67\n",
      "Encoded file 68\n",
      "Encoded file 69\n",
      "Encoded file 70\n",
      "Encoded file 71\n",
      "Encoded file 72\n",
      "Encoded file 73\n",
      "Encoded file 74\n",
      "Encoded file 75\n",
      "Encoded file 76\n",
      "Encoded file 77\n",
      "Encoded file 78\n",
      "Encoded file 79\n",
      "Encoded file 80\n",
      "Encoded file 81\n",
      "Encoded file 82\n",
      "Encoded file 83\n",
      "Encoded file 84\n",
      "Encoded file 85\n",
      "Encoded file 86\n",
      "Encoded file 87\n",
      "Encoded file 88\n",
      "Encoded file 89\n",
      "Encoded file 90\n",
      "Encoded file 91\n",
      "Encoded file 92\n",
      "Encoded file 93\n",
      "Encoded file 94\n",
      "Encoded file 95\n",
      "Encoded file 96\n",
      "Encoded file 97\n",
      "Encoded file 98\n",
      "Encoded file 99\n",
      "Encoded file 100\n",
      "Encoded file 1\n",
      "Encoded file 2\n",
      "Encoded file 3\n",
      "Encoded file 4\n",
      "Encoded file 5\n",
      "Encoded file 6\n",
      "Encoded file 7\n",
      "Encoded file 8\n",
      "Encoded file 9\n",
      "Encoded file 10\n",
      "Encoded file 11\n",
      "Encoded file 12\n",
      "Encoded file 13\n",
      "Encoded file 14\n",
      "Encoded file 15\n",
      "Encoded file 16\n",
      "Encoded file 17\n",
      "Encoded file 18\n",
      "Encoded file 19\n",
      "Encoded file 20\n",
      "Encoded file 21\n",
      "Encoded file 22\n",
      "Encoded file 23\n",
      "Encoded file 24\n",
      "Encoded file 25\n",
      "Encoded file 26\n",
      "Encoded file 27\n",
      "Encoded file 28\n",
      "Encoded file 29\n",
      "Encoded file 30\n",
      "Encoded file 31\n",
      "Encoded file 32\n",
      "Encoded file 33\n",
      "Encoded file 34\n",
      "Encoded file 35\n",
      "Encoded file 36\n",
      "Encoded file 37\n",
      "Encoded file 38\n",
      "Encoded file 39\n",
      "Encoded file 40\n",
      "Encoded file 41\n"
     ]
    }
   ],
   "source": [
    "train_data = raw_data[raw_data[\"des_mut_split\"]==\"train\"]\n",
    "test_data = raw_data[raw_data[\"des_mut_split\"]==\"test\"]\n",
    "\n",
    "\n",
    "train_x_files, train_y_files = one_hot_encode(train_data[\"input_seq\"].tolist(),\n",
    "                                              train_data[\"score\"].tolist(), 2000, \"train\")\n",
    "test_x_files, test_y_files = one_hot_encode(test_data[\"input_seq\"].tolist(),\n",
    "                                            test_data[\"score\"].tolist(), 2000, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99584178",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dset = build_regression_dataset(train_x_files, train_y_files, chunk_size = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b89e96",
   "metadata": {},
   "source": [
    "Here we'll use the FHTConv1d kernel, a kernel for sequences. Convolution kernels are usually slower than RBF / Matern, especially if the sequence is long. We'll run a quick and dirty tuning experiment using 1024 random features, then fine-tune this using a larger number of random features just as we did for the tabular dataset.\n",
    "\n",
    "Many kernels in xGPR have kernel-specific settings. For FHTConv1d, we can set two key options: whether to average over the sequence (defaults to False) and the width of the convolution to use. Just as with a convolutional network, the width of the convolution filters can affect performance. One way to choose a good setting: see what marginal likelihood score you get from hyperparameter tuning (e.g. with ``crude_bayes`` or ``crude_grid``) using a small number of RFFs (e.g. 1024 - 2048) for several different settings of \"conv_width\". The smallest score achieved likely corresponds to the best value for \"conv_width\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c451d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid point 0 acquired.\n",
      "Grid point 1 acquired.\n",
      "Grid point 2 acquired.\n",
      "Grid point 3 acquired.\n",
      "Grid point 4 acquired.\n",
      "Grid point 5 acquired.\n",
      "Grid point 6 acquired.\n",
      "Grid point 7 acquired.\n",
      "Grid point 8 acquired.\n",
      "Grid point 9 acquired.\n",
      "New hparams: [-2.1170445]\n",
      "Additional acquisition 10.\n",
      "New hparams: [-2.2990037]\n",
      "Additional acquisition 11.\n",
      "New hparams: [-2.2856463]\n",
      "Best score achieved: 130393.122\n",
      "Best hyperparams: [-1.0931465 -2.2856463]\n",
      "Best estimated negative marginal log likelihood: 130393.122\n",
      "Wallclock: 31.07062029838562\n"
     ]
    }
   ],
   "source": [
    "aav_model = xGPReg(num_rffs = 1024, variance_rffs = 512,\n",
    "                  kernel_choice = \"FHTConv1d\",\n",
    "                   kernel_settings = {\"conv_width\":9, \"averaging\":False},\n",
    "                   verbose = True, device = \"gpu\")\n",
    "\n",
    "start_time = time.time()\n",
    "hparams, niter, best_score = aav_model.tune_hyperparams_crude(training_dset)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Best estimated negative marginal log likelihood: {best_score}\")\n",
    "print(f\"Wallclock: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9974ca79-ec65-44ca-a897-6288d7bed2a7",
   "metadata": {},
   "source": [
    "We now have a rough estimate of our hyperparameters, acquired using a sketchy kernel approximation\n",
    "(num_rffs=1024) and a crude tuning procedure. Let's fine-tune this a little. We could use\n",
    "the built-in tuning routine in xGPR the way we did for the tabular data, or we could use\n",
    "Optuna (or some other library), or we could do a simple gridsearch. For illustrative\n",
    "purposes here, we'll use Optuna using num_rffs=4,096 (a somewhat better kernel\n",
    "approximation) and see what that looks like. We'll search the region around the\n",
    "hyperparameters obtained from ``tune_hyperparams_crude``. To run this\n",
    "next piece, you'll need to have Optuna installed. Optuna is one of our\n",
    "favorite approaches and is often able to do a little better than other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d6ec16a-6e18-4b46-923f-a357fb745d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "def objective(trial):\n",
    "    lambda_ = trial.suggest_float(\"lambda_\", -2., 0.)\n",
    "    sigma = trial.suggest_float(\"sigma\", -3., -1.)\n",
    "    hparams = np.array([lambda_, sigma])\n",
    "    nmll = aav_model.exact_nmll(hparams, training_dset)\n",
    "    return nmll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aef1d565-62f2-438e-9e47-be6a396a9b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:45:09,310] A new study created in memory with name: no-name-e07ce6e5-f71f-4c9e-b987-5f01481589c9\n",
      "[I 2023-11-28 09:45:26,211] Trial 0 finished with value: 116884.97261995246 and parameters: {'lambda_': -0.6070616288042767, 'sigma': -2.4277213300992413}. Best is trial 0 with value: 116884.97261995246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:45:43,088] Trial 1 finished with value: 114181.22032483175 and parameters: {'lambda_': -1.5462970928715938, 'sigma': -1.8973704618342175}. Best is trial 1 with value: 114181.22032483175.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:45:59,962] Trial 2 finished with value: 113271.88301457987 and parameters: {'lambda_': -0.5610620604288739, 'sigma': -2.153787079751078}. Best is trial 2 with value: 113271.88301457987.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:46:16,900] Trial 3 finished with value: 112182.98616781154 and parameters: {'lambda_': -0.038471603230769036, 'sigma': -1.6303405228302734}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:46:33,838] Trial 4 finished with value: 112451.94625265888 and parameters: {'lambda_': -1.0381361970312781, 'sigma': -2.215764963611699}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:46:50,780] Trial 5 finished with value: 116679.78219362846 and parameters: {'lambda_': -1.3136439676982612, 'sigma': -1.5419005852319168}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:47:07,721] Trial 6 finished with value: 120520.54953081356 and parameters: {'lambda_': -1.1228555106407512, 'sigma': -2.8806442067808633}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:47:24,666] Trial 7 finished with value: 116443.92207441722 and parameters: {'lambda_': -1.2039114893391372, 'sigma': -1.5240091885359286}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:47:41,605] Trial 8 finished with value: 114600.58825822489 and parameters: {'lambda_': -1.635016539093, 'sigma': -2.649096487705015}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:47:58,542] Trial 9 finished with value: 112309.72714681382 and parameters: {'lambda_': -0.9368972523163233, 'sigma': -1.9363448258062679}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:48:15,484] Trial 10 finished with value: 118087.34232658173 and parameters: {'lambda_': -0.03129046371014721, 'sigma': -1.0097302786311597}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:48:32,427] Trial 11 finished with value: 112422.48824147781 and parameters: {'lambda_': -0.01866037953665966, 'sigma': -1.8420837673609056}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:48:49,370] Trial 12 finished with value: 117675.56910373297 and parameters: {'lambda_': -1.86792286212751, 'sigma': -1.6554794205210857}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:49:06,316] Trial 13 finished with value: 116479.30082963311 and parameters: {'lambda_': -0.6682392377917878, 'sigma': -1.334284575460567}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:49:23,258] Trial 14 finished with value: 112972.71033390879 and parameters: {'lambda_': -0.3272278654086118, 'sigma': -2.0359901306985515}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:49:40,203] Trial 15 finished with value: 112217.96159582998 and parameters: {'lambda_': -0.8172325331915455, 'sigma': -1.9106811994190158}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:49:57,157] Trial 16 finished with value: 117274.06183211948 and parameters: {'lambda_': -0.2603175001600282, 'sigma': -2.3111339546818375}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:50:14,100] Trial 17 finished with value: 112619.09588957127 and parameters: {'lambda_': -0.8180620085440145, 'sigma': -1.8200765777075854}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:50:31,043] Trial 18 finished with value: 116250.46632943655 and parameters: {'lambda_': -0.32229338117455153, 'sigma': -1.2419508741475265}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:50:47,986] Trial 19 finished with value: 114084.89684029567 and parameters: {'lambda_': -0.8671099982598062, 'sigma': -1.6394201895068492}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:51:04,927] Trial 20 finished with value: 113199.17909443154 and parameters: {'lambda_': -0.532872551556751, 'sigma': -2.136297897825651}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:51:21,869] Trial 21 finished with value: 112390.44567547613 and parameters: {'lambda_': -0.9186721161131867, 'sigma': -1.9082246988035152}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:51:38,814] Trial 22 finished with value: 113226.48339402488 and parameters: {'lambda_': -0.8068172896190198, 'sigma': -1.7220230284031095}. Best is trial 3 with value: 112182.98616781154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:51:55,757] Trial 23 finished with value: 112114.72530880311 and parameters: {'lambda_': -1.0103391936363806, 'sigma': -2.0911671517463963}. Best is trial 23 with value: 112114.72530880311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:52:12,696] Trial 24 finished with value: 112280.49477969573 and parameters: {'lambda_': -1.2392140586015046, 'sigma': -2.087070595587511}. Best is trial 23 with value: 112114.72530880311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:52:29,638] Trial 25 finished with value: 114474.11009340384 and parameters: {'lambda_': -1.0468149298796818, 'sigma': -2.4317724702573495}. Best is trial 23 with value: 112114.72530880311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:52:46,581] Trial 26 finished with value: 112187.96857642675 and parameters: {'lambda_': -0.7052050499628298, 'sigma': -2.049740057759603}. Best is trial 23 with value: 112114.72530880311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:53:03,525] Trial 27 finished with value: 112561.07469358988 and parameters: {'lambda_': -0.4200102911513557, 'sigma': -2.020155365111411}. Best is trial 23 with value: 112114.72530880311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:53:20,467] Trial 28 finished with value: 112025.64316648839 and parameters: {'lambda_': -0.15817474787806624, 'sigma': -1.7725920521360994}. Best is trial 28 with value: 112025.64316648839.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:53:37,410] Trial 29 finished with value: 112043.3765583417 and parameters: {'lambda_': -0.15429868271440328, 'sigma': -1.7910748578352933}. Best is trial 28 with value: 112025.64316648839.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:53:54,354] Trial 30 finished with value: 117769.18858275587 and parameters: {'lambda_': -0.19240335145379095, 'sigma': -2.3114322360951163}. Best is trial 28 with value: 112025.64316648839.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:54:11,296] Trial 31 finished with value: 112027.72722358054 and parameters: {'lambda_': -0.15545204796200673, 'sigma': -1.774862465080108}. Best is trial 28 with value: 112025.64316648839.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:54:28,241] Trial 32 finished with value: 112031.75142268102 and parameters: {'lambda_': -0.14590070421398404, 'sigma': -1.7753784396393886}. Best is trial 28 with value: 112025.64316648839.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:54:45,188] Trial 33 finished with value: 112163.16659169078 and parameters: {'lambda_': -0.457054472835695, 'sigma': -1.7798674390851137}. Best is trial 28 with value: 112025.64316648839.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 09:55:02,137] Trial 34 finished with value: 112021.80990490183 and parameters: {'lambda_': -0.17193176584567704, 'sigma': -1.7713977474762077}. Best is trial 34 with value: 112021.80990490183.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    }
   ],
   "source": [
    "aav_model.num_rffs = 4096\n",
    "\n",
    "sampler = TPESampler(seed=123)\n",
    "study = optuna.create_study(sampler=sampler)\n",
    "study.optimize(objective, n_trials=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f479d2-eea9-4e0d-bde6-9a01b9d499b9",
   "metadata": {},
   "source": [
    "Set the model hyperparameters to the best ones found by Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec8b4763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda_': -0.17193176584567704, 'sigma': -1.7713977474762077}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f55ef42-abec-408a-8750-30e4a1ef40b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aav_model.set_hyperparams(np.array([-0.17193176, -1.771397]), training_dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47e4f4e",
   "metadata": {},
   "source": [
    "Now we'll fit the model using 8192 RFFs. We like to use a more accurate kernel approximationwhen fitting than when tuning for two reasons. First, tuning is more expensive because the model has to be fit multiple times when tuning hyperparameters. Second, model performance usually\n",
    "increases faster by increasing the number of rffs used for fitting than for tuning. (Using 16,384 RFFs here for fitting further\n",
    "increases test set performance as you'd expect.)\n",
    "\n",
    "On gpu, for fitting, ``mode=exact`` works well up to 8,192 RFFs or so, while ``mode=cg`` although\n",
    "slower for small numbers of RFFs is more scalable. On this dataset, using 8,192 RFFs, \"exact\" takes about 70 seconds on our GPU.\n",
    "We'll use cg here just for illustrative purposes. Notice that using fitting with default settings takes about 45 iterations with\n",
    "CG. We can speed this up by changing the defaults (see the Advanced Tutorials for more on how to do this).\n",
    "\n",
    "``tol`` determines how tight the fit is. 1e-6 (default) is usually fine. Decreasing the number will improve performance but\n",
    "with rapidly diminishing returns and make fitting take longer. For noise free data or to get a small additional boost in\n",
    "performance, use 1e-7. 1e-8 is (nearly always) overkill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa173a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fitting\n",
      "Chunk 0 complete.\n",
      "Chunk 10 complete.\n",
      "Chunk 20 complete.\n",
      "Chunk 30 complete.\n",
      "Chunk 40 complete.\n",
      "Chunk 50 complete.\n",
      "Chunk 60 complete.\n",
      "Chunk 70 complete.\n",
      "Chunk 80 complete.\n",
      "Chunk 90 complete.\n",
      "Chunk 0 complete.\n",
      "Chunk 10 complete.\n",
      "Chunk 20 complete.\n",
      "Chunk 30 complete.\n",
      "Chunk 40 complete.\n",
      "Chunk 50 complete.\n",
      "Chunk 60 complete.\n",
      "Chunk 70 complete.\n",
      "Chunk 80 complete.\n",
      "Chunk 90 complete.\n",
      "Using rank: 1024\n",
      "Chunk 0 complete.\n",
      "Chunk 10 complete.\n",
      "Chunk 20 complete.\n",
      "Chunk 30 complete.\n",
      "Chunk 40 complete.\n",
      "Chunk 50 complete.\n",
      "Chunk 60 complete.\n",
      "Chunk 70 complete.\n",
      "Chunk 80 complete.\n",
      "Chunk 90 complete.\n",
      "Iteration 0\n",
      "Iteration 5\n",
      "Iteration 10\n",
      "Iteration 15\n",
      "Iteration 20\n",
      "Iteration 25\n",
      "Iteration 30\n",
      "Iteration 35\n",
      "Iteration 40\n",
      "Iteration 45\n",
      "Now performing variance calculations...\n",
      "Fitting complete.\n",
      "Wallclock: 419.55269742012024\n"
     ]
    }
   ],
   "source": [
    "aav_model.num_rffs = 8192\n",
    "start_time = time.time()\n",
    "aav_model.fit(training_dset, mode = 'cg', tol = 1e-6)\n",
    "end_time = time.time()\n",
    "print(f\"Wallclock: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af17b1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wallclock: 3.5997021198272705\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "all_preds, ground_truth = [], []\n",
    "for xfile, yfile in zip(test_x_files, test_y_files):\n",
    "    x, y = np.load(xfile), np.load(yfile)\n",
    "    ground_truth.append(y)\n",
    "    preds = aav_model.predict(x, get_var = False)\n",
    "    all_preds.append(preds)\n",
    "    \n",
    "all_preds, ground_truth = np.concatenate(all_preds), np.concatenate(ground_truth)\n",
    "end_time = time.time()\n",
    "print(f\"Wallclock: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca63c6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=0.7548986561289404, pvalue=0.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "spearmanr(all_preds, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e3d321",
   "metadata": {},
   "source": [
    "Spearman's r of 0.75 plus matches the performance for a 1d-CNN reported by Dallago et al\n",
    "for this dataset and is similar to the performance of a fine-tuned LLM (Spearman's r 0.79).\n",
    "As discussed above, we can get further slight improvements in performance\n",
    "just by tweaking this model. We can do even better by using a more informative\n",
    "representation of the protein sequences. In our original paper we achieved a Spearman's r\n",
    "of about 0.8 on this dataset, outperforming fine-tuned LLMs (and costing significantly less to train\n",
    "than a fine-tuned LLM).\n",
    "Whether small gains in performance from further \"tweaking\" or more informative representations is worthwhile\n",
    "obviously depends on your application..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1897a0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02dd194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for testx, testy in zip(test_x_files, test_y_files):\n",
    "    os.remove(testx)\n",
    "    os.remove(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b857b33e-a21e-45c3-9394-fdb50806ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xfile, yfile in zip(train_x_files, train_y_files):\n",
    "    os.remove(xfile)\n",
    "    os.remove(yfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
