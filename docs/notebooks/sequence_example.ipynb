{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41f0fa12",
   "metadata": {},
   "source": [
    "## Example: Sequence Data\n",
    "\n",
    "Next, let's consider the AAV dataset, designed vs mutant split, \n",
    "from the FLIP benchmark suite. For this dataset, we train on 200,000\n",
    "length 57 amino acid sequences and try to predict the fitness\n",
    "of a pre-specified test set. Dallago et al. report that a standard\n",
    "1d-CNN trained on this achieves a Spearman's r of 0.75, while\n",
    "a 750-million parameter pretrained model that took 50 GPU-days of\n",
    "time to train achieves Spearman's r of 0.71.\n",
    "\n",
    "We'll evaluate a convolution kernel and show that we can easily\n",
    "match or outperform the deep learning baselines without too\n",
    "much effort.\n",
    "\n",
    "This was originally run on an GTX1070 GPU with 8 GB of RAM, using xGPR 0.1.3.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9a773dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import math\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xGPR import xGPRegression as xGPReg\n",
    "from xGPR import build_offline_sequence_dataset\n",
    "from xGPR.static_layers import FastConv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42875b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'FLIP'...\n",
      "Checking out files: 100% (59/59), done.\n"
     ]
    }
   ],
   "source": [
    "#This may take a minute...\n",
    "subprocess.run([\"git\", \"clone\", \"https://github.com/J-SNACKKB/FLIP\"])\n",
    "\n",
    "shutil.move(os.path.join(\"FLIP\", \"splits\", \"aav\", \"full_data.csv.zip\"), \"full_data.csv.zip\")\n",
    "fname = \"full_data.csv.zip\"\n",
    "\n",
    "with zipfile.ZipFile(fname, \"r\") as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "\n",
    "os.remove(\"full_data.csv.zip\")\n",
    "\n",
    "\n",
    "shutil.rmtree(\"FLIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e5dc401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20174/4195622896.py:1: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = pd.read_csv(\"full_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"full_data.csv\")\n",
    "os.remove(\"full_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80ee02b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[\"input_seq\"] = [f.upper().replace(\"*\", \"\") for f in raw_data[\"mutated_region\"].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fef6ad7",
   "metadata": {},
   "source": [
    "We'll use simple one-hot encoding for the sequences. This may take a minute to set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98745fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(input_seq_list, y_values, chunk_size, ftype = \"train\"):\n",
    "    aas = [\"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\",\n",
    "               \"K\", \"L\", \"M\", \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\",\n",
    "               \"V\", \"W\", \"Y\", \"-\"]\n",
    "    output_x, output_y = [], []\n",
    "    xfiles, yfiles = [], []\n",
    "    fcounter = 0\n",
    "    \n",
    "    for seq, y_value in zip(input_seq_list, y_values):\n",
    "        encoded_x = np.zeros((1,57,21), dtype = np.uint8)\n",
    "        for i, letter in enumerate(seq):\n",
    "            encoded_x[0, i, aas.index(letter)] = 1\n",
    "\n",
    "        output_x.append(encoded_x)\n",
    "        output_y.append(y_value)\n",
    "\n",
    "        if len(output_x) >= chunk_size:\n",
    "            xfiles.append(f\"{fcounter}_{ftype}_xblock.npy\")\n",
    "            yfiles.append(f\"{fcounter}_{ftype}_yblock.npy\")\n",
    "            np.save(xfiles[-1], np.vstack(output_x))\n",
    "            np.save(yfiles[-1], np.asarray(output_y))\n",
    "            fcounter += 1\n",
    "            output_x, output_y = [], []\n",
    "            print(f\"Encoded file {fcounter}\")\n",
    "    return xfiles, yfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18d97977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded file 1\n",
      "Encoded file 2\n",
      "Encoded file 3\n",
      "Encoded file 4\n",
      "Encoded file 5\n",
      "Encoded file 6\n",
      "Encoded file 7\n",
      "Encoded file 8\n",
      "Encoded file 9\n",
      "Encoded file 10\n",
      "Encoded file 11\n",
      "Encoded file 12\n",
      "Encoded file 13\n",
      "Encoded file 14\n",
      "Encoded file 15\n",
      "Encoded file 16\n",
      "Encoded file 17\n",
      "Encoded file 18\n",
      "Encoded file 19\n",
      "Encoded file 20\n",
      "Encoded file 21\n",
      "Encoded file 22\n",
      "Encoded file 23\n",
      "Encoded file 24\n",
      "Encoded file 25\n",
      "Encoded file 26\n",
      "Encoded file 27\n",
      "Encoded file 28\n",
      "Encoded file 29\n",
      "Encoded file 30\n",
      "Encoded file 31\n",
      "Encoded file 32\n",
      "Encoded file 33\n",
      "Encoded file 34\n",
      "Encoded file 35\n",
      "Encoded file 36\n",
      "Encoded file 37\n",
      "Encoded file 38\n",
      "Encoded file 39\n",
      "Encoded file 40\n",
      "Encoded file 41\n",
      "Encoded file 42\n",
      "Encoded file 43\n",
      "Encoded file 44\n",
      "Encoded file 45\n",
      "Encoded file 46\n",
      "Encoded file 47\n",
      "Encoded file 48\n",
      "Encoded file 49\n",
      "Encoded file 50\n",
      "Encoded file 51\n",
      "Encoded file 52\n",
      "Encoded file 53\n",
      "Encoded file 54\n",
      "Encoded file 55\n",
      "Encoded file 56\n",
      "Encoded file 57\n",
      "Encoded file 58\n",
      "Encoded file 59\n",
      "Encoded file 60\n",
      "Encoded file 61\n",
      "Encoded file 62\n",
      "Encoded file 63\n",
      "Encoded file 64\n",
      "Encoded file 65\n",
      "Encoded file 66\n",
      "Encoded file 67\n",
      "Encoded file 68\n",
      "Encoded file 69\n",
      "Encoded file 70\n",
      "Encoded file 71\n",
      "Encoded file 72\n",
      "Encoded file 73\n",
      "Encoded file 74\n",
      "Encoded file 75\n",
      "Encoded file 76\n",
      "Encoded file 77\n",
      "Encoded file 78\n",
      "Encoded file 79\n",
      "Encoded file 80\n",
      "Encoded file 81\n",
      "Encoded file 82\n",
      "Encoded file 83\n",
      "Encoded file 84\n",
      "Encoded file 85\n",
      "Encoded file 86\n",
      "Encoded file 87\n",
      "Encoded file 88\n",
      "Encoded file 89\n",
      "Encoded file 90\n",
      "Encoded file 91\n",
      "Encoded file 92\n",
      "Encoded file 93\n",
      "Encoded file 94\n",
      "Encoded file 95\n",
      "Encoded file 96\n",
      "Encoded file 97\n",
      "Encoded file 98\n",
      "Encoded file 99\n",
      "Encoded file 100\n",
      "Encoded file 1\n",
      "Encoded file 2\n",
      "Encoded file 3\n",
      "Encoded file 4\n",
      "Encoded file 5\n",
      "Encoded file 6\n",
      "Encoded file 7\n",
      "Encoded file 8\n",
      "Encoded file 9\n",
      "Encoded file 10\n",
      "Encoded file 11\n",
      "Encoded file 12\n",
      "Encoded file 13\n",
      "Encoded file 14\n",
      "Encoded file 15\n",
      "Encoded file 16\n",
      "Encoded file 17\n",
      "Encoded file 18\n",
      "Encoded file 19\n",
      "Encoded file 20\n",
      "Encoded file 21\n",
      "Encoded file 22\n",
      "Encoded file 23\n",
      "Encoded file 24\n",
      "Encoded file 25\n",
      "Encoded file 26\n",
      "Encoded file 27\n",
      "Encoded file 28\n",
      "Encoded file 29\n",
      "Encoded file 30\n",
      "Encoded file 31\n",
      "Encoded file 32\n",
      "Encoded file 33\n",
      "Encoded file 34\n",
      "Encoded file 35\n",
      "Encoded file 36\n",
      "Encoded file 37\n",
      "Encoded file 38\n",
      "Encoded file 39\n",
      "Encoded file 40\n",
      "Encoded file 41\n"
     ]
    }
   ],
   "source": [
    "train_data = raw_data[raw_data[\"des_mut_split\"]==\"train\"]\n",
    "test_data = raw_data[raw_data[\"des_mut_split\"]==\"test\"]\n",
    "\n",
    "\n",
    "train_x_files, train_y_files = one_hot_encode(train_data[\"input_seq\"].tolist(),\n",
    "                                              train_data[\"score\"].tolist(), 2000, \"train\")\n",
    "test_x_files, test_y_files = one_hot_encode(test_data[\"input_seq\"].tolist(),\n",
    "                                            test_data[\"score\"].tolist(), 2000, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99584178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notice that unlike for tabular data, we build an offline sequence dataset (not fixed vector).\n",
    "#This dataset might be too large to load into memory, so we'll build an offline dataset only.\n",
    "training_dset = build_offline_sequence_dataset(train_x_files, train_y_files, chunk_size = 2000,\n",
    "                                              skip_safety_checks = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b89e96",
   "metadata": {},
   "source": [
    "Here we'll evaluate FHTConv1d. Convolution kernels are usually slower than RBF / Matern, especially if the sequence is long. We'll tune using 3000 random features, which is closer to the upper end of what you want to use for\n",
    "tuning with the ``crude_bayes`` function; in general, if you want to tune using a larger number of random features,\n",
    "it's better to find a good starting point with a smaller number of RFFs, then use\n",
    "``my_model.tune_hyperparams_fine_direct`` or ``my_model.tune_hyperparams_fine_bayes`` as illustrated in the tabular data example to \"fine-tune\" that result with a larger number of RFFs. Finally, we could alternatively use ``crude_grid`` (illustrated in the small molecule tutorial) or ``crude_lbfgs`` instead.\n",
    "\n",
    "Note that we specify a kernel specific option in the kernel_specific_params dict -- the width of the convolution to use. Just as with a convolutional network, the width of the convolution filters can affect performance. One way to\n",
    "choose a good setting: see what marginal likelihood score you get from hyperparameter tuning (e.g. with ``crude_bayes`` or ``crude_grid``) using a small number of RFFs (e.g. 1024 - 2048) for several different settings of \"conv_width\". The smallest score achieved likely corresponds to the best value for \"conv_width\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c451d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting_tuning\n",
      "Grid point 0 acquired.\n",
      "Grid point 1 acquired.\n",
      "Grid point 2 acquired.\n",
      "Grid point 3 acquired.\n",
      "Grid point 4 acquired.\n",
      "Grid point 5 acquired.\n",
      "Grid point 6 acquired.\n",
      "Grid point 7 acquired.\n",
      "Grid point 8 acquired.\n",
      "Grid point 9 acquired.\n",
      "New hparams: [-0.8298276]\n",
      "Additional acquisition 10.\n",
      "New hparams: [-0.838633]\n",
      "Additional acquisition 11.\n",
      "New hparams: [-0.8383481]\n",
      "Additional acquisition 12.\n",
      "New hparams: [-0.8468422]\n",
      "Additional acquisition 13.\n",
      "New hparams: [-0.8321154]\n",
      "Additional acquisition 14.\n",
      "New hparams: [-0.8445669]\n",
      "Additional acquisition 15.\n",
      "New hparams: [-0.8072598]\n",
      "Best score achieved: 121310.218\n",
      "Best hyperparams: [-0.852417  -1.6094379 -0.8298276]\n",
      "Tuning complete.\n",
      "Best estimated negative marginal log likelihood: 121310.218\n",
      "Wallclock: 667.0209712982178\n"
     ]
    }
   ],
   "source": [
    "aav_model = xGPReg(training_rffs = 3000, fitting_rffs = 8192, variance_rffs = 1024,\n",
    "                  kernel_choice = \"FHTConv1d\",\n",
    "                   kernel_specific_params = {\"conv_width\":9},\n",
    "                   verbose = True, device = \"gpu\")\n",
    "\n",
    "start_time = time.time()\n",
    "hparams, niter, best_score, scores = aav_model.tune_hyperparams_crude_bayes(training_dset,\n",
    "                                                                              max_bayes_iter = 30)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Best estimated negative marginal log likelihood: {best_score}\")\n",
    "print(f\"Wallclock: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8b4763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d47e4f4e",
   "metadata": {},
   "source": [
    "Now we'll build a preconditioner and fit. In this case, since the\n",
    "dataset is small and we're not using too many random features,\n",
    "we're unlikely to have a disk space issue if we pre-generate\n",
    "the random features, and for convolution kernels, especially on long sequences / graphs,\n",
    "this is usually faster vs generating them on the fly (whereas for Matern / RBF / poly, generating\n",
    "on the fly on GPU is faster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa173a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now pretransforming data.\n"
     ]
    }
   ],
   "source": [
    "pretransformed_data = aav_model.pretransform_data(training_dset, os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c0c8a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 complete.\n",
      "Chunk 10 complete.\n",
      "Chunk 20 complete.\n",
      "Chunk 30 complete.\n",
      "Chunk 40 complete.\n",
      "Chunk 50 complete.\n",
      "Chunk 60 complete.\n",
      "Chunk 70 complete.\n",
      "Chunk 80 complete.\n",
      "Chunk 90 complete.\n",
      "Chunk 0 complete.\n",
      "Chunk 10 complete.\n",
      "Chunk 20 complete.\n",
      "Chunk 30 complete.\n",
      "Chunk 40 complete.\n",
      "Chunk 50 complete.\n",
      "Chunk 60 complete.\n",
      "Chunk 70 complete.\n",
      "Chunk 80 complete.\n",
      "Chunk 90 complete.\n",
      "Wallclock: 51.56280732154846\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "preconditioner, ratio = aav_model.build_preconditioner(pretransformed_data, max_rank = 1024,\n",
    "                                                      method = \"srht_2\")\n",
    "end_time = time.time()\n",
    "print(f\"Wallclock: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d198345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fitting\n",
      "Iteration 0\n",
      "Iteration 5\n",
      "Iteration 10\n",
      "Iteration 15\n",
      "Iteration 20\n",
      "Iteration 25\n",
      "Iteration 30\n",
      "Now performing variance calculations...\n",
      "Fitting complete.\n",
      "Wallclock: 65.16638588905334\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "aav_model.fit(pretransformed_data, preconditioner = preconditioner, mode = 'cg',\n",
    "             max_iter = 500)\n",
    "end_time = time.time()\n",
    "print(f\"Wallclock: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af17b1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wallclock: 9.972362279891968\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "all_preds, ground_truth = [], []\n",
    "for xfile, yfile in zip(test_x_files, test_y_files):\n",
    "    x, y = np.load(xfile), np.load(yfile)\n",
    "    ground_truth.append(y)\n",
    "    preds = aav_model.predict(x, get_var = False)\n",
    "    all_preds.append(preds)\n",
    "    \n",
    "all_preds, ground_truth = np.concatenate(all_preds), np.concatenate(ground_truth)\n",
    "end_time = time.time()\n",
    "print(f\"Wallclock: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca63c6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.7664973351782205, pvalue=0.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "spearmanr(all_preds, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e3d321",
   "metadata": {},
   "source": [
    "Notice we're already at 0.766, outperforming a CNN for sequences also trained\n",
    "on one-hot encoded input. It is of course possible\n",
    "to use another representation (e.g. the output of a language model)\n",
    "as the input to a GP. We discuss some other\n",
    "possible representations and show that for some tasks using a language\n",
    "model embedding can improve results (for this dataset, to Spearman's r\n",
    "of about 0.8, which is SOTA as of July 2023)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1897a0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19aba2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dset.delete_dataset_files()\n",
    "pretransformed_data.delete_dataset_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02dd194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for testx, testy in zip(test_x_files, test_y_files):\n",
    "    os.remove(testx)\n",
    "    os.remove(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313b76c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
