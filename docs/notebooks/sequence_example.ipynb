{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41f0fa12",
   "metadata": {},
   "source": [
    "## Example: Sequence Data\n",
    "\n",
    "Next, let's consider the AAV dataset, designed vs mutant split, \n",
    "from the FLIP benchmark suite. For this dataset, we train on 200,000\n",
    "length 57 amino acid sequences and try to predict the fitness\n",
    "of a pre-specified test set. Dallago et al. report that a standard\n",
    "1d-CNN trained on this achieves a Spearman's r of 0.75, while\n",
    "a 750-million parameter pretrained model that took 50 GPU-days of\n",
    "time to train achieves Spearman's r of 0.79.\n",
    "\n",
    "We'll evaluate a convolution kernel and show that we can easily\n",
    "match or outperform the deep learning baselines without too\n",
    "much effort.\n",
    "\n",
    "This was originally run using xGPR v0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9a773dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd1/Documents/gp_proteins/venv_testing/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import math\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xGPR import xGPRegression as xGPReg\n",
    "from xGPR import build_regression_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42875b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'FLIP'...\n"
     ]
    }
   ],
   "source": [
    "#This may take a minute...\n",
    "subprocess.run([\"git\", \"clone\", \"https://github.com/J-SNACKKB/FLIP\"])\n",
    "\n",
    "shutil.move(os.path.join(\"FLIP\", \"splits\", \"aav\", \"full_data.csv.zip\"), \"full_data.csv.zip\")\n",
    "fname = \"full_data.csv.zip\"\n",
    "\n",
    "with zipfile.ZipFile(fname, \"r\") as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "\n",
    "os.remove(\"full_data.csv.zip\")\n",
    "\n",
    "\n",
    "shutil.rmtree(\"FLIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e5dc401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43070/4195622896.py:1: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = pd.read_csv(\"full_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"full_data.csv\")\n",
    "os.remove(\"full_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80ee02b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[\"input_seq\"] = [f.upper().replace(\"*\", \"\") for f in raw_data[\"mutated_region\"].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fef6ad7",
   "metadata": {},
   "source": [
    "We'll use simple one-hot encoding for the sequences. This may take a minute to set up. Notice that when\n",
    "encoding the sequences we record the length of each sequence so that the zero-padding we've added\n",
    "to the end of the sequence can be masked-out when fitting the model. This is new in xGPR 0.3. If you\n",
    "want the zero-padding included for some reason, you can just set all sequence lengths to be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98745fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(input_seq_list, y_values, chunk_size, ftype = \"train\"):\n",
    "    aas = [\"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\",\n",
    "               \"K\", \"L\", \"M\", \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\",\n",
    "               \"V\", \"W\", \"Y\", \"-\"]\n",
    "    output_x, output_y, output_seqlen = [], [], []\n",
    "    xfiles, yfiles, seqlen_files = [], [], []\n",
    "    fcounter = 0\n",
    "    \n",
    "    for seq, y_value in zip(input_seq_list, y_values):\n",
    "        encoded_x = np.zeros((1,57,21), dtype = np.uint8)\n",
    "        for i, letter in enumerate(seq):\n",
    "            encoded_x[0, i, aas.index(letter)] = 1\n",
    "\n",
    "        output_x.append(encoded_x)\n",
    "        output_y.append(y_value)\n",
    "        output_seqlen.append(len(seq))\n",
    "\n",
    "        if len(output_x) >= chunk_size:\n",
    "            xfiles.append(f\"{fcounter}_{ftype}_xblock.npy\")\n",
    "            yfiles.append(f\"{fcounter}_{ftype}_yblock.npy\")\n",
    "            seqlen_files.append(f\"{fcounter}_{ftype}_seqlen.npy\")\n",
    "            np.save(xfiles[-1], np.vstack(output_x))\n",
    "            np.save(yfiles[-1], np.asarray(output_y))\n",
    "            np.save(seqlen_files[-1], np.array(output_seqlen).astype(np.int32))\n",
    "            fcounter += 1\n",
    "            output_x, output_y, output_seqlen = [], [], []\n",
    "            print(f\"Encoded file {fcounter}\")\n",
    "    return xfiles, yfiles, seqlen_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18d97977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded file 1\n",
      "Encoded file 2\n",
      "Encoded file 3\n",
      "Encoded file 4\n",
      "Encoded file 5\n",
      "Encoded file 6\n",
      "Encoded file 7\n",
      "Encoded file 8\n",
      "Encoded file 9\n",
      "Encoded file 10\n",
      "Encoded file 11\n",
      "Encoded file 12\n",
      "Encoded file 13\n",
      "Encoded file 14\n",
      "Encoded file 15\n",
      "Encoded file 16\n",
      "Encoded file 17\n",
      "Encoded file 18\n",
      "Encoded file 19\n",
      "Encoded file 20\n",
      "Encoded file 21\n",
      "Encoded file 22\n",
      "Encoded file 23\n",
      "Encoded file 24\n",
      "Encoded file 25\n",
      "Encoded file 26\n",
      "Encoded file 27\n",
      "Encoded file 28\n",
      "Encoded file 29\n",
      "Encoded file 30\n",
      "Encoded file 31\n",
      "Encoded file 32\n",
      "Encoded file 33\n",
      "Encoded file 34\n",
      "Encoded file 35\n",
      "Encoded file 36\n",
      "Encoded file 37\n",
      "Encoded file 38\n",
      "Encoded file 39\n",
      "Encoded file 40\n",
      "Encoded file 41\n",
      "Encoded file 42\n",
      "Encoded file 43\n",
      "Encoded file 44\n",
      "Encoded file 45\n",
      "Encoded file 46\n",
      "Encoded file 47\n",
      "Encoded file 48\n",
      "Encoded file 49\n",
      "Encoded file 50\n",
      "Encoded file 51\n",
      "Encoded file 52\n",
      "Encoded file 53\n",
      "Encoded file 54\n",
      "Encoded file 55\n",
      "Encoded file 56\n",
      "Encoded file 57\n",
      "Encoded file 58\n",
      "Encoded file 59\n",
      "Encoded file 60\n",
      "Encoded file 61\n",
      "Encoded file 62\n",
      "Encoded file 63\n",
      "Encoded file 64\n",
      "Encoded file 65\n",
      "Encoded file 66\n",
      "Encoded file 67\n",
      "Encoded file 68\n",
      "Encoded file 69\n",
      "Encoded file 70\n",
      "Encoded file 71\n",
      "Encoded file 72\n",
      "Encoded file 73\n",
      "Encoded file 74\n",
      "Encoded file 75\n",
      "Encoded file 76\n",
      "Encoded file 77\n",
      "Encoded file 78\n",
      "Encoded file 79\n",
      "Encoded file 80\n",
      "Encoded file 81\n",
      "Encoded file 82\n",
      "Encoded file 83\n",
      "Encoded file 84\n",
      "Encoded file 85\n",
      "Encoded file 86\n",
      "Encoded file 87\n",
      "Encoded file 88\n",
      "Encoded file 89\n",
      "Encoded file 90\n",
      "Encoded file 91\n",
      "Encoded file 92\n",
      "Encoded file 93\n",
      "Encoded file 94\n",
      "Encoded file 95\n",
      "Encoded file 96\n",
      "Encoded file 97\n",
      "Encoded file 98\n",
      "Encoded file 99\n",
      "Encoded file 100\n",
      "Encoded file 1\n",
      "Encoded file 2\n",
      "Encoded file 3\n",
      "Encoded file 4\n",
      "Encoded file 5\n",
      "Encoded file 6\n",
      "Encoded file 7\n",
      "Encoded file 8\n",
      "Encoded file 9\n",
      "Encoded file 10\n",
      "Encoded file 11\n",
      "Encoded file 12\n",
      "Encoded file 13\n",
      "Encoded file 14\n",
      "Encoded file 15\n",
      "Encoded file 16\n",
      "Encoded file 17\n",
      "Encoded file 18\n",
      "Encoded file 19\n",
      "Encoded file 20\n",
      "Encoded file 21\n",
      "Encoded file 22\n",
      "Encoded file 23\n",
      "Encoded file 24\n",
      "Encoded file 25\n",
      "Encoded file 26\n",
      "Encoded file 27\n",
      "Encoded file 28\n",
      "Encoded file 29\n",
      "Encoded file 30\n",
      "Encoded file 31\n",
      "Encoded file 32\n",
      "Encoded file 33\n",
      "Encoded file 34\n",
      "Encoded file 35\n",
      "Encoded file 36\n",
      "Encoded file 37\n",
      "Encoded file 38\n",
      "Encoded file 39\n",
      "Encoded file 40\n",
      "Encoded file 41\n"
     ]
    }
   ],
   "source": [
    "train_data = raw_data[raw_data[\"des_mut_split\"]==\"train\"]\n",
    "test_data = raw_data[raw_data[\"des_mut_split\"]==\"test\"]\n",
    "\n",
    "\n",
    "train_x_files, train_y_files, train_seqlen_files = one_hot_encode(train_data[\"input_seq\"].tolist(),\n",
    "                                              train_data[\"score\"].tolist(), 2000, \"train\")\n",
    "test_x_files, test_y_files, test_seqlen_files = one_hot_encode(test_data[\"input_seq\"].tolist(),\n",
    "                                            test_data[\"score\"].tolist(), 2000, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b24d58-245d-454e-973b-b3ef81f4e740",
   "metadata": {},
   "source": [
    "Notice that we pass the list of seqlen_files into the dataset builder. This is required if working with\n",
    "3d arrays / convolution kernels. If you are working with 2d arrays / fixed-length vector kernels,\n",
    "the default for the third argument (```None```) is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99584178",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dset = build_regression_dataset(train_x_files, train_y_files, train_seqlen_files, chunk_size = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b89e96",
   "metadata": {},
   "source": [
    "Here we'll use the Conv1dRBF kernel, a kernel for sequences. Convolution kernels are usually slower than RBF / Matern, especially if the sequence is long. We'll run a quick and dirty tuning experiment using 1024 random features, then fine-tune this using a larger number of random features just as we did for the tabular dataset.\n",
    "\n",
    "Many kernels in xGPR have kernel-specific settings. For Conv1dRBF, we can set two key options: sequence averaging, which is one of 'none', 'sqrt' or 'full', and the width of the convolution to use. Just as with a convolutional network, the width of the convolution filters can affect performance. One way to choose a good setting: see what marginal likelihood score you get from hyperparameter tuning (e.g. with ``crude_bayes`` or ``crude_grid``) using a small number of RFFs (e.g. 1024 - 2048) for several different settings of \"conv_width\". The smallest score achieved likely corresponds to the best value for \"conv_width\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c451d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid point 0 acquired.\n",
      "Grid point 1 acquired.\n",
      "Grid point 2 acquired.\n",
      "Grid point 3 acquired.\n",
      "Grid point 4 acquired.\n",
      "Grid point 5 acquired.\n",
      "Grid point 6 acquired.\n",
      "Grid point 7 acquired.\n",
      "Grid point 8 acquired.\n",
      "Grid point 9 acquired.\n",
      "New hparams: [-2.1136193]\n",
      "Additional acquisition 10.\n",
      "New hparams: [-1.7113183]\n",
      "Additional acquisition 11.\n",
      "New hparams: [-1.601644]\n",
      "Best score achieved: 129179.362\n",
      "Best hyperparams: [-3.0363038 -1.601644 ]\n",
      "Best estimated negative marginal log likelihood: 129179.362\n",
      "Wallclock: 24.44625163078308\n"
     ]
    }
   ],
   "source": [
    "aav_model = xGPReg(num_rffs = 1024, variance_rffs = 512,\n",
    "                  kernel_choice = \"Conv1dRBF\",\n",
    "                   kernel_settings = {\"conv_width\":11, \"averaging\":'none'},\n",
    "                   verbose = True, device = \"gpu\")\n",
    "\n",
    "start_time = time.time()\n",
    "hparams, niter, best_score = aav_model.tune_hyperparams_crude(training_dset)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Best estimated negative marginal log likelihood: {best_score}\")\n",
    "print(f\"Wallclock: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9974ca79-ec65-44ca-a897-6288d7bed2a7",
   "metadata": {},
   "source": [
    "We now have a rough estimate of our hyperparameters, acquired using a sketchy kernel approximation\n",
    "(num_rffs=1024) and a crude tuning procedure. Let's fine-tune this a little. We could use\n",
    "the built-in tuning routine in xGPR the way we did for the tabular data, or we could use\n",
    "Optuna (or some other library), or we could do a simple gridsearch. For illustrative\n",
    "purposes here, we'll use Optuna using num_rffs=4,096 (a somewhat better kernel\n",
    "approximation) and see what that looks like. We'll search the region around the\n",
    "hyperparameters obtained from ``tune_hyperparams_crude``. To run this\n",
    "next piece, you'll need to have Optuna installed. Optuna is one of our\n",
    "favorite approaches and is often able to do a little better than other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d6ec16a-6e18-4b46-923f-a357fb745d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "def objective(trial):\n",
    "    lambda_ = trial.suggest_float(\"lambda_\", -2., 0.)\n",
    "    sigma = trial.suggest_float(\"sigma\", -3., -1.)\n",
    "    hparams = np.array([lambda_, sigma])\n",
    "    nmll = aav_model.exact_nmll(hparams, training_dset)\n",
    "    return nmll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aef1d565-62f2-438e-9e47-be6a396a9b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:51:37,848] A new study created in memory with name: no-name-07d4d74d-1f68-40c2-90f3-add8c8746d1b\n",
      "[I 2024-02-28 14:51:52,970] Trial 0 finished with value: 191010.51515248106 and parameters: {'lambda_': -0.6070616288042767, 'sigma': -2.4277213300992413}. Best is trial 0 with value: 191010.51515248106.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:52:08,106] Trial 1 finished with value: 139098.10635091155 and parameters: {'lambda_': -1.5462970928715938, 'sigma': -1.8973704618342175}. Best is trial 1 with value: 139098.10635091155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:52:23,307] Trial 2 finished with value: 179035.2427503361 and parameters: {'lambda_': -0.5610620604288739, 'sigma': -2.153787079751078}. Best is trial 1 with value: 139098.10635091155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:52:38,505] Trial 3 finished with value: 172288.1657109192 and parameters: {'lambda_': -0.038471603230769036, 'sigma': -1.6303405228302734}. Best is trial 1 with value: 139098.10635091155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:52:53,704] Trial 4 finished with value: 165436.6996476398 and parameters: {'lambda_': -1.0381361970312781, 'sigma': -2.215764963611699}. Best is trial 1 with value: 139098.10635091155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:53:08,901] Trial 5 finished with value: 131532.96759474633 and parameters: {'lambda_': -1.3136439676982612, 'sigma': -1.5419005852319168}. Best is trial 5 with value: 131532.96759474633.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:53:24,094] Trial 6 finished with value: 192336.93498199942 and parameters: {'lambda_': -1.1228555106407512, 'sigma': -2.8806442067808633}. Best is trial 5 with value: 131532.96759474633.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:53:39,317] Trial 7 finished with value: 133291.688314279 and parameters: {'lambda_': -1.2039114893391372, 'sigma': -1.5240091885359286}. Best is trial 5 with value: 131532.96759474633.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:53:54,640] Trial 8 finished with value: 166185.98465624175 and parameters: {'lambda_': -1.635016539093, 'sigma': -2.649096487705015}. Best is trial 5 with value: 131532.96759474633.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:54:09,971] Trial 9 finished with value: 156150.76989813204 and parameters: {'lambda_': -0.9368972523163233, 'sigma': -1.9363448258062679}. Best is trial 5 with value: 131532.96759474633.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:54:25,305] Trial 10 finished with value: 111334.22656963504 and parameters: {'lambda_': -1.8041913070310849, 'sigma': -1.0083487851495223}. Best is trial 10 with value: 111334.22656963504.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:54:40,641] Trial 11 finished with value: 110739.69821716385 and parameters: {'lambda_': -1.9316015294012514, 'sigma': -1.0461089979443123}. Best is trial 11 with value: 110739.69821716385.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:54:55,978] Trial 12 finished with value: 110615.42786483007 and parameters: {'lambda_': -1.9697942932881722, 'sigma': -1.0625029186361101}. Best is trial 12 with value: 110615.42786483007.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:55:11,314] Trial 13 finished with value: 110289.24437218352 and parameters: {'lambda_': -1.9923237115324908, 'sigma': -1.0312083464477573}. Best is trial 13 with value: 110289.24437218352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:55:26,657] Trial 14 finished with value: 112657.04601012528 and parameters: {'lambda_': -1.9741907548353694, 'sigma': -1.238809634853463}. Best is trial 13 with value: 110289.24437218352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:55:41,991] Trial 15 finished with value: 118612.16505182625 and parameters: {'lambda_': -1.6626657406640857, 'sigma': -1.3325845613948655}. Best is trial 13 with value: 110289.24437218352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:55:57,322] Trial 16 finished with value: 113355.71398185895 and parameters: {'lambda_': -1.979911115241622, 'sigma': -1.282551755845012}. Best is trial 13 with value: 110289.24437218352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:56:12,657] Trial 17 finished with value: 115027.21113692805 and parameters: {'lambda_': -1.44070011461748, 'sigma': -1.016021201953487}. Best is trial 13 with value: 110289.24437218352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:56:27,992] Trial 18 finished with value: 130971.75932766096 and parameters: {'lambda_': -1.7605244043847585, 'sigma': -1.7898449770498086}. Best is trial 13 with value: 110289.24437218352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:56:43,341] Trial 19 finished with value: 123053.40935089342 and parameters: {'lambda_': -1.4663024401332163, 'sigma': -1.3737507499679595}. Best is trial 13 with value: 110289.24437218352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:56:58,678] Trial 20 finished with value: 113608.10209868877 and parameters: {'lambda_': -1.7729705022760882, 'sigma': -1.1697605744816058}. Best is trial 13 with value: 110289.24437218352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:57:14,012] Trial 21 finished with value: 110342.09086018638 and parameters: {'lambda_': -1.958363634417783, 'sigma': -1.004823531585883}. Best is trial 13 with value: 110289.24437218352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:57:29,351] Trial 22 finished with value: 111344.37591478857 and parameters: {'lambda_': -1.9926447281221582, 'sigma': -1.156675028124563}. Best is trial 13 with value: 110289.24437218352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:57:44,685] Trial 23 finished with value: 118983.5770222494 and parameters: {'lambda_': -1.7506340815240233, 'sigma': -1.3972777365917783}. Best is trial 13 with value: 110289.24437218352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:58:00,017] Trial 24 finished with value: 111980.00307648914 and parameters: {'lambda_': -1.8425516828455992, 'sigma': -1.1049320833171015}. Best is trial 13 with value: 110289.24437218352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:58:15,354] Trial 25 finished with value: 117286.81287115451 and parameters: {'lambda_': -1.5510336616392377, 'sigma': -1.2107364825415443}. Best is trial 13 with value: 110289.24437218352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:58:30,697] Trial 26 finished with value: 119212.55923930157 and parameters: {'lambda_': -1.8446486815766967, 'sigma': -1.4581632870322487}. Best is trial 13 with value: 110289.24437218352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:58:46,040] Trial 27 finished with value: 128302.00065426654 and parameters: {'lambda_': -1.691677142394271, 'sigma': -1.6698962260217383}. Best is trial 13 with value: 110289.24437218352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:59:01,377] Trial 28 finished with value: 110135.62559608728 and parameters: {'lambda_': -1.999704295150311, 'sigma': -1.0054636279089055}. Best is trial 28 with value: 110135.62559608728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:59:16,710] Trial 29 finished with value: 114448.50938787832 and parameters: {'lambda_': -1.8708026583766026, 'sigma': -1.2755007084944523}. Best is trial 28 with value: 110135.62559608728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:59:32,044] Trial 30 finished with value: 115188.77677291981 and parameters: {'lambda_': -1.6377650041263696, 'sigma': -1.1681786788801491}. Best is trial 28 with value: 110135.62559608728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 14:59:47,379] Trial 31 finished with value: 110272.25703744689 and parameters: {'lambda_': -1.9921321214425995, 'sigma': -1.0276982897258669}. Best is trial 28 with value: 110135.62559608728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 15:00:02,713] Trial 32 finished with value: 116888.90020478022 and parameters: {'lambda_': -1.8255404598855574, 'sigma': -1.3584664560199293}. Best is trial 28 with value: 110135.62559608728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 15:00:18,044] Trial 33 finished with value: 111917.0952403296 and parameters: {'lambda_': -1.8770955212827354, 'sigma': -1.1245007589287543}. Best is trial 28 with value: 110135.62559608728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 15:00:33,380] Trial 34 finished with value: 110201.41865947528 and parameters: {'lambda_': -1.9928388001115445, 'sigma': -1.0133404395427514}. Best is trial 28 with value: 110135.62559608728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated NMLL.\n"
     ]
    }
   ],
   "source": [
    "aav_model.num_rffs = 4096\n",
    "\n",
    "sampler = TPESampler(seed=123)\n",
    "study = optuna.create_study(sampler=sampler)\n",
    "study.optimize(objective, n_trials=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f479d2-eea9-4e0d-bde6-9a01b9d499b9",
   "metadata": {},
   "source": [
    "Set the model hyperparameters to the best ones found by Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec8b4763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda_': -1.999704295150311, 'sigma': -1.0054636279089055}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f55ef42-abec-408a-8750-30e4a1ef40b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aav_model.set_hyperparams(np.array([-1.9997, -1.005464]), training_dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47e4f4e",
   "metadata": {},
   "source": [
    "Now we'll fit the model using 8192 RFFs. We like to use a more accurate kernel approximationwhen fitting than when tuning for two reasons. First, tuning is more expensive because the model has to be fit multiple times when tuning hyperparameters. Second, model performance usually\n",
    "increases faster by increasing the number of rffs used for fitting than for tuning. (Using 16,384 RFFs here for fitting further\n",
    "increases test set performance as you'd expect.)\n",
    "\n",
    "On gpu, for fitting, ``mode=exact`` works well up to 8,192 RFFs or so, while ``mode=cg`` although\n",
    "slower for small numbers of RFFs is more scalable. On this dataset, using 8,192 RFFs, \"exact\" takes about 70 seconds on our GPU.\n",
    "We'll use cg here just for illustrative purposes. Notice that using fitting with default settings takes about 45 iterations with\n",
    "CG. We can speed this up by changing the defaults (see the Advanced Tutorials for more on how to do this).\n",
    "\n",
    "``tol`` determines how tight the fit is. 1e-6 (default) is usually fine. Decreasing the number will improve performance but\n",
    "with rapidly diminishing returns and make fitting take longer. For noise free data or to get a small additional boost in\n",
    "performance, use 1e-7. 1e-8 is (nearly always) overkill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa173a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fitting\n",
      "Chunk 0 complete.\n",
      "Chunk 10 complete.\n",
      "Chunk 20 complete.\n",
      "Chunk 30 complete.\n",
      "Chunk 40 complete.\n",
      "Chunk 50 complete.\n",
      "Chunk 60 complete.\n",
      "Chunk 70 complete.\n",
      "Chunk 80 complete.\n",
      "Chunk 90 complete.\n",
      "Using rank: 512\n",
      "Chunk 0 complete.\n",
      "Chunk 10 complete.\n",
      "Chunk 20 complete.\n",
      "Chunk 30 complete.\n",
      "Chunk 40 complete.\n",
      "Chunk 50 complete.\n",
      "Chunk 60 complete.\n",
      "Chunk 70 complete.\n",
      "Chunk 80 complete.\n",
      "Chunk 90 complete.\n",
      "Iteration 0\n",
      "Iteration 5\n",
      "Iteration 10\n",
      "Iteration 15\n",
      "Iteration 20\n",
      "Now performing variance calculations...\n",
      "Fitting complete.\n",
      "Wallclock: 142.21557712554932\n"
     ]
    }
   ],
   "source": [
    "aav_model.num_rffs = 8192\n",
    "start_time = time.time()\n",
    "aav_model.fit(training_dset, mode = 'cg', tol = 1e-6)\n",
    "end_time = time.time()\n",
    "print(f\"Wallclock: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af17b1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wallclock: 2.0209038257598877\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "all_preds, ground_truth = [], []\n",
    "for xfile, yfile, sfile in zip(test_x_files, test_y_files, test_seqlen_files):\n",
    "    x, y, s = np.load(xfile), np.load(yfile), np.load(sfile)\n",
    "    ground_truth.append(y)\n",
    "    preds = aav_model.predict(x, s, get_var = False)\n",
    "    all_preds.append(preds)\n",
    "    \n",
    "all_preds, ground_truth = np.concatenate(all_preds), np.concatenate(ground_truth)\n",
    "end_time = time.time()\n",
    "print(f\"Wallclock: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca63c6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=0.7587165981515888, pvalue=0.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "spearmanr(all_preds, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e3d321",
   "metadata": {},
   "source": [
    "Spearman's r of 0.76 plus matches the performance for a 1d-CNN reported by Dallago et al\n",
    "for this dataset and is similar to the performance of a fine-tuned LLM (Spearman's r 0.79).\n",
    "As discussed above, we can get further slight improvements in performance\n",
    "just by tweaking this model. We can do even better by using a more informative\n",
    "representation of the protein sequences. In our original paper we achieved a Spearman's r\n",
    "of about 0.8 on this dataset, outperforming fine-tuned LLMs (and costing significantly less to train\n",
    "than a fine-tuned LLM).\n",
    "Whether small gains in performance from further \"tweaking\" or more informative representations is worthwhile\n",
    "obviously depends on your application..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1897a0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02dd194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for testx, testy, tests in zip(test_x_files, test_y_files, test_seqlen_files):\n",
    "    os.remove(testx)\n",
    "    os.remove(testy)\n",
    "    os.remove(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b857b33e-a21e-45c3-9394-fdb50806ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xfile, yfile, sfile in zip(train_x_files, train_y_files, train_seqlen_files):\n",
    "    os.remove(xfile)\n",
    "    os.remove(yfile)\n",
    "    os.remove(sfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fadc454-058d-4e0e-be8f-e0313cd28e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
