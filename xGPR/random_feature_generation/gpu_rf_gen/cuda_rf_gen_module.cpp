/* Generated by Cython 3.0.3 */

/* BEGIN: Cython Metadata
{
    "distutils": {
        "depends": [
            "/ssd1/Documents/gp_proteins/venv_testing/lib/python3.10/site-packages/numpy/core/include/numpy/arrayobject.h",
            "/ssd1/Documents/gp_proteins/venv_testing/lib/python3.10/site-packages/numpy/core/include/numpy/arrayscalars.h",
            "/ssd1/Documents/gp_proteins/venv_testing/lib/python3.10/site-packages/numpy/core/include/numpy/ndarrayobject.h",
            "/ssd1/Documents/gp_proteins/venv_testing/lib/python3.10/site-packages/numpy/core/include/numpy/ndarraytypes.h",
            "/ssd1/Documents/gp_proteins/venv_testing/lib/python3.10/site-packages/numpy/core/include/numpy/ufuncobject.h",
            "xGPR/random_feature_generation/gpu_rf_gen/basic_ops/basic_array_operations.h",
            "xGPR/random_feature_generation/gpu_rf_gen/convolution_ops/arccos_convolution.h",
            "xGPR/random_feature_generation/gpu_rf_gen/convolution_ops/convolution.h",
            "xGPR/random_feature_generation/gpu_rf_gen/convolution_ops/rbf_convolution.h",
            "xGPR/random_feature_generation/gpu_rf_gen/poly_ops/polynomial_operations.h",
            "xGPR/random_feature_generation/gpu_rf_gen/rbf_ops/rbf_ops.h"
        ],
        "extra_link_args": [
            "-lrt"
        ],
        "include_dirs": [
            "xGPR/random_feature_generation/gpu_rf_gen",
            "/ssd1/Documents/gp_proteins/venv_testing/lib/python3.10/site-packages/numpy/core/include",
            "/usr/bin/include"
        ],
        "language": "c++",
        "libraries": [
            "array_operations",
            "cudart_static"
        ],
        "library_dirs": [
            "/ssd1/Documents/gp_proteins/xGPR/xGPR/random_feature_generation/gpu_rf_gen",
            "/usr/bin/lib64"
        ],
        "name": "cuda_rf_gen_module",
        "sources": [
            "/ssd1/Documents/gp_proteins/xGPR/xGPR/random_feature_generation/gpu_rf_gen/cuda_rf_gen_module.pyx"
        ]
    },
    "module_name": "cuda_rf_gen_module"
}
END: Cython Metadata */

#ifndef PY_SSIZE_T_CLEAN
#define PY_SSIZE_T_CLEAN
#endif /* PY_SSIZE_T_CLEAN */
#if defined(CYTHON_LIMITED_API) && 0
  #ifndef Py_LIMITED_API
    #if CYTHON_LIMITED_API+0 > 0x03030000
      #define Py_LIMITED_API CYTHON_LIMITED_API
    #else
      #define Py_LIMITED_API 0x03030000
    #endif
  #endif
#endif

#include "Python.h"
#ifndef Py_PYTHON_H
    #error Python headers needed to compile C extensions, please install development version of Python.
#elif PY_VERSION_HEX < 0x02070000 || (0x03000000 <= PY_VERSION_HEX && PY_VERSION_HEX < 0x03030000)
    #error Cython requires Python 2.7+ or Python 3.3+.
#else
#if CYTHON_LIMITED_API
#define __PYX_EXTRA_ABI_MODULE_NAME "limited"
#else
#define __PYX_EXTRA_ABI_MODULE_NAME ""
#endif
#define CYTHON_ABI "3_0_3" __PYX_EXTRA_ABI_MODULE_NAME
#define __PYX_ABI_MODULE_NAME "_cython_" CYTHON_ABI
#define __PYX_TYPE_MODULE_PREFIX __PYX_ABI_MODULE_NAME "."
#define CYTHON_HEX_VERSION 0x030003F0
#define CYTHON_FUTURE_DIVISION 1
#include <stddef.h>
#ifndef offsetof
  #define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
#endif
#if !defined(_WIN32) && !defined(WIN32) && !defined(MS_WINDOWS)
  #ifndef __stdcall
    #define __stdcall
  #endif
  #ifndef __cdecl
    #define __cdecl
  #endif
  #ifndef __fastcall
    #define __fastcall
  #endif
#endif
#ifndef DL_IMPORT
  #define DL_IMPORT(t) t
#endif
#ifndef DL_EXPORT
  #define DL_EXPORT(t) t
#endif
#define __PYX_COMMA ,
#ifndef HAVE_LONG_LONG
  #define HAVE_LONG_LONG
#endif
#ifndef PY_LONG_LONG
  #define PY_LONG_LONG LONG_LONG
#endif
#ifndef Py_HUGE_VAL
  #define Py_HUGE_VAL HUGE_VAL
#endif
#define __PYX_LIMITED_VERSION_HEX PY_VERSION_HEX
#if defined(GRAALVM_PYTHON)
  /* For very preliminary testing purposes. Most variables are set the same as PyPy.
     The existence of this section does not imply that anything works or is even tested */
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #define CYTHON_COMPILING_IN_LIMITED_API 0
  #define CYTHON_COMPILING_IN_GRAAL 1
  #define CYTHON_COMPILING_IN_NOGIL 0
  #undef CYTHON_USE_TYPE_SLOTS
  #define CYTHON_USE_TYPE_SLOTS 0
  #undef CYTHON_USE_TYPE_SPECS
  #define CYTHON_USE_TYPE_SPECS 0
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #if PY_VERSION_HEX < 0x03050000
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #undef CYTHON_USE_UNICODE_INTERNALS
  #define CYTHON_USE_UNICODE_INTERNALS 0
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #undef CYTHON_AVOID_BORROWED_REFS
  #define CYTHON_AVOID_BORROWED_REFS 1
  #undef CYTHON_ASSUME_SAFE_MACROS
  #define CYTHON_ASSUME_SAFE_MACROS 0
  #undef CYTHON_UNPACK_METHODS
  #define CYTHON_UNPACK_METHODS 0
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_GIL
  #define CYTHON_FAST_GIL 0
  #undef CYTHON_METH_FASTCALL
  #define CYTHON_METH_FASTCALL 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #ifndef CYTHON_PEP487_INIT_SUBCLASS
    #define CYTHON_PEP487_INIT_SUBCLASS (PY_MAJOR_VERSION >= 3)
  #endif
  #undef CYTHON_PEP489_MULTI_PHASE_INIT
  #define CYTHON_PEP489_MULTI_PHASE_INIT 1
  #undef CYTHON_USE_MODULE_STATE
  #define CYTHON_USE_MODULE_STATE 0
  #undef CYTHON_USE_TP_FINALIZE
  #define CYTHON_USE_TP_FINALIZE 0
  #undef CYTHON_USE_DICT_VERSIONS
  #define CYTHON_USE_DICT_VERSIONS 0
  #undef CYTHON_USE_EXC_INFO_STACK
  #define CYTHON_USE_EXC_INFO_STACK 0
  #ifndef CYTHON_UPDATE_DESCRIPTOR_DOC
    #define CYTHON_UPDATE_DESCRIPTOR_DOC 0
  #endif
#elif defined(PYPY_VERSION)
  #define CYTHON_COMPILING_IN_PYPY 1
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #define CYTHON_COMPILING_IN_LIMITED_API 0
  #define CYTHON_COMPILING_IN_GRAAL 0
  #define CYTHON_COMPILING_IN_NOGIL 0
  #undef CYTHON_USE_TYPE_SLOTS
  #define CYTHON_USE_TYPE_SLOTS 0
  #ifndef CYTHON_USE_TYPE_SPECS
    #define CYTHON_USE_TYPE_SPECS 0
  #endif
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #if PY_VERSION_HEX < 0x03050000
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #undef CYTHON_USE_UNICODE_INTERNALS
  #define CYTHON_USE_UNICODE_INTERNALS 0
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #undef CYTHON_AVOID_BORROWED_REFS
  #define CYTHON_AVOID_BORROWED_REFS 1
  #undef CYTHON_ASSUME_SAFE_MACROS
  #define CYTHON_ASSUME_SAFE_MACROS 0
  #undef CYTHON_UNPACK_METHODS
  #define CYTHON_UNPACK_METHODS 0
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_GIL
  #define CYTHON_FAST_GIL 0
  #undef CYTHON_METH_FASTCALL
  #define CYTHON_METH_FASTCALL 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #ifndef CYTHON_PEP487_INIT_SUBCLASS
    #define CYTHON_PEP487_INIT_SUBCLASS (PY_MAJOR_VERSION >= 3)
  #endif
  #if PY_VERSION_HEX < 0x03090000
    #undef CYTHON_PEP489_MULTI_PHASE_INIT
    #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #elif !defined(CYTHON_PEP489_MULTI_PHASE_INIT)
    #define CYTHON_PEP489_MULTI_PHASE_INIT 1
  #endif
  #undef CYTHON_USE_MODULE_STATE
  #define CYTHON_USE_MODULE_STATE 0
  #undef CYTHON_USE_TP_FINALIZE
  #define CYTHON_USE_TP_FINALIZE (PY_VERSION_HEX >= 0x030400a1 && PYPY_VERSION_NUM >= 0x07030C00)
  #undef CYTHON_USE_DICT_VERSIONS
  #define CYTHON_USE_DICT_VERSIONS 0
  #undef CYTHON_USE_EXC_INFO_STACK
  #define CYTHON_USE_EXC_INFO_STACK 0
  #ifndef CYTHON_UPDATE_DESCRIPTOR_DOC
    #define CYTHON_UPDATE_DESCRIPTOR_DOC 0
  #endif
#elif defined(CYTHON_LIMITED_API)
  #ifdef Py_LIMITED_API
    #undef __PYX_LIMITED_VERSION_HEX
    #define __PYX_LIMITED_VERSION_HEX Py_LIMITED_API
  #endif
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #define CYTHON_COMPILING_IN_LIMITED_API 1
  #define CYTHON_COMPILING_IN_GRAAL 0
  #define CYTHON_COMPILING_IN_NOGIL 0
  #undef CYTHON_CLINE_IN_TRACEBACK
  #define CYTHON_CLINE_IN_TRACEBACK 0
  #undef CYTHON_USE_TYPE_SLOTS
  #define CYTHON_USE_TYPE_SLOTS 0
  #undef CYTHON_USE_TYPE_SPECS
  #define CYTHON_USE_TYPE_SPECS 1
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #undef CYTHON_USE_ASYNC_SLOTS
  #define CYTHON_USE_ASYNC_SLOTS 0
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #undef CYTHON_USE_UNICODE_INTERNALS
  #define CYTHON_USE_UNICODE_INTERNALS 0
  #ifndef CYTHON_USE_UNICODE_WRITER
    #define CYTHON_USE_UNICODE_WRITER 0
  #endif
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #undef CYTHON_ASSUME_SAFE_MACROS
  #define CYTHON_ASSUME_SAFE_MACROS 0
  #undef CYTHON_UNPACK_METHODS
  #define CYTHON_UNPACK_METHODS 0
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_GIL
  #define CYTHON_FAST_GIL 0
  #undef CYTHON_METH_FASTCALL
  #define CYTHON_METH_FASTCALL 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #ifndef CYTHON_PEP487_INIT_SUBCLASS
    #define CYTHON_PEP487_INIT_SUBCLASS 1
  #endif
  #undef CYTHON_PEP489_MULTI_PHASE_INIT
  #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #undef CYTHON_USE_MODULE_STATE
  #define CYTHON_USE_MODULE_STATE 1
  #ifndef CYTHON_USE_TP_FINALIZE
    #define CYTHON_USE_TP_FINALIZE 0
  #endif
  #undef CYTHON_USE_DICT_VERSIONS
  #define CYTHON_USE_DICT_VERSIONS 0
  #undef CYTHON_USE_EXC_INFO_STACK
  #define CYTHON_USE_EXC_INFO_STACK 0
  #ifndef CYTHON_UPDATE_DESCRIPTOR_DOC
    #define CYTHON_UPDATE_DESCRIPTOR_DOC 0
  #endif
#elif defined(PY_NOGIL)
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #define CYTHON_COMPILING_IN_LIMITED_API 0
  #define CYTHON_COMPILING_IN_GRAAL 0
  #define CYTHON_COMPILING_IN_NOGIL 1
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #ifndef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #ifndef CYTHON_PEP489_MULTI_PHASE_INIT
    #define CYTHON_PEP489_MULTI_PHASE_INIT 1
  #endif
  #ifndef CYTHON_USE_TP_FINALIZE
    #define CYTHON_USE_TP_FINALIZE 1
  #endif
  #undef CYTHON_USE_DICT_VERSIONS
  #define CYTHON_USE_DICT_VERSIONS 0
  #undef CYTHON_USE_EXC_INFO_STACK
  #define CYTHON_USE_EXC_INFO_STACK 0
#else
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_CPYTHON 1
  #define CYTHON_COMPILING_IN_LIMITED_API 0
  #define CYTHON_COMPILING_IN_GRAAL 0
  #define CYTHON_COMPILING_IN_NOGIL 0
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #ifndef CYTHON_USE_TYPE_SPECS
    #define CYTHON_USE_TYPE_SPECS 0
  #endif
  #ifndef CYTHON_USE_PYTYPE_LOOKUP
    #define CYTHON_USE_PYTYPE_LOOKUP 1
  #endif
  #if PY_MAJOR_VERSION < 3
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #ifndef CYTHON_USE_PYLONG_INTERNALS
    #define CYTHON_USE_PYLONG_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_PYLIST_INTERNALS
    #define CYTHON_USE_PYLIST_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #if PY_VERSION_HEX < 0x030300F0 || PY_VERSION_HEX >= 0x030B00A2
    #undef CYTHON_USE_UNICODE_WRITER
    #define CYTHON_USE_UNICODE_WRITER 0
  #elif !defined(CYTHON_USE_UNICODE_WRITER)
    #define CYTHON_USE_UNICODE_WRITER 1
  #endif
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #ifndef CYTHON_FAST_THREAD_STATE
    #define CYTHON_FAST_THREAD_STATE 1
  #endif
  #ifndef CYTHON_FAST_GIL
    #define CYTHON_FAST_GIL (PY_MAJOR_VERSION < 3 || PY_VERSION_HEX >= 0x03060000 && PY_VERSION_HEX < 0x030C00A6)
  #endif
  #ifndef CYTHON_METH_FASTCALL
    #define CYTHON_METH_FASTCALL (PY_VERSION_HEX >= 0x030700A1)
  #endif
  #ifndef CYTHON_FAST_PYCALL
    #define CYTHON_FAST_PYCALL 1
  #endif
  #ifndef CYTHON_PEP487_INIT_SUBCLASS
    #define CYTHON_PEP487_INIT_SUBCLASS 1
  #endif
  #if PY_VERSION_HEX < 0x03050000
    #undef CYTHON_PEP489_MULTI_PHASE_INIT
    #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #elif !defined(CYTHON_PEP489_MULTI_PHASE_INIT)
    #define CYTHON_PEP489_MULTI_PHASE_INIT 1
  #endif
  #ifndef CYTHON_USE_MODULE_STATE
    #define CYTHON_USE_MODULE_STATE 0
  #endif
  #if PY_VERSION_HEX < 0x030400a1
    #undef CYTHON_USE_TP_FINALIZE
    #define CYTHON_USE_TP_FINALIZE 0
  #elif !defined(CYTHON_USE_TP_FINALIZE)
    #define CYTHON_USE_TP_FINALIZE 1
  #endif
  #if PY_VERSION_HEX < 0x030600B1
    #undef CYTHON_USE_DICT_VERSIONS
    #define CYTHON_USE_DICT_VERSIONS 0
  #elif !defined(CYTHON_USE_DICT_VERSIONS)
    #define CYTHON_USE_DICT_VERSIONS  (PY_VERSION_HEX < 0x030C00A5)
  #endif
  #if PY_VERSION_HEX < 0x030700A3
    #undef CYTHON_USE_EXC_INFO_STACK
    #define CYTHON_USE_EXC_INFO_STACK 0
  #elif !defined(CYTHON_USE_EXC_INFO_STACK)
    #define CYTHON_USE_EXC_INFO_STACK 1
  #endif
  #ifndef CYTHON_UPDATE_DESCRIPTOR_DOC
    #define CYTHON_UPDATE_DESCRIPTOR_DOC 1
  #endif
#endif
#if !defined(CYTHON_FAST_PYCCALL)
#define CYTHON_FAST_PYCCALL  (CYTHON_FAST_PYCALL && PY_VERSION_HEX >= 0x030600B1)
#endif
#if !defined(CYTHON_VECTORCALL)
#define CYTHON_VECTORCALL  (CYTHON_FAST_PYCCALL && PY_VERSION_HEX >= 0x030800B1)
#endif
#define CYTHON_BACKPORT_VECTORCALL (CYTHON_METH_FASTCALL && PY_VERSION_HEX < 0x030800B1)
#if CYTHON_USE_PYLONG_INTERNALS
  #if PY_MAJOR_VERSION < 3
    #include "longintrepr.h"
  #endif
  #undef SHIFT
  #undef BASE
  #undef MASK
  #ifdef SIZEOF_VOID_P
    enum { __pyx_check_sizeof_voidp = 1 / (int)(SIZEOF_VOID_P == sizeof(void*)) };
  #endif
#endif
#ifndef __has_attribute
  #define __has_attribute(x) 0
#endif
#ifndef __has_cpp_attribute
  #define __has_cpp_attribute(x) 0
#endif
#ifndef CYTHON_RESTRICT
  #if defined(__GNUC__)
    #define CYTHON_RESTRICT __restrict__
  #elif defined(_MSC_VER) && _MSC_VER >= 1400
    #define CYTHON_RESTRICT __restrict
  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define CYTHON_RESTRICT restrict
  #else
    #define CYTHON_RESTRICT
  #endif
#endif
#ifndef CYTHON_UNUSED
  #if defined(__cplusplus)
    /* for clang __has_cpp_attribute(maybe_unused) is true even before C++17
     * but leads to warnings with -pedantic, since it is a C++17 feature */
    #if ((defined(_MSVC_LANG) && _MSVC_LANG >= 201703L) || __cplusplus >= 201703L)
      #if __has_cpp_attribute(maybe_unused)
        #define CYTHON_UNUSED [[maybe_unused]]
      #endif
    #endif
  #endif
#endif
#ifndef CYTHON_UNUSED
# if defined(__GNUC__)
#   if !(defined(__cplusplus)) || (__GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 4))
#     define CYTHON_UNUSED __attribute__ ((__unused__))
#   else
#     define CYTHON_UNUSED
#   endif
# elif defined(__ICC) || (defined(__INTEL_COMPILER) && !defined(_MSC_VER))
#   define CYTHON_UNUSED __attribute__ ((__unused__))
# else
#   define CYTHON_UNUSED
# endif
#endif
#ifndef CYTHON_UNUSED_VAR
#  if defined(__cplusplus)
     template<class T> void CYTHON_UNUSED_VAR( const T& ) { }
#  else
#    define CYTHON_UNUSED_VAR(x) (void)(x)
#  endif
#endif
#ifndef CYTHON_MAYBE_UNUSED_VAR
  #define CYTHON_MAYBE_UNUSED_VAR(x) CYTHON_UNUSED_VAR(x)
#endif
#ifndef CYTHON_NCP_UNUSED
# if CYTHON_COMPILING_IN_CPYTHON
#  define CYTHON_NCP_UNUSED
# else
#  define CYTHON_NCP_UNUSED CYTHON_UNUSED
# endif
#endif
#ifndef CYTHON_USE_CPP_STD_MOVE
  #if defined(__cplusplus) && (\
    __cplusplus >= 201103L || (defined(_MSC_VER) && _MSC_VER >= 1600))
    #define CYTHON_USE_CPP_STD_MOVE 1
  #else
    #define CYTHON_USE_CPP_STD_MOVE 0
  #endif
#endif
#define __Pyx_void_to_None(void_result) ((void)(void_result), Py_INCREF(Py_None), Py_None)
#ifdef _MSC_VER
    #ifndef _MSC_STDINT_H_
        #if _MSC_VER < 1300
            typedef unsigned char     uint8_t;
            typedef unsigned short    uint16_t;
            typedef unsigned int      uint32_t;
        #else
            typedef unsigned __int8   uint8_t;
            typedef unsigned __int16  uint16_t;
            typedef unsigned __int32  uint32_t;
        #endif
    #endif
    #if _MSC_VER < 1300
        #ifdef _WIN64
            typedef unsigned long long  __pyx_uintptr_t;
        #else
            typedef unsigned int        __pyx_uintptr_t;
        #endif
    #else
        #ifdef _WIN64
            typedef unsigned __int64    __pyx_uintptr_t;
        #else
            typedef unsigned __int32    __pyx_uintptr_t;
        #endif
    #endif
#else
    #include <stdint.h>
    typedef uintptr_t  __pyx_uintptr_t;
#endif
#ifndef CYTHON_FALLTHROUGH
  #if defined(__cplusplus)
    /* for clang __has_cpp_attribute(fallthrough) is true even before C++17
     * but leads to warnings with -pedantic, since it is a C++17 feature */
    #if ((defined(_MSVC_LANG) && _MSVC_LANG >= 201703L) || __cplusplus >= 201703L)
      #if __has_cpp_attribute(fallthrough)
        #define CYTHON_FALLTHROUGH [[fallthrough]]
      #endif
    #endif
    #ifndef CYTHON_FALLTHROUGH
      #if __has_cpp_attribute(clang::fallthrough)
        #define CYTHON_FALLTHROUGH [[clang::fallthrough]]
      #elif __has_cpp_attribute(gnu::fallthrough)
        #define CYTHON_FALLTHROUGH [[gnu::fallthrough]]
      #endif
    #endif
  #endif
  #ifndef CYTHON_FALLTHROUGH
    #if __has_attribute(fallthrough)
      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))
    #else
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
  #if defined(__clang__) && defined(__apple_build_version__)
    #if __apple_build_version__ < 7000000
      #undef  CYTHON_FALLTHROUGH
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
#endif
#ifdef __cplusplus
  template <typename T>
  struct __PYX_IS_UNSIGNED_IMPL {static const bool value = T(0) < T(-1);};
  #define __PYX_IS_UNSIGNED(type) (__PYX_IS_UNSIGNED_IMPL<type>::value)
#else
  #define __PYX_IS_UNSIGNED(type) (((type)-1) > 0)
#endif
#if CYTHON_COMPILING_IN_PYPY == 1
  #define __PYX_NEED_TP_PRINT_SLOT  (PY_VERSION_HEX >= 0x030800b4 && PY_VERSION_HEX < 0x030A0000)
#else
  #define __PYX_NEED_TP_PRINT_SLOT  (PY_VERSION_HEX >= 0x030800b4 && PY_VERSION_HEX < 0x03090000)
#endif
#define __PYX_REINTERPRET_FUNCION(func_pointer, other_pointer) ((func_pointer)(void(*)(void))(other_pointer))

#ifndef __cplusplus
  #error "Cython files generated with the C++ option must be compiled with a C++ compiler."
#endif
#ifndef CYTHON_INLINE
  #if defined(__clang__)
    #define CYTHON_INLINE __inline__ __attribute__ ((__unused__))
  #else
    #define CYTHON_INLINE inline
  #endif
#endif
template<typename T>
void __Pyx_call_destructor(T& x) {
    x.~T();
}
template<typename T>
class __Pyx_FakeReference {
  public:
    __Pyx_FakeReference() : ptr(NULL) { }
    __Pyx_FakeReference(const T& ref) : ptr(const_cast<T*>(&ref)) { }
    T *operator->() { return ptr; }
    T *operator&() { return ptr; }
    operator T&() { return *ptr; }
    template<typename U> bool operator ==(const U& other) const { return *ptr == other; }
    template<typename U> bool operator !=(const U& other) const { return *ptr != other; }
    template<typename U> bool operator==(const __Pyx_FakeReference<U>& other) const { return *ptr == *other.ptr; }
    template<typename U> bool operator!=(const __Pyx_FakeReference<U>& other) const { return *ptr != *other.ptr; }
  private:
    T *ptr;
};

#define __PYX_BUILD_PY_SSIZE_T "n"
#define CYTHON_FORMAT_SSIZE_T "z"
#if PY_MAJOR_VERSION < 3
  #define __Pyx_BUILTIN_MODULE_NAME "__builtin__"
  #define __Pyx_DefaultClassType PyClass_Type
  #define __Pyx_PyCode_New(a, p, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a+k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
#else
  #define __Pyx_BUILTIN_MODULE_NAME "builtins"
  #define __Pyx_DefaultClassType PyType_Type
#if CYTHON_COMPILING_IN_LIMITED_API
    static CYTHON_INLINE PyObject* __Pyx_PyCode_New(int a, int p, int k, int l, int s, int f,
                                                    PyObject *code, PyObject *c, PyObject* n, PyObject *v,
                                                    PyObject *fv, PyObject *cell, PyObject* fn,
                                                    PyObject *name, int fline, PyObject *lnos) {
        PyObject *exception_table = NULL;
        PyObject *types_module=NULL, *code_type=NULL, *result=NULL;
        #if __PYX_LIMITED_VERSION_HEX < 0x030B0000
        PyObject *version_info; // borrowed
        #endif
        PyObject *py_minor_version = NULL;
        long minor_version = 0;
        PyObject *type, *value, *traceback;
        PyErr_Fetch(&type, &value, &traceback);
        #if __PYX_LIMITED_VERSION_HEX >= 0x030B0000
        minor_version = 11; // we don't yet need to distinguish between versions > 11
        #else
        if (!(version_info = PySys_GetObject("version_info"))) goto end;
        if (!(py_minor_version = PySequence_GetItem(version_info, 1))) goto end;
        minor_version = PyLong_AsLong(py_minor_version);
        if (minor_version == -1 && PyErr_Occurred()) goto end;
        #endif
        if (!(types_module = PyImport_ImportModule("types"))) goto end;
        if (!(code_type = PyObject_GetAttrString(types_module, "CodeType"))) goto end;
        if (minor_version <= 7) {
            (void)p;
            result = PyObject_CallFunction(code_type, "iiiiiOOOOOOiOO", a, k, l, s, f, code,
                          c, n, v, fn, name, fline, lnos, fv, cell);
        } else if (minor_version <= 10) {
            result = PyObject_CallFunction(code_type, "iiiiiiOOOOOOiOO", a,p, k, l, s, f, code,
                          c, n, v, fn, name, fline, lnos, fv, cell);
        } else {
            if (!(exception_table = PyBytes_FromStringAndSize(NULL, 0))) goto end;
            result = PyObject_CallFunction(code_type, "iiiiiiOOOOOOOiOO", a,p, k, l, s, f, code,
                          c, n, v, fn, name, name, fline, lnos, exception_table, fv, cell);
        }
    end:
        Py_XDECREF(code_type);
        Py_XDECREF(exception_table);
        Py_XDECREF(types_module);
        Py_XDECREF(py_minor_version);
        if (type) {
            PyErr_Restore(type, value, traceback);
        }
        return result;
    }
    #ifndef CO_OPTIMIZED
    #define CO_OPTIMIZED 0x0001
    #endif
    #ifndef CO_NEWLOCALS
    #define CO_NEWLOCALS 0x0002
    #endif
    #ifndef CO_VARARGS
    #define CO_VARARGS 0x0004
    #endif
    #ifndef CO_VARKEYWORDS
    #define CO_VARKEYWORDS 0x0008
    #endif
    #ifndef CO_ASYNC_GENERATOR
    #define CO_ASYNC_GENERATOR 0x0200
    #endif
    #ifndef CO_GENERATOR
    #define CO_GENERATOR 0x0020
    #endif
    #ifndef CO_COROUTINE
    #define CO_COROUTINE 0x0080
    #endif
#elif PY_VERSION_HEX >= 0x030B0000
  static CYTHON_INLINE PyCodeObject* __Pyx_PyCode_New(int a, int p, int k, int l, int s, int f,
                                                    PyObject *code, PyObject *c, PyObject* n, PyObject *v,
                                                    PyObject *fv, PyObject *cell, PyObject* fn,
                                                    PyObject *name, int fline, PyObject *lnos) {
    PyCodeObject *result;
    PyObject *empty_bytes = PyBytes_FromStringAndSize("", 0);  // we don't have access to __pyx_empty_bytes here
    if (!empty_bytes) return NULL;
    result =
      #if PY_VERSION_HEX >= 0x030C0000
        PyUnstable_Code_NewWithPosOnlyArgs
      #else
        PyCode_NewWithPosOnlyArgs
      #endif
        (a, p, k, l, s, f, code, c, n, v, fv, cell, fn, name, name, fline, lnos, empty_bytes);
    Py_DECREF(empty_bytes);
    return result;
  }
#elif PY_VERSION_HEX >= 0x030800B2 && !CYTHON_COMPILING_IN_PYPY
  #define __Pyx_PyCode_New(a, p, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_NewWithPosOnlyArgs(a, p, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
#else
  #define __Pyx_PyCode_New(a, p, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
#endif
#endif
#if PY_VERSION_HEX >= 0x030900A4 || defined(Py_IS_TYPE)
  #define __Pyx_IS_TYPE(ob, type) Py_IS_TYPE(ob, type)
#else
  #define __Pyx_IS_TYPE(ob, type) (((const PyObject*)ob)->ob_type == (type))
#endif
#if PY_VERSION_HEX >= 0x030A00B1 || defined(Py_Is)
  #define __Pyx_Py_Is(x, y)  Py_Is(x, y)
#else
  #define __Pyx_Py_Is(x, y) ((x) == (y))
#endif
#if PY_VERSION_HEX >= 0x030A00B1 || defined(Py_IsNone)
  #define __Pyx_Py_IsNone(ob) Py_IsNone(ob)
#else
  #define __Pyx_Py_IsNone(ob) __Pyx_Py_Is((ob), Py_None)
#endif
#if PY_VERSION_HEX >= 0x030A00B1 || defined(Py_IsTrue)
  #define __Pyx_Py_IsTrue(ob) Py_IsTrue(ob)
#else
  #define __Pyx_Py_IsTrue(ob) __Pyx_Py_Is((ob), Py_True)
#endif
#if PY_VERSION_HEX >= 0x030A00B1 || defined(Py_IsFalse)
  #define __Pyx_Py_IsFalse(ob) Py_IsFalse(ob)
#else
  #define __Pyx_Py_IsFalse(ob) __Pyx_Py_Is((ob), Py_False)
#endif
#define __Pyx_NoneAsNull(obj)  (__Pyx_Py_IsNone(obj) ? NULL : (obj))
#if PY_VERSION_HEX >= 0x030900F0 && !CYTHON_COMPILING_IN_PYPY
  #define __Pyx_PyObject_GC_IsFinalized(o) PyObject_GC_IsFinalized(o)
#else
  #define __Pyx_PyObject_GC_IsFinalized(o) _PyGC_FINALIZED(o)
#endif
#ifndef CO_COROUTINE
  #define CO_COROUTINE 0x80
#endif
#ifndef CO_ASYNC_GENERATOR
  #define CO_ASYNC_GENERATOR 0x200
#endif
#ifndef Py_TPFLAGS_CHECKTYPES
  #define Py_TPFLAGS_CHECKTYPES 0
#endif
#ifndef Py_TPFLAGS_HAVE_INDEX
  #define Py_TPFLAGS_HAVE_INDEX 0
#endif
#ifndef Py_TPFLAGS_HAVE_NEWBUFFER
  #define Py_TPFLAGS_HAVE_NEWBUFFER 0
#endif
#ifndef Py_TPFLAGS_HAVE_FINALIZE
  #define Py_TPFLAGS_HAVE_FINALIZE 0
#endif
#ifndef Py_TPFLAGS_SEQUENCE
  #define Py_TPFLAGS_SEQUENCE 0
#endif
#ifndef Py_TPFLAGS_MAPPING
  #define Py_TPFLAGS_MAPPING 0
#endif
#ifndef METH_STACKLESS
  #define METH_STACKLESS 0
#endif
#if PY_VERSION_HEX <= 0x030700A3 || !defined(METH_FASTCALL)
  #ifndef METH_FASTCALL
     #define METH_FASTCALL 0x80
  #endif
  typedef PyObject *(*__Pyx_PyCFunctionFast) (PyObject *self, PyObject *const *args, Py_ssize_t nargs);
  typedef PyObject *(*__Pyx_PyCFunctionFastWithKeywords) (PyObject *self, PyObject *const *args,
                                                          Py_ssize_t nargs, PyObject *kwnames);
#else
  #define __Pyx_PyCFunctionFast _PyCFunctionFast
  #define __Pyx_PyCFunctionFastWithKeywords _PyCFunctionFastWithKeywords
#endif
#if CYTHON_METH_FASTCALL
  #define __Pyx_METH_FASTCALL METH_FASTCALL
  #define __Pyx_PyCFunction_FastCall __Pyx_PyCFunctionFast
  #define __Pyx_PyCFunction_FastCallWithKeywords __Pyx_PyCFunctionFastWithKeywords
#else
  #define __Pyx_METH_FASTCALL METH_VARARGS
  #define __Pyx_PyCFunction_FastCall PyCFunction
  #define __Pyx_PyCFunction_FastCallWithKeywords PyCFunctionWithKeywords
#endif
#if CYTHON_VECTORCALL
  #define __pyx_vectorcallfunc vectorcallfunc
  #define __Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET  PY_VECTORCALL_ARGUMENTS_OFFSET
  #define __Pyx_PyVectorcall_NARGS(n)  PyVectorcall_NARGS((size_t)(n))
#elif CYTHON_BACKPORT_VECTORCALL
  typedef PyObject *(*__pyx_vectorcallfunc)(PyObject *callable, PyObject *const *args,
                                            size_t nargsf, PyObject *kwnames);
  #define __Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET  ((size_t)1 << (8 * sizeof(size_t) - 1))
  #define __Pyx_PyVectorcall_NARGS(n)  ((Py_ssize_t)(((size_t)(n)) & ~__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET))
#else
  #define __Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET  0
  #define __Pyx_PyVectorcall_NARGS(n)  ((Py_ssize_t)(n))
#endif
#if PY_MAJOR_VERSION >= 0x030900B1
#define __Pyx_PyCFunction_CheckExact(func)  PyCFunction_CheckExact(func)
#else
#define __Pyx_PyCFunction_CheckExact(func)  PyCFunction_Check(func)
#endif
#define __Pyx_CyOrPyCFunction_Check(func)  PyCFunction_Check(func)
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_CyOrPyCFunction_GET_FUNCTION(func)  (((PyCFunctionObject*)(func))->m_ml->ml_meth)
#elif !CYTHON_COMPILING_IN_LIMITED_API
#define __Pyx_CyOrPyCFunction_GET_FUNCTION(func)  PyCFunction_GET_FUNCTION(func)
#endif
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_CyOrPyCFunction_GET_FLAGS(func)  (((PyCFunctionObject*)(func))->m_ml->ml_flags)
static CYTHON_INLINE PyObject* __Pyx_CyOrPyCFunction_GET_SELF(PyObject *func) {
    return (__Pyx_CyOrPyCFunction_GET_FLAGS(func) & METH_STATIC) ? NULL : ((PyCFunctionObject*)func)->m_self;
}
#endif
static CYTHON_INLINE int __Pyx__IsSameCFunction(PyObject *func, void *cfunc) {
#if CYTHON_COMPILING_IN_LIMITED_API
    return PyCFunction_Check(func) && PyCFunction_GetFunction(func) == (PyCFunction) cfunc;
#else
    return PyCFunction_Check(func) && PyCFunction_GET_FUNCTION(func) == (PyCFunction) cfunc;
#endif
}
#define __Pyx_IsSameCFunction(func, cfunc)   __Pyx__IsSameCFunction(func, cfunc)
#if __PYX_LIMITED_VERSION_HEX < 0x030900B1
  #define __Pyx_PyType_FromModuleAndSpec(m, s, b)  ((void)m, PyType_FromSpecWithBases(s, b))
  typedef PyObject *(*__Pyx_PyCMethod)(PyObject *, PyTypeObject *, PyObject *const *, size_t, PyObject *);
#else
  #define __Pyx_PyType_FromModuleAndSpec(m, s, b)  PyType_FromModuleAndSpec(m, s, b)
  #define __Pyx_PyCMethod  PyCMethod
#endif
#ifndef METH_METHOD
  #define METH_METHOD 0x200
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Malloc)
  #define PyObject_Malloc(s)   PyMem_Malloc(s)
  #define PyObject_Free(p)     PyMem_Free(p)
  #define PyObject_Realloc(p)  PyMem_Realloc(p)
#endif
#if CYTHON_COMPILING_IN_LIMITED_API
  #define __Pyx_PyCode_HasFreeVars(co)  (PyCode_GetNumFree(co) > 0)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno)
#else
  #define __Pyx_PyCode_HasFreeVars(co)  (PyCode_GetNumFree(co) > 0)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno)  (frame)->f_lineno = (lineno)
#endif
#if CYTHON_COMPILING_IN_LIMITED_API
  #define __Pyx_PyThreadState_Current PyThreadState_Get()
#elif !CYTHON_FAST_THREAD_STATE
  #define __Pyx_PyThreadState_Current PyThreadState_GET()
#elif PY_VERSION_HEX >= 0x03060000
  #define __Pyx_PyThreadState_Current _PyThreadState_UncheckedGet()
#elif PY_VERSION_HEX >= 0x03000000
  #define __Pyx_PyThreadState_Current PyThreadState_GET()
#else
  #define __Pyx_PyThreadState_Current _PyThreadState_Current
#endif
#if CYTHON_COMPILING_IN_LIMITED_API
static CYTHON_INLINE void *__Pyx_PyModule_GetState(PyObject *op)
{
    void *result;
    result = PyModule_GetState(op);
    if (!result)
        Py_FatalError("Couldn't find the module state");
    return result;
}
#endif
#define __Pyx_PyObject_GetSlot(obj, name, func_ctype)  __Pyx_PyType_GetSlot(Py_TYPE(obj), name, func_ctype)
#if CYTHON_COMPILING_IN_LIMITED_API
  #define __Pyx_PyType_GetSlot(type, name, func_ctype)  ((func_ctype) PyType_GetSlot((type), Py_##name))
#else
  #define __Pyx_PyType_GetSlot(type, name, func_ctype)  ((type)->name)
#endif
#if PY_VERSION_HEX < 0x030700A2 && !defined(PyThread_tss_create) && !defined(Py_tss_NEEDS_INIT)
#include "pythread.h"
#define Py_tss_NEEDS_INIT 0
typedef int Py_tss_t;
static CYTHON_INLINE int PyThread_tss_create(Py_tss_t *key) {
  *key = PyThread_create_key();
  return 0;
}
static CYTHON_INLINE Py_tss_t * PyThread_tss_alloc(void) {
  Py_tss_t *key = (Py_tss_t *)PyObject_Malloc(sizeof(Py_tss_t));
  *key = Py_tss_NEEDS_INIT;
  return key;
}
static CYTHON_INLINE void PyThread_tss_free(Py_tss_t *key) {
  PyObject_Free(key);
}
static CYTHON_INLINE int PyThread_tss_is_created(Py_tss_t *key) {
  return *key != Py_tss_NEEDS_INIT;
}
static CYTHON_INLINE void PyThread_tss_delete(Py_tss_t *key) {
  PyThread_delete_key(*key);
  *key = Py_tss_NEEDS_INIT;
}
static CYTHON_INLINE int PyThread_tss_set(Py_tss_t *key, void *value) {
  return PyThread_set_key_value(*key, value);
}
static CYTHON_INLINE void * PyThread_tss_get(Py_tss_t *key) {
  return PyThread_get_key_value(*key);
}
#endif
#if PY_MAJOR_VERSION < 3
    #if CYTHON_COMPILING_IN_PYPY
        #if PYPY_VERSION_NUM < 0x07030600
            #if defined(__cplusplus) && __cplusplus >= 201402L
                [[deprecated("`with nogil:` inside a nogil function will not release the GIL in PyPy2 < 7.3.6")]]
            #elif defined(__GNUC__) || defined(__clang__)
                __attribute__ ((__deprecated__("`with nogil:` inside a nogil function will not release the GIL in PyPy2 < 7.3.6")))
            #elif defined(_MSC_VER)
                __declspec(deprecated("`with nogil:` inside a nogil function will not release the GIL in PyPy2 < 7.3.6"))
            #endif
            static CYTHON_INLINE int PyGILState_Check(void) {
                return 0;
            }
        #else  // PYPY_VERSION_NUM < 0x07030600
        #endif  // PYPY_VERSION_NUM < 0x07030600
    #else
        static CYTHON_INLINE int PyGILState_Check(void) {
            PyThreadState * tstate = _PyThreadState_Current;
            return tstate && (tstate == PyGILState_GetThisThreadState());
        }
    #endif
#endif
#if CYTHON_COMPILING_IN_CPYTHON || defined(_PyDict_NewPresized)
#define __Pyx_PyDict_NewPresized(n)  ((n <= 8) ? PyDict_New() : _PyDict_NewPresized(n))
#else
#define __Pyx_PyDict_NewPresized(n)  PyDict_New()
#endif
#if PY_MAJOR_VERSION >= 3 || CYTHON_FUTURE_DIVISION
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceTrueDivide(x,y)
#else
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_Divide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceDivide(x,y)
#endif
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX > 0x030600B4 && CYTHON_USE_UNICODE_INTERNALS
#define __Pyx_PyDict_GetItemStrWithError(dict, name)  _PyDict_GetItem_KnownHash(dict, name, ((PyASCIIObject *) name)->hash)
static CYTHON_INLINE PyObject * __Pyx_PyDict_GetItemStr(PyObject *dict, PyObject *name) {
    PyObject *res = __Pyx_PyDict_GetItemStrWithError(dict, name);
    if (res == NULL) PyErr_Clear();
    return res;
}
#elif PY_MAJOR_VERSION >= 3 && (!CYTHON_COMPILING_IN_PYPY || PYPY_VERSION_NUM >= 0x07020000)
#define __Pyx_PyDict_GetItemStrWithError  PyDict_GetItemWithError
#define __Pyx_PyDict_GetItemStr           PyDict_GetItem
#else
static CYTHON_INLINE PyObject * __Pyx_PyDict_GetItemStrWithError(PyObject *dict, PyObject *name) {
#if CYTHON_COMPILING_IN_PYPY
    return PyDict_GetItem(dict, name);
#else
    PyDictEntry *ep;
    PyDictObject *mp = (PyDictObject*) dict;
    long hash = ((PyStringObject *) name)->ob_shash;
    assert(hash != -1);
    ep = (mp->ma_lookup)(mp, name, hash);
    if (ep == NULL) {
        return NULL;
    }
    return ep->me_value;
#endif
}
#define __Pyx_PyDict_GetItemStr           PyDict_GetItem
#endif
#if CYTHON_USE_TYPE_SLOTS
  #define __Pyx_PyType_GetFlags(tp)   (((PyTypeObject *)tp)->tp_flags)
  #define __Pyx_PyType_HasFeature(type, feature)  ((__Pyx_PyType_GetFlags(type) & (feature)) != 0)
  #define __Pyx_PyObject_GetIterNextFunc(obj)  (Py_TYPE(obj)->tp_iternext)
#else
  #define __Pyx_PyType_GetFlags(tp)   (PyType_GetFlags((PyTypeObject *)tp))
  #define __Pyx_PyType_HasFeature(type, feature)  PyType_HasFeature(type, feature)
  #define __Pyx_PyObject_GetIterNextFunc(obj)  PyIter_Next
#endif
#if CYTHON_COMPILING_IN_LIMITED_API
  #define __Pyx_SetItemOnTypeDict(tp, k, v) PyObject_GenericSetAttr((PyObject*)tp, k, v)
#else
  #define __Pyx_SetItemOnTypeDict(tp, k, v) PyDict_SetItem(tp->tp_dict, k, v)
#endif
#if CYTHON_USE_TYPE_SPECS && PY_VERSION_HEX >= 0x03080000
#define __Pyx_PyHeapTypeObject_GC_Del(obj)  {\
    PyTypeObject *type = Py_TYPE(obj);\
    assert(__Pyx_PyType_HasFeature(type, Py_TPFLAGS_HEAPTYPE));\
    PyObject_GC_Del(obj);\
    Py_DECREF(type);\
}
#else
#define __Pyx_PyHeapTypeObject_GC_Del(obj)  PyObject_GC_Del(obj)
#endif
#if CYTHON_COMPILING_IN_LIMITED_API
  #define CYTHON_PEP393_ENABLED 1
  #define __Pyx_PyUnicode_READY(op)       (0)
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GetLength(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) PyUnicode_ReadChar(u, i)
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   ((void)u, 1114111U)
  #define __Pyx_PyUnicode_KIND(u)         ((void)u, (0))
  #define __Pyx_PyUnicode_DATA(u)         ((void*)u)
  #define __Pyx_PyUnicode_READ(k, d, i)   ((void)k, PyUnicode_ReadChar((PyObject*)(d), i))
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GetLength(u))
#elif PY_VERSION_HEX > 0x03030000 && defined(PyUnicode_KIND)
  #define CYTHON_PEP393_ENABLED 1
  #if PY_VERSION_HEX >= 0x030C0000
    #define __Pyx_PyUnicode_READY(op)       (0)
  #else
    #define __Pyx_PyUnicode_READY(op)       (likely(PyUnicode_IS_READY(op)) ?\
                                                0 : _PyUnicode_Ready((PyObject *)(op)))
  #endif
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_LENGTH(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) PyUnicode_READ_CHAR(u, i)
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   PyUnicode_MAX_CHAR_VALUE(u)
  #define __Pyx_PyUnicode_KIND(u)         ((int)PyUnicode_KIND(u))
  #define __Pyx_PyUnicode_DATA(u)         PyUnicode_DATA(u)
  #define __Pyx_PyUnicode_READ(k, d, i)   PyUnicode_READ(k, d, i)
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  PyUnicode_WRITE(k, d, i, (Py_UCS4) ch)
  #if PY_VERSION_HEX >= 0x030C0000
    #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GET_LENGTH(u))
  #else
    #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x03090000
    #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : ((PyCompactUnicodeObject *)(u))->wstr_length))
    #else
    #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : PyUnicode_GET_SIZE(u)))
    #endif
  #endif
#else
  #define CYTHON_PEP393_ENABLED 0
  #define PyUnicode_1BYTE_KIND  1
  #define PyUnicode_2BYTE_KIND  2
  #define PyUnicode_4BYTE_KIND  4
  #define __Pyx_PyUnicode_READY(op)       (0)
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_SIZE(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) ((Py_UCS4)(PyUnicode_AS_UNICODE(u)[i]))
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   ((sizeof(Py_UNICODE) == 2) ? 65535U : 1114111U)
  #define __Pyx_PyUnicode_KIND(u)         ((int)sizeof(Py_UNICODE))
  #define __Pyx_PyUnicode_DATA(u)         ((void*)PyUnicode_AS_UNICODE(u))
  #define __Pyx_PyUnicode_READ(k, d, i)   ((void)(k), (Py_UCS4)(((Py_UNICODE*)d)[i]))
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  (((void)(k)), ((Py_UNICODE*)d)[i] = (Py_UNICODE) ch)
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GET_SIZE(u))
#endif
#if CYTHON_COMPILING_IN_PYPY
  #define __Pyx_PyUnicode_Concat(a, b)      PyNumber_Add(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  PyNumber_Add(a, b)
#else
  #define __Pyx_PyUnicode_Concat(a, b)      PyUnicode_Concat(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  ((unlikely((a) == Py_None) || unlikely((b) == Py_None)) ?\
      PyNumber_Add(a, b) : __Pyx_PyUnicode_Concat(a, b))
#endif
#if CYTHON_COMPILING_IN_PYPY
  #if !defined(PyUnicode_DecodeUnicodeEscape)
    #define PyUnicode_DecodeUnicodeEscape(s, size, errors)  PyUnicode_Decode(s, size, "unicode_escape", errors)
  #endif
  #if !defined(PyUnicode_Contains) || (PY_MAJOR_VERSION == 2 && PYPY_VERSION_NUM < 0x07030500)
    #undef PyUnicode_Contains
    #define PyUnicode_Contains(u, s)  PySequence_Contains(u, s)
  #endif
  #if !defined(PyByteArray_Check)
    #define PyByteArray_Check(obj)  PyObject_TypeCheck(obj, &PyByteArray_Type)
  #endif
  #if !defined(PyObject_Format)
    #define PyObject_Format(obj, fmt)  PyObject_CallMethod(obj, "__format__", "O", fmt)
  #endif
#endif
#define __Pyx_PyString_FormatSafe(a, b)   ((unlikely((a) == Py_None || (PyString_Check(b) && !PyString_CheckExact(b)))) ? PyNumber_Remainder(a, b) : __Pyx_PyString_Format(a, b))
#define __Pyx_PyUnicode_FormatSafe(a, b)  ((unlikely((a) == Py_None || (PyUnicode_Check(b) && !PyUnicode_CheckExact(b)))) ? PyNumber_Remainder(a, b) : PyUnicode_Format(a, b))
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyString_Format(a, b)  PyUnicode_Format(a, b)
#else
  #define __Pyx_PyString_Format(a, b)  PyString_Format(a, b)
#endif
#if PY_MAJOR_VERSION < 3 && !defined(PyObject_ASCII)
  #define PyObject_ASCII(o)            PyObject_Repr(o)
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBaseString_Type            PyUnicode_Type
  #define PyStringObject               PyUnicodeObject
  #define PyString_Type                PyUnicode_Type
  #define PyString_Check               PyUnicode_Check
  #define PyString_CheckExact          PyUnicode_CheckExact
#ifndef PyObject_Unicode
  #define PyObject_Unicode             PyObject_Str
#endif
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyBaseString_Check(obj) PyUnicode_Check(obj)
  #define __Pyx_PyBaseString_CheckExact(obj) PyUnicode_CheckExact(obj)
#else
  #define __Pyx_PyBaseString_Check(obj) (PyString_Check(obj) || PyUnicode_Check(obj))
  #define __Pyx_PyBaseString_CheckExact(obj) (PyString_CheckExact(obj) || PyUnicode_CheckExact(obj))
#endif
#if CYTHON_COMPILING_IN_CPYTHON
  #define __Pyx_PySequence_ListKeepNew(obj)\
    (likely(PyList_CheckExact(obj) && Py_REFCNT(obj) == 1) ? __Pyx_NewRef(obj) : PySequence_List(obj))
#else
  #define __Pyx_PySequence_ListKeepNew(obj)  PySequence_List(obj)
#endif
#ifndef PySet_CheckExact
  #define PySet_CheckExact(obj)        __Pyx_IS_TYPE(obj, &PySet_Type)
#endif
#if PY_VERSION_HEX >= 0x030900A4
  #define __Pyx_SET_REFCNT(obj, refcnt) Py_SET_REFCNT(obj, refcnt)
  #define __Pyx_SET_SIZE(obj, size) Py_SET_SIZE(obj, size)
#else
  #define __Pyx_SET_REFCNT(obj, refcnt) Py_REFCNT(obj) = (refcnt)
  #define __Pyx_SET_SIZE(obj, size) Py_SIZE(obj) = (size)
#endif
#if CYTHON_ASSUME_SAFE_MACROS
  #define __Pyx_PySequence_ITEM(o, i) PySequence_ITEM(o, i)
  #define __Pyx_PySequence_SIZE(seq)  Py_SIZE(seq)
  #define __Pyx_PyTuple_SET_ITEM(o, i, v) (PyTuple_SET_ITEM(o, i, v), (0))
  #define __Pyx_PyList_SET_ITEM(o, i, v) (PyList_SET_ITEM(o, i, v), (0))
  #define __Pyx_PyTuple_GET_SIZE(o) PyTuple_GET_SIZE(o)
  #define __Pyx_PyList_GET_SIZE(o) PyList_GET_SIZE(o)
  #define __Pyx_PySet_GET_SIZE(o) PySet_GET_SIZE(o)
  #define __Pyx_PyBytes_GET_SIZE(o) PyBytes_GET_SIZE(o)
  #define __Pyx_PyByteArray_GET_SIZE(o) PyByteArray_GET_SIZE(o)
#else
  #define __Pyx_PySequence_ITEM(o, i) PySequence_GetItem(o, i)
  #define __Pyx_PySequence_SIZE(seq)  PySequence_Size(seq)
  #define __Pyx_PyTuple_SET_ITEM(o, i, v) PyTuple_SetItem(o, i, v)
  #define __Pyx_PyList_SET_ITEM(o, i, v) PyList_SetItem(o, i, v)
  #define __Pyx_PyTuple_GET_SIZE(o) PyTuple_Size(o)
  #define __Pyx_PyList_GET_SIZE(o) PyList_Size(o)
  #define __Pyx_PySet_GET_SIZE(o) PySet_Size(o)
  #define __Pyx_PyBytes_GET_SIZE(o) PyBytes_Size(o)
  #define __Pyx_PyByteArray_GET_SIZE(o) PyByteArray_Size(o)
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyIntObject                  PyLongObject
  #define PyInt_Type                   PyLong_Type
  #define PyInt_Check(op)              PyLong_Check(op)
  #define PyInt_CheckExact(op)         PyLong_CheckExact(op)
  #define __Pyx_Py3Int_Check(op)       PyLong_Check(op)
  #define __Pyx_Py3Int_CheckExact(op)  PyLong_CheckExact(op)
  #define PyInt_FromString             PyLong_FromString
  #define PyInt_FromUnicode            PyLong_FromUnicode
  #define PyInt_FromLong               PyLong_FromLong
  #define PyInt_FromSize_t             PyLong_FromSize_t
  #define PyInt_FromSsize_t            PyLong_FromSsize_t
  #define PyInt_AsLong                 PyLong_AsLong
  #define PyInt_AS_LONG                PyLong_AS_LONG
  #define PyInt_AsSsize_t              PyLong_AsSsize_t
  #define PyInt_AsUnsignedLongMask     PyLong_AsUnsignedLongMask
  #define PyInt_AsUnsignedLongLongMask PyLong_AsUnsignedLongLongMask
  #define PyNumber_Int                 PyNumber_Long
#else
  #define __Pyx_Py3Int_Check(op)       (PyLong_Check(op) || PyInt_Check(op))
  #define __Pyx_Py3Int_CheckExact(op)  (PyLong_CheckExact(op) || PyInt_CheckExact(op))
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBoolObject                 PyLongObject
#endif
#if PY_MAJOR_VERSION >= 3 && CYTHON_COMPILING_IN_PYPY
  #ifndef PyUnicode_InternFromString
    #define PyUnicode_InternFromString(s) PyUnicode_FromString(s)
  #endif
#endif
#if PY_VERSION_HEX < 0x030200A4
  typedef long Py_hash_t;
  #define __Pyx_PyInt_FromHash_t PyInt_FromLong
  #define __Pyx_PyInt_AsHash_t   __Pyx_PyIndex_AsHash_t
#else
  #define __Pyx_PyInt_FromHash_t PyInt_FromSsize_t
  #define __Pyx_PyInt_AsHash_t   __Pyx_PyIndex_AsSsize_t
#endif
#if CYTHON_USE_ASYNC_SLOTS
  #if PY_VERSION_HEX >= 0x030500B1
    #define __Pyx_PyAsyncMethodsStruct PyAsyncMethods
    #define __Pyx_PyType_AsAsync(obj) (Py_TYPE(obj)->tp_as_async)
  #else
    #define __Pyx_PyType_AsAsync(obj) ((__Pyx_PyAsyncMethodsStruct*) (Py_TYPE(obj)->tp_reserved))
  #endif
#else
  #define __Pyx_PyType_AsAsync(obj) NULL
#endif
#ifndef __Pyx_PyAsyncMethodsStruct
    typedef struct {
        unaryfunc am_await;
        unaryfunc am_aiter;
        unaryfunc am_anext;
    } __Pyx_PyAsyncMethodsStruct;
#endif

#if defined(_WIN32) || defined(WIN32) || defined(MS_WINDOWS)
  #if !defined(_USE_MATH_DEFINES)
    #define _USE_MATH_DEFINES
  #endif
#endif
#include <math.h>
#ifdef NAN
#define __PYX_NAN() ((float) NAN)
#else
static CYTHON_INLINE float __PYX_NAN() {
  float value;
  memset(&value, 0xFF, sizeof(value));
  return value;
}
#endif
#if defined(__CYGWIN__) && defined(_LDBL_EQ_DBL)
#define __Pyx_truncl trunc
#else
#define __Pyx_truncl truncl
#endif

#define __PYX_MARK_ERR_POS(f_index, lineno) \
    { __pyx_filename = __pyx_f[f_index]; (void)__pyx_filename; __pyx_lineno = lineno; (void)__pyx_lineno; __pyx_clineno = __LINE__; (void)__pyx_clineno; }
#define __PYX_ERR(f_index, lineno, Ln_error) \
    { __PYX_MARK_ERR_POS(f_index, lineno) goto Ln_error; }

#ifdef CYTHON_EXTERN_C
    #undef __PYX_EXTERN_C
    #define __PYX_EXTERN_C CYTHON_EXTERN_C
#elif defined(__PYX_EXTERN_C)
    #ifdef _MSC_VER
    #pragma message ("Please do not define the '__PYX_EXTERN_C' macro externally. Use 'CYTHON_EXTERN_C' instead.")
    #else
    #warning Please do not define the '__PYX_EXTERN_C' macro externally. Use 'CYTHON_EXTERN_C' instead.
    #endif
#else
    #define __PYX_EXTERN_C extern "C++"
#endif

#define __PYX_HAVE__cuda_rf_gen_module
#define __PYX_HAVE_API__cuda_rf_gen_module
/* Early includes */
#include <string.h>
#include <stdio.h>

    /* Using NumPy API declarations from "numpy/__init__.cython-30.pxd" */
    
#include "numpy/arrayobject.h"
#include "numpy/ndarrayobject.h"
#include "numpy/ndarraytypes.h"
#include "numpy/arrayscalars.h"
#include "numpy/ufuncobject.h"
#include <stdint.h>
#include "basic_ops/basic_array_operations.h"
#include "convolution_ops/convolution.h"
#include "convolution_ops/rbf_convolution.h"
#include "convolution_ops/arccos_convolution.h"
#include "poly_ops/polynomial_operations.h"
#include "rbf_ops/rbf_ops.h"
#ifdef _OPENMP
#include <omp.h>
#endif /* _OPENMP */

#if defined(PYREX_WITHOUT_ASSERTIONS) && !defined(CYTHON_WITHOUT_ASSERTIONS)
#define CYTHON_WITHOUT_ASSERTIONS
#endif

typedef struct {PyObject **p; const char *s; const Py_ssize_t n; const char* encoding;
                const char is_unicode; const char is_str; const char intern; } __Pyx_StringTabEntry;

#define __PYX_DEFAULT_STRING_ENCODING_IS_ASCII 0
#define __PYX_DEFAULT_STRING_ENCODING_IS_UTF8 0
#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT (PY_MAJOR_VERSION >= 3 && __PYX_DEFAULT_STRING_ENCODING_IS_UTF8)
#define __PYX_DEFAULT_STRING_ENCODING ""
#define __Pyx_PyObject_FromString __Pyx_PyBytes_FromString
#define __Pyx_PyObject_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#define __Pyx_uchar_cast(c) ((unsigned char)c)
#define __Pyx_long_cast(x) ((long)x)
#define __Pyx_fits_Py_ssize_t(v, type, is_signed)  (\
    (sizeof(type) < sizeof(Py_ssize_t))  ||\
    (sizeof(type) > sizeof(Py_ssize_t) &&\
          likely(v < (type)PY_SSIZE_T_MAX ||\
                 v == (type)PY_SSIZE_T_MAX)  &&\
          (!is_signed || likely(v > (type)PY_SSIZE_T_MIN ||\
                                v == (type)PY_SSIZE_T_MIN)))  ||\
    (sizeof(type) == sizeof(Py_ssize_t) &&\
          (is_signed || likely(v < (type)PY_SSIZE_T_MAX ||\
                               v == (type)PY_SSIZE_T_MAX)))  )
static CYTHON_INLINE int __Pyx_is_valid_index(Py_ssize_t i, Py_ssize_t limit) {
    return (size_t) i < (size_t) limit;
}
#if defined (__cplusplus) && __cplusplus >= 201103L
    #include <cstdlib>
    #define __Pyx_sst_abs(value) std::abs(value)
#elif SIZEOF_INT >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) abs(value)
#elif SIZEOF_LONG >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) labs(value)
#elif defined (_MSC_VER)
    #define __Pyx_sst_abs(value) ((Py_ssize_t)_abs64(value))
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define __Pyx_sst_abs(value) llabs(value)
#elif defined (__GNUC__)
    #define __Pyx_sst_abs(value) __builtin_llabs(value)
#else
    #define __Pyx_sst_abs(value) ((value<0) ? -value : value)
#endif
static CYTHON_INLINE Py_ssize_t __Pyx_ssize_strlen(const char *s);
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject*);
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject*, Py_ssize_t* length);
static CYTHON_INLINE PyObject* __Pyx_PyByteArray_FromString(const char*);
#define __Pyx_PyByteArray_FromStringAndSize(s, l) PyByteArray_FromStringAndSize((const char*)s, l)
#define __Pyx_PyBytes_FromString        PyBytes_FromString
#define __Pyx_PyBytes_FromStringAndSize PyBytes_FromStringAndSize
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char*);
#if PY_MAJOR_VERSION < 3
    #define __Pyx_PyStr_FromString        __Pyx_PyBytes_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#else
    #define __Pyx_PyStr_FromString        __Pyx_PyUnicode_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyUnicode_FromStringAndSize
#endif
#define __Pyx_PyBytes_AsWritableString(s)     ((char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsWritableSString(s)    ((signed char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsWritableUString(s)    ((unsigned char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsString(s)     ((const char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsSString(s)    ((const signed char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsUString(s)    ((const unsigned char*) PyBytes_AS_STRING(s))
#define __Pyx_PyObject_AsWritableString(s)    ((char*)(__pyx_uintptr_t) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableSString(s)    ((signed char*)(__pyx_uintptr_t) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableUString(s)    ((unsigned char*)(__pyx_uintptr_t) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsSString(s)    ((const signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsUString(s)    ((const unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_FromCString(s)  __Pyx_PyObject_FromString((const char*)s)
#define __Pyx_PyBytes_FromCString(s)   __Pyx_PyBytes_FromString((const char*)s)
#define __Pyx_PyByteArray_FromCString(s)   __Pyx_PyByteArray_FromString((const char*)s)
#define __Pyx_PyStr_FromCString(s)     __Pyx_PyStr_FromString((const char*)s)
#define __Pyx_PyUnicode_FromCString(s) __Pyx_PyUnicode_FromString((const char*)s)
#if CYTHON_COMPILING_IN_LIMITED_API
static CYTHON_INLINE size_t __Pyx_Py_UNICODE_strlen(const wchar_t *u)
{
    const wchar_t *u_end = u;
    while (*u_end++) ;
    return (size_t)(u_end - u - 1);
}
#else
static CYTHON_INLINE size_t __Pyx_Py_UNICODE_strlen(const Py_UNICODE *u)
{
    const Py_UNICODE *u_end = u;
    while (*u_end++) ;
    return (size_t)(u_end - u - 1);
}
#endif
#define __Pyx_PyUnicode_FromOrdinal(o)       PyUnicode_FromOrdinal((int)o)
#define __Pyx_PyUnicode_FromUnicode(u)       PyUnicode_FromUnicode(u, __Pyx_Py_UNICODE_strlen(u))
#define __Pyx_PyUnicode_FromUnicodeAndLength PyUnicode_FromUnicode
#define __Pyx_PyUnicode_AsUnicode            PyUnicode_AsUnicode
#define __Pyx_NewRef(obj) (Py_INCREF(obj), obj)
#define __Pyx_Owned_Py_None(b) __Pyx_NewRef(Py_None)
static CYTHON_INLINE PyObject * __Pyx_PyBool_FromLong(long b);
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject*);
static CYTHON_INLINE int __Pyx_PyObject_IsTrueAndDecref(PyObject*);
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x);
#define __Pyx_PySequence_Tuple(obj)\
    (likely(PyTuple_CheckExact(obj)) ? __Pyx_NewRef(obj) : PySequence_Tuple(obj))
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject*);
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t);
static CYTHON_INLINE Py_hash_t __Pyx_PyIndex_AsHash_t(PyObject*);
#if CYTHON_ASSUME_SAFE_MACROS
#define __pyx_PyFloat_AsDouble(x) (PyFloat_CheckExact(x) ? PyFloat_AS_DOUBLE(x) : PyFloat_AsDouble(x))
#else
#define __pyx_PyFloat_AsDouble(x) PyFloat_AsDouble(x)
#endif
#define __pyx_PyFloat_AsFloat(x) ((float) __pyx_PyFloat_AsDouble(x))
#if PY_MAJOR_VERSION >= 3
#define __Pyx_PyNumber_Int(x) (PyLong_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Long(x))
#else
#define __Pyx_PyNumber_Int(x) (PyInt_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Int(x))
#endif
#if CYTHON_USE_PYLONG_INTERNALS
  #if PY_VERSION_HEX >= 0x030C00A7
  #ifndef _PyLong_SIGN_MASK
    #define _PyLong_SIGN_MASK 3
  #endif
  #ifndef _PyLong_NON_SIZE_BITS
    #define _PyLong_NON_SIZE_BITS 3
  #endif
  #define __Pyx_PyLong_Sign(x)  (((PyLongObject*)x)->long_value.lv_tag & _PyLong_SIGN_MASK)
  #define __Pyx_PyLong_IsNeg(x)  ((__Pyx_PyLong_Sign(x) & 2) != 0)
  #define __Pyx_PyLong_IsNonNeg(x)  (!__Pyx_PyLong_IsNeg(x))
  #define __Pyx_PyLong_IsZero(x)  (__Pyx_PyLong_Sign(x) & 1)
  #define __Pyx_PyLong_IsPos(x)  (__Pyx_PyLong_Sign(x) == 0)
  #define __Pyx_PyLong_CompactValueUnsigned(x)  (__Pyx_PyLong_Digits(x)[0])
  #define __Pyx_PyLong_DigitCount(x)  ((Py_ssize_t) (((PyLongObject*)x)->long_value.lv_tag >> _PyLong_NON_SIZE_BITS))
  #define __Pyx_PyLong_SignedDigitCount(x)\
        ((1 - (Py_ssize_t) __Pyx_PyLong_Sign(x)) * __Pyx_PyLong_DigitCount(x))
  #if defined(PyUnstable_Long_IsCompact) && defined(PyUnstable_Long_CompactValue)
    #define __Pyx_PyLong_IsCompact(x)     PyUnstable_Long_IsCompact((PyLongObject*) x)
    #define __Pyx_PyLong_CompactValue(x)  PyUnstable_Long_CompactValue((PyLongObject*) x)
  #else
    #define __Pyx_PyLong_IsCompact(x)     (((PyLongObject*)x)->long_value.lv_tag < (2 << _PyLong_NON_SIZE_BITS))
    #define __Pyx_PyLong_CompactValue(x)  ((1 - (Py_ssize_t) __Pyx_PyLong_Sign(x)) * (Py_ssize_t) __Pyx_PyLong_Digits(x)[0])
  #endif
  typedef Py_ssize_t  __Pyx_compact_pylong;
  typedef size_t  __Pyx_compact_upylong;
  #else  // Py < 3.12
  #define __Pyx_PyLong_IsNeg(x)  (Py_SIZE(x) < 0)
  #define __Pyx_PyLong_IsNonNeg(x)  (Py_SIZE(x) >= 0)
  #define __Pyx_PyLong_IsZero(x)  (Py_SIZE(x) == 0)
  #define __Pyx_PyLong_IsPos(x)  (Py_SIZE(x) > 0)
  #define __Pyx_PyLong_CompactValueUnsigned(x)  ((Py_SIZE(x) == 0) ? 0 : __Pyx_PyLong_Digits(x)[0])
  #define __Pyx_PyLong_DigitCount(x)  __Pyx_sst_abs(Py_SIZE(x))
  #define __Pyx_PyLong_SignedDigitCount(x)  Py_SIZE(x)
  #define __Pyx_PyLong_IsCompact(x)  (Py_SIZE(x) == 0 || Py_SIZE(x) == 1 || Py_SIZE(x) == -1)
  #define __Pyx_PyLong_CompactValue(x)\
        ((Py_SIZE(x) == 0) ? (sdigit) 0 : ((Py_SIZE(x) < 0) ? -(sdigit)__Pyx_PyLong_Digits(x)[0] : (sdigit)__Pyx_PyLong_Digits(x)[0]))
  typedef sdigit  __Pyx_compact_pylong;
  typedef digit  __Pyx_compact_upylong;
  #endif
  #if PY_VERSION_HEX >= 0x030C00A5
  #define __Pyx_PyLong_Digits(x)  (((PyLongObject*)x)->long_value.ob_digit)
  #else
  #define __Pyx_PyLong_Digits(x)  (((PyLongObject*)x)->ob_digit)
  #endif
#endif
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
#include <string.h>
static int __Pyx_sys_getdefaultencoding_not_ascii;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    PyObject* ascii_chars_u = NULL;
    PyObject* ascii_chars_b = NULL;
    const char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    if (strcmp(default_encoding_c, "ascii") == 0) {
        __Pyx_sys_getdefaultencoding_not_ascii = 0;
    } else {
        char ascii_chars[128];
        int c;
        for (c = 0; c < 128; c++) {
            ascii_chars[c] = (char) c;
        }
        __Pyx_sys_getdefaultencoding_not_ascii = 1;
        ascii_chars_u = PyUnicode_DecodeASCII(ascii_chars, 128, NULL);
        if (!ascii_chars_u) goto bad;
        ascii_chars_b = PyUnicode_AsEncodedString(ascii_chars_u, default_encoding_c, NULL);
        if (!ascii_chars_b || !PyBytes_Check(ascii_chars_b) || memcmp(ascii_chars, PyBytes_AS_STRING(ascii_chars_b), 128) != 0) {
            PyErr_Format(
                PyExc_ValueError,
                "This module compiled with c_string_encoding=ascii, but default encoding '%.200s' is not a superset of ascii.",
                default_encoding_c);
            goto bad;
        }
        Py_DECREF(ascii_chars_u);
        Py_DECREF(ascii_chars_b);
    }
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    Py_XDECREF(ascii_chars_u);
    Py_XDECREF(ascii_chars_b);
    return -1;
}
#endif
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT && PY_MAJOR_VERSION >= 3
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_DecodeUTF8(c_str, size, NULL)
#else
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_Decode(c_str, size, __PYX_DEFAULT_STRING_ENCODING, NULL)
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
#include <string.h>
static char* __PYX_DEFAULT_STRING_ENCODING;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) (const char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    __PYX_DEFAULT_STRING_ENCODING = (char*) malloc(strlen(default_encoding_c) + 1);
    if (!__PYX_DEFAULT_STRING_ENCODING) goto bad;
    strcpy(__PYX_DEFAULT_STRING_ENCODING, default_encoding_c);
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    return -1;
}
#endif
#endif


/* Test for GCC > 2.95 */
#if defined(__GNUC__)     && (__GNUC__ > 2 || (__GNUC__ == 2 && (__GNUC_MINOR__ > 95)))
  #define likely(x)   __builtin_expect(!!(x), 1)
  #define unlikely(x) __builtin_expect(!!(x), 0)
#else /* !__GNUC__ or GCC < 2.95 */
  #define likely(x)   (x)
  #define unlikely(x) (x)
#endif /* __GNUC__ */
static CYTHON_INLINE void __Pyx_pretend_to_initialize(void* ptr) { (void)ptr; }

#if !CYTHON_USE_MODULE_STATE
static PyObject *__pyx_m = NULL;
#endif
static int __pyx_lineno;
static int __pyx_clineno = 0;
static const char * __pyx_cfilenm = __FILE__;
static const char *__pyx_filename;

/* Header.proto */
#if !defined(CYTHON_CCOMPLEX)
  #if defined(__cplusplus)
    #define CYTHON_CCOMPLEX 1
  #elif (defined(_Complex_I) && !defined(_MSC_VER)) || ((defined (__STDC_VERSION__) && __STDC_VERSION__ >= 201112L) && !defined(__STDC_NO_COMPLEX__))
    #define CYTHON_CCOMPLEX 1
  #else
    #define CYTHON_CCOMPLEX 0
  #endif
#endif
#if CYTHON_CCOMPLEX
  #ifdef __cplusplus
    #include <complex>
  #else
    #include <complex.h>
  #endif
#endif
#if CYTHON_CCOMPLEX && !defined(__cplusplus) && defined(__sun__) && defined(__GNUC__)
  #undef _Complex_I
  #define _Complex_I 1.0fj
#endif

/* #### Code section: filename_table ### */

static const char *__pyx_f[] = {
  "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx",
  "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx",
  "__init__.cython-30.pxd",
  "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx",
  "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx",
  "xGPR/random_feature_generation/gpu_rf_gen/cuda_rf_gen_module.pyx",
  "type.pxd",
};
/* #### Code section: utility_code_proto_before_types ### */
/* ForceInitThreads.proto */
#ifndef __PYX_FORCE_INIT_THREADS
  #define __PYX_FORCE_INIT_THREADS 0
#endif

/* BufferFormatStructs.proto */
struct __Pyx_StructField_;
#define __PYX_BUF_FLAGS_PACKED_STRUCT (1 << 0)
typedef struct {
  const char* name;
  struct __Pyx_StructField_* fields;
  size_t size;
  size_t arraysize[8];
  int ndim;
  char typegroup;
  char is_unsigned;
  int flags;
} __Pyx_TypeInfo;
typedef struct __Pyx_StructField_ {
  __Pyx_TypeInfo* type;
  const char* name;
  size_t offset;
} __Pyx_StructField;
typedef struct {
  __Pyx_StructField* field;
  size_t parent_offset;
} __Pyx_BufFmt_StackElem;
typedef struct {
  __Pyx_StructField root;
  __Pyx_BufFmt_StackElem* head;
  size_t fmt_offset;
  size_t new_count, enc_count;
  size_t struct_alignment;
  int is_complex;
  char enc_type;
  char new_packmode;
  char enc_packmode;
  char is_valid_array;
} __Pyx_BufFmt_Context;

/* #### Code section: numeric_typedefs ### */

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":730
 * # in Cython to enable them only on the right systems.
 * 
 * ctypedef npy_int8       int8_t             # <<<<<<<<<<<<<<
 * ctypedef npy_int16      int16_t
 * ctypedef npy_int32      int32_t
 */
typedef npy_int8 __pyx_t_5numpy_int8_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":731
 * 
 * ctypedef npy_int8       int8_t
 * ctypedef npy_int16      int16_t             # <<<<<<<<<<<<<<
 * ctypedef npy_int32      int32_t
 * ctypedef npy_int64      int64_t
 */
typedef npy_int16 __pyx_t_5numpy_int16_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":732
 * ctypedef npy_int8       int8_t
 * ctypedef npy_int16      int16_t
 * ctypedef npy_int32      int32_t             # <<<<<<<<<<<<<<
 * ctypedef npy_int64      int64_t
 * #ctypedef npy_int96      int96_t
 */
typedef npy_int32 __pyx_t_5numpy_int32_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":733
 * ctypedef npy_int16      int16_t
 * ctypedef npy_int32      int32_t
 * ctypedef npy_int64      int64_t             # <<<<<<<<<<<<<<
 * #ctypedef npy_int96      int96_t
 * #ctypedef npy_int128     int128_t
 */
typedef npy_int64 __pyx_t_5numpy_int64_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":737
 * #ctypedef npy_int128     int128_t
 * 
 * ctypedef npy_uint8      uint8_t             # <<<<<<<<<<<<<<
 * ctypedef npy_uint16     uint16_t
 * ctypedef npy_uint32     uint32_t
 */
typedef npy_uint8 __pyx_t_5numpy_uint8_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":738
 * 
 * ctypedef npy_uint8      uint8_t
 * ctypedef npy_uint16     uint16_t             # <<<<<<<<<<<<<<
 * ctypedef npy_uint32     uint32_t
 * ctypedef npy_uint64     uint64_t
 */
typedef npy_uint16 __pyx_t_5numpy_uint16_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":739
 * ctypedef npy_uint8      uint8_t
 * ctypedef npy_uint16     uint16_t
 * ctypedef npy_uint32     uint32_t             # <<<<<<<<<<<<<<
 * ctypedef npy_uint64     uint64_t
 * #ctypedef npy_uint96     uint96_t
 */
typedef npy_uint32 __pyx_t_5numpy_uint32_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":740
 * ctypedef npy_uint16     uint16_t
 * ctypedef npy_uint32     uint32_t
 * ctypedef npy_uint64     uint64_t             # <<<<<<<<<<<<<<
 * #ctypedef npy_uint96     uint96_t
 * #ctypedef npy_uint128    uint128_t
 */
typedef npy_uint64 __pyx_t_5numpy_uint64_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":744
 * #ctypedef npy_uint128    uint128_t
 * 
 * ctypedef npy_float32    float32_t             # <<<<<<<<<<<<<<
 * ctypedef npy_float64    float64_t
 * #ctypedef npy_float80    float80_t
 */
typedef npy_float32 __pyx_t_5numpy_float32_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":745
 * 
 * ctypedef npy_float32    float32_t
 * ctypedef npy_float64    float64_t             # <<<<<<<<<<<<<<
 * #ctypedef npy_float80    float80_t
 * #ctypedef npy_float128   float128_t
 */
typedef npy_float64 __pyx_t_5numpy_float64_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":754
 * # The int types are mapped a bit surprising --
 * # numpy.int corresponds to 'l' and numpy.long to 'q'
 * ctypedef npy_long       int_t             # <<<<<<<<<<<<<<
 * ctypedef npy_longlong   longlong_t
 * 
 */
typedef npy_long __pyx_t_5numpy_int_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":755
 * # numpy.int corresponds to 'l' and numpy.long to 'q'
 * ctypedef npy_long       int_t
 * ctypedef npy_longlong   longlong_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_ulong      uint_t
 */
typedef npy_longlong __pyx_t_5numpy_longlong_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":757
 * ctypedef npy_longlong   longlong_t
 * 
 * ctypedef npy_ulong      uint_t             # <<<<<<<<<<<<<<
 * ctypedef npy_ulonglong  ulonglong_t
 * 
 */
typedef npy_ulong __pyx_t_5numpy_uint_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":758
 * 
 * ctypedef npy_ulong      uint_t
 * ctypedef npy_ulonglong  ulonglong_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_intp       intp_t
 */
typedef npy_ulonglong __pyx_t_5numpy_ulonglong_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":760
 * ctypedef npy_ulonglong  ulonglong_t
 * 
 * ctypedef npy_intp       intp_t             # <<<<<<<<<<<<<<
 * ctypedef npy_uintp      uintp_t
 * 
 */
typedef npy_intp __pyx_t_5numpy_intp_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":761
 * 
 * ctypedef npy_intp       intp_t
 * ctypedef npy_uintp      uintp_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_double     float_t
 */
typedef npy_uintp __pyx_t_5numpy_uintp_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":763
 * ctypedef npy_uintp      uintp_t
 * 
 * ctypedef npy_double     float_t             # <<<<<<<<<<<<<<
 * ctypedef npy_double     double_t
 * ctypedef npy_longdouble longdouble_t
 */
typedef npy_double __pyx_t_5numpy_float_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":764
 * 
 * ctypedef npy_double     float_t
 * ctypedef npy_double     double_t             # <<<<<<<<<<<<<<
 * ctypedef npy_longdouble longdouble_t
 * 
 */
typedef npy_double __pyx_t_5numpy_double_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":765
 * ctypedef npy_double     float_t
 * ctypedef npy_double     double_t
 * ctypedef npy_longdouble longdouble_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_cfloat      cfloat_t
 */
typedef npy_longdouble __pyx_t_5numpy_longdouble_t;
/* #### Code section: complex_type_declarations ### */
/* Declarations.proto */
#if CYTHON_CCOMPLEX && (1) && (!0 || __cplusplus)
  #ifdef __cplusplus
    typedef ::std::complex< float > __pyx_t_float_complex;
  #else
    typedef float _Complex __pyx_t_float_complex;
  #endif
#else
    typedef struct { float real, imag; } __pyx_t_float_complex;
#endif
static CYTHON_INLINE __pyx_t_float_complex __pyx_t_float_complex_from_parts(float, float);

/* Declarations.proto */
#if CYTHON_CCOMPLEX && (1) && (!0 || __cplusplus)
  #ifdef __cplusplus
    typedef ::std::complex< double > __pyx_t_double_complex;
  #else
    typedef double _Complex __pyx_t_double_complex;
  #endif
#else
    typedef struct { double real, imag; } __pyx_t_double_complex;
#endif
static CYTHON_INLINE __pyx_t_double_complex __pyx_t_double_complex_from_parts(double, double);

/* #### Code section: type_declarations ### */

/*--- Type declarations ---*/

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":767
 * ctypedef npy_longdouble longdouble_t
 * 
 * ctypedef npy_cfloat      cfloat_t             # <<<<<<<<<<<<<<
 * ctypedef npy_cdouble     cdouble_t
 * ctypedef npy_clongdouble clongdouble_t
 */
typedef npy_cfloat __pyx_t_5numpy_cfloat_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":768
 * 
 * ctypedef npy_cfloat      cfloat_t
 * ctypedef npy_cdouble     cdouble_t             # <<<<<<<<<<<<<<
 * ctypedef npy_clongdouble clongdouble_t
 * 
 */
typedef npy_cdouble __pyx_t_5numpy_cdouble_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":769
 * ctypedef npy_cfloat      cfloat_t
 * ctypedef npy_cdouble     cdouble_t
 * ctypedef npy_clongdouble clongdouble_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_cdouble     complex_t
 */
typedef npy_clongdouble __pyx_t_5numpy_clongdouble_t;

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":771
 * ctypedef npy_clongdouble clongdouble_t
 * 
 * ctypedef npy_cdouble     complex_t             # <<<<<<<<<<<<<<
 * 
 * cdef inline object PyArray_MultiIterNew1(a):
 */
typedef npy_cdouble __pyx_t_5numpy_complex_t;
/* #### Code section: utility_code_proto ### */

/* --- Runtime support code (head) --- */
/* Refnanny.proto */
#ifndef CYTHON_REFNANNY
  #define CYTHON_REFNANNY 0
#endif
#if CYTHON_REFNANNY
  typedef struct {
    void (*INCREF)(void*, PyObject*, Py_ssize_t);
    void (*DECREF)(void*, PyObject*, Py_ssize_t);
    void (*GOTREF)(void*, PyObject*, Py_ssize_t);
    void (*GIVEREF)(void*, PyObject*, Py_ssize_t);
    void* (*SetupContext)(const char*, Py_ssize_t, const char*);
    void (*FinishContext)(void**);
  } __Pyx_RefNannyAPIStruct;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNanny = NULL;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname);
  #define __Pyx_RefNannyDeclarations void *__pyx_refnanny = NULL;
#ifdef WITH_THREAD
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          if (acquire_gil) {\
              PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), (__LINE__), (__FILE__));\
              PyGILState_Release(__pyx_gilstate_save);\
          } else {\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), (__LINE__), (__FILE__));\
          }
  #define __Pyx_RefNannyFinishContextNogil() {\
              PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();\
              __Pyx_RefNannyFinishContext();\
              PyGILState_Release(__pyx_gilstate_save);\
          }
#else
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), (__LINE__), (__FILE__))
  #define __Pyx_RefNannyFinishContextNogil() __Pyx_RefNannyFinishContext()
#endif
  #define __Pyx_RefNannyFinishContextNogil() {\
              PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();\
              __Pyx_RefNannyFinishContext();\
              PyGILState_Release(__pyx_gilstate_save);\
          }
  #define __Pyx_RefNannyFinishContext()\
          __Pyx_RefNanny->FinishContext(&__pyx_refnanny)
  #define __Pyx_INCREF(r)  __Pyx_RefNanny->INCREF(__pyx_refnanny, (PyObject *)(r), (__LINE__))
  #define __Pyx_DECREF(r)  __Pyx_RefNanny->DECREF(__pyx_refnanny, (PyObject *)(r), (__LINE__))
  #define __Pyx_GOTREF(r)  __Pyx_RefNanny->GOTREF(__pyx_refnanny, (PyObject *)(r), (__LINE__))
  #define __Pyx_GIVEREF(r) __Pyx_RefNanny->GIVEREF(__pyx_refnanny, (PyObject *)(r), (__LINE__))
  #define __Pyx_XINCREF(r)  do { if((r) == NULL); else {__Pyx_INCREF(r); }} while(0)
  #define __Pyx_XDECREF(r)  do { if((r) == NULL); else {__Pyx_DECREF(r); }} while(0)
  #define __Pyx_XGOTREF(r)  do { if((r) == NULL); else {__Pyx_GOTREF(r); }} while(0)
  #define __Pyx_XGIVEREF(r) do { if((r) == NULL); else {__Pyx_GIVEREF(r);}} while(0)
#else
  #define __Pyx_RefNannyDeclarations
  #define __Pyx_RefNannySetupContext(name, acquire_gil)
  #define __Pyx_RefNannyFinishContextNogil()
  #define __Pyx_RefNannyFinishContext()
  #define __Pyx_INCREF(r) Py_INCREF(r)
  #define __Pyx_DECREF(r) Py_DECREF(r)
  #define __Pyx_GOTREF(r)
  #define __Pyx_GIVEREF(r)
  #define __Pyx_XINCREF(r) Py_XINCREF(r)
  #define __Pyx_XDECREF(r) Py_XDECREF(r)
  #define __Pyx_XGOTREF(r)
  #define __Pyx_XGIVEREF(r)
#endif
#define __Pyx_Py_XDECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; Py_XDECREF(tmp);\
    } while (0)
#define __Pyx_XDECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_XDECREF(tmp);\
    } while (0)
#define __Pyx_DECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_DECREF(tmp);\
    } while (0)
#define __Pyx_CLEAR(r)    do { PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);} while(0)
#define __Pyx_XCLEAR(r)   do { if((r) != NULL) {PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);}} while(0)

/* PyErrExceptionMatches.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_ExceptionMatches(err) __Pyx_PyErr_ExceptionMatchesInState(__pyx_tstate, err)
static CYTHON_INLINE int __Pyx_PyErr_ExceptionMatchesInState(PyThreadState* tstate, PyObject* err);
#else
#define __Pyx_PyErr_ExceptionMatches(err)  PyErr_ExceptionMatches(err)
#endif

/* PyThreadStateGet.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyThreadState_declare  PyThreadState *__pyx_tstate;
#define __Pyx_PyThreadState_assign  __pyx_tstate = __Pyx_PyThreadState_Current;
#if PY_VERSION_HEX >= 0x030C00A6
#define __Pyx_PyErr_Occurred()  (__pyx_tstate->current_exception != NULL)
#define __Pyx_PyErr_CurrentExceptionType()  (__pyx_tstate->current_exception ? (PyObject*) Py_TYPE(__pyx_tstate->current_exception) : (PyObject*) NULL)
#else
#define __Pyx_PyErr_Occurred()  (__pyx_tstate->curexc_type != NULL)
#define __Pyx_PyErr_CurrentExceptionType()  (__pyx_tstate->curexc_type)
#endif
#else
#define __Pyx_PyThreadState_declare
#define __Pyx_PyThreadState_assign
#define __Pyx_PyErr_Occurred()  (PyErr_Occurred() != NULL)
#define __Pyx_PyErr_CurrentExceptionType()  PyErr_Occurred()
#endif

/* PyErrFetchRestore.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_Clear() __Pyx_ErrRestore(NULL, NULL, NULL)
#define __Pyx_ErrRestoreWithState(type, value, tb)  __Pyx_ErrRestoreInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)    __Pyx_ErrFetchInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  __Pyx_ErrRestoreInState(__pyx_tstate, type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)    __Pyx_ErrFetchInState(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030C00A6
#define __Pyx_PyErr_SetNone(exc) (Py_INCREF(exc), __Pyx_ErrRestore((exc), NULL, NULL))
#else
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#endif
#else
#define __Pyx_PyErr_Clear() PyErr_Clear()
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#define __Pyx_ErrRestoreWithState(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestoreInState(tstate, type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchInState(tstate, type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)  PyErr_Fetch(type, value, tb)
#endif

/* PyObjectGetAttrStr.proto */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStr(PyObject* obj, PyObject* attr_name);
#else
#define __Pyx_PyObject_GetAttrStr(o,n) PyObject_GetAttr(o,n)
#endif

/* PyObjectGetAttrStrNoError.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStrNoError(PyObject* obj, PyObject* attr_name);

/* GetBuiltinName.proto */
static PyObject *__Pyx_GetBuiltinName(PyObject *name);

/* GetTopmostException.proto */
#if CYTHON_USE_EXC_INFO_STACK && CYTHON_FAST_THREAD_STATE
static _PyErr_StackItem * __Pyx_PyErr_GetTopmostException(PyThreadState *tstate);
#endif

/* SaveResetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ExceptionSave(type, value, tb)  __Pyx__ExceptionSave(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionSave(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#define __Pyx_ExceptionReset(type, value, tb)  __Pyx__ExceptionReset(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionReset(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
#else
#define __Pyx_ExceptionSave(type, value, tb)   PyErr_GetExcInfo(type, value, tb)
#define __Pyx_ExceptionReset(type, value, tb)  PyErr_SetExcInfo(type, value, tb)
#endif

/* GetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_GetException(type, value, tb)  __Pyx__GetException(__pyx_tstate, type, value, tb)
static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb);
#endif

/* PyObjectCall.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw);
#else
#define __Pyx_PyObject_Call(func, arg, kw) PyObject_Call(func, arg, kw)
#endif

/* RaiseException.proto */
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause);

/* TupleAndListFromArray.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyList_FromArray(PyObject *const *src, Py_ssize_t n);
static CYTHON_INLINE PyObject* __Pyx_PyTuple_FromArray(PyObject *const *src, Py_ssize_t n);
#endif

/* IncludeStringH.proto */
#include <string.h>

/* BytesEquals.proto */
static CYTHON_INLINE int __Pyx_PyBytes_Equals(PyObject* s1, PyObject* s2, int equals);

/* UnicodeEquals.proto */
static CYTHON_INLINE int __Pyx_PyUnicode_Equals(PyObject* s1, PyObject* s2, int equals);

/* fastcall.proto */
#if CYTHON_AVOID_BORROWED_REFS
    #define __Pyx_Arg_VARARGS(args, i) PySequence_GetItem(args, i)
#elif CYTHON_ASSUME_SAFE_MACROS
    #define __Pyx_Arg_VARARGS(args, i) PyTuple_GET_ITEM(args, i)
#else
    #define __Pyx_Arg_VARARGS(args, i) PyTuple_GetItem(args, i)
#endif
#if CYTHON_AVOID_BORROWED_REFS
    #define __Pyx_Arg_NewRef_VARARGS(arg) __Pyx_NewRef(arg)
    #define __Pyx_Arg_XDECREF_VARARGS(arg) Py_XDECREF(arg)
#else
    #define __Pyx_Arg_NewRef_VARARGS(arg) arg // no-op
    #define __Pyx_Arg_XDECREF_VARARGS(arg) // no-op - arg is borrowed
#endif
#define __Pyx_NumKwargs_VARARGS(kwds) PyDict_Size(kwds)
#define __Pyx_KwValues_VARARGS(args, nargs) NULL
#define __Pyx_GetKwValue_VARARGS(kw, kwvalues, s) __Pyx_PyDict_GetItemStrWithError(kw, s)
#define __Pyx_KwargsAsDict_VARARGS(kw, kwvalues) PyDict_Copy(kw)
#if CYTHON_METH_FASTCALL
    #define __Pyx_Arg_FASTCALL(args, i) args[i]
    #define __Pyx_NumKwargs_FASTCALL(kwds) PyTuple_GET_SIZE(kwds)
    #define __Pyx_KwValues_FASTCALL(args, nargs) ((args) + (nargs))
    static CYTHON_INLINE PyObject * __Pyx_GetKwValue_FASTCALL(PyObject *kwnames, PyObject *const *kwvalues, PyObject *s);
    #define __Pyx_KwargsAsDict_FASTCALL(kw, kwvalues) _PyStack_AsDict(kwvalues, kw)
    #define __Pyx_Arg_NewRef_FASTCALL(arg) arg // no-op, __Pyx_Arg_FASTCALL is direct and this needs
    #define __Pyx_Arg_XDECREF_FASTCALL(arg)  // no-op - arg was returned from array
#else
    #define __Pyx_Arg_FASTCALL __Pyx_Arg_VARARGS
    #define __Pyx_NumKwargs_FASTCALL __Pyx_NumKwargs_VARARGS
    #define __Pyx_KwValues_FASTCALL __Pyx_KwValues_VARARGS
    #define __Pyx_GetKwValue_FASTCALL __Pyx_GetKwValue_VARARGS
    #define __Pyx_KwargsAsDict_FASTCALL __Pyx_KwargsAsDict_VARARGS
    #define __Pyx_Arg_NewRef_FASTCALL(arg) __Pyx_Arg_NewRef_VARARGS(arg)
    #define __Pyx_Arg_XDECREF_FASTCALL(arg) __Pyx_Arg_XDECREF_VARARGS(arg)
#endif
#if CYTHON_COMPILING_IN_CPYTHON && CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
#define __Pyx_ArgsSlice_VARARGS(args, start, stop) __Pyx_PyTuple_FromArray(&__Pyx_Arg_VARARGS(args, start), stop - start)
#define __Pyx_ArgsSlice_FASTCALL(args, start, stop) __Pyx_PyTuple_FromArray(&__Pyx_Arg_FASTCALL(args, start), stop - start)
#else
#define __Pyx_ArgsSlice_VARARGS(args, start, stop) PyTuple_GetSlice(args, start, stop)
#define __Pyx_ArgsSlice_FASTCALL(args, start, stop) PyTuple_GetSlice(args, start, stop)
#endif

/* RaiseArgTupleInvalid.proto */
static void __Pyx_RaiseArgtupleInvalid(const char* func_name, int exact,
    Py_ssize_t num_min, Py_ssize_t num_max, Py_ssize_t num_found);

/* RaiseDoubleKeywords.proto */
static void __Pyx_RaiseDoubleKeywordsError(const char* func_name, PyObject* kw_name);

/* ParseKeywords.proto */
static int __Pyx_ParseOptionalKeywords(PyObject *kwds, PyObject *const *kwvalues,
    PyObject **argnames[],
    PyObject *kwds2, PyObject *values[], Py_ssize_t num_pos_args,
    const char* function_name);

/* GetItemInt.proto */
#define __Pyx_GetItemInt(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Fast(o, (Py_ssize_t)i, is_list, wraparound, boundscheck) :\
    (is_list ? (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL) :\
               __Pyx_GetItemInt_Generic(o, to_py_func(i))))
#define __Pyx_GetItemInt_List(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_List_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
#define __Pyx_GetItemInt_Tuple(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Tuple_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "tuple index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
static PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j);
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i,
                                                     int is_list, int wraparound, int boundscheck);

/* PyIntCompare.proto */
static CYTHON_INLINE int __Pyx_PyInt_BoolEqObjC(PyObject *op1, PyObject *op2, long intval, long inplace);

/* PyIntCompare.proto */
static CYTHON_INLINE int __Pyx_PyInt_BoolNeObjC(PyObject *op1, PyObject *op2, long intval, long inplace);

/* DictGetItem.proto */
#if PY_MAJOR_VERSION >= 3 && !CYTHON_COMPILING_IN_PYPY
static PyObject *__Pyx_PyDict_GetItem(PyObject *d, PyObject* key);
#define __Pyx_PyObject_Dict_GetItem(obj, name)\
    (likely(PyDict_CheckExact(obj)) ?\
     __Pyx_PyDict_GetItem(obj, name) : PyObject_GetItem(obj, name))
#else
#define __Pyx_PyDict_GetItem(d, key) PyObject_GetItem(d, key)
#define __Pyx_PyObject_Dict_GetItem(obj, name)  PyObject_GetItem(obj, name)
#endif

/* PyDictVersioning.proto */
#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
#define __PYX_DICT_VERSION_INIT  ((PY_UINT64_T) -1)
#define __PYX_GET_DICT_VERSION(dict)  (((PyDictObject*)(dict))->ma_version_tag)
#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)\
    (version_var) = __PYX_GET_DICT_VERSION(dict);\
    (cache_var) = (value);
#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP) {\
    static PY_UINT64_T __pyx_dict_version = 0;\
    static PyObject *__pyx_dict_cached_value = NULL;\
    if (likely(__PYX_GET_DICT_VERSION(DICT) == __pyx_dict_version)) {\
        (VAR) = __pyx_dict_cached_value;\
    } else {\
        (VAR) = __pyx_dict_cached_value = (LOOKUP);\
        __pyx_dict_version = __PYX_GET_DICT_VERSION(DICT);\
    }\
}
static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj);
static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj);
static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version);
#else
#define __PYX_GET_DICT_VERSION(dict)  (0)
#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)
#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP)  (VAR) = (LOOKUP);
#endif

/* GetModuleGlobalName.proto */
#if CYTHON_USE_DICT_VERSIONS
#define __Pyx_GetModuleGlobalName(var, name)  do {\
    static PY_UINT64_T __pyx_dict_version = 0;\
    static PyObject *__pyx_dict_cached_value = NULL;\
    (var) = (likely(__pyx_dict_version == __PYX_GET_DICT_VERSION(__pyx_d))) ?\
        (likely(__pyx_dict_cached_value) ? __Pyx_NewRef(__pyx_dict_cached_value) : __Pyx_GetBuiltinName(name)) :\
        __Pyx__GetModuleGlobalName(name, &__pyx_dict_version, &__pyx_dict_cached_value);\
} while(0)
#define __Pyx_GetModuleGlobalNameUncached(var, name)  do {\
    PY_UINT64_T __pyx_dict_version;\
    PyObject *__pyx_dict_cached_value;\
    (var) = __Pyx__GetModuleGlobalName(name, &__pyx_dict_version, &__pyx_dict_cached_value);\
} while(0)
static PyObject *__Pyx__GetModuleGlobalName(PyObject *name, PY_UINT64_T *dict_version, PyObject **dict_cached_value);
#else
#define __Pyx_GetModuleGlobalName(var, name)  (var) = __Pyx__GetModuleGlobalName(name)
#define __Pyx_GetModuleGlobalNameUncached(var, name)  (var) = __Pyx__GetModuleGlobalName(name)
static CYTHON_INLINE PyObject *__Pyx__GetModuleGlobalName(PyObject *name);
#endif

/* PyFunctionFastCall.proto */
#if CYTHON_FAST_PYCALL
#if !CYTHON_VECTORCALL
#define __Pyx_PyFunction_FastCall(func, args, nargs)\
    __Pyx_PyFunction_FastCallDict((func), (args), (nargs), NULL)
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs);
#endif
#define __Pyx_BUILD_ASSERT_EXPR(cond)\
    (sizeof(char [1 - 2*!(cond)]) - 1)
#ifndef Py_MEMBER_SIZE
#define Py_MEMBER_SIZE(type, member) sizeof(((type *)0)->member)
#endif
#if !CYTHON_VECTORCALL
#if PY_VERSION_HEX >= 0x03080000
  #include "frameobject.h"
#if PY_VERSION_HEX >= 0x030b00a6 && !CYTHON_COMPILING_IN_LIMITED_API
  #ifndef Py_BUILD_CORE
    #define Py_BUILD_CORE 1
  #endif
  #include "internal/pycore_frame.h"
#endif
  #define __Pxy_PyFrame_Initialize_Offsets()
  #define __Pyx_PyFrame_GetLocalsplus(frame)  ((frame)->f_localsplus)
#else
  static size_t __pyx_pyframe_localsplus_offset = 0;
  #include "frameobject.h"
  #define __Pxy_PyFrame_Initialize_Offsets()\
    ((void)__Pyx_BUILD_ASSERT_EXPR(sizeof(PyFrameObject) == offsetof(PyFrameObject, f_localsplus) + Py_MEMBER_SIZE(PyFrameObject, f_localsplus)),\
     (void)(__pyx_pyframe_localsplus_offset = ((size_t)PyFrame_Type.tp_basicsize) - Py_MEMBER_SIZE(PyFrameObject, f_localsplus)))
  #define __Pyx_PyFrame_GetLocalsplus(frame)\
    (assert(__pyx_pyframe_localsplus_offset), (PyObject **)(((char *)(frame)) + __pyx_pyframe_localsplus_offset))
#endif
#endif
#endif

/* PyObjectCallMethO.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg);
#endif

/* PyObjectFastCall.proto */
#define __Pyx_PyObject_FastCall(func, args, nargs)  __Pyx_PyObject_FastCallDict(func, args, (size_t)(nargs), NULL)
static CYTHON_INLINE PyObject* __Pyx_PyObject_FastCallDict(PyObject *func, PyObject **args, size_t nargs, PyObject *kwargs);

/* decode_c_string_utf16.proto */
static CYTHON_INLINE PyObject *__Pyx_PyUnicode_DecodeUTF16(const char *s, Py_ssize_t size, const char *errors) {
    int byteorder = 0;
    return PyUnicode_DecodeUTF16(s, size, errors, &byteorder);
}
static CYTHON_INLINE PyObject *__Pyx_PyUnicode_DecodeUTF16LE(const char *s, Py_ssize_t size, const char *errors) {
    int byteorder = -1;
    return PyUnicode_DecodeUTF16(s, size, errors, &byteorder);
}
static CYTHON_INLINE PyObject *__Pyx_PyUnicode_DecodeUTF16BE(const char *s, Py_ssize_t size, const char *errors) {
    int byteorder = 1;
    return PyUnicode_DecodeUTF16(s, size, errors, &byteorder);
}

/* decode_c_string.proto */
static CYTHON_INLINE PyObject* __Pyx_decode_c_string(
         const char* cstring, Py_ssize_t start, Py_ssize_t stop,
         const char* encoding, const char* errors,
         PyObject* (*decode_func)(const char *s, Py_ssize_t size, const char *errors));

/* ArgTypeTest.proto */
#define __Pyx_ArgTypeTest(obj, type, none_allowed, name, exact)\
    ((likely(__Pyx_IS_TYPE(obj, type) | (none_allowed && (obj == Py_None)))) ? 1 :\
        __Pyx__ArgTypeTest(obj, type, name, exact))
static int __Pyx__ArgTypeTest(PyObject *obj, PyTypeObject *type, const char *name, int exact);

/* IsLittleEndian.proto */
static CYTHON_INLINE int __Pyx_Is_Little_Endian(void);

/* BufferFormatCheck.proto */
static const char* __Pyx_BufFmt_CheckString(__Pyx_BufFmt_Context* ctx, const char* ts);
static void __Pyx_BufFmt_Init(__Pyx_BufFmt_Context* ctx,
                              __Pyx_BufFmt_StackElem* stack,
                              __Pyx_TypeInfo* type);

/* BufferGetAndValidate.proto */
#define __Pyx_GetBufferAndValidate(buf, obj, dtype, flags, nd, cast, stack)\
    ((obj == Py_None || obj == NULL) ?\
    (__Pyx_ZeroBuffer(buf), 0) :\
    __Pyx__GetBufferAndValidate(buf, obj, dtype, flags, nd, cast, stack))
static int  __Pyx__GetBufferAndValidate(Py_buffer* buf, PyObject* obj,
    __Pyx_TypeInfo* dtype, int flags, int nd, int cast, __Pyx_BufFmt_StackElem* stack);
static void __Pyx_ZeroBuffer(Py_buffer* buf);
static CYTHON_INLINE void __Pyx_SafeReleaseBuffer(Py_buffer* info);
static Py_ssize_t __Pyx_minusones[] = { -1, -1, -1, -1, -1, -1, -1, -1 };
static Py_ssize_t __Pyx_zeros[] = { 0, 0, 0, 0, 0, 0, 0, 0 };

/* PyObjectCallOneArg.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg);

/* ObjectGetItem.proto */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject *__Pyx_PyObject_GetItem(PyObject *obj, PyObject *key);
#else
#define __Pyx_PyObject_GetItem(obj, key)  PyObject_GetItem(obj, key)
#endif

/* PyIntBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_SubtractObjC(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check);
#else
#define __Pyx_PyInt_SubtractObjC(op1, op2, intval, inplace, zerodivision_check)\
    (inplace ? PyNumber_InPlaceSubtract(op1, op2) : PyNumber_Subtract(op1, op2))
#endif

/* SliceObject.proto */
#define __Pyx_PyObject_DelSlice(obj, cstart, cstop, py_start, py_stop, py_slice, has_cstart, has_cstop, wraparound)\
    __Pyx_PyObject_SetSlice(obj, (PyObject*)NULL, cstart, cstop, py_start, py_stop, py_slice, has_cstart, has_cstop, wraparound)
static CYTHON_INLINE int __Pyx_PyObject_SetSlice(
        PyObject* obj, PyObject* value, Py_ssize_t cstart, Py_ssize_t cstop,
        PyObject** py_start, PyObject** py_stop, PyObject** py_slice,
        int has_cstart, int has_cstop, int wraparound);

/* PyIntBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_RemainderObjC(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check);
#else
#define __Pyx_PyInt_RemainderObjC(op1, op2, intval, inplace, zerodivision_check)\
    (inplace ? PyNumber_InPlaceRemainder(op1, op2) : PyNumber_Remainder(op1, op2))
#endif

/* PyIntBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_MultiplyCObj(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check);
#else
#define __Pyx_PyInt_MultiplyCObj(op1, op2, intval, inplace, zerodivision_check)\
    (inplace ? PyNumber_InPlaceMultiply(op1, op2) : PyNumber_Multiply(op1, op2))
#endif

/* PyIntBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_TrueDivideObjC(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check);
#else
#define __Pyx_PyInt_TrueDivideObjC(op1, op2, intval, inplace, zerodivision_check)\
    (inplace ? PyNumber_InPlaceTrueDivide(op1, op2) : PyNumber_TrueDivide(op1, op2))
#endif

/* PyIntBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_AddObjC(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check);
#else
#define __Pyx_PyInt_AddObjC(op1, op2, intval, inplace, zerodivision_check)\
    (inplace ? PyNumber_InPlaceAdd(op1, op2) : PyNumber_Add(op1, op2))
#endif

/* TypeImport.proto */
#ifndef __PYX_HAVE_RT_ImportType_proto_3_0_3
#define __PYX_HAVE_RT_ImportType_proto_3_0_3
#if defined (__STDC_VERSION__) && __STDC_VERSION__ >= 201112L
#include <stdalign.h>
#endif
#if (defined (__STDC_VERSION__) && __STDC_VERSION__ >= 201112L) || __cplusplus >= 201103L
#define __PYX_GET_STRUCT_ALIGNMENT_3_0_3(s) alignof(s)
#else
#define __PYX_GET_STRUCT_ALIGNMENT_3_0_3(s) sizeof(void*)
#endif
enum __Pyx_ImportType_CheckSize_3_0_3 {
   __Pyx_ImportType_CheckSize_Error_3_0_3 = 0,
   __Pyx_ImportType_CheckSize_Warn_3_0_3 = 1,
   __Pyx_ImportType_CheckSize_Ignore_3_0_3 = 2
};
static PyTypeObject *__Pyx_ImportType_3_0_3(PyObject* module, const char *module_name, const char *class_name, size_t size, size_t alignment, enum __Pyx_ImportType_CheckSize_3_0_3 check_size);
#endif

/* Import.proto */
static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level);

/* ImportDottedModule.proto */
static PyObject *__Pyx_ImportDottedModule(PyObject *name, PyObject *parts_tuple);
#if PY_MAJOR_VERSION >= 3
static PyObject *__Pyx_ImportDottedModule_WalkParts(PyObject *module, PyObject *name, PyObject *parts_tuple);
#endif

/* IncludeStructmemberH.proto */
#include <structmember.h>

/* FixUpExtensionType.proto */
#if CYTHON_USE_TYPE_SPECS
static int __Pyx_fix_up_extension_type_from_spec(PyType_Spec *spec, PyTypeObject *type);
#endif

/* FetchSharedCythonModule.proto */
static PyObject *__Pyx_FetchSharedCythonABIModule(void);

/* FetchCommonType.proto */
#if !CYTHON_USE_TYPE_SPECS
static PyTypeObject* __Pyx_FetchCommonType(PyTypeObject* type);
#else
static PyTypeObject* __Pyx_FetchCommonTypeFromSpec(PyObject *module, PyType_Spec *spec, PyObject *bases);
#endif

/* PyMethodNew.proto */
#if CYTHON_COMPILING_IN_LIMITED_API
static PyObject *__Pyx_PyMethod_New(PyObject *func, PyObject *self, PyObject *typ) {
    PyObject *typesModule=NULL, *methodType=NULL, *result=NULL;
    CYTHON_UNUSED_VAR(typ);
    if (!self)
        return __Pyx_NewRef(func);
    typesModule = PyImport_ImportModule("types");
    if (!typesModule) return NULL;
    methodType = PyObject_GetAttrString(typesModule, "MethodType");
    Py_DECREF(typesModule);
    if (!methodType) return NULL;
    result = PyObject_CallFunctionObjArgs(methodType, func, self, NULL);
    Py_DECREF(methodType);
    return result;
}
#elif PY_MAJOR_VERSION >= 3
static PyObject *__Pyx_PyMethod_New(PyObject *func, PyObject *self, PyObject *typ) {
    CYTHON_UNUSED_VAR(typ);
    if (!self)
        return __Pyx_NewRef(func);
    return PyMethod_New(func, self);
}
#else
    #define __Pyx_PyMethod_New PyMethod_New
#endif

/* PyVectorcallFastCallDict.proto */
#if CYTHON_METH_FASTCALL
static CYTHON_INLINE PyObject *__Pyx_PyVectorcall_FastCallDict(PyObject *func, __pyx_vectorcallfunc vc, PyObject *const *args, size_t nargs, PyObject *kw);
#endif

/* CythonFunctionShared.proto */
#define __Pyx_CyFunction_USED
#define __Pyx_CYFUNCTION_STATICMETHOD  0x01
#define __Pyx_CYFUNCTION_CLASSMETHOD   0x02
#define __Pyx_CYFUNCTION_CCLASS        0x04
#define __Pyx_CYFUNCTION_COROUTINE     0x08
#define __Pyx_CyFunction_GetClosure(f)\
    (((__pyx_CyFunctionObject *) (f))->func_closure)
#if PY_VERSION_HEX < 0x030900B1 || CYTHON_COMPILING_IN_LIMITED_API
  #define __Pyx_CyFunction_GetClassObj(f)\
      (((__pyx_CyFunctionObject *) (f))->func_classobj)
#else
  #define __Pyx_CyFunction_GetClassObj(f)\
      ((PyObject*) ((PyCMethodObject *) (f))->mm_class)
#endif
#define __Pyx_CyFunction_SetClassObj(f, classobj)\
    __Pyx__CyFunction_SetClassObj((__pyx_CyFunctionObject *) (f), (classobj))
#define __Pyx_CyFunction_Defaults(type, f)\
    ((type *)(((__pyx_CyFunctionObject *) (f))->defaults))
#define __Pyx_CyFunction_SetDefaultsGetter(f, g)\
    ((__pyx_CyFunctionObject *) (f))->defaults_getter = (g)
typedef struct {
#if CYTHON_COMPILING_IN_LIMITED_API
    PyObject_HEAD
    PyObject *func;
#elif PY_VERSION_HEX < 0x030900B1
    PyCFunctionObject func;
#else
    PyCMethodObject func;
#endif
#if CYTHON_BACKPORT_VECTORCALL
    __pyx_vectorcallfunc func_vectorcall;
#endif
#if PY_VERSION_HEX < 0x030500A0 || CYTHON_COMPILING_IN_LIMITED_API
    PyObject *func_weakreflist;
#endif
    PyObject *func_dict;
    PyObject *func_name;
    PyObject *func_qualname;
    PyObject *func_doc;
    PyObject *func_globals;
    PyObject *func_code;
    PyObject *func_closure;
#if PY_VERSION_HEX < 0x030900B1 || CYTHON_COMPILING_IN_LIMITED_API
    PyObject *func_classobj;
#endif
    void *defaults;
    int defaults_pyobjects;
    size_t defaults_size;  // used by FusedFunction for copying defaults
    int flags;
    PyObject *defaults_tuple;
    PyObject *defaults_kwdict;
    PyObject *(*defaults_getter)(PyObject *);
    PyObject *func_annotations;
    PyObject *func_is_coroutine;
} __pyx_CyFunctionObject;
#undef __Pyx_CyOrPyCFunction_Check
#define __Pyx_CyFunction_Check(obj)  __Pyx_TypeCheck(obj, __pyx_CyFunctionType)
#define __Pyx_CyOrPyCFunction_Check(obj)  __Pyx_TypeCheck2(obj, __pyx_CyFunctionType, &PyCFunction_Type)
#define __Pyx_CyFunction_CheckExact(obj)  __Pyx_IS_TYPE(obj, __pyx_CyFunctionType)
static CYTHON_INLINE int __Pyx__IsSameCyOrCFunction(PyObject *func, void *cfunc);
#undef __Pyx_IsSameCFunction
#define __Pyx_IsSameCFunction(func, cfunc)   __Pyx__IsSameCyOrCFunction(func, cfunc)
static PyObject *__Pyx_CyFunction_Init(__pyx_CyFunctionObject* op, PyMethodDef *ml,
                                      int flags, PyObject* qualname,
                                      PyObject *closure,
                                      PyObject *module, PyObject *globals,
                                      PyObject* code);
static CYTHON_INLINE void __Pyx__CyFunction_SetClassObj(__pyx_CyFunctionObject* f, PyObject* classobj);
static CYTHON_INLINE void *__Pyx_CyFunction_InitDefaults(PyObject *m,
                                                         size_t size,
                                                         int pyobjects);
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsTuple(PyObject *m,
                                                            PyObject *tuple);
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsKwDict(PyObject *m,
                                                             PyObject *dict);
static CYTHON_INLINE void __Pyx_CyFunction_SetAnnotationsDict(PyObject *m,
                                                              PyObject *dict);
static int __pyx_CyFunction_init(PyObject *module);
#if CYTHON_METH_FASTCALL
static PyObject * __Pyx_CyFunction_Vectorcall_NOARGS(PyObject *func, PyObject *const *args, size_t nargsf, PyObject *kwnames);
static PyObject * __Pyx_CyFunction_Vectorcall_O(PyObject *func, PyObject *const *args, size_t nargsf, PyObject *kwnames);
static PyObject * __Pyx_CyFunction_Vectorcall_FASTCALL_KEYWORDS(PyObject *func, PyObject *const *args, size_t nargsf, PyObject *kwnames);
static PyObject * __Pyx_CyFunction_Vectorcall_FASTCALL_KEYWORDS_METHOD(PyObject *func, PyObject *const *args, size_t nargsf, PyObject *kwnames);
#if CYTHON_BACKPORT_VECTORCALL
#define __Pyx_CyFunction_func_vectorcall(f) (((__pyx_CyFunctionObject*)f)->func_vectorcall)
#else
#define __Pyx_CyFunction_func_vectorcall(f) (((PyCFunctionObject*)f)->vectorcall)
#endif
#endif

/* CythonFunction.proto */
static PyObject *__Pyx_CyFunction_New(PyMethodDef *ml,
                                      int flags, PyObject* qualname,
                                      PyObject *closure,
                                      PyObject *module, PyObject *globals,
                                      PyObject* code);

/* CLineInTraceback.proto */
#ifdef CYTHON_CLINE_IN_TRACEBACK
#define __Pyx_CLineForTraceback(tstate, c_line)  (((CYTHON_CLINE_IN_TRACEBACK)) ? c_line : 0)
#else
static int __Pyx_CLineForTraceback(PyThreadState *tstate, int c_line);
#endif

/* CodeObjectCache.proto */
#if !CYTHON_COMPILING_IN_LIMITED_API
typedef struct {
    PyCodeObject* code_object;
    int code_line;
} __Pyx_CodeObjectCacheEntry;
struct __Pyx_CodeObjectCache {
    int count;
    int max_count;
    __Pyx_CodeObjectCacheEntry* entries;
};
static struct __Pyx_CodeObjectCache __pyx_code_cache = {0,0,NULL};
static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line);
static PyCodeObject *__pyx_find_code_object(int code_line);
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object);
#endif

/* AddTraceback.proto */
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename);

/* BufferStructDeclare.proto */
typedef struct {
  Py_ssize_t shape, strides, suboffsets;
} __Pyx_Buf_DimInfo;
typedef struct {
  size_t refcount;
  Py_buffer pybuffer;
} __Pyx_Buffer;
typedef struct {
  __Pyx_Buffer *rcbuffer;
  char *data;
  __Pyx_Buf_DimInfo diminfo[8];
} __Pyx_LocalBuf_ND;

#if PY_MAJOR_VERSION < 3
    static int __Pyx_GetBuffer(PyObject *obj, Py_buffer *view, int flags);
    static void __Pyx_ReleaseBuffer(Py_buffer *view);
#else
    #define __Pyx_GetBuffer PyObject_GetBuffer
    #define __Pyx_ReleaseBuffer PyBuffer_Release
#endif


/* GCCDiagnostics.proto */
#if !defined(__INTEL_COMPILER) && defined(__GNUC__) && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 6))
#define __Pyx_HAS_GCC_DIAGNOSTIC
#endif

/* RealImag.proto */
#if CYTHON_CCOMPLEX
  #ifdef __cplusplus
    #define __Pyx_CREAL(z) ((z).real())
    #define __Pyx_CIMAG(z) ((z).imag())
  #else
    #define __Pyx_CREAL(z) (__real__(z))
    #define __Pyx_CIMAG(z) (__imag__(z))
  #endif
#else
    #define __Pyx_CREAL(z) ((z).real)
    #define __Pyx_CIMAG(z) ((z).imag)
#endif
#if defined(__cplusplus) && CYTHON_CCOMPLEX\
        && (defined(_WIN32) || defined(__clang__) || (defined(__GNUC__) && (__GNUC__ >= 5 || __GNUC__ == 4 && __GNUC_MINOR__ >= 4 )) || __cplusplus >= 201103)
    #define __Pyx_SET_CREAL(z,x) ((z).real(x))
    #define __Pyx_SET_CIMAG(z,y) ((z).imag(y))
#else
    #define __Pyx_SET_CREAL(z,x) __Pyx_CREAL(z) = (x)
    #define __Pyx_SET_CIMAG(z,y) __Pyx_CIMAG(z) = (y)
#endif

/* Arithmetic.proto */
#if CYTHON_CCOMPLEX && (1) && (!0 || __cplusplus)
    #define __Pyx_c_eq_float(a, b)   ((a)==(b))
    #define __Pyx_c_sum_float(a, b)  ((a)+(b))
    #define __Pyx_c_diff_float(a, b) ((a)-(b))
    #define __Pyx_c_prod_float(a, b) ((a)*(b))
    #define __Pyx_c_quot_float(a, b) ((a)/(b))
    #define __Pyx_c_neg_float(a)     (-(a))
  #ifdef __cplusplus
    #define __Pyx_c_is_zero_float(z) ((z)==(float)0)
    #define __Pyx_c_conj_float(z)    (::std::conj(z))
    #if 1
        #define __Pyx_c_abs_float(z)     (::std::abs(z))
        #define __Pyx_c_pow_float(a, b)  (::std::pow(a, b))
    #endif
  #else
    #define __Pyx_c_is_zero_float(z) ((z)==0)
    #define __Pyx_c_conj_float(z)    (conjf(z))
    #if 1
        #define __Pyx_c_abs_float(z)     (cabsf(z))
        #define __Pyx_c_pow_float(a, b)  (cpowf(a, b))
    #endif
 #endif
#else
    static CYTHON_INLINE int __Pyx_c_eq_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_sum_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_diff_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_prod_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_quot_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_neg_float(__pyx_t_float_complex);
    static CYTHON_INLINE int __Pyx_c_is_zero_float(__pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_conj_float(__pyx_t_float_complex);
    #if 1
        static CYTHON_INLINE float __Pyx_c_abs_float(__pyx_t_float_complex);
        static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_pow_float(__pyx_t_float_complex, __pyx_t_float_complex);
    #endif
#endif

/* Arithmetic.proto */
#if CYTHON_CCOMPLEX && (1) && (!0 || __cplusplus)
    #define __Pyx_c_eq_double(a, b)   ((a)==(b))
    #define __Pyx_c_sum_double(a, b)  ((a)+(b))
    #define __Pyx_c_diff_double(a, b) ((a)-(b))
    #define __Pyx_c_prod_double(a, b) ((a)*(b))
    #define __Pyx_c_quot_double(a, b) ((a)/(b))
    #define __Pyx_c_neg_double(a)     (-(a))
  #ifdef __cplusplus
    #define __Pyx_c_is_zero_double(z) ((z)==(double)0)
    #define __Pyx_c_conj_double(z)    (::std::conj(z))
    #if 1
        #define __Pyx_c_abs_double(z)     (::std::abs(z))
        #define __Pyx_c_pow_double(a, b)  (::std::pow(a, b))
    #endif
  #else
    #define __Pyx_c_is_zero_double(z) ((z)==0)
    #define __Pyx_c_conj_double(z)    (conj(z))
    #if 1
        #define __Pyx_c_abs_double(z)     (cabs(z))
        #define __Pyx_c_pow_double(a, b)  (cpow(a, b))
    #endif
 #endif
#else
    static CYTHON_INLINE int __Pyx_c_eq_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_sum_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_diff_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_prod_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_quot_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_neg_double(__pyx_t_double_complex);
    static CYTHON_INLINE int __Pyx_c_is_zero_double(__pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_conj_double(__pyx_t_double_complex);
    #if 1
        static CYTHON_INLINE double __Pyx_c_abs_double(__pyx_t_double_complex);
        static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_pow_double(__pyx_t_double_complex, __pyx_t_double_complex);
    #endif
#endif

/* CIntFromPy.proto */
static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE size_t __Pyx_PyInt_As_size_t(PyObject *);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value);

/* FormatTypeName.proto */
#if CYTHON_COMPILING_IN_LIMITED_API
typedef PyObject *__Pyx_TypeName;
#define __Pyx_FMT_TYPENAME "%U"
static __Pyx_TypeName __Pyx_PyType_GetName(PyTypeObject* tp);
#define __Pyx_DECREF_TypeName(obj) Py_XDECREF(obj)
#else
typedef const char *__Pyx_TypeName;
#define __Pyx_FMT_TYPENAME "%.200s"
#define __Pyx_PyType_GetName(tp) ((tp)->tp_name)
#define __Pyx_DECREF_TypeName(obj)
#endif

/* CIntFromPy.proto */
static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *);

/* FastTypeChecks.proto */
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_TypeCheck(obj, type) __Pyx_IsSubtype(Py_TYPE(obj), (PyTypeObject *)type)
#define __Pyx_TypeCheck2(obj, type1, type2) __Pyx_IsAnySubtype2(Py_TYPE(obj), (PyTypeObject *)type1, (PyTypeObject *)type2)
static CYTHON_INLINE int __Pyx_IsSubtype(PyTypeObject *a, PyTypeObject *b);
static CYTHON_INLINE int __Pyx_IsAnySubtype2(PyTypeObject *cls, PyTypeObject *a, PyTypeObject *b);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches(PyObject *err, PyObject *type);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *type1, PyObject *type2);
#else
#define __Pyx_TypeCheck(obj, type) PyObject_TypeCheck(obj, (PyTypeObject *)type)
#define __Pyx_TypeCheck2(obj, type1, type2) (PyObject_TypeCheck(obj, (PyTypeObject *)type1) || PyObject_TypeCheck(obj, (PyTypeObject *)type2))
#define __Pyx_PyErr_GivenExceptionMatches(err, type) PyErr_GivenExceptionMatches(err, type)
#define __Pyx_PyErr_GivenExceptionMatches2(err, type1, type2) (PyErr_GivenExceptionMatches(err, type1) || PyErr_GivenExceptionMatches(err, type2))
#endif
#define __Pyx_PyErr_ExceptionMatches2(err1, err2)  __Pyx_PyErr_GivenExceptionMatches2(__Pyx_PyErr_CurrentExceptionType(), err1, err2)
#define __Pyx_PyException_Check(obj) __Pyx_TypeCheck(obj, PyExc_Exception)

/* CheckBinaryVersion.proto */
static unsigned long __Pyx_get_runtime_version();
static int __Pyx_check_binary_version(unsigned long ct_version, unsigned long rt_version, int allow_newer);

/* InitStrings.proto */
static int __Pyx_InitStrings(__Pyx_StringTabEntry *t);

/* #### Code section: module_declarations ### */
static CYTHON_INLINE PyObject *__pyx_f_5numpy_7ndarray_4base_base(PyArrayObject *__pyx_v_self); /* proto*/
static CYTHON_INLINE PyArray_Descr *__pyx_f_5numpy_7ndarray_5descr_descr(PyArrayObject *__pyx_v_self); /* proto*/
static CYTHON_INLINE int __pyx_f_5numpy_7ndarray_4ndim_ndim(PyArrayObject *__pyx_v_self); /* proto*/
static CYTHON_INLINE npy_intp *__pyx_f_5numpy_7ndarray_5shape_shape(PyArrayObject *__pyx_v_self); /* proto*/
static CYTHON_INLINE npy_intp *__pyx_f_5numpy_7ndarray_7strides_strides(PyArrayObject *__pyx_v_self); /* proto*/
static CYTHON_INLINE npy_intp __pyx_f_5numpy_7ndarray_4size_size(PyArrayObject *__pyx_v_self); /* proto*/
static CYTHON_INLINE char *__pyx_f_5numpy_7ndarray_4data_data(PyArrayObject *__pyx_v_self); /* proto*/

/* Module declarations from "cython" */

/* Module declarations from "libc.string" */

/* Module declarations from "libc.stdio" */

/* Module declarations from "__builtin__" */

/* Module declarations from "cpython.type" */

/* Module declarations from "cpython" */

/* Module declarations from "cpython.object" */

/* Module declarations from "cpython.ref" */

/* Module declarations from "numpy" */

/* Module declarations from "numpy" */

/* Module declarations from "libc" */

/* Module declarations from "libc.stdint" */

/* Module declarations from "libcpp" */

/* Module declarations from "cuda_rf_gen_module" */
/* #### Code section: typeinfo ### */
static __Pyx_TypeInfo __Pyx_TypeInfo_nn___pyx_t_5numpy_int64_t = { "int64_t", NULL, sizeof(__pyx_t_5numpy_int64_t), { 0 }, 0, __PYX_IS_UNSIGNED(__pyx_t_5numpy_int64_t) ? 'U' : 'I', __PYX_IS_UNSIGNED(__pyx_t_5numpy_int64_t), 0 };
/* #### Code section: before_global_var ### */
#define __Pyx_MODULE_NAME "cuda_rf_gen_module"
extern int __pyx_module_is_main_cuda_rf_gen_module;
int __pyx_module_is_main_cuda_rf_gen_module = 0;

/* Implementation of "cuda_rf_gen_module" */
/* #### Code section: global_var ### */
static PyObject *__pyx_builtin_ValueError;
static PyObject *__pyx_builtin_range;
static PyObject *__pyx_builtin_ImportError;
/* #### Code section: string_decls ### */
static const char __pyx_k_Z[] = "Z";
static const char __pyx_k_i[] = "i";
static const char __pyx_k_j[] = "j";
static const char __pyx_k_k[] = "k";
static const char __pyx_k_cp[] = "cp";
static const char __pyx_k_np[] = "np";
static const char __pyx_k_os[] = "os";
static const char __pyx_k__70[] = "*";
static const char __pyx_k__96[] = "?";
static const char __pyx_k_max[] = "max";
static const char __pyx_k_ptr[] = "ptr";
static const char __pyx_k_sum[] = "sum";
static const char __pyx_k_addr[] = "addr";
static const char __pyx_k_axis[] = "axis";
static const char __pyx_k_beta[] = "beta_";
static const char __pyx_k_ceil[] = "ceil";
static const char __pyx_k_copy[] = "copy";
static const char __pyx_k_cupy[] = "cupy";
static const char __pyx_k_data[] = "data";
static const char __pyx_k_int8[] = "int8";
static const char __pyx_k_log2[] = "log2";
static const char __pyx_k_main[] = "__main__";
static const char __pyx_k_math[] = "math";
static const char __pyx_k_name[] = "__name__";
static const char __pyx_k_spec[] = "__spec__";
static const char __pyx_k_sqrt[] = "sqrt";
static const char __pyx_k_test[] = "__test__";
static const char __pyx_k_dtype[] = "dtype";
static const char __pyx_k_flags[] = "flags";
static const char __pyx_k_floor[] = "floor";
static const char __pyx_k_int32[] = "int32";
static const char __pyx_k_numpy[] = "numpy";
static const char __pyx_k_radem[] = "radem";
static const char __pyx_k_range[] = "range";
static const char __pyx_k_shape[] = "shape";
static const char __pyx_k_sigma[] = "sigma";
static const char __pyx_k_zeros[] = "zeros";
static const char __pyx_k_chiArr[] = "chiArr";
static const char __pyx_k_cutoff[] = "cutoff";
static const char __pyx_k_import[] = "__import__";
static const char __pyx_k_inputX[] = "inputX";
static const char __pyx_k_logdim[] = "logdim";
static const char __pyx_k_cpArray[] = "cpArray";
static const char __pyx_k_cutoff2[] = "cutoff2";
static const char __pyx_k_errCode[] = "errCode";
static const char __pyx_k_float32[] = "float32";
static const char __pyx_k_float64[] = "float64";
static const char __pyx_k_sampler[] = "sampler";
static const char __pyx_k_addr_chi[] = "addr_chi";
static const char __pyx_k_cudaSRHT[] = "cudaSRHT";
static const char __pyx_k_gradient[] = "gradient";
static const char __pyx_k_no_error[] = "no_error";
static const char __pyx_k_sigmaMap[] = "sigmaMap";
static const char __pyx_k_addr_grad[] = "addr_grad";
static const char __pyx_k_radem_ptr[] = "radem_ptr";
static const char __pyx_k_reshapedX[] = "reshapedX";
static const char __pyx_k_sigmaVals[] = "sigmaVals";
static const char __pyx_k_startPos2[] = "startPos2";
static const char __pyx_k_ValueError[] = "ValueError";
static const char __pyx_k_addr_input[] = "addr_input";
static const char __pyx_k_addr_radem[] = "addr_radem";
static const char __pyx_k_betaHparam[] = "betaHparam";
static const char __pyx_k_gpuPolyFHT[] = "gpuPolyFHT";
static const char __pyx_k_inputArray[] = "inputArray";
static const char __pyx_k_numThreads[] = "numThreads";
static const char __pyx_k_polydegree[] = "polydegree";
static const char __pyx_k_ImportError[] = "ImportError";
static const char __pyx_k_addr_output[] = "addr_output";
static const char __pyx_k_cudaRBFGrad[] = "cudaRBFGrad";
static const char __pyx_k_gpuConvGrad[] = "gpuConvGrad";
static const char __pyx_k_kernelOrder[] = "kernelOrder";
static const char __pyx_k_num_repeats[] = "num_repeats";
static const char __pyx_k_outputArray[] = "outputArray";
static const char __pyx_k_preSumFeats[] = "preSumFeats";
static const char __pyx_k_scalingTerm[] = "scalingTerm";
static const char __pyx_k_sigmaHparam[] = "sigmaHparam";
static const char __pyx_k_C_CONTIGUOUS[] = "C_CONTIGUOUS";
static const char __pyx_k_featureArray[] = "featureArray";
static const char __pyx_k_fitIntercept[] = "fitIntercept";
static const char __pyx_k_initializing[] = "_initializing";
static const char __pyx_k_is_coroutine[] = "_is_coroutine";
static const char __pyx_k_sigmaMap_ptr[] = "sigmaMap_ptr";
static const char __pyx_k_addr_gradient[] = "addr_gradient";
static const char __pyx_k_class_getitem[] = "__class_getitem__";
static const char __pyx_k_gpuConv1dFGen[] = "gpuConv1dFGen";
static const char __pyx_k_reshapedXCopy[] = "reshapedXCopy";
static const char __pyx_k_startPosition[] = "startPosition";
static const char __pyx_k_addr_reshapedX[] = "addr_reshapedX";
static const char __pyx_k_addr_sigma_map[] = "addr_sigma_map";
static const char __pyx_k_precompWeights[] = "precompWeights";
static const char __pyx_k_scaling_factor[] = "scaling_factor";
static const char __pyx_k_addr_sigma_vals[] = "addr_sigma_vals";
static const char __pyx_k_cudaMiniARDGrad[] = "cudaMiniARDGrad";
static const char __pyx_k_gpuGraphPolyFHT[] = "gpuGraphPolyFHT";
static const char __pyx_k_numLengthscales[] = "numLengthscales";
static const char __pyx_k_rbfNormConstant[] = "rbfNormConstant";
static const char __pyx_k_addr_preSumFeats[] = "addr_preSumFeats";
static const char __pyx_k_compression_size[] = "compression_size";
static const char __pyx_k_gpuConv1dMaxpool[] = "gpuConv1dMaxpool";
static const char __pyx_k_numExpectedFeats[] = "numExpectedFeats";
static const char __pyx_k_addr_featureArray[] = "addr_featureArray";
static const char __pyx_k_addr_random_feats[] = "addr_random_feats";
static const char __pyx_k_addr_reshapedCopy[] = "addr_reshapedCopy";
static const char __pyx_k_cudaRBFFeatureGen[] = "cudaRBFFeatureGen";
static const char __pyx_k_asyncio_coroutines[] = "asyncio.coroutines";
static const char __pyx_k_cline_in_traceback[] = "cline_in_traceback";
static const char __pyx_k_cudaExactQuadratic[] = "cudaExactQuadratic";
static const char __pyx_k_cuda_rf_gen_module[] = "cuda_rf_gen_module";
static const char __pyx_k_radem_must_be_int8[] = "radem must be int8.";
static const char __pyx_k_cudaPySORFTransform[] = "cudaPySORFTransform";
static const char __pyx_k_gpuConv1dArcCosFGen[] = "gpuConv1dArcCosFGen";
static const char __pyx_k_X_must_be_a_3d_array[] = "X must be a 3d array.";
static const char __pyx_k_addr_precomp_weights[] = "addr_precomp_weights";
static const char __pyx_k_Fatal_error_encountered[] = "Fatal error encountered.";
static const char __pyx_k_radem_must_be_a_3d_array[] = "radem must be a 3d array.";
static const char __pyx_k_radem_must_be_of_type_int8[] = "radem must be of type int8.";
static const char __pyx_k_Incorrect_array_dims_passed[] = "Incorrect array dims passed.";
static const char __pyx_k_Incorrect_data_types_passed[] = "Incorrect data types passed.";
static const char __pyx_k_Incorrect_data_types_supplied[] = "Incorrect data types supplied.";
static const char __pyx_k_chiArr_shape_0_must_polydegree[] = "chiArr.shape[0] must == polydegree.";
static const char __pyx_k_Both_inputArray_and_outputArray[] = "Both inputArray and outputArray for the exact quadratic must be 2d arrays.";
static const char __pyx_k_Inconsistent_array_types_passed[] = "Inconsistent array types passed to wrapped C++ function.";
static const char __pyx_k_The_input_and_chiArr_arrays_are[] = "The input and chiArr arrays are of inconsistent types.";
static const char __pyx_k_The_number_of_datapoints_in_the[] = "The number of datapoints in the outputs and the inputs do not agree.";
static const char __pyx_k_Unexpected_array_type_passed_to[] = "Unexpected array type passed to a wrapped C++ function.";
static const char __pyx_k_chiArr_input_to_RBF_feature_gen[] = "chiArr input to RBF feature gen is of incorrect size.";
static const char __pyx_k_chiArr_shape_0_must_radem_shape[] = "chiArr.shape[0] must == radem.shape[2].";
static const char __pyx_k_chiArr_shape_1_must_radem_shape[] = "chiArr.shape[1] must == radem.shape[2].";
static const char __pyx_k_dim1_of_the_input_array_must_be[] = "dim1 of the input array must be a power of 2 >= 2.";
static const char __pyx_k_numpy_core_multiarray_failed_to[] = "numpy.core.multiarray failed to import";
static const char __pyx_k_Compression_size_must_be_num_rff[] = "Compression size must be <= num rffs but >= 2.";
static const char __pyx_k_Fatal_error_encountered_in_CudaR[] = "Fatal error encountered in CudaRBFFeatureGen.";
static const char __pyx_k_Fatal_error_encountered_in_RBF_f[] = "Fatal error encountered in RBF feature gen.";
static const char __pyx_k_Fatal_error_encountered_in_doubl[] = "Fatal error encountered in doubleCudaRBFFeatureGen.";
static const char __pyx_k_Fatal_error_encountered_in_float[] = "Fatal error encountered in floatCudaSORF3d.";
static const char __pyx_k_Fatal_error_encountered_while_pe[] = "Fatal error encountered while performing FHT RF generation.";
static const char __pyx_k_Inconsistent_types_passed_to_a_w[] = "Inconsistent types passed to a wrapped C++ function.";
static const char __pyx_k_Incorrect_array_dims_passed_to_a[] = "Incorrect array dims passed to a wrapped RBF feature gen function.";
static const char __pyx_k_Incorrect_array_dims_passed_to_f[] = "Incorrect array dims passed to floatCudaPySORFTransform.";
static const char __pyx_k_One_or_more_arguments_is_not_C_c[] = "One or more arguments is not C contiguous.";
static const char __pyx_k_One_or_more_arguments_to_a_wrapp[] = "One or more arguments to a wrapped RBF feature gen function is not C contiguous.";
static const char __pyx_k_One_or_more_arguments_to_cpuSORF[] = "One or more arguments to cpuSORFTransform is not C contiguous.";
static const char __pyx_k_One_or_more_arguments_to_floatCu[] = "One or more arguments to floatCudaPySORFTransform is not C contiguous.";
static const char __pyx_k_Shape_of_output_array_and_or_chi[] = "Shape of output array and / or chiArr is inappropriate.";
static const char __pyx_k_Shape_of_output_array_is_not_app[] = "Shape of output array is not appropriate.";
static const char __pyx_k_Sizes_on_input_and_output_arrays[] = "Sizes on input and output arrays to RBF feature gen are inappropriate.";
static const char __pyx_k_The_input_arrays_to_a_wrapped_RB[] = "The input arrays to a wrapped RBF feature gen function have incorrect shapes.";
static const char __pyx_k_The_number_of_input_and_output_d[] = "The number of input and output datapoints do not agree.";
static const char __pyx_k_The_number_of_sampled_frequencie[] = "The number of sampled frequencies should be an integer multiple of reshapedX.shape[2].";
static const char __pyx_k_The_shape_of_the_output_array_is[] = "The shape of the output array is incorrect for a quadratic.";
static const char __pyx_k_There_must_be_at_least_one_datap[] = "There must be at least one datapoint.";
static const char __pyx_k_This_main_Cython_extension_combi[] = "This 'main' Cython extension combines all the other\nCuda Cython extensions so that all of them are built as\na single .so. This is slightly clunky, but at this time\nthere does not appear to be a better way to merge\nmultiple .pyx files to a single extension.";
static const char __pyx_k_Unexpected_kernel_order_supplied[] = "Unexpected kernel order supplied.";
static const char __pyx_k_Unexpected_types_passed_to_wrapp[] = "Unexpected types passed to wrapped C++ function.";
static const char __pyx_k_chiArr_must_be_a_1d_array_output[] = "chiArr must be a 1d array; outputArray must be 2d.";
static const char __pyx_k_chiArr_must_have_same_shape_1_an[] = "chiArr must have same shape[1] and shape[2] as radem.";
static const char __pyx_k_chiArr_radem_and_reshapedX_shoul[] = "chiArr, radem and reshapedX should be 3d arrays.";
static const char __pyx_k_chiArr_should_be_a_1d_array_rade[] = "chiArr should be a 1d array. radem and reshapedX should be 3d arrays.";
static const char __pyx_k_chiArr_should_be_a_2d_array_rade[] = "chiArr should be a 2d array. radem and reshapedX should be 3d arrays.";
static const char __pyx_k_dim2_of_the_input_array_to_RBF_f[] = "dim2 of the input array to RBF feature gen functions must be a power of 2 >= 2.";
static const char __pyx_k_dim2_of_the_input_array_to_float[] = "dim2 of the input array to floatCudaPySORFTransform must be a power of 2 >= 2.";
static const char __pyx_k_dim2_of_the_reshapedX_array_must[] = "dim2 of the reshapedX array must be a power of 2 >= 2.";
static const char __pyx_k_inputArray_and_outputArray_to_RB[] = "inputArray and outputArray to RBF feature gen must have same number of datapoints.";
static const char __pyx_k_numpy_core_umath_failed_to_impor[] = "numpy.core.umath failed to import";
static const char __pyx_k_outputArray_shape_1_must_be_an_i[] = "outputArray.shape[1] must be an integer multiple of the next largest power of 2 greater than the kernel width * X.shape[2].";
static const char __pyx_k_outputArray_shape_1_must_be_rade[] = "outputArray.shape[1] must be radem.shape[2], which must be an integer multiple of the next power of 2 greater than the kernel width * X.shape[2].";
static const char __pyx_k_outputArray_should_be_a_2d_array[] = "outputArray should be a 2d array.";
static const char __pyx_k_outputArray_should_be_a_3d_array[] = "outputArray should be a 3d array.";
static const char __pyx_k_radem_chiArr_must_have_length_po[] = "radem & chiArr must have length polydegree for dim 0.";
static const char __pyx_k_radem_must_have_length_3_for_dim[] = "radem must have length 3 for dim 0.";
static const char __pyx_k_radem_must_have_length_polydegre[] = "radem must have length polydegree for dim 0 and length 1 for dim1.";
static const char __pyx_k_reshapedX_shape_1_and_shape_2_mu[] = "reshapedX shape[1] and shape[2] must == radem shape[1] and shape[2].";
static const char __pyx_k_xGPR_random_feature_generation_g[] = "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx";
static const char __pyx_k_Fatal_error_encountered_in_float_2[] = "Fatal error encountered in floatGpuConv1dTransform_.";
static const char __pyx_k_Fatal_error_encountered_while_pe_2[] = "Fatal error encountered while performing graph convolution.";
static const char __pyx_k_The_input_arrays_to_a_wrapped_RB_2[] = "The input arrays to a wrapped RBF feature gen function have incorrect types.";
static const char __pyx_k_radem_must_have_length_3_for_dim_2[] = "radem must have length 3 for dim 0 and length 1 for dim1.";
static const char __pyx_k_xGPR_random_feature_generation_g_2[] = "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx";
static const char __pyx_k_xGPR_random_feature_generation_g_3[] = "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx";
static const char __pyx_k_xGPR_random_feature_generation_g_4[] = "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx";
/* #### Code section: decls ### */
static PyObject *__pyx_pf_18cuda_rf_gen_module_cudaPySORFTransform(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_cpArray, PyObject *__pyx_v_radem, CYTHON_UNUSED int __pyx_v_numThreads); /* proto */
static PyObject *__pyx_pf_18cuda_rf_gen_module_2cudaSRHT(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_Z, PyObject *__pyx_v_radem, PyArrayObject *__pyx_v_sampler, int __pyx_v_compression_size, CYTHON_UNUSED int __pyx_v_numThreads); /* proto */
static PyObject *__pyx_pf_18cuda_rf_gen_module_4gpuConv1dMaxpool(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_reshapedX, PyObject *__pyx_v_radem, PyObject *__pyx_v_outputArray, PyObject *__pyx_v_chiArr, CYTHON_UNUSED int __pyx_v_numThreads); /* proto */
static PyObject *__pyx_pf_18cuda_rf_gen_module_6gpuConv1dFGen(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_reshapedX, PyObject *__pyx_v_radem, PyObject *__pyx_v_outputArray, PyObject *__pyx_v_chiArr, CYTHON_UNUSED int __pyx_v_numThreads, float __pyx_v_beta_, bool __pyx_v_fitIntercept); /* proto */
static PyObject *__pyx_pf_18cuda_rf_gen_module_8gpuConvGrad(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_reshapedX, PyObject *__pyx_v_radem, PyObject *__pyx_v_outputArray, PyObject *__pyx_v_chiArr, CYTHON_UNUSED int __pyx_v_numThreads, float __pyx_v_sigma, float __pyx_v_beta_, bool __pyx_v_fitIntercept); /* proto */
static PyObject *__pyx_pf_18cuda_rf_gen_module_10gpuConv1dArcCosFGen(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_reshapedX, PyObject *__pyx_v_radem, PyObject *__pyx_v_outputArray, PyObject *__pyx_v_chiArr, CYTHON_UNUSED int __pyx_v_numThreads, float __pyx_v_beta_, int __pyx_v_kernelOrder, bool __pyx_v_fitIntercept); /* proto */
static PyObject *__pyx_pf_18cuda_rf_gen_module_12gpuGraphPolyFHT(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_reshapedX, PyObject *__pyx_v_radem, PyObject *__pyx_v_chiArr, PyObject *__pyx_v_outputArray, int __pyx_v_polydegree, CYTHON_UNUSED int __pyx_v_numThreads); /* proto */
static PyObject *__pyx_pf_18cuda_rf_gen_module_14gpuPolyFHT(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_reshapedX, PyObject *__pyx_v_radem, PyObject *__pyx_v_chiArr, PyObject *__pyx_v_outputArray, int __pyx_v_polydegree, CYTHON_UNUSED int __pyx_v_numThreads); /* proto */
static PyObject *__pyx_pf_18cuda_rf_gen_module_16cudaExactQuadratic(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_inputArray, PyObject *__pyx_v_outputArray, CYTHON_UNUSED int __pyx_v_numThreads); /* proto */
static PyObject *__pyx_pf_18cuda_rf_gen_module_18cudaRBFFeatureGen(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_inputArray, PyObject *__pyx_v_outputArray, PyObject *__pyx_v_radem, PyObject *__pyx_v_chiArr, double __pyx_v_betaHparam, CYTHON_UNUSED int __pyx_v_numThreads, PyObject *__pyx_v_fitIntercept); /* proto */
static PyObject *__pyx_pf_18cuda_rf_gen_module_20cudaRBFGrad(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_inputArray, PyObject *__pyx_v_outputArray, PyObject *__pyx_v_radem, PyObject *__pyx_v_chiArr, double __pyx_v_betaHparam, double __pyx_v_sigmaHparam, CYTHON_UNUSED int __pyx_v_numThreads, bool __pyx_v_fitIntercept); /* proto */
static PyObject *__pyx_pf_18cuda_rf_gen_module_22cudaMiniARDGrad(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_inputX, PyObject *__pyx_v_outputArray, PyObject *__pyx_v_precompWeights, PyObject *__pyx_v_sigmaMap, PyObject *__pyx_v_sigmaVals, double __pyx_v_betaHparam, CYTHON_UNUSED int __pyx_v_numThreads, bool __pyx_v_fitIntercept); /* proto */
/* #### Code section: late_includes ### */
/* #### Code section: module_state ### */
typedef struct {
  PyObject *__pyx_d;
  PyObject *__pyx_b;
  PyObject *__pyx_cython_runtime;
  PyObject *__pyx_empty_tuple;
  PyObject *__pyx_empty_bytes;
  PyObject *__pyx_empty_unicode;
  #ifdef __Pyx_CyFunction_USED
  PyTypeObject *__pyx_CyFunctionType;
  #endif
  #ifdef __Pyx_FusedFunction_USED
  PyTypeObject *__pyx_FusedFunctionType;
  #endif
  #ifdef __Pyx_Generator_USED
  PyTypeObject *__pyx_GeneratorType;
  #endif
  #ifdef __Pyx_IterableCoroutine_USED
  PyTypeObject *__pyx_IterableCoroutineType;
  #endif
  #ifdef __Pyx_Coroutine_USED
  PyTypeObject *__pyx_CoroutineAwaitType;
  #endif
  #ifdef __Pyx_Coroutine_USED
  PyTypeObject *__pyx_CoroutineType;
  #endif
  #if CYTHON_USE_MODULE_STATE
  #endif
  #if CYTHON_USE_MODULE_STATE
  #endif
  #if CYTHON_USE_MODULE_STATE
  #endif
  #if CYTHON_USE_MODULE_STATE
  #endif
  #if CYTHON_USE_MODULE_STATE
  #endif
  PyTypeObject *__pyx_ptype_7cpython_4type_type;
  #if CYTHON_USE_MODULE_STATE
  #endif
  #if CYTHON_USE_MODULE_STATE
  #endif
  #if CYTHON_USE_MODULE_STATE
  #endif
  #if CYTHON_USE_MODULE_STATE
  #endif
  #if CYTHON_USE_MODULE_STATE
  #endif
  PyTypeObject *__pyx_ptype_5numpy_dtype;
  PyTypeObject *__pyx_ptype_5numpy_flatiter;
  PyTypeObject *__pyx_ptype_5numpy_broadcast;
  PyTypeObject *__pyx_ptype_5numpy_ndarray;
  PyTypeObject *__pyx_ptype_5numpy_generic;
  PyTypeObject *__pyx_ptype_5numpy_number;
  PyTypeObject *__pyx_ptype_5numpy_integer;
  PyTypeObject *__pyx_ptype_5numpy_signedinteger;
  PyTypeObject *__pyx_ptype_5numpy_unsignedinteger;
  PyTypeObject *__pyx_ptype_5numpy_inexact;
  PyTypeObject *__pyx_ptype_5numpy_floating;
  PyTypeObject *__pyx_ptype_5numpy_complexfloating;
  PyTypeObject *__pyx_ptype_5numpy_flexible;
  PyTypeObject *__pyx_ptype_5numpy_character;
  PyTypeObject *__pyx_ptype_5numpy_ufunc;
  #if CYTHON_USE_MODULE_STATE
  #endif
  #if CYTHON_USE_MODULE_STATE
  #endif
  #if CYTHON_USE_MODULE_STATE
  #endif
  #if CYTHON_USE_MODULE_STATE
  #endif
  PyObject *__pyx_kp_u_Both_inputArray_and_outputArray;
  PyObject *__pyx_n_u_C_CONTIGUOUS;
  PyObject *__pyx_kp_u_Compression_size_must_be_num_rff;
  PyObject *__pyx_kp_u_Fatal_error_encountered;
  PyObject *__pyx_kp_u_Fatal_error_encountered_in_CudaR;
  PyObject *__pyx_kp_u_Fatal_error_encountered_in_RBF_f;
  PyObject *__pyx_kp_u_Fatal_error_encountered_in_doubl;
  PyObject *__pyx_kp_u_Fatal_error_encountered_in_float;
  PyObject *__pyx_kp_u_Fatal_error_encountered_in_float_2;
  PyObject *__pyx_kp_u_Fatal_error_encountered_while_pe;
  PyObject *__pyx_kp_u_Fatal_error_encountered_while_pe_2;
  PyObject *__pyx_n_s_ImportError;
  PyObject *__pyx_kp_u_Inconsistent_array_types_passed;
  PyObject *__pyx_kp_u_Inconsistent_types_passed_to_a_w;
  PyObject *__pyx_kp_u_Incorrect_array_dims_passed;
  PyObject *__pyx_kp_u_Incorrect_array_dims_passed_to_a;
  PyObject *__pyx_kp_u_Incorrect_array_dims_passed_to_f;
  PyObject *__pyx_kp_u_Incorrect_data_types_passed;
  PyObject *__pyx_kp_u_Incorrect_data_types_supplied;
  PyObject *__pyx_kp_u_One_or_more_arguments_is_not_C_c;
  PyObject *__pyx_kp_u_One_or_more_arguments_to_a_wrapp;
  PyObject *__pyx_kp_u_One_or_more_arguments_to_cpuSORF;
  PyObject *__pyx_kp_u_One_or_more_arguments_to_floatCu;
  PyObject *__pyx_kp_u_Shape_of_output_array_and_or_chi;
  PyObject *__pyx_kp_u_Shape_of_output_array_is_not_app;
  PyObject *__pyx_kp_u_Sizes_on_input_and_output_arrays;
  PyObject *__pyx_kp_u_The_input_and_chiArr_arrays_are;
  PyObject *__pyx_kp_u_The_input_arrays_to_a_wrapped_RB;
  PyObject *__pyx_kp_u_The_input_arrays_to_a_wrapped_RB_2;
  PyObject *__pyx_kp_u_The_number_of_datapoints_in_the;
  PyObject *__pyx_kp_u_The_number_of_input_and_output_d;
  PyObject *__pyx_kp_u_The_number_of_sampled_frequencie;
  PyObject *__pyx_kp_u_The_shape_of_the_output_array_is;
  PyObject *__pyx_kp_u_There_must_be_at_least_one_datap;
  PyObject *__pyx_kp_u_Unexpected_array_type_passed_to;
  PyObject *__pyx_kp_u_Unexpected_kernel_order_supplied;
  PyObject *__pyx_kp_u_Unexpected_types_passed_to_wrapp;
  PyObject *__pyx_n_s_ValueError;
  PyObject *__pyx_kp_u_X_must_be_a_3d_array;
  PyObject *__pyx_n_s_Z;
  PyObject *__pyx_n_s__70;
  PyObject *__pyx_n_s__96;
  PyObject *__pyx_n_s_addr;
  PyObject *__pyx_n_s_addr_chi;
  PyObject *__pyx_n_s_addr_featureArray;
  PyObject *__pyx_n_s_addr_grad;
  PyObject *__pyx_n_s_addr_gradient;
  PyObject *__pyx_n_s_addr_input;
  PyObject *__pyx_n_s_addr_output;
  PyObject *__pyx_n_s_addr_preSumFeats;
  PyObject *__pyx_n_s_addr_precomp_weights;
  PyObject *__pyx_n_s_addr_radem;
  PyObject *__pyx_n_s_addr_random_feats;
  PyObject *__pyx_n_s_addr_reshapedCopy;
  PyObject *__pyx_n_s_addr_reshapedX;
  PyObject *__pyx_n_s_addr_sigma_map;
  PyObject *__pyx_n_s_addr_sigma_vals;
  PyObject *__pyx_n_s_asyncio_coroutines;
  PyObject *__pyx_n_s_axis;
  PyObject *__pyx_n_s_beta;
  PyObject *__pyx_n_s_betaHparam;
  PyObject *__pyx_n_s_ceil;
  PyObject *__pyx_n_s_chiArr;
  PyObject *__pyx_kp_u_chiArr_input_to_RBF_feature_gen;
  PyObject *__pyx_kp_u_chiArr_must_be_a_1d_array_output;
  PyObject *__pyx_kp_u_chiArr_must_have_same_shape_1_an;
  PyObject *__pyx_kp_u_chiArr_radem_and_reshapedX_shoul;
  PyObject *__pyx_kp_u_chiArr_shape_0_must_polydegree;
  PyObject *__pyx_kp_u_chiArr_shape_0_must_radem_shape;
  PyObject *__pyx_kp_u_chiArr_shape_1_must_radem_shape;
  PyObject *__pyx_kp_u_chiArr_should_be_a_1d_array_rade;
  PyObject *__pyx_kp_u_chiArr_should_be_a_2d_array_rade;
  PyObject *__pyx_n_s_class_getitem;
  PyObject *__pyx_n_s_cline_in_traceback;
  PyObject *__pyx_n_s_compression_size;
  PyObject *__pyx_n_s_copy;
  PyObject *__pyx_n_s_cp;
  PyObject *__pyx_n_s_cpArray;
  PyObject *__pyx_n_s_cudaExactQuadratic;
  PyObject *__pyx_n_s_cudaMiniARDGrad;
  PyObject *__pyx_n_s_cudaPySORFTransform;
  PyObject *__pyx_n_s_cudaRBFFeatureGen;
  PyObject *__pyx_n_s_cudaRBFGrad;
  PyObject *__pyx_n_s_cudaSRHT;
  PyObject *__pyx_n_s_cuda_rf_gen_module;
  PyObject *__pyx_n_s_cupy;
  PyObject *__pyx_n_s_cutoff;
  PyObject *__pyx_n_s_cutoff2;
  PyObject *__pyx_n_s_data;
  PyObject *__pyx_kp_u_dim1_of_the_input_array_must_be;
  PyObject *__pyx_kp_u_dim2_of_the_input_array_to_RBF_f;
  PyObject *__pyx_kp_u_dim2_of_the_input_array_to_float;
  PyObject *__pyx_kp_u_dim2_of_the_reshapedX_array_must;
  PyObject *__pyx_n_s_dtype;
  PyObject *__pyx_n_s_errCode;
  PyObject *__pyx_n_s_featureArray;
  PyObject *__pyx_n_s_fitIntercept;
  PyObject *__pyx_n_s_flags;
  PyObject *__pyx_n_s_float32;
  PyObject *__pyx_n_u_float32;
  PyObject *__pyx_n_s_float64;
  PyObject *__pyx_n_u_float64;
  PyObject *__pyx_n_s_floor;
  PyObject *__pyx_n_s_gpuConv1dArcCosFGen;
  PyObject *__pyx_n_s_gpuConv1dFGen;
  PyObject *__pyx_n_s_gpuConv1dMaxpool;
  PyObject *__pyx_n_s_gpuConvGrad;
  PyObject *__pyx_n_s_gpuGraphPolyFHT;
  PyObject *__pyx_n_s_gpuPolyFHT;
  PyObject *__pyx_n_s_gradient;
  PyObject *__pyx_n_s_i;
  PyObject *__pyx_n_s_import;
  PyObject *__pyx_n_s_initializing;
  PyObject *__pyx_n_s_inputArray;
  PyObject *__pyx_kp_u_inputArray_and_outputArray_to_RB;
  PyObject *__pyx_n_s_inputX;
  PyObject *__pyx_n_u_int32;
  PyObject *__pyx_n_u_int8;
  PyObject *__pyx_n_s_is_coroutine;
  PyObject *__pyx_n_s_j;
  PyObject *__pyx_n_s_k;
  PyObject *__pyx_n_s_kernelOrder;
  PyObject *__pyx_n_s_log2;
  PyObject *__pyx_n_s_logdim;
  PyObject *__pyx_n_s_main;
  PyObject *__pyx_n_s_math;
  PyObject *__pyx_n_s_max;
  PyObject *__pyx_n_s_name;
  PyObject *__pyx_n_u_no_error;
  PyObject *__pyx_n_s_np;
  PyObject *__pyx_n_s_numExpectedFeats;
  PyObject *__pyx_n_s_numLengthscales;
  PyObject *__pyx_n_s_numThreads;
  PyObject *__pyx_n_s_num_repeats;
  PyObject *__pyx_n_s_numpy;
  PyObject *__pyx_kp_u_numpy_core_multiarray_failed_to;
  PyObject *__pyx_kp_u_numpy_core_umath_failed_to_impor;
  PyObject *__pyx_n_s_os;
  PyObject *__pyx_n_s_outputArray;
  PyObject *__pyx_kp_u_outputArray_shape_1_must_be_an_i;
  PyObject *__pyx_kp_u_outputArray_shape_1_must_be_rade;
  PyObject *__pyx_kp_u_outputArray_should_be_a_2d_array;
  PyObject *__pyx_kp_u_outputArray_should_be_a_3d_array;
  PyObject *__pyx_n_s_polydegree;
  PyObject *__pyx_n_s_preSumFeats;
  PyObject *__pyx_n_s_precompWeights;
  PyObject *__pyx_n_s_ptr;
  PyObject *__pyx_n_s_radem;
  PyObject *__pyx_kp_u_radem_chiArr_must_have_length_po;
  PyObject *__pyx_kp_u_radem_must_be_a_3d_array;
  PyObject *__pyx_kp_u_radem_must_be_int8;
  PyObject *__pyx_kp_u_radem_must_be_of_type_int8;
  PyObject *__pyx_kp_u_radem_must_have_length_3_for_dim;
  PyObject *__pyx_kp_u_radem_must_have_length_3_for_dim_2;
  PyObject *__pyx_kp_u_radem_must_have_length_polydegre;
  PyObject *__pyx_n_s_radem_ptr;
  PyObject *__pyx_n_s_range;
  PyObject *__pyx_n_s_rbfNormConstant;
  PyObject *__pyx_n_s_reshapedX;
  PyObject *__pyx_n_s_reshapedXCopy;
  PyObject *__pyx_kp_u_reshapedX_shape_1_and_shape_2_mu;
  PyObject *__pyx_n_s_sampler;
  PyObject *__pyx_n_s_scalingTerm;
  PyObject *__pyx_n_s_scaling_factor;
  PyObject *__pyx_n_s_shape;
  PyObject *__pyx_n_s_sigma;
  PyObject *__pyx_n_s_sigmaHparam;
  PyObject *__pyx_n_s_sigmaMap;
  PyObject *__pyx_n_s_sigmaMap_ptr;
  PyObject *__pyx_n_s_sigmaVals;
  PyObject *__pyx_n_s_spec;
  PyObject *__pyx_n_s_sqrt;
  PyObject *__pyx_n_s_startPos2;
  PyObject *__pyx_n_s_startPosition;
  PyObject *__pyx_n_s_sum;
  PyObject *__pyx_n_s_test;
  PyObject *__pyx_kp_s_xGPR_random_feature_generation_g;
  PyObject *__pyx_kp_s_xGPR_random_feature_generation_g_2;
  PyObject *__pyx_kp_s_xGPR_random_feature_generation_g_3;
  PyObject *__pyx_kp_s_xGPR_random_feature_generation_g_4;
  PyObject *__pyx_n_s_zeros;
  PyObject *__pyx_int_0;
  PyObject *__pyx_int_1;
  PyObject *__pyx_int_2;
  PyObject *__pyx_int_3;
  PyObject *__pyx_tuple_;
  PyObject *__pyx_tuple__2;
  PyObject *__pyx_tuple__3;
  PyObject *__pyx_tuple__4;
  PyObject *__pyx_tuple__5;
  PyObject *__pyx_tuple__6;
  PyObject *__pyx_tuple__7;
  PyObject *__pyx_tuple__8;
  PyObject *__pyx_tuple__9;
  PyObject *__pyx_slice__17;
  PyObject *__pyx_slice__45;
  PyObject *__pyx_tuple__10;
  PyObject *__pyx_tuple__11;
  PyObject *__pyx_tuple__12;
  PyObject *__pyx_tuple__13;
  PyObject *__pyx_tuple__14;
  PyObject *__pyx_tuple__15;
  PyObject *__pyx_tuple__16;
  PyObject *__pyx_tuple__18;
  PyObject *__pyx_tuple__19;
  PyObject *__pyx_tuple__20;
  PyObject *__pyx_tuple__21;
  PyObject *__pyx_tuple__22;
  PyObject *__pyx_tuple__23;
  PyObject *__pyx_tuple__24;
  PyObject *__pyx_tuple__25;
  PyObject *__pyx_tuple__26;
  PyObject *__pyx_tuple__27;
  PyObject *__pyx_tuple__28;
  PyObject *__pyx_tuple__29;
  PyObject *__pyx_tuple__30;
  PyObject *__pyx_tuple__31;
  PyObject *__pyx_tuple__32;
  PyObject *__pyx_tuple__33;
  PyObject *__pyx_tuple__34;
  PyObject *__pyx_tuple__35;
  PyObject *__pyx_tuple__36;
  PyObject *__pyx_tuple__37;
  PyObject *__pyx_tuple__38;
  PyObject *__pyx_tuple__39;
  PyObject *__pyx_tuple__40;
  PyObject *__pyx_tuple__41;
  PyObject *__pyx_tuple__42;
  PyObject *__pyx_tuple__43;
  PyObject *__pyx_tuple__44;
  PyObject *__pyx_tuple__46;
  PyObject *__pyx_tuple__47;
  PyObject *__pyx_tuple__48;
  PyObject *__pyx_tuple__49;
  PyObject *__pyx_tuple__50;
  PyObject *__pyx_tuple__51;
  PyObject *__pyx_tuple__52;
  PyObject *__pyx_tuple__53;
  PyObject *__pyx_tuple__54;
  PyObject *__pyx_tuple__55;
  PyObject *__pyx_tuple__56;
  PyObject *__pyx_tuple__57;
  PyObject *__pyx_tuple__58;
  PyObject *__pyx_tuple__59;
  PyObject *__pyx_tuple__60;
  PyObject *__pyx_tuple__61;
  PyObject *__pyx_tuple__62;
  PyObject *__pyx_tuple__63;
  PyObject *__pyx_tuple__64;
  PyObject *__pyx_tuple__65;
  PyObject *__pyx_tuple__66;
  PyObject *__pyx_tuple__67;
  PyObject *__pyx_tuple__68;
  PyObject *__pyx_tuple__69;
  PyObject *__pyx_tuple__71;
  PyObject *__pyx_tuple__73;
  PyObject *__pyx_tuple__75;
  PyObject *__pyx_tuple__77;
  PyObject *__pyx_tuple__79;
  PyObject *__pyx_tuple__81;
  PyObject *__pyx_tuple__83;
  PyObject *__pyx_tuple__85;
  PyObject *__pyx_tuple__87;
  PyObject *__pyx_tuple__89;
  PyObject *__pyx_tuple__91;
  PyObject *__pyx_tuple__92;
  PyObject *__pyx_tuple__94;
  PyObject *__pyx_codeobj__72;
  PyObject *__pyx_codeobj__74;
  PyObject *__pyx_codeobj__76;
  PyObject *__pyx_codeobj__78;
  PyObject *__pyx_codeobj__80;
  PyObject *__pyx_codeobj__82;
  PyObject *__pyx_codeobj__84;
  PyObject *__pyx_codeobj__86;
  PyObject *__pyx_codeobj__88;
  PyObject *__pyx_codeobj__90;
  PyObject *__pyx_codeobj__93;
  PyObject *__pyx_codeobj__95;
} __pyx_mstate;

#if CYTHON_USE_MODULE_STATE
#ifdef __cplusplus
namespace {
  extern struct PyModuleDef __pyx_moduledef;
} /* anonymous namespace */
#else
static struct PyModuleDef __pyx_moduledef;
#endif

#define __pyx_mstate(o) ((__pyx_mstate *)__Pyx_PyModule_GetState(o))

#define __pyx_mstate_global (__pyx_mstate(PyState_FindModule(&__pyx_moduledef)))

#define __pyx_m (PyState_FindModule(&__pyx_moduledef))
#else
static __pyx_mstate __pyx_mstate_global_static =
#ifdef __cplusplus
    {};
#else
    {0};
#endif
static __pyx_mstate *__pyx_mstate_global = &__pyx_mstate_global_static;
#endif
/* #### Code section: module_state_clear ### */
#if CYTHON_USE_MODULE_STATE
static int __pyx_m_clear(PyObject *m) {
  __pyx_mstate *clear_module_state = __pyx_mstate(m);
  if (!clear_module_state) return 0;
  Py_CLEAR(clear_module_state->__pyx_d);
  Py_CLEAR(clear_module_state->__pyx_b);
  Py_CLEAR(clear_module_state->__pyx_cython_runtime);
  Py_CLEAR(clear_module_state->__pyx_empty_tuple);
  Py_CLEAR(clear_module_state->__pyx_empty_bytes);
  Py_CLEAR(clear_module_state->__pyx_empty_unicode);
  #ifdef __Pyx_CyFunction_USED
  Py_CLEAR(clear_module_state->__pyx_CyFunctionType);
  #endif
  #ifdef __Pyx_FusedFunction_USED
  Py_CLEAR(clear_module_state->__pyx_FusedFunctionType);
  #endif
  Py_CLEAR(clear_module_state->__pyx_ptype_7cpython_4type_type);
  Py_CLEAR(clear_module_state->__pyx_ptype_5numpy_dtype);
  Py_CLEAR(clear_module_state->__pyx_ptype_5numpy_flatiter);
  Py_CLEAR(clear_module_state->__pyx_ptype_5numpy_broadcast);
  Py_CLEAR(clear_module_state->__pyx_ptype_5numpy_ndarray);
  Py_CLEAR(clear_module_state->__pyx_ptype_5numpy_generic);
  Py_CLEAR(clear_module_state->__pyx_ptype_5numpy_number);
  Py_CLEAR(clear_module_state->__pyx_ptype_5numpy_integer);
  Py_CLEAR(clear_module_state->__pyx_ptype_5numpy_signedinteger);
  Py_CLEAR(clear_module_state->__pyx_ptype_5numpy_unsignedinteger);
  Py_CLEAR(clear_module_state->__pyx_ptype_5numpy_inexact);
  Py_CLEAR(clear_module_state->__pyx_ptype_5numpy_floating);
  Py_CLEAR(clear_module_state->__pyx_ptype_5numpy_complexfloating);
  Py_CLEAR(clear_module_state->__pyx_ptype_5numpy_flexible);
  Py_CLEAR(clear_module_state->__pyx_ptype_5numpy_character);
  Py_CLEAR(clear_module_state->__pyx_ptype_5numpy_ufunc);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Both_inputArray_and_outputArray);
  Py_CLEAR(clear_module_state->__pyx_n_u_C_CONTIGUOUS);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Compression_size_must_be_num_rff);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Fatal_error_encountered);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Fatal_error_encountered_in_CudaR);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Fatal_error_encountered_in_RBF_f);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Fatal_error_encountered_in_doubl);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Fatal_error_encountered_in_float);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Fatal_error_encountered_in_float_2);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Fatal_error_encountered_while_pe);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Fatal_error_encountered_while_pe_2);
  Py_CLEAR(clear_module_state->__pyx_n_s_ImportError);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Inconsistent_array_types_passed);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Inconsistent_types_passed_to_a_w);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Incorrect_array_dims_passed);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Incorrect_array_dims_passed_to_a);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Incorrect_array_dims_passed_to_f);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Incorrect_data_types_passed);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Incorrect_data_types_supplied);
  Py_CLEAR(clear_module_state->__pyx_kp_u_One_or_more_arguments_is_not_C_c);
  Py_CLEAR(clear_module_state->__pyx_kp_u_One_or_more_arguments_to_a_wrapp);
  Py_CLEAR(clear_module_state->__pyx_kp_u_One_or_more_arguments_to_cpuSORF);
  Py_CLEAR(clear_module_state->__pyx_kp_u_One_or_more_arguments_to_floatCu);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Shape_of_output_array_and_or_chi);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Shape_of_output_array_is_not_app);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Sizes_on_input_and_output_arrays);
  Py_CLEAR(clear_module_state->__pyx_kp_u_The_input_and_chiArr_arrays_are);
  Py_CLEAR(clear_module_state->__pyx_kp_u_The_input_arrays_to_a_wrapped_RB);
  Py_CLEAR(clear_module_state->__pyx_kp_u_The_input_arrays_to_a_wrapped_RB_2);
  Py_CLEAR(clear_module_state->__pyx_kp_u_The_number_of_datapoints_in_the);
  Py_CLEAR(clear_module_state->__pyx_kp_u_The_number_of_input_and_output_d);
  Py_CLEAR(clear_module_state->__pyx_kp_u_The_number_of_sampled_frequencie);
  Py_CLEAR(clear_module_state->__pyx_kp_u_The_shape_of_the_output_array_is);
  Py_CLEAR(clear_module_state->__pyx_kp_u_There_must_be_at_least_one_datap);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Unexpected_array_type_passed_to);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Unexpected_kernel_order_supplied);
  Py_CLEAR(clear_module_state->__pyx_kp_u_Unexpected_types_passed_to_wrapp);
  Py_CLEAR(clear_module_state->__pyx_n_s_ValueError);
  Py_CLEAR(clear_module_state->__pyx_kp_u_X_must_be_a_3d_array);
  Py_CLEAR(clear_module_state->__pyx_n_s_Z);
  Py_CLEAR(clear_module_state->__pyx_n_s__70);
  Py_CLEAR(clear_module_state->__pyx_n_s__96);
  Py_CLEAR(clear_module_state->__pyx_n_s_addr);
  Py_CLEAR(clear_module_state->__pyx_n_s_addr_chi);
  Py_CLEAR(clear_module_state->__pyx_n_s_addr_featureArray);
  Py_CLEAR(clear_module_state->__pyx_n_s_addr_grad);
  Py_CLEAR(clear_module_state->__pyx_n_s_addr_gradient);
  Py_CLEAR(clear_module_state->__pyx_n_s_addr_input);
  Py_CLEAR(clear_module_state->__pyx_n_s_addr_output);
  Py_CLEAR(clear_module_state->__pyx_n_s_addr_preSumFeats);
  Py_CLEAR(clear_module_state->__pyx_n_s_addr_precomp_weights);
  Py_CLEAR(clear_module_state->__pyx_n_s_addr_radem);
  Py_CLEAR(clear_module_state->__pyx_n_s_addr_random_feats);
  Py_CLEAR(clear_module_state->__pyx_n_s_addr_reshapedCopy);
  Py_CLEAR(clear_module_state->__pyx_n_s_addr_reshapedX);
  Py_CLEAR(clear_module_state->__pyx_n_s_addr_sigma_map);
  Py_CLEAR(clear_module_state->__pyx_n_s_addr_sigma_vals);
  Py_CLEAR(clear_module_state->__pyx_n_s_asyncio_coroutines);
  Py_CLEAR(clear_module_state->__pyx_n_s_axis);
  Py_CLEAR(clear_module_state->__pyx_n_s_beta);
  Py_CLEAR(clear_module_state->__pyx_n_s_betaHparam);
  Py_CLEAR(clear_module_state->__pyx_n_s_ceil);
  Py_CLEAR(clear_module_state->__pyx_n_s_chiArr);
  Py_CLEAR(clear_module_state->__pyx_kp_u_chiArr_input_to_RBF_feature_gen);
  Py_CLEAR(clear_module_state->__pyx_kp_u_chiArr_must_be_a_1d_array_output);
  Py_CLEAR(clear_module_state->__pyx_kp_u_chiArr_must_have_same_shape_1_an);
  Py_CLEAR(clear_module_state->__pyx_kp_u_chiArr_radem_and_reshapedX_shoul);
  Py_CLEAR(clear_module_state->__pyx_kp_u_chiArr_shape_0_must_polydegree);
  Py_CLEAR(clear_module_state->__pyx_kp_u_chiArr_shape_0_must_radem_shape);
  Py_CLEAR(clear_module_state->__pyx_kp_u_chiArr_shape_1_must_radem_shape);
  Py_CLEAR(clear_module_state->__pyx_kp_u_chiArr_should_be_a_1d_array_rade);
  Py_CLEAR(clear_module_state->__pyx_kp_u_chiArr_should_be_a_2d_array_rade);
  Py_CLEAR(clear_module_state->__pyx_n_s_class_getitem);
  Py_CLEAR(clear_module_state->__pyx_n_s_cline_in_traceback);
  Py_CLEAR(clear_module_state->__pyx_n_s_compression_size);
  Py_CLEAR(clear_module_state->__pyx_n_s_copy);
  Py_CLEAR(clear_module_state->__pyx_n_s_cp);
  Py_CLEAR(clear_module_state->__pyx_n_s_cpArray);
  Py_CLEAR(clear_module_state->__pyx_n_s_cudaExactQuadratic);
  Py_CLEAR(clear_module_state->__pyx_n_s_cudaMiniARDGrad);
  Py_CLEAR(clear_module_state->__pyx_n_s_cudaPySORFTransform);
  Py_CLEAR(clear_module_state->__pyx_n_s_cudaRBFFeatureGen);
  Py_CLEAR(clear_module_state->__pyx_n_s_cudaRBFGrad);
  Py_CLEAR(clear_module_state->__pyx_n_s_cudaSRHT);
  Py_CLEAR(clear_module_state->__pyx_n_s_cuda_rf_gen_module);
  Py_CLEAR(clear_module_state->__pyx_n_s_cupy);
  Py_CLEAR(clear_module_state->__pyx_n_s_cutoff);
  Py_CLEAR(clear_module_state->__pyx_n_s_cutoff2);
  Py_CLEAR(clear_module_state->__pyx_n_s_data);
  Py_CLEAR(clear_module_state->__pyx_kp_u_dim1_of_the_input_array_must_be);
  Py_CLEAR(clear_module_state->__pyx_kp_u_dim2_of_the_input_array_to_RBF_f);
  Py_CLEAR(clear_module_state->__pyx_kp_u_dim2_of_the_input_array_to_float);
  Py_CLEAR(clear_module_state->__pyx_kp_u_dim2_of_the_reshapedX_array_must);
  Py_CLEAR(clear_module_state->__pyx_n_s_dtype);
  Py_CLEAR(clear_module_state->__pyx_n_s_errCode);
  Py_CLEAR(clear_module_state->__pyx_n_s_featureArray);
  Py_CLEAR(clear_module_state->__pyx_n_s_fitIntercept);
  Py_CLEAR(clear_module_state->__pyx_n_s_flags);
  Py_CLEAR(clear_module_state->__pyx_n_s_float32);
  Py_CLEAR(clear_module_state->__pyx_n_u_float32);
  Py_CLEAR(clear_module_state->__pyx_n_s_float64);
  Py_CLEAR(clear_module_state->__pyx_n_u_float64);
  Py_CLEAR(clear_module_state->__pyx_n_s_floor);
  Py_CLEAR(clear_module_state->__pyx_n_s_gpuConv1dArcCosFGen);
  Py_CLEAR(clear_module_state->__pyx_n_s_gpuConv1dFGen);
  Py_CLEAR(clear_module_state->__pyx_n_s_gpuConv1dMaxpool);
  Py_CLEAR(clear_module_state->__pyx_n_s_gpuConvGrad);
  Py_CLEAR(clear_module_state->__pyx_n_s_gpuGraphPolyFHT);
  Py_CLEAR(clear_module_state->__pyx_n_s_gpuPolyFHT);
  Py_CLEAR(clear_module_state->__pyx_n_s_gradient);
  Py_CLEAR(clear_module_state->__pyx_n_s_i);
  Py_CLEAR(clear_module_state->__pyx_n_s_import);
  Py_CLEAR(clear_module_state->__pyx_n_s_initializing);
  Py_CLEAR(clear_module_state->__pyx_n_s_inputArray);
  Py_CLEAR(clear_module_state->__pyx_kp_u_inputArray_and_outputArray_to_RB);
  Py_CLEAR(clear_module_state->__pyx_n_s_inputX);
  Py_CLEAR(clear_module_state->__pyx_n_u_int32);
  Py_CLEAR(clear_module_state->__pyx_n_u_int8);
  Py_CLEAR(clear_module_state->__pyx_n_s_is_coroutine);
  Py_CLEAR(clear_module_state->__pyx_n_s_j);
  Py_CLEAR(clear_module_state->__pyx_n_s_k);
  Py_CLEAR(clear_module_state->__pyx_n_s_kernelOrder);
  Py_CLEAR(clear_module_state->__pyx_n_s_log2);
  Py_CLEAR(clear_module_state->__pyx_n_s_logdim);
  Py_CLEAR(clear_module_state->__pyx_n_s_main);
  Py_CLEAR(clear_module_state->__pyx_n_s_math);
  Py_CLEAR(clear_module_state->__pyx_n_s_max);
  Py_CLEAR(clear_module_state->__pyx_n_s_name);
  Py_CLEAR(clear_module_state->__pyx_n_u_no_error);
  Py_CLEAR(clear_module_state->__pyx_n_s_np);
  Py_CLEAR(clear_module_state->__pyx_n_s_numExpectedFeats);
  Py_CLEAR(clear_module_state->__pyx_n_s_numLengthscales);
  Py_CLEAR(clear_module_state->__pyx_n_s_numThreads);
  Py_CLEAR(clear_module_state->__pyx_n_s_num_repeats);
  Py_CLEAR(clear_module_state->__pyx_n_s_numpy);
  Py_CLEAR(clear_module_state->__pyx_kp_u_numpy_core_multiarray_failed_to);
  Py_CLEAR(clear_module_state->__pyx_kp_u_numpy_core_umath_failed_to_impor);
  Py_CLEAR(clear_module_state->__pyx_n_s_os);
  Py_CLEAR(clear_module_state->__pyx_n_s_outputArray);
  Py_CLEAR(clear_module_state->__pyx_kp_u_outputArray_shape_1_must_be_an_i);
  Py_CLEAR(clear_module_state->__pyx_kp_u_outputArray_shape_1_must_be_rade);
  Py_CLEAR(clear_module_state->__pyx_kp_u_outputArray_should_be_a_2d_array);
  Py_CLEAR(clear_module_state->__pyx_kp_u_outputArray_should_be_a_3d_array);
  Py_CLEAR(clear_module_state->__pyx_n_s_polydegree);
  Py_CLEAR(clear_module_state->__pyx_n_s_preSumFeats);
  Py_CLEAR(clear_module_state->__pyx_n_s_precompWeights);
  Py_CLEAR(clear_module_state->__pyx_n_s_ptr);
  Py_CLEAR(clear_module_state->__pyx_n_s_radem);
  Py_CLEAR(clear_module_state->__pyx_kp_u_radem_chiArr_must_have_length_po);
  Py_CLEAR(clear_module_state->__pyx_kp_u_radem_must_be_a_3d_array);
  Py_CLEAR(clear_module_state->__pyx_kp_u_radem_must_be_int8);
  Py_CLEAR(clear_module_state->__pyx_kp_u_radem_must_be_of_type_int8);
  Py_CLEAR(clear_module_state->__pyx_kp_u_radem_must_have_length_3_for_dim);
  Py_CLEAR(clear_module_state->__pyx_kp_u_radem_must_have_length_3_for_dim_2);
  Py_CLEAR(clear_module_state->__pyx_kp_u_radem_must_have_length_polydegre);
  Py_CLEAR(clear_module_state->__pyx_n_s_radem_ptr);
  Py_CLEAR(clear_module_state->__pyx_n_s_range);
  Py_CLEAR(clear_module_state->__pyx_n_s_rbfNormConstant);
  Py_CLEAR(clear_module_state->__pyx_n_s_reshapedX);
  Py_CLEAR(clear_module_state->__pyx_n_s_reshapedXCopy);
  Py_CLEAR(clear_module_state->__pyx_kp_u_reshapedX_shape_1_and_shape_2_mu);
  Py_CLEAR(clear_module_state->__pyx_n_s_sampler);
  Py_CLEAR(clear_module_state->__pyx_n_s_scalingTerm);
  Py_CLEAR(clear_module_state->__pyx_n_s_scaling_factor);
  Py_CLEAR(clear_module_state->__pyx_n_s_shape);
  Py_CLEAR(clear_module_state->__pyx_n_s_sigma);
  Py_CLEAR(clear_module_state->__pyx_n_s_sigmaHparam);
  Py_CLEAR(clear_module_state->__pyx_n_s_sigmaMap);
  Py_CLEAR(clear_module_state->__pyx_n_s_sigmaMap_ptr);
  Py_CLEAR(clear_module_state->__pyx_n_s_sigmaVals);
  Py_CLEAR(clear_module_state->__pyx_n_s_spec);
  Py_CLEAR(clear_module_state->__pyx_n_s_sqrt);
  Py_CLEAR(clear_module_state->__pyx_n_s_startPos2);
  Py_CLEAR(clear_module_state->__pyx_n_s_startPosition);
  Py_CLEAR(clear_module_state->__pyx_n_s_sum);
  Py_CLEAR(clear_module_state->__pyx_n_s_test);
  Py_CLEAR(clear_module_state->__pyx_kp_s_xGPR_random_feature_generation_g);
  Py_CLEAR(clear_module_state->__pyx_kp_s_xGPR_random_feature_generation_g_2);
  Py_CLEAR(clear_module_state->__pyx_kp_s_xGPR_random_feature_generation_g_3);
  Py_CLEAR(clear_module_state->__pyx_kp_s_xGPR_random_feature_generation_g_4);
  Py_CLEAR(clear_module_state->__pyx_n_s_zeros);
  Py_CLEAR(clear_module_state->__pyx_int_0);
  Py_CLEAR(clear_module_state->__pyx_int_1);
  Py_CLEAR(clear_module_state->__pyx_int_2);
  Py_CLEAR(clear_module_state->__pyx_int_3);
  Py_CLEAR(clear_module_state->__pyx_tuple_);
  Py_CLEAR(clear_module_state->__pyx_tuple__2);
  Py_CLEAR(clear_module_state->__pyx_tuple__3);
  Py_CLEAR(clear_module_state->__pyx_tuple__4);
  Py_CLEAR(clear_module_state->__pyx_tuple__5);
  Py_CLEAR(clear_module_state->__pyx_tuple__6);
  Py_CLEAR(clear_module_state->__pyx_tuple__7);
  Py_CLEAR(clear_module_state->__pyx_tuple__8);
  Py_CLEAR(clear_module_state->__pyx_tuple__9);
  Py_CLEAR(clear_module_state->__pyx_slice__17);
  Py_CLEAR(clear_module_state->__pyx_slice__45);
  Py_CLEAR(clear_module_state->__pyx_tuple__10);
  Py_CLEAR(clear_module_state->__pyx_tuple__11);
  Py_CLEAR(clear_module_state->__pyx_tuple__12);
  Py_CLEAR(clear_module_state->__pyx_tuple__13);
  Py_CLEAR(clear_module_state->__pyx_tuple__14);
  Py_CLEAR(clear_module_state->__pyx_tuple__15);
  Py_CLEAR(clear_module_state->__pyx_tuple__16);
  Py_CLEAR(clear_module_state->__pyx_tuple__18);
  Py_CLEAR(clear_module_state->__pyx_tuple__19);
  Py_CLEAR(clear_module_state->__pyx_tuple__20);
  Py_CLEAR(clear_module_state->__pyx_tuple__21);
  Py_CLEAR(clear_module_state->__pyx_tuple__22);
  Py_CLEAR(clear_module_state->__pyx_tuple__23);
  Py_CLEAR(clear_module_state->__pyx_tuple__24);
  Py_CLEAR(clear_module_state->__pyx_tuple__25);
  Py_CLEAR(clear_module_state->__pyx_tuple__26);
  Py_CLEAR(clear_module_state->__pyx_tuple__27);
  Py_CLEAR(clear_module_state->__pyx_tuple__28);
  Py_CLEAR(clear_module_state->__pyx_tuple__29);
  Py_CLEAR(clear_module_state->__pyx_tuple__30);
  Py_CLEAR(clear_module_state->__pyx_tuple__31);
  Py_CLEAR(clear_module_state->__pyx_tuple__32);
  Py_CLEAR(clear_module_state->__pyx_tuple__33);
  Py_CLEAR(clear_module_state->__pyx_tuple__34);
  Py_CLEAR(clear_module_state->__pyx_tuple__35);
  Py_CLEAR(clear_module_state->__pyx_tuple__36);
  Py_CLEAR(clear_module_state->__pyx_tuple__37);
  Py_CLEAR(clear_module_state->__pyx_tuple__38);
  Py_CLEAR(clear_module_state->__pyx_tuple__39);
  Py_CLEAR(clear_module_state->__pyx_tuple__40);
  Py_CLEAR(clear_module_state->__pyx_tuple__41);
  Py_CLEAR(clear_module_state->__pyx_tuple__42);
  Py_CLEAR(clear_module_state->__pyx_tuple__43);
  Py_CLEAR(clear_module_state->__pyx_tuple__44);
  Py_CLEAR(clear_module_state->__pyx_tuple__46);
  Py_CLEAR(clear_module_state->__pyx_tuple__47);
  Py_CLEAR(clear_module_state->__pyx_tuple__48);
  Py_CLEAR(clear_module_state->__pyx_tuple__49);
  Py_CLEAR(clear_module_state->__pyx_tuple__50);
  Py_CLEAR(clear_module_state->__pyx_tuple__51);
  Py_CLEAR(clear_module_state->__pyx_tuple__52);
  Py_CLEAR(clear_module_state->__pyx_tuple__53);
  Py_CLEAR(clear_module_state->__pyx_tuple__54);
  Py_CLEAR(clear_module_state->__pyx_tuple__55);
  Py_CLEAR(clear_module_state->__pyx_tuple__56);
  Py_CLEAR(clear_module_state->__pyx_tuple__57);
  Py_CLEAR(clear_module_state->__pyx_tuple__58);
  Py_CLEAR(clear_module_state->__pyx_tuple__59);
  Py_CLEAR(clear_module_state->__pyx_tuple__60);
  Py_CLEAR(clear_module_state->__pyx_tuple__61);
  Py_CLEAR(clear_module_state->__pyx_tuple__62);
  Py_CLEAR(clear_module_state->__pyx_tuple__63);
  Py_CLEAR(clear_module_state->__pyx_tuple__64);
  Py_CLEAR(clear_module_state->__pyx_tuple__65);
  Py_CLEAR(clear_module_state->__pyx_tuple__66);
  Py_CLEAR(clear_module_state->__pyx_tuple__67);
  Py_CLEAR(clear_module_state->__pyx_tuple__68);
  Py_CLEAR(clear_module_state->__pyx_tuple__69);
  Py_CLEAR(clear_module_state->__pyx_tuple__71);
  Py_CLEAR(clear_module_state->__pyx_tuple__73);
  Py_CLEAR(clear_module_state->__pyx_tuple__75);
  Py_CLEAR(clear_module_state->__pyx_tuple__77);
  Py_CLEAR(clear_module_state->__pyx_tuple__79);
  Py_CLEAR(clear_module_state->__pyx_tuple__81);
  Py_CLEAR(clear_module_state->__pyx_tuple__83);
  Py_CLEAR(clear_module_state->__pyx_tuple__85);
  Py_CLEAR(clear_module_state->__pyx_tuple__87);
  Py_CLEAR(clear_module_state->__pyx_tuple__89);
  Py_CLEAR(clear_module_state->__pyx_tuple__91);
  Py_CLEAR(clear_module_state->__pyx_tuple__92);
  Py_CLEAR(clear_module_state->__pyx_tuple__94);
  Py_CLEAR(clear_module_state->__pyx_codeobj__72);
  Py_CLEAR(clear_module_state->__pyx_codeobj__74);
  Py_CLEAR(clear_module_state->__pyx_codeobj__76);
  Py_CLEAR(clear_module_state->__pyx_codeobj__78);
  Py_CLEAR(clear_module_state->__pyx_codeobj__80);
  Py_CLEAR(clear_module_state->__pyx_codeobj__82);
  Py_CLEAR(clear_module_state->__pyx_codeobj__84);
  Py_CLEAR(clear_module_state->__pyx_codeobj__86);
  Py_CLEAR(clear_module_state->__pyx_codeobj__88);
  Py_CLEAR(clear_module_state->__pyx_codeobj__90);
  Py_CLEAR(clear_module_state->__pyx_codeobj__93);
  Py_CLEAR(clear_module_state->__pyx_codeobj__95);
  return 0;
}
#endif
/* #### Code section: module_state_traverse ### */
#if CYTHON_USE_MODULE_STATE
static int __pyx_m_traverse(PyObject *m, visitproc visit, void *arg) {
  __pyx_mstate *traverse_module_state = __pyx_mstate(m);
  if (!traverse_module_state) return 0;
  Py_VISIT(traverse_module_state->__pyx_d);
  Py_VISIT(traverse_module_state->__pyx_b);
  Py_VISIT(traverse_module_state->__pyx_cython_runtime);
  Py_VISIT(traverse_module_state->__pyx_empty_tuple);
  Py_VISIT(traverse_module_state->__pyx_empty_bytes);
  Py_VISIT(traverse_module_state->__pyx_empty_unicode);
  #ifdef __Pyx_CyFunction_USED
  Py_VISIT(traverse_module_state->__pyx_CyFunctionType);
  #endif
  #ifdef __Pyx_FusedFunction_USED
  Py_VISIT(traverse_module_state->__pyx_FusedFunctionType);
  #endif
  Py_VISIT(traverse_module_state->__pyx_ptype_7cpython_4type_type);
  Py_VISIT(traverse_module_state->__pyx_ptype_5numpy_dtype);
  Py_VISIT(traverse_module_state->__pyx_ptype_5numpy_flatiter);
  Py_VISIT(traverse_module_state->__pyx_ptype_5numpy_broadcast);
  Py_VISIT(traverse_module_state->__pyx_ptype_5numpy_ndarray);
  Py_VISIT(traverse_module_state->__pyx_ptype_5numpy_generic);
  Py_VISIT(traverse_module_state->__pyx_ptype_5numpy_number);
  Py_VISIT(traverse_module_state->__pyx_ptype_5numpy_integer);
  Py_VISIT(traverse_module_state->__pyx_ptype_5numpy_signedinteger);
  Py_VISIT(traverse_module_state->__pyx_ptype_5numpy_unsignedinteger);
  Py_VISIT(traverse_module_state->__pyx_ptype_5numpy_inexact);
  Py_VISIT(traverse_module_state->__pyx_ptype_5numpy_floating);
  Py_VISIT(traverse_module_state->__pyx_ptype_5numpy_complexfloating);
  Py_VISIT(traverse_module_state->__pyx_ptype_5numpy_flexible);
  Py_VISIT(traverse_module_state->__pyx_ptype_5numpy_character);
  Py_VISIT(traverse_module_state->__pyx_ptype_5numpy_ufunc);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Both_inputArray_and_outputArray);
  Py_VISIT(traverse_module_state->__pyx_n_u_C_CONTIGUOUS);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Compression_size_must_be_num_rff);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Fatal_error_encountered);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Fatal_error_encountered_in_CudaR);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Fatal_error_encountered_in_RBF_f);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Fatal_error_encountered_in_doubl);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Fatal_error_encountered_in_float);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Fatal_error_encountered_in_float_2);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Fatal_error_encountered_while_pe);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Fatal_error_encountered_while_pe_2);
  Py_VISIT(traverse_module_state->__pyx_n_s_ImportError);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Inconsistent_array_types_passed);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Inconsistent_types_passed_to_a_w);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Incorrect_array_dims_passed);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Incorrect_array_dims_passed_to_a);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Incorrect_array_dims_passed_to_f);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Incorrect_data_types_passed);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Incorrect_data_types_supplied);
  Py_VISIT(traverse_module_state->__pyx_kp_u_One_or_more_arguments_is_not_C_c);
  Py_VISIT(traverse_module_state->__pyx_kp_u_One_or_more_arguments_to_a_wrapp);
  Py_VISIT(traverse_module_state->__pyx_kp_u_One_or_more_arguments_to_cpuSORF);
  Py_VISIT(traverse_module_state->__pyx_kp_u_One_or_more_arguments_to_floatCu);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Shape_of_output_array_and_or_chi);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Shape_of_output_array_is_not_app);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Sizes_on_input_and_output_arrays);
  Py_VISIT(traverse_module_state->__pyx_kp_u_The_input_and_chiArr_arrays_are);
  Py_VISIT(traverse_module_state->__pyx_kp_u_The_input_arrays_to_a_wrapped_RB);
  Py_VISIT(traverse_module_state->__pyx_kp_u_The_input_arrays_to_a_wrapped_RB_2);
  Py_VISIT(traverse_module_state->__pyx_kp_u_The_number_of_datapoints_in_the);
  Py_VISIT(traverse_module_state->__pyx_kp_u_The_number_of_input_and_output_d);
  Py_VISIT(traverse_module_state->__pyx_kp_u_The_number_of_sampled_frequencie);
  Py_VISIT(traverse_module_state->__pyx_kp_u_The_shape_of_the_output_array_is);
  Py_VISIT(traverse_module_state->__pyx_kp_u_There_must_be_at_least_one_datap);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Unexpected_array_type_passed_to);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Unexpected_kernel_order_supplied);
  Py_VISIT(traverse_module_state->__pyx_kp_u_Unexpected_types_passed_to_wrapp);
  Py_VISIT(traverse_module_state->__pyx_n_s_ValueError);
  Py_VISIT(traverse_module_state->__pyx_kp_u_X_must_be_a_3d_array);
  Py_VISIT(traverse_module_state->__pyx_n_s_Z);
  Py_VISIT(traverse_module_state->__pyx_n_s__70);
  Py_VISIT(traverse_module_state->__pyx_n_s__96);
  Py_VISIT(traverse_module_state->__pyx_n_s_addr);
  Py_VISIT(traverse_module_state->__pyx_n_s_addr_chi);
  Py_VISIT(traverse_module_state->__pyx_n_s_addr_featureArray);
  Py_VISIT(traverse_module_state->__pyx_n_s_addr_grad);
  Py_VISIT(traverse_module_state->__pyx_n_s_addr_gradient);
  Py_VISIT(traverse_module_state->__pyx_n_s_addr_input);
  Py_VISIT(traverse_module_state->__pyx_n_s_addr_output);
  Py_VISIT(traverse_module_state->__pyx_n_s_addr_preSumFeats);
  Py_VISIT(traverse_module_state->__pyx_n_s_addr_precomp_weights);
  Py_VISIT(traverse_module_state->__pyx_n_s_addr_radem);
  Py_VISIT(traverse_module_state->__pyx_n_s_addr_random_feats);
  Py_VISIT(traverse_module_state->__pyx_n_s_addr_reshapedCopy);
  Py_VISIT(traverse_module_state->__pyx_n_s_addr_reshapedX);
  Py_VISIT(traverse_module_state->__pyx_n_s_addr_sigma_map);
  Py_VISIT(traverse_module_state->__pyx_n_s_addr_sigma_vals);
  Py_VISIT(traverse_module_state->__pyx_n_s_asyncio_coroutines);
  Py_VISIT(traverse_module_state->__pyx_n_s_axis);
  Py_VISIT(traverse_module_state->__pyx_n_s_beta);
  Py_VISIT(traverse_module_state->__pyx_n_s_betaHparam);
  Py_VISIT(traverse_module_state->__pyx_n_s_ceil);
  Py_VISIT(traverse_module_state->__pyx_n_s_chiArr);
  Py_VISIT(traverse_module_state->__pyx_kp_u_chiArr_input_to_RBF_feature_gen);
  Py_VISIT(traverse_module_state->__pyx_kp_u_chiArr_must_be_a_1d_array_output);
  Py_VISIT(traverse_module_state->__pyx_kp_u_chiArr_must_have_same_shape_1_an);
  Py_VISIT(traverse_module_state->__pyx_kp_u_chiArr_radem_and_reshapedX_shoul);
  Py_VISIT(traverse_module_state->__pyx_kp_u_chiArr_shape_0_must_polydegree);
  Py_VISIT(traverse_module_state->__pyx_kp_u_chiArr_shape_0_must_radem_shape);
  Py_VISIT(traverse_module_state->__pyx_kp_u_chiArr_shape_1_must_radem_shape);
  Py_VISIT(traverse_module_state->__pyx_kp_u_chiArr_should_be_a_1d_array_rade);
  Py_VISIT(traverse_module_state->__pyx_kp_u_chiArr_should_be_a_2d_array_rade);
  Py_VISIT(traverse_module_state->__pyx_n_s_class_getitem);
  Py_VISIT(traverse_module_state->__pyx_n_s_cline_in_traceback);
  Py_VISIT(traverse_module_state->__pyx_n_s_compression_size);
  Py_VISIT(traverse_module_state->__pyx_n_s_copy);
  Py_VISIT(traverse_module_state->__pyx_n_s_cp);
  Py_VISIT(traverse_module_state->__pyx_n_s_cpArray);
  Py_VISIT(traverse_module_state->__pyx_n_s_cudaExactQuadratic);
  Py_VISIT(traverse_module_state->__pyx_n_s_cudaMiniARDGrad);
  Py_VISIT(traverse_module_state->__pyx_n_s_cudaPySORFTransform);
  Py_VISIT(traverse_module_state->__pyx_n_s_cudaRBFFeatureGen);
  Py_VISIT(traverse_module_state->__pyx_n_s_cudaRBFGrad);
  Py_VISIT(traverse_module_state->__pyx_n_s_cudaSRHT);
  Py_VISIT(traverse_module_state->__pyx_n_s_cuda_rf_gen_module);
  Py_VISIT(traverse_module_state->__pyx_n_s_cupy);
  Py_VISIT(traverse_module_state->__pyx_n_s_cutoff);
  Py_VISIT(traverse_module_state->__pyx_n_s_cutoff2);
  Py_VISIT(traverse_module_state->__pyx_n_s_data);
  Py_VISIT(traverse_module_state->__pyx_kp_u_dim1_of_the_input_array_must_be);
  Py_VISIT(traverse_module_state->__pyx_kp_u_dim2_of_the_input_array_to_RBF_f);
  Py_VISIT(traverse_module_state->__pyx_kp_u_dim2_of_the_input_array_to_float);
  Py_VISIT(traverse_module_state->__pyx_kp_u_dim2_of_the_reshapedX_array_must);
  Py_VISIT(traverse_module_state->__pyx_n_s_dtype);
  Py_VISIT(traverse_module_state->__pyx_n_s_errCode);
  Py_VISIT(traverse_module_state->__pyx_n_s_featureArray);
  Py_VISIT(traverse_module_state->__pyx_n_s_fitIntercept);
  Py_VISIT(traverse_module_state->__pyx_n_s_flags);
  Py_VISIT(traverse_module_state->__pyx_n_s_float32);
  Py_VISIT(traverse_module_state->__pyx_n_u_float32);
  Py_VISIT(traverse_module_state->__pyx_n_s_float64);
  Py_VISIT(traverse_module_state->__pyx_n_u_float64);
  Py_VISIT(traverse_module_state->__pyx_n_s_floor);
  Py_VISIT(traverse_module_state->__pyx_n_s_gpuConv1dArcCosFGen);
  Py_VISIT(traverse_module_state->__pyx_n_s_gpuConv1dFGen);
  Py_VISIT(traverse_module_state->__pyx_n_s_gpuConv1dMaxpool);
  Py_VISIT(traverse_module_state->__pyx_n_s_gpuConvGrad);
  Py_VISIT(traverse_module_state->__pyx_n_s_gpuGraphPolyFHT);
  Py_VISIT(traverse_module_state->__pyx_n_s_gpuPolyFHT);
  Py_VISIT(traverse_module_state->__pyx_n_s_gradient);
  Py_VISIT(traverse_module_state->__pyx_n_s_i);
  Py_VISIT(traverse_module_state->__pyx_n_s_import);
  Py_VISIT(traverse_module_state->__pyx_n_s_initializing);
  Py_VISIT(traverse_module_state->__pyx_n_s_inputArray);
  Py_VISIT(traverse_module_state->__pyx_kp_u_inputArray_and_outputArray_to_RB);
  Py_VISIT(traverse_module_state->__pyx_n_s_inputX);
  Py_VISIT(traverse_module_state->__pyx_n_u_int32);
  Py_VISIT(traverse_module_state->__pyx_n_u_int8);
  Py_VISIT(traverse_module_state->__pyx_n_s_is_coroutine);
  Py_VISIT(traverse_module_state->__pyx_n_s_j);
  Py_VISIT(traverse_module_state->__pyx_n_s_k);
  Py_VISIT(traverse_module_state->__pyx_n_s_kernelOrder);
  Py_VISIT(traverse_module_state->__pyx_n_s_log2);
  Py_VISIT(traverse_module_state->__pyx_n_s_logdim);
  Py_VISIT(traverse_module_state->__pyx_n_s_main);
  Py_VISIT(traverse_module_state->__pyx_n_s_math);
  Py_VISIT(traverse_module_state->__pyx_n_s_max);
  Py_VISIT(traverse_module_state->__pyx_n_s_name);
  Py_VISIT(traverse_module_state->__pyx_n_u_no_error);
  Py_VISIT(traverse_module_state->__pyx_n_s_np);
  Py_VISIT(traverse_module_state->__pyx_n_s_numExpectedFeats);
  Py_VISIT(traverse_module_state->__pyx_n_s_numLengthscales);
  Py_VISIT(traverse_module_state->__pyx_n_s_numThreads);
  Py_VISIT(traverse_module_state->__pyx_n_s_num_repeats);
  Py_VISIT(traverse_module_state->__pyx_n_s_numpy);
  Py_VISIT(traverse_module_state->__pyx_kp_u_numpy_core_multiarray_failed_to);
  Py_VISIT(traverse_module_state->__pyx_kp_u_numpy_core_umath_failed_to_impor);
  Py_VISIT(traverse_module_state->__pyx_n_s_os);
  Py_VISIT(traverse_module_state->__pyx_n_s_outputArray);
  Py_VISIT(traverse_module_state->__pyx_kp_u_outputArray_shape_1_must_be_an_i);
  Py_VISIT(traverse_module_state->__pyx_kp_u_outputArray_shape_1_must_be_rade);
  Py_VISIT(traverse_module_state->__pyx_kp_u_outputArray_should_be_a_2d_array);
  Py_VISIT(traverse_module_state->__pyx_kp_u_outputArray_should_be_a_3d_array);
  Py_VISIT(traverse_module_state->__pyx_n_s_polydegree);
  Py_VISIT(traverse_module_state->__pyx_n_s_preSumFeats);
  Py_VISIT(traverse_module_state->__pyx_n_s_precompWeights);
  Py_VISIT(traverse_module_state->__pyx_n_s_ptr);
  Py_VISIT(traverse_module_state->__pyx_n_s_radem);
  Py_VISIT(traverse_module_state->__pyx_kp_u_radem_chiArr_must_have_length_po);
  Py_VISIT(traverse_module_state->__pyx_kp_u_radem_must_be_a_3d_array);
  Py_VISIT(traverse_module_state->__pyx_kp_u_radem_must_be_int8);
  Py_VISIT(traverse_module_state->__pyx_kp_u_radem_must_be_of_type_int8);
  Py_VISIT(traverse_module_state->__pyx_kp_u_radem_must_have_length_3_for_dim);
  Py_VISIT(traverse_module_state->__pyx_kp_u_radem_must_have_length_3_for_dim_2);
  Py_VISIT(traverse_module_state->__pyx_kp_u_radem_must_have_length_polydegre);
  Py_VISIT(traverse_module_state->__pyx_n_s_radem_ptr);
  Py_VISIT(traverse_module_state->__pyx_n_s_range);
  Py_VISIT(traverse_module_state->__pyx_n_s_rbfNormConstant);
  Py_VISIT(traverse_module_state->__pyx_n_s_reshapedX);
  Py_VISIT(traverse_module_state->__pyx_n_s_reshapedXCopy);
  Py_VISIT(traverse_module_state->__pyx_kp_u_reshapedX_shape_1_and_shape_2_mu);
  Py_VISIT(traverse_module_state->__pyx_n_s_sampler);
  Py_VISIT(traverse_module_state->__pyx_n_s_scalingTerm);
  Py_VISIT(traverse_module_state->__pyx_n_s_scaling_factor);
  Py_VISIT(traverse_module_state->__pyx_n_s_shape);
  Py_VISIT(traverse_module_state->__pyx_n_s_sigma);
  Py_VISIT(traverse_module_state->__pyx_n_s_sigmaHparam);
  Py_VISIT(traverse_module_state->__pyx_n_s_sigmaMap);
  Py_VISIT(traverse_module_state->__pyx_n_s_sigmaMap_ptr);
  Py_VISIT(traverse_module_state->__pyx_n_s_sigmaVals);
  Py_VISIT(traverse_module_state->__pyx_n_s_spec);
  Py_VISIT(traverse_module_state->__pyx_n_s_sqrt);
  Py_VISIT(traverse_module_state->__pyx_n_s_startPos2);
  Py_VISIT(traverse_module_state->__pyx_n_s_startPosition);
  Py_VISIT(traverse_module_state->__pyx_n_s_sum);
  Py_VISIT(traverse_module_state->__pyx_n_s_test);
  Py_VISIT(traverse_module_state->__pyx_kp_s_xGPR_random_feature_generation_g);
  Py_VISIT(traverse_module_state->__pyx_kp_s_xGPR_random_feature_generation_g_2);
  Py_VISIT(traverse_module_state->__pyx_kp_s_xGPR_random_feature_generation_g_3);
  Py_VISIT(traverse_module_state->__pyx_kp_s_xGPR_random_feature_generation_g_4);
  Py_VISIT(traverse_module_state->__pyx_n_s_zeros);
  Py_VISIT(traverse_module_state->__pyx_int_0);
  Py_VISIT(traverse_module_state->__pyx_int_1);
  Py_VISIT(traverse_module_state->__pyx_int_2);
  Py_VISIT(traverse_module_state->__pyx_int_3);
  Py_VISIT(traverse_module_state->__pyx_tuple_);
  Py_VISIT(traverse_module_state->__pyx_tuple__2);
  Py_VISIT(traverse_module_state->__pyx_tuple__3);
  Py_VISIT(traverse_module_state->__pyx_tuple__4);
  Py_VISIT(traverse_module_state->__pyx_tuple__5);
  Py_VISIT(traverse_module_state->__pyx_tuple__6);
  Py_VISIT(traverse_module_state->__pyx_tuple__7);
  Py_VISIT(traverse_module_state->__pyx_tuple__8);
  Py_VISIT(traverse_module_state->__pyx_tuple__9);
  Py_VISIT(traverse_module_state->__pyx_slice__17);
  Py_VISIT(traverse_module_state->__pyx_slice__45);
  Py_VISIT(traverse_module_state->__pyx_tuple__10);
  Py_VISIT(traverse_module_state->__pyx_tuple__11);
  Py_VISIT(traverse_module_state->__pyx_tuple__12);
  Py_VISIT(traverse_module_state->__pyx_tuple__13);
  Py_VISIT(traverse_module_state->__pyx_tuple__14);
  Py_VISIT(traverse_module_state->__pyx_tuple__15);
  Py_VISIT(traverse_module_state->__pyx_tuple__16);
  Py_VISIT(traverse_module_state->__pyx_tuple__18);
  Py_VISIT(traverse_module_state->__pyx_tuple__19);
  Py_VISIT(traverse_module_state->__pyx_tuple__20);
  Py_VISIT(traverse_module_state->__pyx_tuple__21);
  Py_VISIT(traverse_module_state->__pyx_tuple__22);
  Py_VISIT(traverse_module_state->__pyx_tuple__23);
  Py_VISIT(traverse_module_state->__pyx_tuple__24);
  Py_VISIT(traverse_module_state->__pyx_tuple__25);
  Py_VISIT(traverse_module_state->__pyx_tuple__26);
  Py_VISIT(traverse_module_state->__pyx_tuple__27);
  Py_VISIT(traverse_module_state->__pyx_tuple__28);
  Py_VISIT(traverse_module_state->__pyx_tuple__29);
  Py_VISIT(traverse_module_state->__pyx_tuple__30);
  Py_VISIT(traverse_module_state->__pyx_tuple__31);
  Py_VISIT(traverse_module_state->__pyx_tuple__32);
  Py_VISIT(traverse_module_state->__pyx_tuple__33);
  Py_VISIT(traverse_module_state->__pyx_tuple__34);
  Py_VISIT(traverse_module_state->__pyx_tuple__35);
  Py_VISIT(traverse_module_state->__pyx_tuple__36);
  Py_VISIT(traverse_module_state->__pyx_tuple__37);
  Py_VISIT(traverse_module_state->__pyx_tuple__38);
  Py_VISIT(traverse_module_state->__pyx_tuple__39);
  Py_VISIT(traverse_module_state->__pyx_tuple__40);
  Py_VISIT(traverse_module_state->__pyx_tuple__41);
  Py_VISIT(traverse_module_state->__pyx_tuple__42);
  Py_VISIT(traverse_module_state->__pyx_tuple__43);
  Py_VISIT(traverse_module_state->__pyx_tuple__44);
  Py_VISIT(traverse_module_state->__pyx_tuple__46);
  Py_VISIT(traverse_module_state->__pyx_tuple__47);
  Py_VISIT(traverse_module_state->__pyx_tuple__48);
  Py_VISIT(traverse_module_state->__pyx_tuple__49);
  Py_VISIT(traverse_module_state->__pyx_tuple__50);
  Py_VISIT(traverse_module_state->__pyx_tuple__51);
  Py_VISIT(traverse_module_state->__pyx_tuple__52);
  Py_VISIT(traverse_module_state->__pyx_tuple__53);
  Py_VISIT(traverse_module_state->__pyx_tuple__54);
  Py_VISIT(traverse_module_state->__pyx_tuple__55);
  Py_VISIT(traverse_module_state->__pyx_tuple__56);
  Py_VISIT(traverse_module_state->__pyx_tuple__57);
  Py_VISIT(traverse_module_state->__pyx_tuple__58);
  Py_VISIT(traverse_module_state->__pyx_tuple__59);
  Py_VISIT(traverse_module_state->__pyx_tuple__60);
  Py_VISIT(traverse_module_state->__pyx_tuple__61);
  Py_VISIT(traverse_module_state->__pyx_tuple__62);
  Py_VISIT(traverse_module_state->__pyx_tuple__63);
  Py_VISIT(traverse_module_state->__pyx_tuple__64);
  Py_VISIT(traverse_module_state->__pyx_tuple__65);
  Py_VISIT(traverse_module_state->__pyx_tuple__66);
  Py_VISIT(traverse_module_state->__pyx_tuple__67);
  Py_VISIT(traverse_module_state->__pyx_tuple__68);
  Py_VISIT(traverse_module_state->__pyx_tuple__69);
  Py_VISIT(traverse_module_state->__pyx_tuple__71);
  Py_VISIT(traverse_module_state->__pyx_tuple__73);
  Py_VISIT(traverse_module_state->__pyx_tuple__75);
  Py_VISIT(traverse_module_state->__pyx_tuple__77);
  Py_VISIT(traverse_module_state->__pyx_tuple__79);
  Py_VISIT(traverse_module_state->__pyx_tuple__81);
  Py_VISIT(traverse_module_state->__pyx_tuple__83);
  Py_VISIT(traverse_module_state->__pyx_tuple__85);
  Py_VISIT(traverse_module_state->__pyx_tuple__87);
  Py_VISIT(traverse_module_state->__pyx_tuple__89);
  Py_VISIT(traverse_module_state->__pyx_tuple__91);
  Py_VISIT(traverse_module_state->__pyx_tuple__92);
  Py_VISIT(traverse_module_state->__pyx_tuple__94);
  Py_VISIT(traverse_module_state->__pyx_codeobj__72);
  Py_VISIT(traverse_module_state->__pyx_codeobj__74);
  Py_VISIT(traverse_module_state->__pyx_codeobj__76);
  Py_VISIT(traverse_module_state->__pyx_codeobj__78);
  Py_VISIT(traverse_module_state->__pyx_codeobj__80);
  Py_VISIT(traverse_module_state->__pyx_codeobj__82);
  Py_VISIT(traverse_module_state->__pyx_codeobj__84);
  Py_VISIT(traverse_module_state->__pyx_codeobj__86);
  Py_VISIT(traverse_module_state->__pyx_codeobj__88);
  Py_VISIT(traverse_module_state->__pyx_codeobj__90);
  Py_VISIT(traverse_module_state->__pyx_codeobj__93);
  Py_VISIT(traverse_module_state->__pyx_codeobj__95);
  return 0;
}
#endif
/* #### Code section: module_state_defines ### */
#define __pyx_d __pyx_mstate_global->__pyx_d
#define __pyx_b __pyx_mstate_global->__pyx_b
#define __pyx_cython_runtime __pyx_mstate_global->__pyx_cython_runtime
#define __pyx_empty_tuple __pyx_mstate_global->__pyx_empty_tuple
#define __pyx_empty_bytes __pyx_mstate_global->__pyx_empty_bytes
#define __pyx_empty_unicode __pyx_mstate_global->__pyx_empty_unicode
#ifdef __Pyx_CyFunction_USED
#define __pyx_CyFunctionType __pyx_mstate_global->__pyx_CyFunctionType
#endif
#ifdef __Pyx_FusedFunction_USED
#define __pyx_FusedFunctionType __pyx_mstate_global->__pyx_FusedFunctionType
#endif
#ifdef __Pyx_Generator_USED
#define __pyx_GeneratorType __pyx_mstate_global->__pyx_GeneratorType
#endif
#ifdef __Pyx_IterableCoroutine_USED
#define __pyx_IterableCoroutineType __pyx_mstate_global->__pyx_IterableCoroutineType
#endif
#ifdef __Pyx_Coroutine_USED
#define __pyx_CoroutineAwaitType __pyx_mstate_global->__pyx_CoroutineAwaitType
#endif
#ifdef __Pyx_Coroutine_USED
#define __pyx_CoroutineType __pyx_mstate_global->__pyx_CoroutineType
#endif
#if CYTHON_USE_MODULE_STATE
#endif
#if CYTHON_USE_MODULE_STATE
#endif
#if CYTHON_USE_MODULE_STATE
#endif
#if CYTHON_USE_MODULE_STATE
#endif
#if CYTHON_USE_MODULE_STATE
#endif
#define __pyx_ptype_7cpython_4type_type __pyx_mstate_global->__pyx_ptype_7cpython_4type_type
#if CYTHON_USE_MODULE_STATE
#endif
#if CYTHON_USE_MODULE_STATE
#endif
#if CYTHON_USE_MODULE_STATE
#endif
#if CYTHON_USE_MODULE_STATE
#endif
#if CYTHON_USE_MODULE_STATE
#endif
#define __pyx_ptype_5numpy_dtype __pyx_mstate_global->__pyx_ptype_5numpy_dtype
#define __pyx_ptype_5numpy_flatiter __pyx_mstate_global->__pyx_ptype_5numpy_flatiter
#define __pyx_ptype_5numpy_broadcast __pyx_mstate_global->__pyx_ptype_5numpy_broadcast
#define __pyx_ptype_5numpy_ndarray __pyx_mstate_global->__pyx_ptype_5numpy_ndarray
#define __pyx_ptype_5numpy_generic __pyx_mstate_global->__pyx_ptype_5numpy_generic
#define __pyx_ptype_5numpy_number __pyx_mstate_global->__pyx_ptype_5numpy_number
#define __pyx_ptype_5numpy_integer __pyx_mstate_global->__pyx_ptype_5numpy_integer
#define __pyx_ptype_5numpy_signedinteger __pyx_mstate_global->__pyx_ptype_5numpy_signedinteger
#define __pyx_ptype_5numpy_unsignedinteger __pyx_mstate_global->__pyx_ptype_5numpy_unsignedinteger
#define __pyx_ptype_5numpy_inexact __pyx_mstate_global->__pyx_ptype_5numpy_inexact
#define __pyx_ptype_5numpy_floating __pyx_mstate_global->__pyx_ptype_5numpy_floating
#define __pyx_ptype_5numpy_complexfloating __pyx_mstate_global->__pyx_ptype_5numpy_complexfloating
#define __pyx_ptype_5numpy_flexible __pyx_mstate_global->__pyx_ptype_5numpy_flexible
#define __pyx_ptype_5numpy_character __pyx_mstate_global->__pyx_ptype_5numpy_character
#define __pyx_ptype_5numpy_ufunc __pyx_mstate_global->__pyx_ptype_5numpy_ufunc
#if CYTHON_USE_MODULE_STATE
#endif
#if CYTHON_USE_MODULE_STATE
#endif
#if CYTHON_USE_MODULE_STATE
#endif
#if CYTHON_USE_MODULE_STATE
#endif
#define __pyx_kp_u_Both_inputArray_and_outputArray __pyx_mstate_global->__pyx_kp_u_Both_inputArray_and_outputArray
#define __pyx_n_u_C_CONTIGUOUS __pyx_mstate_global->__pyx_n_u_C_CONTIGUOUS
#define __pyx_kp_u_Compression_size_must_be_num_rff __pyx_mstate_global->__pyx_kp_u_Compression_size_must_be_num_rff
#define __pyx_kp_u_Fatal_error_encountered __pyx_mstate_global->__pyx_kp_u_Fatal_error_encountered
#define __pyx_kp_u_Fatal_error_encountered_in_CudaR __pyx_mstate_global->__pyx_kp_u_Fatal_error_encountered_in_CudaR
#define __pyx_kp_u_Fatal_error_encountered_in_RBF_f __pyx_mstate_global->__pyx_kp_u_Fatal_error_encountered_in_RBF_f
#define __pyx_kp_u_Fatal_error_encountered_in_doubl __pyx_mstate_global->__pyx_kp_u_Fatal_error_encountered_in_doubl
#define __pyx_kp_u_Fatal_error_encountered_in_float __pyx_mstate_global->__pyx_kp_u_Fatal_error_encountered_in_float
#define __pyx_kp_u_Fatal_error_encountered_in_float_2 __pyx_mstate_global->__pyx_kp_u_Fatal_error_encountered_in_float_2
#define __pyx_kp_u_Fatal_error_encountered_while_pe __pyx_mstate_global->__pyx_kp_u_Fatal_error_encountered_while_pe
#define __pyx_kp_u_Fatal_error_encountered_while_pe_2 __pyx_mstate_global->__pyx_kp_u_Fatal_error_encountered_while_pe_2
#define __pyx_n_s_ImportError __pyx_mstate_global->__pyx_n_s_ImportError
#define __pyx_kp_u_Inconsistent_array_types_passed __pyx_mstate_global->__pyx_kp_u_Inconsistent_array_types_passed
#define __pyx_kp_u_Inconsistent_types_passed_to_a_w __pyx_mstate_global->__pyx_kp_u_Inconsistent_types_passed_to_a_w
#define __pyx_kp_u_Incorrect_array_dims_passed __pyx_mstate_global->__pyx_kp_u_Incorrect_array_dims_passed
#define __pyx_kp_u_Incorrect_array_dims_passed_to_a __pyx_mstate_global->__pyx_kp_u_Incorrect_array_dims_passed_to_a
#define __pyx_kp_u_Incorrect_array_dims_passed_to_f __pyx_mstate_global->__pyx_kp_u_Incorrect_array_dims_passed_to_f
#define __pyx_kp_u_Incorrect_data_types_passed __pyx_mstate_global->__pyx_kp_u_Incorrect_data_types_passed
#define __pyx_kp_u_Incorrect_data_types_supplied __pyx_mstate_global->__pyx_kp_u_Incorrect_data_types_supplied
#define __pyx_kp_u_One_or_more_arguments_is_not_C_c __pyx_mstate_global->__pyx_kp_u_One_or_more_arguments_is_not_C_c
#define __pyx_kp_u_One_or_more_arguments_to_a_wrapp __pyx_mstate_global->__pyx_kp_u_One_or_more_arguments_to_a_wrapp
#define __pyx_kp_u_One_or_more_arguments_to_cpuSORF __pyx_mstate_global->__pyx_kp_u_One_or_more_arguments_to_cpuSORF
#define __pyx_kp_u_One_or_more_arguments_to_floatCu __pyx_mstate_global->__pyx_kp_u_One_or_more_arguments_to_floatCu
#define __pyx_kp_u_Shape_of_output_array_and_or_chi __pyx_mstate_global->__pyx_kp_u_Shape_of_output_array_and_or_chi
#define __pyx_kp_u_Shape_of_output_array_is_not_app __pyx_mstate_global->__pyx_kp_u_Shape_of_output_array_is_not_app
#define __pyx_kp_u_Sizes_on_input_and_output_arrays __pyx_mstate_global->__pyx_kp_u_Sizes_on_input_and_output_arrays
#define __pyx_kp_u_The_input_and_chiArr_arrays_are __pyx_mstate_global->__pyx_kp_u_The_input_and_chiArr_arrays_are
#define __pyx_kp_u_The_input_arrays_to_a_wrapped_RB __pyx_mstate_global->__pyx_kp_u_The_input_arrays_to_a_wrapped_RB
#define __pyx_kp_u_The_input_arrays_to_a_wrapped_RB_2 __pyx_mstate_global->__pyx_kp_u_The_input_arrays_to_a_wrapped_RB_2
#define __pyx_kp_u_The_number_of_datapoints_in_the __pyx_mstate_global->__pyx_kp_u_The_number_of_datapoints_in_the
#define __pyx_kp_u_The_number_of_input_and_output_d __pyx_mstate_global->__pyx_kp_u_The_number_of_input_and_output_d
#define __pyx_kp_u_The_number_of_sampled_frequencie __pyx_mstate_global->__pyx_kp_u_The_number_of_sampled_frequencie
#define __pyx_kp_u_The_shape_of_the_output_array_is __pyx_mstate_global->__pyx_kp_u_The_shape_of_the_output_array_is
#define __pyx_kp_u_There_must_be_at_least_one_datap __pyx_mstate_global->__pyx_kp_u_There_must_be_at_least_one_datap
#define __pyx_kp_u_Unexpected_array_type_passed_to __pyx_mstate_global->__pyx_kp_u_Unexpected_array_type_passed_to
#define __pyx_kp_u_Unexpected_kernel_order_supplied __pyx_mstate_global->__pyx_kp_u_Unexpected_kernel_order_supplied
#define __pyx_kp_u_Unexpected_types_passed_to_wrapp __pyx_mstate_global->__pyx_kp_u_Unexpected_types_passed_to_wrapp
#define __pyx_n_s_ValueError __pyx_mstate_global->__pyx_n_s_ValueError
#define __pyx_kp_u_X_must_be_a_3d_array __pyx_mstate_global->__pyx_kp_u_X_must_be_a_3d_array
#define __pyx_n_s_Z __pyx_mstate_global->__pyx_n_s_Z
#define __pyx_n_s__70 __pyx_mstate_global->__pyx_n_s__70
#define __pyx_n_s__96 __pyx_mstate_global->__pyx_n_s__96
#define __pyx_n_s_addr __pyx_mstate_global->__pyx_n_s_addr
#define __pyx_n_s_addr_chi __pyx_mstate_global->__pyx_n_s_addr_chi
#define __pyx_n_s_addr_featureArray __pyx_mstate_global->__pyx_n_s_addr_featureArray
#define __pyx_n_s_addr_grad __pyx_mstate_global->__pyx_n_s_addr_grad
#define __pyx_n_s_addr_gradient __pyx_mstate_global->__pyx_n_s_addr_gradient
#define __pyx_n_s_addr_input __pyx_mstate_global->__pyx_n_s_addr_input
#define __pyx_n_s_addr_output __pyx_mstate_global->__pyx_n_s_addr_output
#define __pyx_n_s_addr_preSumFeats __pyx_mstate_global->__pyx_n_s_addr_preSumFeats
#define __pyx_n_s_addr_precomp_weights __pyx_mstate_global->__pyx_n_s_addr_precomp_weights
#define __pyx_n_s_addr_radem __pyx_mstate_global->__pyx_n_s_addr_radem
#define __pyx_n_s_addr_random_feats __pyx_mstate_global->__pyx_n_s_addr_random_feats
#define __pyx_n_s_addr_reshapedCopy __pyx_mstate_global->__pyx_n_s_addr_reshapedCopy
#define __pyx_n_s_addr_reshapedX __pyx_mstate_global->__pyx_n_s_addr_reshapedX
#define __pyx_n_s_addr_sigma_map __pyx_mstate_global->__pyx_n_s_addr_sigma_map
#define __pyx_n_s_addr_sigma_vals __pyx_mstate_global->__pyx_n_s_addr_sigma_vals
#define __pyx_n_s_asyncio_coroutines __pyx_mstate_global->__pyx_n_s_asyncio_coroutines
#define __pyx_n_s_axis __pyx_mstate_global->__pyx_n_s_axis
#define __pyx_n_s_beta __pyx_mstate_global->__pyx_n_s_beta
#define __pyx_n_s_betaHparam __pyx_mstate_global->__pyx_n_s_betaHparam
#define __pyx_n_s_ceil __pyx_mstate_global->__pyx_n_s_ceil
#define __pyx_n_s_chiArr __pyx_mstate_global->__pyx_n_s_chiArr
#define __pyx_kp_u_chiArr_input_to_RBF_feature_gen __pyx_mstate_global->__pyx_kp_u_chiArr_input_to_RBF_feature_gen
#define __pyx_kp_u_chiArr_must_be_a_1d_array_output __pyx_mstate_global->__pyx_kp_u_chiArr_must_be_a_1d_array_output
#define __pyx_kp_u_chiArr_must_have_same_shape_1_an __pyx_mstate_global->__pyx_kp_u_chiArr_must_have_same_shape_1_an
#define __pyx_kp_u_chiArr_radem_and_reshapedX_shoul __pyx_mstate_global->__pyx_kp_u_chiArr_radem_and_reshapedX_shoul
#define __pyx_kp_u_chiArr_shape_0_must_polydegree __pyx_mstate_global->__pyx_kp_u_chiArr_shape_0_must_polydegree
#define __pyx_kp_u_chiArr_shape_0_must_radem_shape __pyx_mstate_global->__pyx_kp_u_chiArr_shape_0_must_radem_shape
#define __pyx_kp_u_chiArr_shape_1_must_radem_shape __pyx_mstate_global->__pyx_kp_u_chiArr_shape_1_must_radem_shape
#define __pyx_kp_u_chiArr_should_be_a_1d_array_rade __pyx_mstate_global->__pyx_kp_u_chiArr_should_be_a_1d_array_rade
#define __pyx_kp_u_chiArr_should_be_a_2d_array_rade __pyx_mstate_global->__pyx_kp_u_chiArr_should_be_a_2d_array_rade
#define __pyx_n_s_class_getitem __pyx_mstate_global->__pyx_n_s_class_getitem
#define __pyx_n_s_cline_in_traceback __pyx_mstate_global->__pyx_n_s_cline_in_traceback
#define __pyx_n_s_compression_size __pyx_mstate_global->__pyx_n_s_compression_size
#define __pyx_n_s_copy __pyx_mstate_global->__pyx_n_s_copy
#define __pyx_n_s_cp __pyx_mstate_global->__pyx_n_s_cp
#define __pyx_n_s_cpArray __pyx_mstate_global->__pyx_n_s_cpArray
#define __pyx_n_s_cudaExactQuadratic __pyx_mstate_global->__pyx_n_s_cudaExactQuadratic
#define __pyx_n_s_cudaMiniARDGrad __pyx_mstate_global->__pyx_n_s_cudaMiniARDGrad
#define __pyx_n_s_cudaPySORFTransform __pyx_mstate_global->__pyx_n_s_cudaPySORFTransform
#define __pyx_n_s_cudaRBFFeatureGen __pyx_mstate_global->__pyx_n_s_cudaRBFFeatureGen
#define __pyx_n_s_cudaRBFGrad __pyx_mstate_global->__pyx_n_s_cudaRBFGrad
#define __pyx_n_s_cudaSRHT __pyx_mstate_global->__pyx_n_s_cudaSRHT
#define __pyx_n_s_cuda_rf_gen_module __pyx_mstate_global->__pyx_n_s_cuda_rf_gen_module
#define __pyx_n_s_cupy __pyx_mstate_global->__pyx_n_s_cupy
#define __pyx_n_s_cutoff __pyx_mstate_global->__pyx_n_s_cutoff
#define __pyx_n_s_cutoff2 __pyx_mstate_global->__pyx_n_s_cutoff2
#define __pyx_n_s_data __pyx_mstate_global->__pyx_n_s_data
#define __pyx_kp_u_dim1_of_the_input_array_must_be __pyx_mstate_global->__pyx_kp_u_dim1_of_the_input_array_must_be
#define __pyx_kp_u_dim2_of_the_input_array_to_RBF_f __pyx_mstate_global->__pyx_kp_u_dim2_of_the_input_array_to_RBF_f
#define __pyx_kp_u_dim2_of_the_input_array_to_float __pyx_mstate_global->__pyx_kp_u_dim2_of_the_input_array_to_float
#define __pyx_kp_u_dim2_of_the_reshapedX_array_must __pyx_mstate_global->__pyx_kp_u_dim2_of_the_reshapedX_array_must
#define __pyx_n_s_dtype __pyx_mstate_global->__pyx_n_s_dtype
#define __pyx_n_s_errCode __pyx_mstate_global->__pyx_n_s_errCode
#define __pyx_n_s_featureArray __pyx_mstate_global->__pyx_n_s_featureArray
#define __pyx_n_s_fitIntercept __pyx_mstate_global->__pyx_n_s_fitIntercept
#define __pyx_n_s_flags __pyx_mstate_global->__pyx_n_s_flags
#define __pyx_n_s_float32 __pyx_mstate_global->__pyx_n_s_float32
#define __pyx_n_u_float32 __pyx_mstate_global->__pyx_n_u_float32
#define __pyx_n_s_float64 __pyx_mstate_global->__pyx_n_s_float64
#define __pyx_n_u_float64 __pyx_mstate_global->__pyx_n_u_float64
#define __pyx_n_s_floor __pyx_mstate_global->__pyx_n_s_floor
#define __pyx_n_s_gpuConv1dArcCosFGen __pyx_mstate_global->__pyx_n_s_gpuConv1dArcCosFGen
#define __pyx_n_s_gpuConv1dFGen __pyx_mstate_global->__pyx_n_s_gpuConv1dFGen
#define __pyx_n_s_gpuConv1dMaxpool __pyx_mstate_global->__pyx_n_s_gpuConv1dMaxpool
#define __pyx_n_s_gpuConvGrad __pyx_mstate_global->__pyx_n_s_gpuConvGrad
#define __pyx_n_s_gpuGraphPolyFHT __pyx_mstate_global->__pyx_n_s_gpuGraphPolyFHT
#define __pyx_n_s_gpuPolyFHT __pyx_mstate_global->__pyx_n_s_gpuPolyFHT
#define __pyx_n_s_gradient __pyx_mstate_global->__pyx_n_s_gradient
#define __pyx_n_s_i __pyx_mstate_global->__pyx_n_s_i
#define __pyx_n_s_import __pyx_mstate_global->__pyx_n_s_import
#define __pyx_n_s_initializing __pyx_mstate_global->__pyx_n_s_initializing
#define __pyx_n_s_inputArray __pyx_mstate_global->__pyx_n_s_inputArray
#define __pyx_kp_u_inputArray_and_outputArray_to_RB __pyx_mstate_global->__pyx_kp_u_inputArray_and_outputArray_to_RB
#define __pyx_n_s_inputX __pyx_mstate_global->__pyx_n_s_inputX
#define __pyx_n_u_int32 __pyx_mstate_global->__pyx_n_u_int32
#define __pyx_n_u_int8 __pyx_mstate_global->__pyx_n_u_int8
#define __pyx_n_s_is_coroutine __pyx_mstate_global->__pyx_n_s_is_coroutine
#define __pyx_n_s_j __pyx_mstate_global->__pyx_n_s_j
#define __pyx_n_s_k __pyx_mstate_global->__pyx_n_s_k
#define __pyx_n_s_kernelOrder __pyx_mstate_global->__pyx_n_s_kernelOrder
#define __pyx_n_s_log2 __pyx_mstate_global->__pyx_n_s_log2
#define __pyx_n_s_logdim __pyx_mstate_global->__pyx_n_s_logdim
#define __pyx_n_s_main __pyx_mstate_global->__pyx_n_s_main
#define __pyx_n_s_math __pyx_mstate_global->__pyx_n_s_math
#define __pyx_n_s_max __pyx_mstate_global->__pyx_n_s_max
#define __pyx_n_s_name __pyx_mstate_global->__pyx_n_s_name
#define __pyx_n_u_no_error __pyx_mstate_global->__pyx_n_u_no_error
#define __pyx_n_s_np __pyx_mstate_global->__pyx_n_s_np
#define __pyx_n_s_numExpectedFeats __pyx_mstate_global->__pyx_n_s_numExpectedFeats
#define __pyx_n_s_numLengthscales __pyx_mstate_global->__pyx_n_s_numLengthscales
#define __pyx_n_s_numThreads __pyx_mstate_global->__pyx_n_s_numThreads
#define __pyx_n_s_num_repeats __pyx_mstate_global->__pyx_n_s_num_repeats
#define __pyx_n_s_numpy __pyx_mstate_global->__pyx_n_s_numpy
#define __pyx_kp_u_numpy_core_multiarray_failed_to __pyx_mstate_global->__pyx_kp_u_numpy_core_multiarray_failed_to
#define __pyx_kp_u_numpy_core_umath_failed_to_impor __pyx_mstate_global->__pyx_kp_u_numpy_core_umath_failed_to_impor
#define __pyx_n_s_os __pyx_mstate_global->__pyx_n_s_os
#define __pyx_n_s_outputArray __pyx_mstate_global->__pyx_n_s_outputArray
#define __pyx_kp_u_outputArray_shape_1_must_be_an_i __pyx_mstate_global->__pyx_kp_u_outputArray_shape_1_must_be_an_i
#define __pyx_kp_u_outputArray_shape_1_must_be_rade __pyx_mstate_global->__pyx_kp_u_outputArray_shape_1_must_be_rade
#define __pyx_kp_u_outputArray_should_be_a_2d_array __pyx_mstate_global->__pyx_kp_u_outputArray_should_be_a_2d_array
#define __pyx_kp_u_outputArray_should_be_a_3d_array __pyx_mstate_global->__pyx_kp_u_outputArray_should_be_a_3d_array
#define __pyx_n_s_polydegree __pyx_mstate_global->__pyx_n_s_polydegree
#define __pyx_n_s_preSumFeats __pyx_mstate_global->__pyx_n_s_preSumFeats
#define __pyx_n_s_precompWeights __pyx_mstate_global->__pyx_n_s_precompWeights
#define __pyx_n_s_ptr __pyx_mstate_global->__pyx_n_s_ptr
#define __pyx_n_s_radem __pyx_mstate_global->__pyx_n_s_radem
#define __pyx_kp_u_radem_chiArr_must_have_length_po __pyx_mstate_global->__pyx_kp_u_radem_chiArr_must_have_length_po
#define __pyx_kp_u_radem_must_be_a_3d_array __pyx_mstate_global->__pyx_kp_u_radem_must_be_a_3d_array
#define __pyx_kp_u_radem_must_be_int8 __pyx_mstate_global->__pyx_kp_u_radem_must_be_int8
#define __pyx_kp_u_radem_must_be_of_type_int8 __pyx_mstate_global->__pyx_kp_u_radem_must_be_of_type_int8
#define __pyx_kp_u_radem_must_have_length_3_for_dim __pyx_mstate_global->__pyx_kp_u_radem_must_have_length_3_for_dim
#define __pyx_kp_u_radem_must_have_length_3_for_dim_2 __pyx_mstate_global->__pyx_kp_u_radem_must_have_length_3_for_dim_2
#define __pyx_kp_u_radem_must_have_length_polydegre __pyx_mstate_global->__pyx_kp_u_radem_must_have_length_polydegre
#define __pyx_n_s_radem_ptr __pyx_mstate_global->__pyx_n_s_radem_ptr
#define __pyx_n_s_range __pyx_mstate_global->__pyx_n_s_range
#define __pyx_n_s_rbfNormConstant __pyx_mstate_global->__pyx_n_s_rbfNormConstant
#define __pyx_n_s_reshapedX __pyx_mstate_global->__pyx_n_s_reshapedX
#define __pyx_n_s_reshapedXCopy __pyx_mstate_global->__pyx_n_s_reshapedXCopy
#define __pyx_kp_u_reshapedX_shape_1_and_shape_2_mu __pyx_mstate_global->__pyx_kp_u_reshapedX_shape_1_and_shape_2_mu
#define __pyx_n_s_sampler __pyx_mstate_global->__pyx_n_s_sampler
#define __pyx_n_s_scalingTerm __pyx_mstate_global->__pyx_n_s_scalingTerm
#define __pyx_n_s_scaling_factor __pyx_mstate_global->__pyx_n_s_scaling_factor
#define __pyx_n_s_shape __pyx_mstate_global->__pyx_n_s_shape
#define __pyx_n_s_sigma __pyx_mstate_global->__pyx_n_s_sigma
#define __pyx_n_s_sigmaHparam __pyx_mstate_global->__pyx_n_s_sigmaHparam
#define __pyx_n_s_sigmaMap __pyx_mstate_global->__pyx_n_s_sigmaMap
#define __pyx_n_s_sigmaMap_ptr __pyx_mstate_global->__pyx_n_s_sigmaMap_ptr
#define __pyx_n_s_sigmaVals __pyx_mstate_global->__pyx_n_s_sigmaVals
#define __pyx_n_s_spec __pyx_mstate_global->__pyx_n_s_spec
#define __pyx_n_s_sqrt __pyx_mstate_global->__pyx_n_s_sqrt
#define __pyx_n_s_startPos2 __pyx_mstate_global->__pyx_n_s_startPos2
#define __pyx_n_s_startPosition __pyx_mstate_global->__pyx_n_s_startPosition
#define __pyx_n_s_sum __pyx_mstate_global->__pyx_n_s_sum
#define __pyx_n_s_test __pyx_mstate_global->__pyx_n_s_test
#define __pyx_kp_s_xGPR_random_feature_generation_g __pyx_mstate_global->__pyx_kp_s_xGPR_random_feature_generation_g
#define __pyx_kp_s_xGPR_random_feature_generation_g_2 __pyx_mstate_global->__pyx_kp_s_xGPR_random_feature_generation_g_2
#define __pyx_kp_s_xGPR_random_feature_generation_g_3 __pyx_mstate_global->__pyx_kp_s_xGPR_random_feature_generation_g_3
#define __pyx_kp_s_xGPR_random_feature_generation_g_4 __pyx_mstate_global->__pyx_kp_s_xGPR_random_feature_generation_g_4
#define __pyx_n_s_zeros __pyx_mstate_global->__pyx_n_s_zeros
#define __pyx_int_0 __pyx_mstate_global->__pyx_int_0
#define __pyx_int_1 __pyx_mstate_global->__pyx_int_1
#define __pyx_int_2 __pyx_mstate_global->__pyx_int_2
#define __pyx_int_3 __pyx_mstate_global->__pyx_int_3
#define __pyx_tuple_ __pyx_mstate_global->__pyx_tuple_
#define __pyx_tuple__2 __pyx_mstate_global->__pyx_tuple__2
#define __pyx_tuple__3 __pyx_mstate_global->__pyx_tuple__3
#define __pyx_tuple__4 __pyx_mstate_global->__pyx_tuple__4
#define __pyx_tuple__5 __pyx_mstate_global->__pyx_tuple__5
#define __pyx_tuple__6 __pyx_mstate_global->__pyx_tuple__6
#define __pyx_tuple__7 __pyx_mstate_global->__pyx_tuple__7
#define __pyx_tuple__8 __pyx_mstate_global->__pyx_tuple__8
#define __pyx_tuple__9 __pyx_mstate_global->__pyx_tuple__9
#define __pyx_slice__17 __pyx_mstate_global->__pyx_slice__17
#define __pyx_slice__45 __pyx_mstate_global->__pyx_slice__45
#define __pyx_tuple__10 __pyx_mstate_global->__pyx_tuple__10
#define __pyx_tuple__11 __pyx_mstate_global->__pyx_tuple__11
#define __pyx_tuple__12 __pyx_mstate_global->__pyx_tuple__12
#define __pyx_tuple__13 __pyx_mstate_global->__pyx_tuple__13
#define __pyx_tuple__14 __pyx_mstate_global->__pyx_tuple__14
#define __pyx_tuple__15 __pyx_mstate_global->__pyx_tuple__15
#define __pyx_tuple__16 __pyx_mstate_global->__pyx_tuple__16
#define __pyx_tuple__18 __pyx_mstate_global->__pyx_tuple__18
#define __pyx_tuple__19 __pyx_mstate_global->__pyx_tuple__19
#define __pyx_tuple__20 __pyx_mstate_global->__pyx_tuple__20
#define __pyx_tuple__21 __pyx_mstate_global->__pyx_tuple__21
#define __pyx_tuple__22 __pyx_mstate_global->__pyx_tuple__22
#define __pyx_tuple__23 __pyx_mstate_global->__pyx_tuple__23
#define __pyx_tuple__24 __pyx_mstate_global->__pyx_tuple__24
#define __pyx_tuple__25 __pyx_mstate_global->__pyx_tuple__25
#define __pyx_tuple__26 __pyx_mstate_global->__pyx_tuple__26
#define __pyx_tuple__27 __pyx_mstate_global->__pyx_tuple__27
#define __pyx_tuple__28 __pyx_mstate_global->__pyx_tuple__28
#define __pyx_tuple__29 __pyx_mstate_global->__pyx_tuple__29
#define __pyx_tuple__30 __pyx_mstate_global->__pyx_tuple__30
#define __pyx_tuple__31 __pyx_mstate_global->__pyx_tuple__31
#define __pyx_tuple__32 __pyx_mstate_global->__pyx_tuple__32
#define __pyx_tuple__33 __pyx_mstate_global->__pyx_tuple__33
#define __pyx_tuple__34 __pyx_mstate_global->__pyx_tuple__34
#define __pyx_tuple__35 __pyx_mstate_global->__pyx_tuple__35
#define __pyx_tuple__36 __pyx_mstate_global->__pyx_tuple__36
#define __pyx_tuple__37 __pyx_mstate_global->__pyx_tuple__37
#define __pyx_tuple__38 __pyx_mstate_global->__pyx_tuple__38
#define __pyx_tuple__39 __pyx_mstate_global->__pyx_tuple__39
#define __pyx_tuple__40 __pyx_mstate_global->__pyx_tuple__40
#define __pyx_tuple__41 __pyx_mstate_global->__pyx_tuple__41
#define __pyx_tuple__42 __pyx_mstate_global->__pyx_tuple__42
#define __pyx_tuple__43 __pyx_mstate_global->__pyx_tuple__43
#define __pyx_tuple__44 __pyx_mstate_global->__pyx_tuple__44
#define __pyx_tuple__46 __pyx_mstate_global->__pyx_tuple__46
#define __pyx_tuple__47 __pyx_mstate_global->__pyx_tuple__47
#define __pyx_tuple__48 __pyx_mstate_global->__pyx_tuple__48
#define __pyx_tuple__49 __pyx_mstate_global->__pyx_tuple__49
#define __pyx_tuple__50 __pyx_mstate_global->__pyx_tuple__50
#define __pyx_tuple__51 __pyx_mstate_global->__pyx_tuple__51
#define __pyx_tuple__52 __pyx_mstate_global->__pyx_tuple__52
#define __pyx_tuple__53 __pyx_mstate_global->__pyx_tuple__53
#define __pyx_tuple__54 __pyx_mstate_global->__pyx_tuple__54
#define __pyx_tuple__55 __pyx_mstate_global->__pyx_tuple__55
#define __pyx_tuple__56 __pyx_mstate_global->__pyx_tuple__56
#define __pyx_tuple__57 __pyx_mstate_global->__pyx_tuple__57
#define __pyx_tuple__58 __pyx_mstate_global->__pyx_tuple__58
#define __pyx_tuple__59 __pyx_mstate_global->__pyx_tuple__59
#define __pyx_tuple__60 __pyx_mstate_global->__pyx_tuple__60
#define __pyx_tuple__61 __pyx_mstate_global->__pyx_tuple__61
#define __pyx_tuple__62 __pyx_mstate_global->__pyx_tuple__62
#define __pyx_tuple__63 __pyx_mstate_global->__pyx_tuple__63
#define __pyx_tuple__64 __pyx_mstate_global->__pyx_tuple__64
#define __pyx_tuple__65 __pyx_mstate_global->__pyx_tuple__65
#define __pyx_tuple__66 __pyx_mstate_global->__pyx_tuple__66
#define __pyx_tuple__67 __pyx_mstate_global->__pyx_tuple__67
#define __pyx_tuple__68 __pyx_mstate_global->__pyx_tuple__68
#define __pyx_tuple__69 __pyx_mstate_global->__pyx_tuple__69
#define __pyx_tuple__71 __pyx_mstate_global->__pyx_tuple__71
#define __pyx_tuple__73 __pyx_mstate_global->__pyx_tuple__73
#define __pyx_tuple__75 __pyx_mstate_global->__pyx_tuple__75
#define __pyx_tuple__77 __pyx_mstate_global->__pyx_tuple__77
#define __pyx_tuple__79 __pyx_mstate_global->__pyx_tuple__79
#define __pyx_tuple__81 __pyx_mstate_global->__pyx_tuple__81
#define __pyx_tuple__83 __pyx_mstate_global->__pyx_tuple__83
#define __pyx_tuple__85 __pyx_mstate_global->__pyx_tuple__85
#define __pyx_tuple__87 __pyx_mstate_global->__pyx_tuple__87
#define __pyx_tuple__89 __pyx_mstate_global->__pyx_tuple__89
#define __pyx_tuple__91 __pyx_mstate_global->__pyx_tuple__91
#define __pyx_tuple__92 __pyx_mstate_global->__pyx_tuple__92
#define __pyx_tuple__94 __pyx_mstate_global->__pyx_tuple__94
#define __pyx_codeobj__72 __pyx_mstate_global->__pyx_codeobj__72
#define __pyx_codeobj__74 __pyx_mstate_global->__pyx_codeobj__74
#define __pyx_codeobj__76 __pyx_mstate_global->__pyx_codeobj__76
#define __pyx_codeobj__78 __pyx_mstate_global->__pyx_codeobj__78
#define __pyx_codeobj__80 __pyx_mstate_global->__pyx_codeobj__80
#define __pyx_codeobj__82 __pyx_mstate_global->__pyx_codeobj__82
#define __pyx_codeobj__84 __pyx_mstate_global->__pyx_codeobj__84
#define __pyx_codeobj__86 __pyx_mstate_global->__pyx_codeobj__86
#define __pyx_codeobj__88 __pyx_mstate_global->__pyx_codeobj__88
#define __pyx_codeobj__90 __pyx_mstate_global->__pyx_codeobj__90
#define __pyx_codeobj__93 __pyx_mstate_global->__pyx_codeobj__93
#define __pyx_codeobj__95 __pyx_mstate_global->__pyx_codeobj__95
/* #### Code section: module_code ### */

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":245
 * 
 *         @property
 *         cdef inline PyObject* base(self) nogil:             # <<<<<<<<<<<<<<
 *             """Returns a borrowed reference to the object owning the data/memory.
 *             """
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_7ndarray_4base_base(PyArrayObject *__pyx_v_self) {
  PyObject *__pyx_r;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":248
 *             """Returns a borrowed reference to the object owning the data/memory.
 *             """
 *             return PyArray_BASE(self)             # <<<<<<<<<<<<<<
 * 
 *         @property
 */
  __pyx_r = PyArray_BASE(__pyx_v_self);
  goto __pyx_L0;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":245
 * 
 *         @property
 *         cdef inline PyObject* base(self) nogil:             # <<<<<<<<<<<<<<
 *             """Returns a borrowed reference to the object owning the data/memory.
 *             """
 */

  /* function exit code */
  __pyx_L0:;
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":251
 * 
 *         @property
 *         cdef inline dtype descr(self):             # <<<<<<<<<<<<<<
 *             """Returns an owned reference to the dtype of the array.
 *             """
 */

static CYTHON_INLINE PyArray_Descr *__pyx_f_5numpy_7ndarray_5descr_descr(PyArrayObject *__pyx_v_self) {
  PyArray_Descr *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyArray_Descr *__pyx_t_1;
  __Pyx_RefNannySetupContext("descr", 1);

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":254
 *             """Returns an owned reference to the dtype of the array.
 *             """
 *             return <dtype>PyArray_DESCR(self)             # <<<<<<<<<<<<<<
 * 
 *         @property
 */
  __Pyx_XDECREF((PyObject *)__pyx_r);
  __pyx_t_1 = PyArray_DESCR(__pyx_v_self);
  __Pyx_INCREF((PyObject *)((PyArray_Descr *)__pyx_t_1));
  __pyx_r = ((PyArray_Descr *)__pyx_t_1);
  goto __pyx_L0;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":251
 * 
 *         @property
 *         cdef inline dtype descr(self):             # <<<<<<<<<<<<<<
 *             """Returns an owned reference to the dtype of the array.
 *             """
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":257
 * 
 *         @property
 *         cdef inline int ndim(self) nogil:             # <<<<<<<<<<<<<<
 *             """Returns the number of dimensions in the array.
 *             """
 */

static CYTHON_INLINE int __pyx_f_5numpy_7ndarray_4ndim_ndim(PyArrayObject *__pyx_v_self) {
  int __pyx_r;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":260
 *             """Returns the number of dimensions in the array.
 *             """
 *             return PyArray_NDIM(self)             # <<<<<<<<<<<<<<
 * 
 *         @property
 */
  __pyx_r = PyArray_NDIM(__pyx_v_self);
  goto __pyx_L0;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":257
 * 
 *         @property
 *         cdef inline int ndim(self) nogil:             # <<<<<<<<<<<<<<
 *             """Returns the number of dimensions in the array.
 *             """
 */

  /* function exit code */
  __pyx_L0:;
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":263
 * 
 *         @property
 *         cdef inline npy_intp *shape(self) nogil:             # <<<<<<<<<<<<<<
 *             """Returns a pointer to the dimensions/shape of the array.
 *             The number of elements matches the number of dimensions of the array (ndim).
 */

static CYTHON_INLINE npy_intp *__pyx_f_5numpy_7ndarray_5shape_shape(PyArrayObject *__pyx_v_self) {
  npy_intp *__pyx_r;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":268
 *             Can return NULL for 0-dimensional arrays.
 *             """
 *             return PyArray_DIMS(self)             # <<<<<<<<<<<<<<
 * 
 *         @property
 */
  __pyx_r = PyArray_DIMS(__pyx_v_self);
  goto __pyx_L0;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":263
 * 
 *         @property
 *         cdef inline npy_intp *shape(self) nogil:             # <<<<<<<<<<<<<<
 *             """Returns a pointer to the dimensions/shape of the array.
 *             The number of elements matches the number of dimensions of the array (ndim).
 */

  /* function exit code */
  __pyx_L0:;
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":271
 * 
 *         @property
 *         cdef inline npy_intp *strides(self) nogil:             # <<<<<<<<<<<<<<
 *             """Returns a pointer to the strides of the array.
 *             The number of elements matches the number of dimensions of the array (ndim).
 */

static CYTHON_INLINE npy_intp *__pyx_f_5numpy_7ndarray_7strides_strides(PyArrayObject *__pyx_v_self) {
  npy_intp *__pyx_r;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":275
 *             The number of elements matches the number of dimensions of the array (ndim).
 *             """
 *             return PyArray_STRIDES(self)             # <<<<<<<<<<<<<<
 * 
 *         @property
 */
  __pyx_r = PyArray_STRIDES(__pyx_v_self);
  goto __pyx_L0;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":271
 * 
 *         @property
 *         cdef inline npy_intp *strides(self) nogil:             # <<<<<<<<<<<<<<
 *             """Returns a pointer to the strides of the array.
 *             The number of elements matches the number of dimensions of the array (ndim).
 */

  /* function exit code */
  __pyx_L0:;
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":278
 * 
 *         @property
 *         cdef inline npy_intp size(self) nogil:             # <<<<<<<<<<<<<<
 *             """Returns the total size (in number of elements) of the array.
 *             """
 */

static CYTHON_INLINE npy_intp __pyx_f_5numpy_7ndarray_4size_size(PyArrayObject *__pyx_v_self) {
  npy_intp __pyx_r;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":281
 *             """Returns the total size (in number of elements) of the array.
 *             """
 *             return PyArray_SIZE(self)             # <<<<<<<<<<<<<<
 * 
 *         @property
 */
  __pyx_r = PyArray_SIZE(__pyx_v_self);
  goto __pyx_L0;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":278
 * 
 *         @property
 *         cdef inline npy_intp size(self) nogil:             # <<<<<<<<<<<<<<
 *             """Returns the total size (in number of elements) of the array.
 *             """
 */

  /* function exit code */
  __pyx_L0:;
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":284
 * 
 *         @property
 *         cdef inline char* data(self) nogil:             # <<<<<<<<<<<<<<
 *             """The pointer to the data buffer as a char*.
 *             This is provided for legacy reasons to avoid direct struct field access.
 */

static CYTHON_INLINE char *__pyx_f_5numpy_7ndarray_4data_data(PyArrayObject *__pyx_v_self) {
  char *__pyx_r;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":290
 *             of `PyArray_DATA()` instead, which returns a 'void*'.
 *             """
 *             return PyArray_BYTES(self)             # <<<<<<<<<<<<<<
 * 
 *     ctypedef unsigned char      npy_bool
 */
  __pyx_r = PyArray_BYTES(__pyx_v_self);
  goto __pyx_L0;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":284
 * 
 *         @property
 *         cdef inline char* data(self) nogil:             # <<<<<<<<<<<<<<
 *             """The pointer to the data buffer as a char*.
 *             This is provided for legacy reasons to avoid direct struct field access.
 */

  /* function exit code */
  __pyx_L0:;
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":773
 * ctypedef npy_cdouble     complex_t
 * 
 * cdef inline object PyArray_MultiIterNew1(a):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(1, <void*>a)
 * 
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyArray_MultiIterNew1(PyObject *__pyx_v_a) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("PyArray_MultiIterNew1", 1);

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":774
 * 
 * cdef inline object PyArray_MultiIterNew1(a):
 *     return PyArray_MultiIterNew(1, <void*>a)             # <<<<<<<<<<<<<<
 * 
 * cdef inline object PyArray_MultiIterNew2(a, b):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyArray_MultiIterNew(1, ((void *)__pyx_v_a)); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 774, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":773
 * ctypedef npy_cdouble     complex_t
 * 
 * cdef inline object PyArray_MultiIterNew1(a):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(1, <void*>a)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("numpy.PyArray_MultiIterNew1", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":776
 *     return PyArray_MultiIterNew(1, <void*>a)
 * 
 * cdef inline object PyArray_MultiIterNew2(a, b):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
 * 
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyArray_MultiIterNew2(PyObject *__pyx_v_a, PyObject *__pyx_v_b) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("PyArray_MultiIterNew2", 1);

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":777
 * 
 * cdef inline object PyArray_MultiIterNew2(a, b):
 *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)             # <<<<<<<<<<<<<<
 * 
 * cdef inline object PyArray_MultiIterNew3(a, b, c):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyArray_MultiIterNew(2, ((void *)__pyx_v_a), ((void *)__pyx_v_b)); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 777, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":776
 *     return PyArray_MultiIterNew(1, <void*>a)
 * 
 * cdef inline object PyArray_MultiIterNew2(a, b):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("numpy.PyArray_MultiIterNew2", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":779
 *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
 * 
 * cdef inline object PyArray_MultiIterNew3(a, b, c):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
 * 
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyArray_MultiIterNew3(PyObject *__pyx_v_a, PyObject *__pyx_v_b, PyObject *__pyx_v_c) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("PyArray_MultiIterNew3", 1);

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":780
 * 
 * cdef inline object PyArray_MultiIterNew3(a, b, c):
 *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)             # <<<<<<<<<<<<<<
 * 
 * cdef inline object PyArray_MultiIterNew4(a, b, c, d):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyArray_MultiIterNew(3, ((void *)__pyx_v_a), ((void *)__pyx_v_b), ((void *)__pyx_v_c)); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 780, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":779
 *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
 * 
 * cdef inline object PyArray_MultiIterNew3(a, b, c):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("numpy.PyArray_MultiIterNew3", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":782
 *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
 * 
 * cdef inline object PyArray_MultiIterNew4(a, b, c, d):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
 * 
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyArray_MultiIterNew4(PyObject *__pyx_v_a, PyObject *__pyx_v_b, PyObject *__pyx_v_c, PyObject *__pyx_v_d) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("PyArray_MultiIterNew4", 1);

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":783
 * 
 * cdef inline object PyArray_MultiIterNew4(a, b, c, d):
 *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)             # <<<<<<<<<<<<<<
 * 
 * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyArray_MultiIterNew(4, ((void *)__pyx_v_a), ((void *)__pyx_v_b), ((void *)__pyx_v_c), ((void *)__pyx_v_d)); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 783, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":782
 *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
 * 
 * cdef inline object PyArray_MultiIterNew4(a, b, c, d):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("numpy.PyArray_MultiIterNew4", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":785
 *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
 * 
 * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
 * 
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyArray_MultiIterNew5(PyObject *__pyx_v_a, PyObject *__pyx_v_b, PyObject *__pyx_v_c, PyObject *__pyx_v_d, PyObject *__pyx_v_e) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("PyArray_MultiIterNew5", 1);

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":786
 * 
 * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):
 *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)             # <<<<<<<<<<<<<<
 * 
 * cdef inline tuple PyDataType_SHAPE(dtype d):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyArray_MultiIterNew(5, ((void *)__pyx_v_a), ((void *)__pyx_v_b), ((void *)__pyx_v_c), ((void *)__pyx_v_d), ((void *)__pyx_v_e)); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 786, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":785
 *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
 * 
 * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("numpy.PyArray_MultiIterNew5", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":788
 *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
 * 
 * cdef inline tuple PyDataType_SHAPE(dtype d):             # <<<<<<<<<<<<<<
 *     if PyDataType_HASSUBARRAY(d):
 *         return <tuple>d.subarray.shape
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyDataType_SHAPE(PyArray_Descr *__pyx_v_d) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("PyDataType_SHAPE", 1);

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":789
 * 
 * cdef inline tuple PyDataType_SHAPE(dtype d):
 *     if PyDataType_HASSUBARRAY(d):             # <<<<<<<<<<<<<<
 *         return <tuple>d.subarray.shape
 *     else:
 */
  __pyx_t_1 = PyDataType_HASSUBARRAY(__pyx_v_d);
  if (__pyx_t_1) {

    /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":790
 * cdef inline tuple PyDataType_SHAPE(dtype d):
 *     if PyDataType_HASSUBARRAY(d):
 *         return <tuple>d.subarray.shape             # <<<<<<<<<<<<<<
 *     else:
 *         return ()
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject*)__pyx_v_d->subarray->shape));
    __pyx_r = ((PyObject*)__pyx_v_d->subarray->shape);
    goto __pyx_L0;

    /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":789
 * 
 * cdef inline tuple PyDataType_SHAPE(dtype d):
 *     if PyDataType_HASSUBARRAY(d):             # <<<<<<<<<<<<<<
 *         return <tuple>d.subarray.shape
 *     else:
 */
  }

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":792
 *         return <tuple>d.subarray.shape
 *     else:
 *         return ()             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_empty_tuple);
    __pyx_r = __pyx_empty_tuple;
    goto __pyx_L0;
  }

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":788
 *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
 * 
 * cdef inline tuple PyDataType_SHAPE(dtype d):             # <<<<<<<<<<<<<<
 *     if PyDataType_HASSUBARRAY(d):
 *         return <tuple>d.subarray.shape
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":967
 *     int _import_umath() except -1
 * 
 * cdef inline void set_array_base(ndarray arr, object base):             # <<<<<<<<<<<<<<
 *     Py_INCREF(base) # important to do this before stealing the reference below!
 *     PyArray_SetBaseObject(arr, base)
 */

static CYTHON_INLINE void __pyx_f_5numpy_set_array_base(PyArrayObject *__pyx_v_arr, PyObject *__pyx_v_base) {
  int __pyx_t_1;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":968
 * 
 * cdef inline void set_array_base(ndarray arr, object base):
 *     Py_INCREF(base) # important to do this before stealing the reference below!             # <<<<<<<<<<<<<<
 *     PyArray_SetBaseObject(arr, base)
 * 
 */
  Py_INCREF(__pyx_v_base);

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":969
 * cdef inline void set_array_base(ndarray arr, object base):
 *     Py_INCREF(base) # important to do this before stealing the reference below!
 *     PyArray_SetBaseObject(arr, base)             # <<<<<<<<<<<<<<
 * 
 * cdef inline object get_array_base(ndarray arr):
 */
  __pyx_t_1 = PyArray_SetBaseObject(__pyx_v_arr, __pyx_v_base); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(2, 969, __pyx_L1_error)

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":967
 *     int _import_umath() except -1
 * 
 * cdef inline void set_array_base(ndarray arr, object base):             # <<<<<<<<<<<<<<
 *     Py_INCREF(base) # important to do this before stealing the reference below!
 *     PyArray_SetBaseObject(arr, base)
 */

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("numpy.set_array_base", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":971
 *     PyArray_SetBaseObject(arr, base)
 * 
 * cdef inline object get_array_base(ndarray arr):             # <<<<<<<<<<<<<<
 *     base = PyArray_BASE(arr)
 *     if base is NULL:
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_get_array_base(PyArrayObject *__pyx_v_arr) {
  PyObject *__pyx_v_base;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("get_array_base", 1);

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":972
 * 
 * cdef inline object get_array_base(ndarray arr):
 *     base = PyArray_BASE(arr)             # <<<<<<<<<<<<<<
 *     if base is NULL:
 *         return None
 */
  __pyx_v_base = PyArray_BASE(__pyx_v_arr);

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":973
 * cdef inline object get_array_base(ndarray arr):
 *     base = PyArray_BASE(arr)
 *     if base is NULL:             # <<<<<<<<<<<<<<
 *         return None
 *     return <object>base
 */
  __pyx_t_1 = (__pyx_v_base == NULL);
  if (__pyx_t_1) {

    /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":974
 *     base = PyArray_BASE(arr)
 *     if base is NULL:
 *         return None             # <<<<<<<<<<<<<<
 *     return <object>base
 * 
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_r = Py_None; __Pyx_INCREF(Py_None);
    goto __pyx_L0;

    /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":973
 * cdef inline object get_array_base(ndarray arr):
 *     base = PyArray_BASE(arr)
 *     if base is NULL:             # <<<<<<<<<<<<<<
 *         return None
 *     return <object>base
 */
  }

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":975
 *     if base is NULL:
 *         return None
 *     return <object>base             # <<<<<<<<<<<<<<
 * 
 * # Versions of the import_* functions which are more suitable for
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_base));
  __pyx_r = ((PyObject *)__pyx_v_base);
  goto __pyx_L0;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":971
 *     PyArray_SetBaseObject(arr, base)
 * 
 * cdef inline object get_array_base(ndarray arr):             # <<<<<<<<<<<<<<
 *     base = PyArray_BASE(arr)
 *     if base is NULL:
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":979
 * # Versions of the import_* functions which are more suitable for
 * # Cython code.
 * cdef inline int import_array() except -1:             # <<<<<<<<<<<<<<
 *     try:
 *         __pyx_import_array()
 */

static CYTHON_INLINE int __pyx_f_5numpy_import_array(void) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("import_array", 1);

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":980
 * # Cython code.
 * cdef inline int import_array() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         __pyx_import_array()
 *     except Exception:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
    __Pyx_XGOTREF(__pyx_t_1);
    __Pyx_XGOTREF(__pyx_t_2);
    __Pyx_XGOTREF(__pyx_t_3);
    /*try:*/ {

      /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":981
 * cdef inline int import_array() except -1:
 *     try:
 *         __pyx_import_array()             # <<<<<<<<<<<<<<
 *     except Exception:
 *         raise ImportError("numpy.core.multiarray failed to import")
 */
      __pyx_t_4 = _import_array(); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(2, 981, __pyx_L3_error)

      /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":980
 * # Cython code.
 * cdef inline int import_array() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         __pyx_import_array()
 *     except Exception:
 */
    }
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    goto __pyx_L8_try_end;
    __pyx_L3_error:;

    /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":982
 *     try:
 *         __pyx_import_array()
 *     except Exception:             # <<<<<<<<<<<<<<
 *         raise ImportError("numpy.core.multiarray failed to import")
 * 
 */
    __pyx_t_4 = __Pyx_PyErr_ExceptionMatches(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
    if (__pyx_t_4) {
      __Pyx_AddTraceback("numpy.import_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(2, 982, __pyx_L5_except_error)
      __Pyx_XGOTREF(__pyx_t_5);
      __Pyx_XGOTREF(__pyx_t_6);
      __Pyx_XGOTREF(__pyx_t_7);

      /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":983
 *         __pyx_import_array()
 *     except Exception:
 *         raise ImportError("numpy.core.multiarray failed to import")             # <<<<<<<<<<<<<<
 * 
 * cdef inline int import_umath() except -1:
 */
      __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ImportError, __pyx_tuple_, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(2, 983, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_Raise(__pyx_t_8, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __PYX_ERR(2, 983, __pyx_L5_except_error)
    }
    goto __pyx_L5_except_error;

    /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":980
 * # Cython code.
 * cdef inline int import_array() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         __pyx_import_array()
 *     except Exception:
 */
    __pyx_L5_except_error:;
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L1_error;
    __pyx_L8_try_end:;
  }

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":979
 * # Versions of the import_* functions which are more suitable for
 * # Cython code.
 * cdef inline int import_array() except -1:             # <<<<<<<<<<<<<<
 *     try:
 *         __pyx_import_array()
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("numpy.import_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":985
 *         raise ImportError("numpy.core.multiarray failed to import")
 * 
 * cdef inline int import_umath() except -1:             # <<<<<<<<<<<<<<
 *     try:
 *         _import_umath()
 */

static CYTHON_INLINE int __pyx_f_5numpy_import_umath(void) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("import_umath", 1);

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":986
 * 
 * cdef inline int import_umath() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_umath()
 *     except Exception:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
    __Pyx_XGOTREF(__pyx_t_1);
    __Pyx_XGOTREF(__pyx_t_2);
    __Pyx_XGOTREF(__pyx_t_3);
    /*try:*/ {

      /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":987
 * cdef inline int import_umath() except -1:
 *     try:
 *         _import_umath()             # <<<<<<<<<<<<<<
 *     except Exception:
 *         raise ImportError("numpy.core.umath failed to import")
 */
      __pyx_t_4 = _import_umath(); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(2, 987, __pyx_L3_error)

      /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":986
 * 
 * cdef inline int import_umath() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_umath()
 *     except Exception:
 */
    }
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    goto __pyx_L8_try_end;
    __pyx_L3_error:;

    /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":988
 *     try:
 *         _import_umath()
 *     except Exception:             # <<<<<<<<<<<<<<
 *         raise ImportError("numpy.core.umath failed to import")
 * 
 */
    __pyx_t_4 = __Pyx_PyErr_ExceptionMatches(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
    if (__pyx_t_4) {
      __Pyx_AddTraceback("numpy.import_umath", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(2, 988, __pyx_L5_except_error)
      __Pyx_XGOTREF(__pyx_t_5);
      __Pyx_XGOTREF(__pyx_t_6);
      __Pyx_XGOTREF(__pyx_t_7);

      /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":989
 *         _import_umath()
 *     except Exception:
 *         raise ImportError("numpy.core.umath failed to import")             # <<<<<<<<<<<<<<
 * 
 * cdef inline int import_ufunc() except -1:
 */
      __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ImportError, __pyx_tuple__2, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(2, 989, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_Raise(__pyx_t_8, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __PYX_ERR(2, 989, __pyx_L5_except_error)
    }
    goto __pyx_L5_except_error;

    /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":986
 * 
 * cdef inline int import_umath() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_umath()
 *     except Exception:
 */
    __pyx_L5_except_error:;
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L1_error;
    __pyx_L8_try_end:;
  }

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":985
 *         raise ImportError("numpy.core.multiarray failed to import")
 * 
 * cdef inline int import_umath() except -1:             # <<<<<<<<<<<<<<
 *     try:
 *         _import_umath()
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("numpy.import_umath", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":991
 *         raise ImportError("numpy.core.umath failed to import")
 * 
 * cdef inline int import_ufunc() except -1:             # <<<<<<<<<<<<<<
 *     try:
 *         _import_umath()
 */

static CYTHON_INLINE int __pyx_f_5numpy_import_ufunc(void) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("import_ufunc", 1);

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":992
 * 
 * cdef inline int import_ufunc() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_umath()
 *     except Exception:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
    __Pyx_XGOTREF(__pyx_t_1);
    __Pyx_XGOTREF(__pyx_t_2);
    __Pyx_XGOTREF(__pyx_t_3);
    /*try:*/ {

      /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":993
 * cdef inline int import_ufunc() except -1:
 *     try:
 *         _import_umath()             # <<<<<<<<<<<<<<
 *     except Exception:
 *         raise ImportError("numpy.core.umath failed to import")
 */
      __pyx_t_4 = _import_umath(); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(2, 993, __pyx_L3_error)

      /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":992
 * 
 * cdef inline int import_ufunc() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_umath()
 *     except Exception:
 */
    }
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    goto __pyx_L8_try_end;
    __pyx_L3_error:;

    /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":994
 *     try:
 *         _import_umath()
 *     except Exception:             # <<<<<<<<<<<<<<
 *         raise ImportError("numpy.core.umath failed to import")
 * 
 */
    __pyx_t_4 = __Pyx_PyErr_ExceptionMatches(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
    if (__pyx_t_4) {
      __Pyx_AddTraceback("numpy.import_ufunc", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(2, 994, __pyx_L5_except_error)
      __Pyx_XGOTREF(__pyx_t_5);
      __Pyx_XGOTREF(__pyx_t_6);
      __Pyx_XGOTREF(__pyx_t_7);

      /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":995
 *         _import_umath()
 *     except Exception:
 *         raise ImportError("numpy.core.umath failed to import")             # <<<<<<<<<<<<<<
 * 
 * 
 */
      __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ImportError, __pyx_tuple__2, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(2, 995, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_Raise(__pyx_t_8, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __PYX_ERR(2, 995, __pyx_L5_except_error)
    }
    goto __pyx_L5_except_error;

    /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":992
 * 
 * cdef inline int import_ufunc() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_umath()
 *     except Exception:
 */
    __pyx_L5_except_error:;
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L1_error;
    __pyx_L8_try_end:;
  }

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":991
 *         raise ImportError("numpy.core.umath failed to import")
 * 
 * cdef inline int import_ufunc() except -1:             # <<<<<<<<<<<<<<
 *     try:
 *         _import_umath()
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("numpy.import_ufunc", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":998
 * 
 * 
 * cdef inline bint is_timedelta64_object(object obj):             # <<<<<<<<<<<<<<
 *     """
 *     Cython equivalent of `isinstance(obj, np.timedelta64)`
 */

static CYTHON_INLINE int __pyx_f_5numpy_is_timedelta64_object(PyObject *__pyx_v_obj) {
  int __pyx_r;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":1010
 *     bool
 *     """
 *     return PyObject_TypeCheck(obj, &PyTimedeltaArrType_Type)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_r = PyObject_TypeCheck(__pyx_v_obj, (&PyTimedeltaArrType_Type));
  goto __pyx_L0;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":998
 * 
 * 
 * cdef inline bint is_timedelta64_object(object obj):             # <<<<<<<<<<<<<<
 *     """
 *     Cython equivalent of `isinstance(obj, np.timedelta64)`
 */

  /* function exit code */
  __pyx_L0:;
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":1013
 * 
 * 
 * cdef inline bint is_datetime64_object(object obj):             # <<<<<<<<<<<<<<
 *     """
 *     Cython equivalent of `isinstance(obj, np.datetime64)`
 */

static CYTHON_INLINE int __pyx_f_5numpy_is_datetime64_object(PyObject *__pyx_v_obj) {
  int __pyx_r;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":1025
 *     bool
 *     """
 *     return PyObject_TypeCheck(obj, &PyDatetimeArrType_Type)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_r = PyObject_TypeCheck(__pyx_v_obj, (&PyDatetimeArrType_Type));
  goto __pyx_L0;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":1013
 * 
 * 
 * cdef inline bint is_datetime64_object(object obj):             # <<<<<<<<<<<<<<
 *     """
 *     Cython equivalent of `isinstance(obj, np.datetime64)`
 */

  /* function exit code */
  __pyx_L0:;
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":1028
 * 
 * 
 * cdef inline npy_datetime get_datetime64_value(object obj) nogil:             # <<<<<<<<<<<<<<
 *     """
 *     returns the int64 value underlying scalar numpy datetime64 object
 */

static CYTHON_INLINE npy_datetime __pyx_f_5numpy_get_datetime64_value(PyObject *__pyx_v_obj) {
  npy_datetime __pyx_r;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":1035
 *     also needed.  That can be found using `get_datetime64_unit`.
 *     """
 *     return (<PyDatetimeScalarObject*>obj).obval             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_r = ((PyDatetimeScalarObject *)__pyx_v_obj)->obval;
  goto __pyx_L0;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":1028
 * 
 * 
 * cdef inline npy_datetime get_datetime64_value(object obj) nogil:             # <<<<<<<<<<<<<<
 *     """
 *     returns the int64 value underlying scalar numpy datetime64 object
 */

  /* function exit code */
  __pyx_L0:;
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":1038
 * 
 * 
 * cdef inline npy_timedelta get_timedelta64_value(object obj) nogil:             # <<<<<<<<<<<<<<
 *     """
 *     returns the int64 value underlying scalar numpy timedelta64 object
 */

static CYTHON_INLINE npy_timedelta __pyx_f_5numpy_get_timedelta64_value(PyObject *__pyx_v_obj) {
  npy_timedelta __pyx_r;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":1042
 *     returns the int64 value underlying scalar numpy timedelta64 object
 *     """
 *     return (<PyTimedeltaScalarObject*>obj).obval             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_r = ((PyTimedeltaScalarObject *)__pyx_v_obj)->obval;
  goto __pyx_L0;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":1038
 * 
 * 
 * cdef inline npy_timedelta get_timedelta64_value(object obj) nogil:             # <<<<<<<<<<<<<<
 *     """
 *     returns the int64 value underlying scalar numpy timedelta64 object
 */

  /* function exit code */
  __pyx_L0:;
  return __pyx_r;
}

/* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":1045
 * 
 * 
 * cdef inline NPY_DATETIMEUNIT get_datetime64_unit(object obj) nogil:             # <<<<<<<<<<<<<<
 *     """
 *     returns the unit part of the dtype for a numpy datetime64 object.
 */

static CYTHON_INLINE NPY_DATETIMEUNIT __pyx_f_5numpy_get_datetime64_unit(PyObject *__pyx_v_obj) {
  NPY_DATETIMEUNIT __pyx_r;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":1049
 *     returns the unit part of the dtype for a numpy datetime64 object.
 *     """
 *     return <NPY_DATETIMEUNIT>(<PyDatetimeScalarObject*>obj).obmeta.base             # <<<<<<<<<<<<<<
 */
  __pyx_r = ((NPY_DATETIMEUNIT)((PyDatetimeScalarObject *)__pyx_v_obj)->obmeta.base);
  goto __pyx_L0;

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":1045
 * 
 * 
 * cdef inline NPY_DATETIMEUNIT get_datetime64_unit(object obj) nogil:             # <<<<<<<<<<<<<<
 *     """
 *     returns the unit part of the dtype for a numpy datetime64 object.
 */

  /* function exit code */
  __pyx_L0:;
  return __pyx_r;
}

/* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":26
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaPySORFTransform(cpArray, radem, int numThreads):
 */

/* Python wrapper */
static PyObject *__pyx_pw_18cuda_rf_gen_module_1cudaPySORFTransform(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_18cuda_rf_gen_module_cudaPySORFTransform, "This function performs the calculation of the structured\n    orthogonal features or SORF approach to random Fourier features\n    by wrapping floatCudaSORF3d, when the input array is an array\n    of floats.\n    Note that floatCudaSORF3d should ONLY be accessed through this wrapper\n    since this wrapper performs key checks (the shape of the input\n    arrays, are they C-contiguous etc.) that should not be bypassed.\n\n    Args:\n        cpArray (cp.ndarray): An array of type float32 on which the\n            SORF operation will be performed in place. Must\n            be of shape (N x D x C) where C is a power of 2.\n        radem (cp.ndarray): A stack of diagonal matrices of type int8_t\n            of shape (3 x D x C).\n        num_threads (int): This argument is so that this function has\n            the same interface as the CPU SORF Transform. It is not\n            needed for the GPU transform and is ignored.\n    ");
static PyMethodDef __pyx_mdef_18cuda_rf_gen_module_1cudaPySORFTransform = {"cudaPySORFTransform", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_18cuda_rf_gen_module_1cudaPySORFTransform, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_18cuda_rf_gen_module_cudaPySORFTransform};
static PyObject *__pyx_pw_18cuda_rf_gen_module_1cudaPySORFTransform(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_cpArray = 0;
  PyObject *__pyx_v_radem = 0;
  CYTHON_UNUSED int __pyx_v_numThreads;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[3] = {0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cudaPySORFTransform (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_MACROS
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject **__pyx_pyargnames[] = {&__pyx_n_s_cpArray,&__pyx_n_s_radem,&__pyx_n_s_numThreads,0};
    if (__pyx_kwds) {
      Py_ssize_t kw_args;
      switch (__pyx_nargs) {
        case  3: values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = __Pyx_NumKwargs_FASTCALL(__pyx_kwds);
      switch (__pyx_nargs) {
        case  0:
        if (likely((values[0] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_cpArray)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[0]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 26, __pyx_L3_error)
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_radem)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[1]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 26, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaPySORFTransform", 1, 3, 3, 1); __PYX_ERR(0, 26, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_numThreads)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[2]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 26, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaPySORFTransform", 1, 3, 3, 2); __PYX_ERR(0, 26, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        const Py_ssize_t kwd_pos_args = __pyx_nargs;
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "cudaPySORFTransform") < 0)) __PYX_ERR(0, 26, __pyx_L3_error)
      }
    } else if (unlikely(__pyx_nargs != 3)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
      values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
      values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
    }
    __pyx_v_cpArray = values[0];
    __pyx_v_radem = values[1];
    __pyx_v_numThreads = __Pyx_PyInt_As_int(values[2]); if (unlikely((__pyx_v_numThreads == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 28, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cudaPySORFTransform", 1, 3, 3, __pyx_nargs); __PYX_ERR(0, 26, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_AddTraceback("cuda_rf_gen_module.cudaPySORFTransform", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_18cuda_rf_gen_module_cudaPySORFTransform(__pyx_self, __pyx_v_cpArray, __pyx_v_radem, __pyx_v_numThreads);

  /* function exit code */
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_18cuda_rf_gen_module_cudaPySORFTransform(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_cpArray, PyObject *__pyx_v_radem, CYTHON_UNUSED int __pyx_v_numThreads) {
  char const *__pyx_v_errCode;
  float __pyx_v_logdim;
  uintptr_t __pyx_v_addr;
  uintptr_t __pyx_v_addr_radem;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  uintptr_t __pyx_t_3;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_t_9;
  float __pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  int __pyx_t_12;
  int __pyx_t_13;
  Py_ssize_t __pyx_t_14;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("cudaPySORFTransform", 1);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":49
 *     cdef const char *errCode
 *     cdef float logdim
 *     cdef uintptr_t addr = cpArray.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_radem = radem.data.ptr
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_cpArray, __pyx_n_s_data); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 49, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 49, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 49, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_addr = __pyx_t_3;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":50
 *     cdef float logdim
 *     cdef uintptr_t addr = cpArray.data.ptr
 *     cdef uintptr_t addr_radem = radem.data.ptr             # <<<<<<<<<<<<<<
 * 
 *     #We need to know that cpArray.shape[1] and shape[2] match shape[1]
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 50, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 50, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 50, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_addr_radem = __pyx_t_3;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":56
 *     #have the correct data types, and that shape[2] of cpArray is a power
 *     #of two, which is a requirement for the transform.
 *     if cpArray.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if cpArray.shape[1] != radem.shape[1] or cpArray.shape[2] != radem.shape[2]:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_cpArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 56, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 56, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = (__Pyx_PyInt_BoolEqObjC(__pyx_t_2, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(0, 56, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_4)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":57
 *     #of two, which is a requirement for the transform.
 *     if cpArray.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")             # <<<<<<<<<<<<<<
 *     if cpArray.shape[1] != radem.shape[1] or cpArray.shape[2] != radem.shape[2]:
 *         raise ValueError("Incorrect array dims passed to floatCudaPySORFTransform.")
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 57, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 57, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":56
 *     #have the correct data types, and that shape[2] of cpArray is a power
 *     #of two, which is a requirement for the transform.
 *     if cpArray.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if cpArray.shape[1] != radem.shape[1] or cpArray.shape[2] != radem.shape[2]:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":58
 *     if cpArray.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if cpArray.shape[1] != radem.shape[1] or cpArray.shape[2] != radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Incorrect array dims passed to floatCudaPySORFTransform.")
 *     if radem.shape[0] != 3:
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_cpArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 58, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 58, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 58, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 58, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_1, __pyx_t_5, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 58, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(0, 58, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!__pyx_t_6) {
  } else {
    __pyx_t_4 = __pyx_t_6;
    goto __pyx_L5_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_cpArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 58, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 58, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 58, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 58, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_5, __pyx_t_1, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 58, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(0, 58, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = __pyx_t_6;
  __pyx_L5_bool_binop_done:;
  if (unlikely(__pyx_t_4)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":59
 *         raise ValueError("There must be at least one datapoint.")
 *     if cpArray.shape[1] != radem.shape[1] or cpArray.shape[2] != radem.shape[2]:
 *         raise ValueError("Incorrect array dims passed to floatCudaPySORFTransform.")             # <<<<<<<<<<<<<<
 *     if radem.shape[0] != 3:
 *         raise ValueError("radem must have length 3 for dim 0.")
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__4, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 59, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 59, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":58
 *     if cpArray.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if cpArray.shape[1] != radem.shape[1] or cpArray.shape[2] != radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Incorrect array dims passed to floatCudaPySORFTransform.")
 *     if radem.shape[0] != 3:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":60
 *     if cpArray.shape[1] != radem.shape[1] or cpArray.shape[2] != radem.shape[2]:
 *         raise ValueError("Incorrect array dims passed to floatCudaPySORFTransform.")
 *     if radem.shape[0] != 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must have length 3 for dim 0.")
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 60, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 60, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__Pyx_PyInt_BoolNeObjC(__pyx_t_1, __pyx_int_3, 3, 0)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(0, 60, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (unlikely(__pyx_t_4)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":61
 *         raise ValueError("Incorrect array dims passed to floatCudaPySORFTransform.")
 *     if radem.shape[0] != 3:
 *         raise ValueError("radem must have length 3 for dim 0.")             # <<<<<<<<<<<<<<
 * 
 *     if not cpArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"]:
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 61, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 61, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":60
 *     if cpArray.shape[1] != radem.shape[1] or cpArray.shape[2] != radem.shape[2]:
 *         raise ValueError("Incorrect array dims passed to floatCudaPySORFTransform.")
 *     if radem.shape[0] != 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must have length 3 for dim 0.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":63
 *         raise ValueError("radem must have length 3 for dim 0.")
 * 
 *     if not cpArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments to floatCudaPySORFTransform is not "
 *                 "C contiguous.")
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_cpArray, __pyx_n_s_flags); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 63, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_Dict_GetItem(__pyx_t_1, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 63, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(0, 63, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_7 = (!__pyx_t_6);
  if (!__pyx_t_7) {
  } else {
    __pyx_t_4 = __pyx_t_7;
    goto __pyx_L9_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_flags); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 63, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_Dict_GetItem(__pyx_t_2, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 63, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(0, 63, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_6 = (!__pyx_t_7);
  __pyx_t_4 = __pyx_t_6;
  __pyx_L9_bool_binop_done:;
  if (unlikely(__pyx_t_4)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":64
 * 
 *     if not cpArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments to floatCudaPySORFTransform is not "             # <<<<<<<<<<<<<<
 *                 "C contiguous.")
 *     if not radem.dtype == "int8":
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 64, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 64, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":63
 *         raise ValueError("radem must have length 3 for dim 0.")
 * 
 *     if not cpArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments to floatCudaPySORFTransform is not "
 *                 "C contiguous.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":66
 *         raise ValueError("One or more arguments to floatCudaPySORFTransform is not "
 *                 "C contiguous.")
 *     if not radem.dtype == "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be of type int8.")
 *     logdim = np.log2(cpArray.shape[2])
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_dtype); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 66, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_t_1, __pyx_n_u_int8, Py_EQ)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(0, 66, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_6 = (!__pyx_t_4);
  if (unlikely(__pyx_t_6)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":67
 *                 "C contiguous.")
 *     if not radem.dtype == "int8":
 *         raise ValueError("radem must be of type int8.")             # <<<<<<<<<<<<<<
 *     logdim = np.log2(cpArray.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or cpArray.shape[2] < 2:
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 67, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 67, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":66
 *         raise ValueError("One or more arguments to floatCudaPySORFTransform is not "
 *                 "C contiguous.")
 *     if not radem.dtype == "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be of type int8.")
 *     logdim = np.log2(cpArray.shape[2])
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":68
 *     if not radem.dtype == "int8":
 *         raise ValueError("radem must be of type int8.")
 *     logdim = np.log2(cpArray.shape[2])             # <<<<<<<<<<<<<<
 *     if np.ceil(logdim) != np.floor(logdim) or cpArray.shape[2] < 2:
 *         raise ValueError("dim2 of the input array to floatCudaPySORFTransform "
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_np); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 68, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_log2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 68, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_cpArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 68, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 68, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_9 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_9 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_t_8};
    __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_5, __pyx_callargs+1-__pyx_t_9, 1+__pyx_t_9);
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 68, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __pyx_t_10 = __pyx_PyFloat_AsFloat(__pyx_t_1); if (unlikely((__pyx_t_10 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 68, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_logdim = __pyx_t_10;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":69
 *         raise ValueError("radem must be of type int8.")
 *     logdim = np.log2(cpArray.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or cpArray.shape[2] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim2 of the input array to floatCudaPySORFTransform "
 *                             "must be a power of 2 >= 2.")
 */
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_np); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_ceil); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = PyFloat_FromDouble(__pyx_v_logdim); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_2 = NULL;
  __pyx_t_9 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_8))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_8);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_8, function);
      __pyx_t_9 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_t_5};
    __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_8, __pyx_callargs+1-__pyx_t_9, 1+__pyx_t_9);
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 69, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  }
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_np); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_floor); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = PyFloat_FromDouble(__pyx_v_logdim); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_11 = NULL;
  __pyx_t_9 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_11 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_11)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_11);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_9 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_11, __pyx_t_5};
    __pyx_t_8 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+1-__pyx_t_9, 1+__pyx_t_9);
    __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 69, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_1, __pyx_t_8, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!__pyx_t_4) {
  } else {
    __pyx_t_6 = __pyx_t_4;
    goto __pyx_L13_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_cpArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_8, __pyx_int_2, Py_LT); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_6 = __pyx_t_4;
  __pyx_L13_bool_binop_done:;
  if (unlikely(__pyx_t_6)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":70
 *     logdim = np.log2(cpArray.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or cpArray.shape[2] < 2:
 *         raise ValueError("dim2 of the input array to floatCudaPySORFTransform "             # <<<<<<<<<<<<<<
 *                             "must be a power of 2 >= 2.")
 * 
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__8, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 70, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 70, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":69
 *         raise ValueError("radem must be of type int8.")
 *     logdim = np.log2(cpArray.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or cpArray.shape[2] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim2 of the input array to floatCudaPySORFTransform "
 *                             "must be a power of 2 >= 2.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":74
 * 
 * 
 *     if cpArray.dtype == "float32":             # <<<<<<<<<<<<<<
 *         errCode = cudaSORF3d[float](<float*>addr, <int8_t*>addr_radem,
 *                 cpArray.shape[0], cpArray.shape[1],
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_cpArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 74, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_6 = (__Pyx_PyUnicode_Equals(__pyx_t_2, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(0, 74, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (__pyx_t_6) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":76
 *     if cpArray.dtype == "float32":
 *         errCode = cudaSORF3d[float](<float*>addr, <int8_t*>addr_radem,
 *                 cpArray.shape[0], cpArray.shape[1],             # <<<<<<<<<<<<<<
 *                 cpArray.shape[2])
 *     elif cpArray.dtype == "float64":
 */
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_cpArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 76, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 76, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_9 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_9 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 76, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_cpArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 76, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_8, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 76, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_12 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_12 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 76, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":77
 *         errCode = cudaSORF3d[float](<float*>addr, <int8_t*>addr_radem,
 *                 cpArray.shape[0], cpArray.shape[1],
 *                 cpArray.shape[2])             # <<<<<<<<<<<<<<
 *     elif cpArray.dtype == "float64":
 *         errCode = cudaSORF3d[double](<double*>addr, <int8_t*>addr_radem,
 */
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_cpArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 77, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 77, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_13 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_13 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 77, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":75
 * 
 *     if cpArray.dtype == "float32":
 *         errCode = cudaSORF3d[float](<float*>addr, <int8_t*>addr_radem,             # <<<<<<<<<<<<<<
 *                 cpArray.shape[0], cpArray.shape[1],
 *                 cpArray.shape[2])
 */
    __pyx_v_errCode = cudaSORF3d<float>(((float *)__pyx_v_addr), ((int8_t *)__pyx_v_addr_radem), __pyx_t_9, __pyx_t_12, __pyx_t_13);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":74
 * 
 * 
 *     if cpArray.dtype == "float32":             # <<<<<<<<<<<<<<
 *         errCode = cudaSORF3d[float](<float*>addr, <int8_t*>addr_radem,
 *                 cpArray.shape[0], cpArray.shape[1],
 */
    goto __pyx_L15;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":78
 *                 cpArray.shape[0], cpArray.shape[1],
 *                 cpArray.shape[2])
 *     elif cpArray.dtype == "float64":             # <<<<<<<<<<<<<<
 *         errCode = cudaSORF3d[double](<double*>addr, <int8_t*>addr_radem,
 *                 cpArray.shape[0], cpArray.shape[1],
 */
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_cpArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 78, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_6 = (__Pyx_PyUnicode_Equals(__pyx_t_8, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(0, 78, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (likely(__pyx_t_6)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":80
 *     elif cpArray.dtype == "float64":
 *         errCode = cudaSORF3d[double](<double*>addr, <int8_t*>addr_radem,
 *                 cpArray.shape[0], cpArray.shape[1],             # <<<<<<<<<<<<<<
 *                 cpArray.shape[2])
 *     else:
 */
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_cpArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 80, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_8, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 80, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_13 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_13 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 80, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_cpArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 80, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 80, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_12 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_12 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 80, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":81
 *         errCode = cudaSORF3d[double](<double*>addr, <int8_t*>addr_radem,
 *                 cpArray.shape[0], cpArray.shape[1],
 *                 cpArray.shape[2])             # <<<<<<<<<<<<<<
 *     else:
 *         raise ValueError("Unexpected array type passed to a wrapped C++ function.")
 */
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_cpArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 81, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_8, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 81, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_9 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_9 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 81, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":79
 *                 cpArray.shape[2])
 *     elif cpArray.dtype == "float64":
 *         errCode = cudaSORF3d[double](<double*>addr, <int8_t*>addr_radem,             # <<<<<<<<<<<<<<
 *                 cpArray.shape[0], cpArray.shape[1],
 *                 cpArray.shape[2])
 */
    __pyx_v_errCode = cudaSORF3d<double>(((double *)__pyx_v_addr), ((int8_t *)__pyx_v_addr_radem), __pyx_t_13, __pyx_t_12, __pyx_t_9);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":78
 *                 cpArray.shape[0], cpArray.shape[1],
 *                 cpArray.shape[2])
 *     elif cpArray.dtype == "float64":             # <<<<<<<<<<<<<<
 *         errCode = cudaSORF3d[double](<double*>addr, <int8_t*>addr_radem,
 *                 cpArray.shape[0], cpArray.shape[1],
 */
    goto __pyx_L15;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":83
 *                 cpArray.shape[2])
 *     else:
 *         raise ValueError("Unexpected array type passed to a wrapped C++ function.")             # <<<<<<<<<<<<<<
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered in floatCudaSORF3d.")
 */
  /*else*/ {
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__9, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 83, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 83, __pyx_L1_error)
  }
  __pyx_L15:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":84
 *     else:
 *         raise ValueError("Unexpected array type passed to a wrapped C++ function.")
 *     if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *         raise Exception("Fatal error encountered in floatCudaSORF3d.")
 * 
 */
  __pyx_t_14 = __Pyx_ssize_strlen(__pyx_v_errCode); if (unlikely(__pyx_t_14 == ((Py_ssize_t)-1))) __PYX_ERR(0, 84, __pyx_L1_error)
  __pyx_t_2 = __Pyx_decode_c_string(__pyx_v_errCode, 0, __pyx_t_14, NULL, NULL, PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 84, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_6 = (__Pyx_PyUnicode_Equals(__pyx_t_2, __pyx_n_u_no_error, Py_NE)); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(0, 84, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_6)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":85
 *         raise ValueError("Unexpected array type passed to a wrapped C++ function.")
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered in floatCudaSORF3d.")             # <<<<<<<<<<<<<<
 * 
 * 
 */
    __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__10, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 85, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 85, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":84
 *     else:
 *         raise ValueError("Unexpected array type passed to a wrapped C++ function.")
 *     if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *         raise Exception("Fatal error encountered in floatCudaSORF3d.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":26
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaPySORFTransform(cpArray, radem, int numThreads):
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_AddTraceback("cuda_rf_gen_module.cudaPySORFTransform", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":91
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaSRHT(Z, radem,
 */

/* Python wrapper */
static PyObject *__pyx_pw_18cuda_rf_gen_module_3cudaSRHT(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_18cuda_rf_gen_module_2cudaSRHT, "Wraps the Cuda code for performing an SRHT operation.\n    This wrapper performs all of the bounds checks,\n    type checks etc and should not be bypassed.\n\n    Args:\n        Z (cp.ndarray): The array on which the transform will be performed.\n            Transform is in place so nothing is returned. Shape is (N x C).\n            C must be a power of 2.\n        radem (cp.ndarray): A diagonal matrix with elements drawn from the\n            Rademacher distribution. Shape must be (C).\n        sampler (np.ndarray): An array containing indices that are used to permute\n            the columns of Z post-transform. Shape must be < Z.shape[1].\n        compression_size (int): The number of columns of Z that we plan\n            to keep.\n        numThreads (int): Not currently used, accepted only to preserve\n            shared interface with CPU functions.\n    ");
static PyMethodDef __pyx_mdef_18cuda_rf_gen_module_3cudaSRHT = {"cudaSRHT", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_18cuda_rf_gen_module_3cudaSRHT, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_18cuda_rf_gen_module_2cudaSRHT};
static PyObject *__pyx_pw_18cuda_rf_gen_module_3cudaSRHT(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_Z = 0;
  PyObject *__pyx_v_radem = 0;
  PyArrayObject *__pyx_v_sampler = 0;
  int __pyx_v_compression_size;
  CYTHON_UNUSED int __pyx_v_numThreads;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[5] = {0,0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cudaSRHT (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_MACROS
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject **__pyx_pyargnames[] = {&__pyx_n_s_Z,&__pyx_n_s_radem,&__pyx_n_s_sampler,&__pyx_n_s_compression_size,&__pyx_n_s_numThreads,0};
    if (__pyx_kwds) {
      Py_ssize_t kw_args;
      switch (__pyx_nargs) {
        case  5: values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = __Pyx_NumKwargs_FASTCALL(__pyx_kwds);
      switch (__pyx_nargs) {
        case  0:
        if (likely((values[0] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_Z)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[0]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 91, __pyx_L3_error)
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_radem)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[1]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 91, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaSRHT", 1, 5, 5, 1); __PYX_ERR(0, 91, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_sampler)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[2]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 91, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaSRHT", 1, 5, 5, 2); __PYX_ERR(0, 91, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_compression_size)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[3]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 91, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaSRHT", 1, 5, 5, 3); __PYX_ERR(0, 91, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_numThreads)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[4]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 91, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaSRHT", 1, 5, 5, 4); __PYX_ERR(0, 91, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        const Py_ssize_t kwd_pos_args = __pyx_nargs;
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "cudaSRHT") < 0)) __PYX_ERR(0, 91, __pyx_L3_error)
      }
    } else if (unlikely(__pyx_nargs != 5)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
      values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
      values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
      values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
      values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
    }
    __pyx_v_Z = values[0];
    __pyx_v_radem = values[1];
    __pyx_v_sampler = ((PyArrayObject *)values[2]);
    __pyx_v_compression_size = __Pyx_PyInt_As_int(values[3]); if (unlikely((__pyx_v_compression_size == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 95, __pyx_L3_error)
    __pyx_v_numThreads = __Pyx_PyInt_As_int(values[4]); if (unlikely((__pyx_v_numThreads == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 96, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cudaSRHT", 1, 5, 5, __pyx_nargs); __PYX_ERR(0, 91, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_AddTraceback("cuda_rf_gen_module.cudaSRHT", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_sampler), __pyx_ptype_5numpy_ndarray, 1, "sampler", 0))) __PYX_ERR(0, 94, __pyx_L1_error)
  __pyx_r = __pyx_pf_18cuda_rf_gen_module_2cudaSRHT(__pyx_self, __pyx_v_Z, __pyx_v_radem, __pyx_v_sampler, __pyx_v_compression_size, __pyx_v_numThreads);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_18cuda_rf_gen_module_2cudaSRHT(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_Z, PyObject *__pyx_v_radem, PyArrayObject *__pyx_v_sampler, int __pyx_v_compression_size, CYTHON_UNUSED int __pyx_v_numThreads) {
  char const *__pyx_v_errCode;
  double __pyx_v_scaling_factor;
  uintptr_t __pyx_v_addr;
  uintptr_t __pyx_v_addr_radem;
  PyObject *__pyx_v_logdim = NULL;
  __Pyx_LocalBuf_ND __pyx_pybuffernd_sampler;
  __Pyx_Buffer __pyx_pybuffer_sampler;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  uintptr_t __pyx_t_3;
  int __pyx_t_4;
  Py_ssize_t __pyx_t_5;
  int __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  npy_intp *__pyx_t_8;
  int __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  int __pyx_t_11;
  int __pyx_t_12;
  double __pyx_t_13;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("cudaSRHT", 1);
  __pyx_pybuffer_sampler.pybuffer.buf = NULL;
  __pyx_pybuffer_sampler.refcount = 0;
  __pyx_pybuffernd_sampler.data = NULL;
  __pyx_pybuffernd_sampler.rcbuffer = &__pyx_pybuffer_sampler;
  {
    __Pyx_BufFmt_StackElem __pyx_stack[1];
    if (unlikely(__Pyx_GetBufferAndValidate(&__pyx_pybuffernd_sampler.rcbuffer->pybuffer, (PyObject*)__pyx_v_sampler, &__Pyx_TypeInfo_nn___pyx_t_5numpy_int64_t, PyBUF_FORMAT| PyBUF_STRIDES, 1, 0, __pyx_stack) == -1)) __PYX_ERR(0, 91, __pyx_L1_error)
  }
  __pyx_pybuffernd_sampler.diminfo[0].strides = __pyx_pybuffernd_sampler.rcbuffer->pybuffer.strides[0]; __pyx_pybuffernd_sampler.diminfo[0].shape = __pyx_pybuffernd_sampler.rcbuffer->pybuffer.shape[0];

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":116
 *     cdef const char *errCode
 *     cdef double scaling_factor;
 *     cdef uintptr_t addr = Z.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_radem = radem.data.ptr
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_Z, __pyx_n_s_data); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 116, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 116, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 116, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_addr = __pyx_t_3;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":117
 *     cdef double scaling_factor;
 *     cdef uintptr_t addr = Z.data.ptr
 *     cdef uintptr_t addr_radem = radem.data.ptr             # <<<<<<<<<<<<<<
 * 
 *     if radem.dtype != "int8":
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 117, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 117, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 117, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_addr_radem = __pyx_t_3;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":119
 *     cdef uintptr_t addr_radem = radem.data.ptr
 * 
 *     if radem.dtype != "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("Incorrect data types passed.")
 *     if len(Z.shape) != 2 or len(radem.shape) != 1:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_dtype); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 119, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_t_1, __pyx_n_u_int8, Py_NE)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(0, 119, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (unlikely(__pyx_t_4)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":120
 * 
 *     if radem.dtype != "int8":
 *         raise ValueError("Incorrect data types passed.")             # <<<<<<<<<<<<<<
 *     if len(Z.shape) != 2 or len(radem.shape) != 1:
 *         raise ValueError("Incorrect array dims passed.")
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__11, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 120, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 120, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":119
 *     cdef uintptr_t addr_radem = radem.data.ptr
 * 
 *     if radem.dtype != "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("Incorrect data types passed.")
 *     if len(Z.shape) != 2 or len(radem.shape) != 1:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":121
 *     if radem.dtype != "int8":
 *         raise ValueError("Incorrect data types passed.")
 *     if len(Z.shape) != 2 or len(radem.shape) != 1:             # <<<<<<<<<<<<<<
 *         raise ValueError("Incorrect array dims passed.")
 *     if Z.shape[0] == 0:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_Z, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 121, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 121, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_6 = (__pyx_t_5 != 2);
  if (!__pyx_t_6) {
  } else {
    __pyx_t_4 = __pyx_t_6;
    goto __pyx_L5_bool_binop_done;
  }
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 121, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 121, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_6 = (__pyx_t_5 != 1);
  __pyx_t_4 = __pyx_t_6;
  __pyx_L5_bool_binop_done:;
  if (unlikely(__pyx_t_4)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":122
 *         raise ValueError("Incorrect data types passed.")
 *     if len(Z.shape) != 2 or len(radem.shape) != 1:
 *         raise ValueError("Incorrect array dims passed.")             # <<<<<<<<<<<<<<
 *     if Z.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__12, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 122, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 122, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":121
 *     if radem.dtype != "int8":
 *         raise ValueError("Incorrect data types passed.")
 *     if len(Z.shape) != 2 or len(radem.shape) != 1:             # <<<<<<<<<<<<<<
 *         raise ValueError("Incorrect array dims passed.")
 *     if Z.shape[0] == 0:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":123
 *     if len(Z.shape) != 2 or len(radem.shape) != 1:
 *         raise ValueError("Incorrect array dims passed.")
 *     if Z.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if Z.shape[1] != radem.shape[0]:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_Z, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 123, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 123, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = (__Pyx_PyInt_BoolEqObjC(__pyx_t_2, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(0, 123, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_4)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":124
 *         raise ValueError("Incorrect array dims passed.")
 *     if Z.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")             # <<<<<<<<<<<<<<
 *     if Z.shape[1] != radem.shape[0]:
 *         raise ValueError("Incorrect array dims passed.")
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 124, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 124, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":123
 *     if len(Z.shape) != 2 or len(radem.shape) != 1:
 *         raise ValueError("Incorrect array dims passed.")
 *     if Z.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if Z.shape[1] != radem.shape[0]:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":125
 *     if Z.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if Z.shape[1] != radem.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Incorrect array dims passed.")
 *     if sampler.shape[0] != compression_size:
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_Z, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 125, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 125, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 125, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 125, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_1, __pyx_t_7, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 125, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(0, 125, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_4)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":126
 *         raise ValueError("There must be at least one datapoint.")
 *     if Z.shape[1] != radem.shape[0]:
 *         raise ValueError("Incorrect array dims passed.")             # <<<<<<<<<<<<<<
 *     if sampler.shape[0] != compression_size:
 *         raise ValueError("Incorrect array dims passed.")
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__12, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 126, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 126, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":125
 *     if Z.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if Z.shape[1] != radem.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Incorrect array dims passed.")
 *     if sampler.shape[0] != compression_size:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":127
 *     if Z.shape[1] != radem.shape[0]:
 *         raise ValueError("Incorrect array dims passed.")
 *     if sampler.shape[0] != compression_size:             # <<<<<<<<<<<<<<
 *         raise ValueError("Incorrect array dims passed.")
 *     if compression_size > Z.shape[1] or compression_size < 2:
 */
  __pyx_t_8 = __pyx_f_5numpy_7ndarray_5shape_shape(((PyArrayObject *)__pyx_v_sampler)); if (unlikely(__pyx_t_8 == ((npy_intp *)NULL) && PyErr_Occurred())) __PYX_ERR(0, 127, __pyx_L1_error)
  __pyx_t_4 = ((__pyx_t_8[0]) != __pyx_v_compression_size);
  if (unlikely(__pyx_t_4)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":128
 *         raise ValueError("Incorrect array dims passed.")
 *     if sampler.shape[0] != compression_size:
 *         raise ValueError("Incorrect array dims passed.")             # <<<<<<<<<<<<<<
 *     if compression_size > Z.shape[1] or compression_size < 2:
 *         raise ValueError("Compression size must be <= num rffs but >= 2.")
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__12, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 128, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 128, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":127
 *     if Z.shape[1] != radem.shape[0]:
 *         raise ValueError("Incorrect array dims passed.")
 *     if sampler.shape[0] != compression_size:             # <<<<<<<<<<<<<<
 *         raise ValueError("Incorrect array dims passed.")
 *     if compression_size > Z.shape[1] or compression_size < 2:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":129
 *     if sampler.shape[0] != compression_size:
 *         raise ValueError("Incorrect array dims passed.")
 *     if compression_size > Z.shape[1] or compression_size < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("Compression size must be <= num rffs but >= 2.")
 * 
 */
  __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_compression_size); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 129, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_Z, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 129, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_7, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 129, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_7 = PyObject_RichCompare(__pyx_t_2, __pyx_t_1, Py_GT); __Pyx_XGOTREF(__pyx_t_7); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 129, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_7); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(0, 129, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (!__pyx_t_6) {
  } else {
    __pyx_t_4 = __pyx_t_6;
    goto __pyx_L11_bool_binop_done;
  }
  __pyx_t_6 = (__pyx_v_compression_size < 2);
  __pyx_t_4 = __pyx_t_6;
  __pyx_L11_bool_binop_done:;
  if (unlikely(__pyx_t_4)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":130
 *         raise ValueError("Incorrect array dims passed.")
 *     if compression_size > Z.shape[1] or compression_size < 2:
 *         raise ValueError("Compression size must be <= num rffs but >= 2.")             # <<<<<<<<<<<<<<
 * 
 *     if not Z.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"]:
 */
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__13, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 130, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_Raise(__pyx_t_7, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __PYX_ERR(0, 130, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":129
 *     if sampler.shape[0] != compression_size:
 *         raise ValueError("Incorrect array dims passed.")
 *     if compression_size > Z.shape[1] or compression_size < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("Compression size must be <= num rffs but >= 2.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":132
 *         raise ValueError("Compression size must be <= num rffs but >= 2.")
 * 
 *     if not Z.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments to cpuSORFTransform is not "
 *                 "C contiguous.")
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_Z, __pyx_n_s_flags); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 132, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_1 = __Pyx_PyObject_Dict_GetItem(__pyx_t_7, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 132, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(0, 132, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_9 = (!__pyx_t_6);
  if (!__pyx_t_9) {
  } else {
    __pyx_t_4 = __pyx_t_9;
    goto __pyx_L14_bool_binop_done;
  }
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_flags); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 132, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = __Pyx_PyObject_Dict_GetItem(__pyx_t_1, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 132, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_7); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(0, 132, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_6 = (!__pyx_t_9);
  __pyx_t_4 = __pyx_t_6;
  __pyx_L14_bool_binop_done:;
  if (unlikely(__pyx_t_4)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":133
 * 
 *     if not Z.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments to cpuSORFTransform is not "             # <<<<<<<<<<<<<<
 *                 "C contiguous.")
 *     logdim = np.log2(Z.shape[1])
 */
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__14, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 133, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_Raise(__pyx_t_7, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __PYX_ERR(0, 133, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":132
 *         raise ValueError("Compression size must be <= num rffs but >= 2.")
 * 
 *     if not Z.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments to cpuSORFTransform is not "
 *                 "C contiguous.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":135
 *         raise ValueError("One or more arguments to cpuSORFTransform is not "
 *                 "C contiguous.")
 *     logdim = np.log2(Z.shape[1])             # <<<<<<<<<<<<<<
 *     if np.ceil(logdim) != np.floor(logdim) or Z.shape[1] < 2:
 *         raise ValueError("dim1 of the input array must be a power of 2 >= 2.")
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 135, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_log2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 135, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_Z, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 135, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 135, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  __pyx_t_11 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_11 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_1, __pyx_t_10};
    __pyx_t_7 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+1-__pyx_t_11, 1+__pyx_t_11);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 135, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __pyx_v_logdim = __pyx_t_7;
  __pyx_t_7 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":136
 *                 "C contiguous.")
 *     logdim = np.log2(Z.shape[1])
 *     if np.ceil(logdim) != np.floor(logdim) or Z.shape[1] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim1 of the input array must be a power of 2 >= 2.")
 * 
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_np); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 136, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ceil); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 136, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_11 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_10))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_10);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_10);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_10, function);
      __pyx_t_11 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_v_logdim};
    __pyx_t_7 = __Pyx_PyObject_FastCall(__pyx_t_10, __pyx_callargs+1-__pyx_t_11, 1+__pyx_t_11);
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 136, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  }
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_np); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 136, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_floor); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 136, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_11 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
      __pyx_t_11 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_v_logdim};
    __pyx_t_10 = __Pyx_PyObject_FastCall(__pyx_t_1, __pyx_callargs+1-__pyx_t_11, 1+__pyx_t_11);
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 136, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __pyx_t_1 = PyObject_RichCompare(__pyx_t_7, __pyx_t_10, Py_NE); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 136, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(0, 136, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (!__pyx_t_6) {
  } else {
    __pyx_t_4 = __pyx_t_6;
    goto __pyx_L17_bool_binop_done;
  }
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_Z, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 136, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 136, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyObject_RichCompare(__pyx_t_10, __pyx_int_2, Py_LT); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 136, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(0, 136, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = __pyx_t_6;
  __pyx_L17_bool_binop_done:;
  if (unlikely(__pyx_t_4)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":137
 *     logdim = np.log2(Z.shape[1])
 *     if np.ceil(logdim) != np.floor(logdim) or Z.shape[1] < 2:
 *         raise ValueError("dim1 of the input array must be a power of 2 >= 2.")             # <<<<<<<<<<<<<<
 * 
 *     if Z.dtype == "float32":
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__15, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 137, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 137, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":136
 *                 "C contiguous.")
 *     logdim = np.log2(Z.shape[1])
 *     if np.ceil(logdim) != np.floor(logdim) or Z.shape[1] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim1 of the input array must be a power of 2 >= 2.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":139
 *         raise ValueError("dim1 of the input array must be a power of 2 >= 2.")
 * 
 *     if Z.dtype == "float32":             # <<<<<<<<<<<<<<
 *         errCode = cudaSRHT2d[float](<float*>addr, <int8_t*>addr_radem, Z.shape[0], Z.shape[1])
 *     elif Z.dtype == "float64":
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_Z, __pyx_n_s_dtype); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 139, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_t_1, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(0, 139, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (__pyx_t_4) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":140
 * 
 *     if Z.dtype == "float32":
 *         errCode = cudaSRHT2d[float](<float*>addr, <int8_t*>addr_radem, Z.shape[0], Z.shape[1])             # <<<<<<<<<<<<<<
 *     elif Z.dtype == "float64":
 *         errCode = cudaSRHT2d[double](<double*>addr, <int8_t*>addr_radem, Z.shape[0], Z.shape[1])
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_Z, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 140, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 140, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_11 = __Pyx_PyInt_As_int(__pyx_t_10); if (unlikely((__pyx_t_11 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 140, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_Z, __pyx_n_s_shape); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 140, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_10, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 140, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_12 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_12 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 140, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_errCode = cudaSRHT2d<float>(((float *)__pyx_v_addr), ((int8_t *)__pyx_v_addr_radem), __pyx_t_11, __pyx_t_12);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":139
 *         raise ValueError("dim1 of the input array must be a power of 2 >= 2.")
 * 
 *     if Z.dtype == "float32":             # <<<<<<<<<<<<<<
 *         errCode = cudaSRHT2d[float](<float*>addr, <int8_t*>addr_radem, Z.shape[0], Z.shape[1])
 *     elif Z.dtype == "float64":
 */
    goto __pyx_L19;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":141
 *     if Z.dtype == "float32":
 *         errCode = cudaSRHT2d[float](<float*>addr, <int8_t*>addr_radem, Z.shape[0], Z.shape[1])
 *     elif Z.dtype == "float64":             # <<<<<<<<<<<<<<
 *         errCode = cudaSRHT2d[double](<double*>addr, <int8_t*>addr_radem, Z.shape[0], Z.shape[1])
 *     else:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_Z, __pyx_n_s_dtype); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 141, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_t_1, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(0, 141, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (likely(__pyx_t_4)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":142
 *         errCode = cudaSRHT2d[float](<float*>addr, <int8_t*>addr_radem, Z.shape[0], Z.shape[1])
 *     elif Z.dtype == "float64":
 *         errCode = cudaSRHT2d[double](<double*>addr, <int8_t*>addr_radem, Z.shape[0], Z.shape[1])             # <<<<<<<<<<<<<<
 *     else:
 *         raise ValueError("Incorrect data types passed.")
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_Z, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 142, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 142, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_12 = __Pyx_PyInt_As_int(__pyx_t_10); if (unlikely((__pyx_t_12 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 142, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_Z, __pyx_n_s_shape); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 142, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_10, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 142, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_11 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_11 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 142, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_errCode = cudaSRHT2d<double>(((double *)__pyx_v_addr), ((int8_t *)__pyx_v_addr_radem), __pyx_t_12, __pyx_t_11);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":141
 *     if Z.dtype == "float32":
 *         errCode = cudaSRHT2d[float](<float*>addr, <int8_t*>addr_radem, Z.shape[0], Z.shape[1])
 *     elif Z.dtype == "float64":             # <<<<<<<<<<<<<<
 *         errCode = cudaSRHT2d[double](<double*>addr, <int8_t*>addr_radem, Z.shape[0], Z.shape[1])
 *     else:
 */
    goto __pyx_L19;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":144
 *         errCode = cudaSRHT2d[double](<double*>addr, <int8_t*>addr_radem, Z.shape[0], Z.shape[1])
 *     else:
 *         raise ValueError("Incorrect data types passed.")             # <<<<<<<<<<<<<<
 * 
 *     if errCode.decode("UTF-8") != "no_error":
 */
  /*else*/ {
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__11, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 144, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 144, __pyx_L1_error)
  }
  __pyx_L19:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":146
 *         raise ValueError("Incorrect data types passed.")
 * 
 *     if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *         raise Exception("Fatal error encountered.")
 * 
 */
  __pyx_t_5 = __Pyx_ssize_strlen(__pyx_v_errCode); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 146, __pyx_L1_error)
  __pyx_t_1 = __Pyx_decode_c_string(__pyx_v_errCode, 0, __pyx_t_5, NULL, NULL, PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 146, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_t_1, __pyx_n_u_no_error, Py_NE)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(0, 146, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (unlikely(__pyx_t_4)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":147
 * 
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered.")             # <<<<<<<<<<<<<<
 * 
 *     Z[:,:compression_size] = Z[:,sampler]
 */
    __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__16, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 147, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 147, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":146
 *         raise ValueError("Incorrect data types passed.")
 * 
 *     if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *         raise Exception("Fatal error encountered.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":149
 *         raise Exception("Fatal error encountered.")
 * 
 *     Z[:,:compression_size] = Z[:,sampler]             # <<<<<<<<<<<<<<
 *     scaling_factor = np.sqrt( <double>radem.shape[0] / <double>compression_size )
 *     Z[:,:compression_size] *= scaling_factor
 */
  __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 149, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(__pyx_slice__17);
  __Pyx_GIVEREF(__pyx_slice__17);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_slice__17)) __PYX_ERR(0, 149, __pyx_L1_error);
  __Pyx_INCREF((PyObject *)__pyx_v_sampler);
  __Pyx_GIVEREF((PyObject *)__pyx_v_sampler);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 1, ((PyObject *)__pyx_v_sampler))) __PYX_ERR(0, 149, __pyx_L1_error);
  __pyx_t_10 = __Pyx_PyObject_GetItem(__pyx_v_Z, __pyx_t_1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 149, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_compression_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 149, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = PySlice_New(Py_None, __pyx_t_1, Py_None); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 149, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 149, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(__pyx_slice__17);
  __Pyx_GIVEREF(__pyx_slice__17);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_slice__17)) __PYX_ERR(0, 149, __pyx_L1_error);
  __Pyx_GIVEREF(__pyx_t_7);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_t_7)) __PYX_ERR(0, 149, __pyx_L1_error);
  __pyx_t_7 = 0;
  if (unlikely((PyObject_SetItem(__pyx_v_Z, __pyx_t_1, __pyx_t_10) < 0))) __PYX_ERR(0, 149, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":150
 * 
 *     Z[:,:compression_size] = Z[:,sampler]
 *     scaling_factor = np.sqrt( <double>radem.shape[0] / <double>compression_size )             # <<<<<<<<<<<<<<
 *     Z[:,:compression_size] *= scaling_factor
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 150, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_sqrt); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 150, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 150, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 150, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_13 = __pyx_PyFloat_AsDouble(__pyx_t_2); if (unlikely((__pyx_t_13 == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 150, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(((double)__pyx_v_compression_size) == 0)) {
    PyErr_SetString(PyExc_ZeroDivisionError, "float division");
    __PYX_ERR(0, 150, __pyx_L1_error)
  }
  __pyx_t_2 = PyFloat_FromDouble((((double)__pyx_t_13) / ((double)__pyx_v_compression_size))); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 150, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = NULL;
  __pyx_t_11 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_7))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_7);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_7, function);
      __pyx_t_11 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_1, __pyx_t_2};
    __pyx_t_10 = __Pyx_PyObject_FastCall(__pyx_t_7, __pyx_callargs+1-__pyx_t_11, 1+__pyx_t_11);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 150, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  }
  __pyx_t_13 = __pyx_PyFloat_AsDouble(__pyx_t_10); if (unlikely((__pyx_t_13 == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 150, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_v_scaling_factor = __pyx_t_13;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":151
 *     Z[:,:compression_size] = Z[:,sampler]
 *     scaling_factor = np.sqrt( <double>radem.shape[0] / <double>compression_size )
 *     Z[:,:compression_size] *= scaling_factor             # <<<<<<<<<<<<<<
 */
  __pyx_t_10 = __Pyx_PyInt_From_int(__pyx_v_compression_size); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 151, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_7 = PySlice_New(Py_None, __pyx_t_10, Py_None); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 151, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_t_10 = PyTuple_New(2); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 151, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_INCREF(__pyx_slice__17);
  __Pyx_GIVEREF(__pyx_slice__17);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_slice__17)) __PYX_ERR(0, 151, __pyx_L1_error);
  __Pyx_GIVEREF(__pyx_t_7);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_10, 1, __pyx_t_7)) __PYX_ERR(0, 151, __pyx_L1_error);
  __pyx_t_7 = 0;
  __pyx_t_7 = __Pyx_PyObject_GetItem(__pyx_v_Z, __pyx_t_10); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 151, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_2 = PyFloat_FromDouble(__pyx_v_scaling_factor); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 151, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = PyNumber_InPlaceMultiply(__pyx_t_7, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 151, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely((PyObject_SetItem(__pyx_v_Z, __pyx_t_10, __pyx_t_1) < 0))) __PYX_ERR(0, 151, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":91
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaSRHT(Z, radem,
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_10);
  { PyObject *__pyx_type, *__pyx_value, *__pyx_tb;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&__pyx_type, &__pyx_value, &__pyx_tb);
    __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_sampler.rcbuffer->pybuffer);
  __Pyx_ErrRestore(__pyx_type, __pyx_value, __pyx_tb);}
  __Pyx_AddTraceback("cuda_rf_gen_module.cudaSRHT", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  goto __pyx_L2;
  __pyx_L0:;
  __Pyx_SafeReleaseBuffer(&__pyx_pybuffernd_sampler.rcbuffer->pybuffer);
  __pyx_L2:;
  __Pyx_XDECREF(__pyx_v_logdim);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":46
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuConv1dMaxpool(reshapedX, radem, outputArray, chiArr,
 */

/* Python wrapper */
static PyObject *__pyx_pw_18cuda_rf_gen_module_5gpuConv1dMaxpool(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_18cuda_rf_gen_module_4gpuConv1dMaxpool, "Uses wrapped C extensions to perform random feature generation\n    with ReLU activation and maxpooling. TODO: Transfer the loop\n    and sum operations in here to a Cuda kernel and wrap.\n\n    Args:\n        reshapedX (cp.ndarray): An array of type float32 from which\n            the features will be generated. Is not modified. Must\n            be of shape (N x D x C) where C is a power of 2. Should\n            have been reshaped to be appropriate for convolution.\n        radem (cp.ndarray): A stack of diagonal matrices of type int8_t\n            of shape (3 x 1 x m * C), where R is the number of random\n            features requested and m is ceil(R / C).\n        outputArray (cp.ndarray): An N x R array in which the output features\n            will be stored.\n        chiArr (cp.ndarray): A stack of diagonal matrices stored as an\n            array of shape (R) drawn from a chi distribution.\n        num_threads (int): This argument is so that this function has\n            the same interface as the CPU SORF Transform. It is not\n            needed for the GPU transform and is ignored.\n    ");
static PyMethodDef __pyx_mdef_18cuda_rf_gen_module_5gpuConv1dMaxpool = {"gpuConv1dMaxpool", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_18cuda_rf_gen_module_5gpuConv1dMaxpool, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_18cuda_rf_gen_module_4gpuConv1dMaxpool};
static PyObject *__pyx_pw_18cuda_rf_gen_module_5gpuConv1dMaxpool(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_reshapedX = 0;
  PyObject *__pyx_v_radem = 0;
  PyObject *__pyx_v_outputArray = 0;
  PyObject *__pyx_v_chiArr = 0;
  CYTHON_UNUSED int __pyx_v_numThreads;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[5] = {0,0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("gpuConv1dMaxpool (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_MACROS
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject **__pyx_pyargnames[] = {&__pyx_n_s_reshapedX,&__pyx_n_s_radem,&__pyx_n_s_outputArray,&__pyx_n_s_chiArr,&__pyx_n_s_numThreads,0};
    if (__pyx_kwds) {
      Py_ssize_t kw_args;
      switch (__pyx_nargs) {
        case  5: values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = __Pyx_NumKwargs_FASTCALL(__pyx_kwds);
      switch (__pyx_nargs) {
        case  0:
        if (likely((values[0] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_reshapedX)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[0]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 46, __pyx_L3_error)
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_radem)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[1]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 46, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConv1dMaxpool", 1, 5, 5, 1); __PYX_ERR(1, 46, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_outputArray)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[2]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 46, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConv1dMaxpool", 1, 5, 5, 2); __PYX_ERR(1, 46, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_chiArr)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[3]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 46, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConv1dMaxpool", 1, 5, 5, 3); __PYX_ERR(1, 46, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_numThreads)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[4]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 46, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConv1dMaxpool", 1, 5, 5, 4); __PYX_ERR(1, 46, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        const Py_ssize_t kwd_pos_args = __pyx_nargs;
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "gpuConv1dMaxpool") < 0)) __PYX_ERR(1, 46, __pyx_L3_error)
      }
    } else if (unlikely(__pyx_nargs != 5)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
      values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
      values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
      values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
      values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
    }
    __pyx_v_reshapedX = values[0];
    __pyx_v_radem = values[1];
    __pyx_v_outputArray = values[2];
    __pyx_v_chiArr = values[3];
    __pyx_v_numThreads = __Pyx_PyInt_As_int(values[4]); if (unlikely((__pyx_v_numThreads == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 49, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("gpuConv1dMaxpool", 1, 5, 5, __pyx_nargs); __PYX_ERR(1, 46, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_AddTraceback("cuda_rf_gen_module.gpuConv1dMaxpool", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_18cuda_rf_gen_module_4gpuConv1dMaxpool(__pyx_self, __pyx_v_reshapedX, __pyx_v_radem, __pyx_v_outputArray, __pyx_v_chiArr, __pyx_v_numThreads);

  /* function exit code */
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_18cuda_rf_gen_module_4gpuConv1dMaxpool(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_reshapedX, PyObject *__pyx_v_radem, PyObject *__pyx_v_outputArray, PyObject *__pyx_v_chiArr, CYTHON_UNUSED int __pyx_v_numThreads) {
  char const *__pyx_v_errCode;
  int __pyx_v_i;
  int __pyx_v_startPosition;
  int __pyx_v_cutoff;
  int __pyx_v_num_repeats;
  PyObject *__pyx_v_reshapedXCopy = NULL;
  uintptr_t __pyx_v_addr_reshapedCopy;
  uintptr_t __pyx_v_addr_radem;
  PyObject *__pyx_v_logdim = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  uintptr_t __pyx_t_5;
  int __pyx_t_6;
  Py_ssize_t __pyx_t_7;
  int __pyx_t_8;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_t_10;
  int __pyx_t_11;
  int __pyx_t_12;
  int __pyx_t_13;
  int __pyx_t_14;
  int __pyx_t_15;
  int __pyx_t_16;
  int __pyx_t_17;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("gpuConv1dMaxpool", 1);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":72
 *     cdef const char *errCode
 *     cdef int i, startPosition, cutoff
 *     cdef int num_repeats = (radem.shape[2] + reshapedX.shape[2] - 1) // reshapedX.shape[2]             # <<<<<<<<<<<<<<
 *     reshapedXCopy = reshapedX.copy()
 *     cdef uintptr_t addr_reshapedCopy = reshapedXCopy.data.ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 72, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 72, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 72, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 72, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Add(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 72, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyInt_SubtractObjC(__pyx_t_1, __pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 72, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 72, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 72, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_FloorDivide(__pyx_t_3, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 72, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 72, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_num_repeats = __pyx_t_4;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":73
 *     cdef int i, startPosition, cutoff
 *     cdef int num_repeats = (radem.shape[2] + reshapedX.shape[2] - 1) // reshapedX.shape[2]
 *     reshapedXCopy = reshapedX.copy()             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_reshapedCopy = reshapedXCopy.data.ptr
 *     cdef uintptr_t addr_radem = radem.data.ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_copy); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 73, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  __pyx_t_4 = 0;
  #if CYTHON_UNPACK_METHODS
  if (likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_4 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_3, NULL};
    __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+1-__pyx_t_4, 0+__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 73, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __pyx_v_reshapedXCopy = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":74
 *     cdef int num_repeats = (radem.shape[2] + reshapedX.shape[2] - 1) // reshapedX.shape[2]
 *     reshapedXCopy = reshapedX.copy()
 *     cdef uintptr_t addr_reshapedCopy = reshapedXCopy.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_radem = radem.data.ptr
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedXCopy, __pyx_n_s_data); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 74, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 74, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_5 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 74, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_addr_reshapedCopy = __pyx_t_5;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":75
 *     reshapedXCopy = reshapedX.copy()
 *     cdef uintptr_t addr_reshapedCopy = reshapedXCopy.data.ptr
 *     cdef uintptr_t addr_radem = radem.data.ptr             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 75, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 75, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_5 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 75, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_addr_radem = __pyx_t_5;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":79
 * 
 *     #Check that all arrays have expected sizes and data types.
 *     if reshapedX.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 79, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 79, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_6 = (__Pyx_PyInt_BoolEqObjC(__pyx_t_2, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(1, 79, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_6)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":80
 *     #Check that all arrays have expected sizes and data types.
 *     if reshapedX.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")             # <<<<<<<<<<<<<<
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 *         raise ValueError("The number of input and output datapoints do not "
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 80, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 80, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":79
 * 
 *     #Check that all arrays have expected sizes and data types.
 *     if reshapedX.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":81
 *     if reshapedX.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of input and output datapoints do not "
 *                 "agree.")
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 81, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 81, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 81, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 81, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_1, __pyx_t_3, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 81, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(1, 81, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_6)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":82
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 *         raise ValueError("The number of input and output datapoints do not "             # <<<<<<<<<<<<<<
 *                 "agree.")
 *     if not len(radem.shape) == 3:
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__18, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 82, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 82, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":81
 *     if reshapedX.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of input and output datapoints do not "
 *                 "agree.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":84
 *         raise ValueError("The number of input and output datapoints do not "
 *                 "agree.")
 *     if not len(radem.shape) == 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be a 3d array.")
 *     if not len(chiArr.shape) == 1 or not len(outputArray.shape) == 2:
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 84, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = PyObject_Length(__pyx_t_2); if (unlikely(__pyx_t_7 == ((Py_ssize_t)-1))) __PYX_ERR(1, 84, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_6 = (!(__pyx_t_7 == 3));
  if (unlikely(__pyx_t_6)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":85
 *                 "agree.")
 *     if not len(radem.shape) == 3:
 *         raise ValueError("radem must be a 3d array.")             # <<<<<<<<<<<<<<
 *     if not len(chiArr.shape) == 1 or not len(outputArray.shape) == 2:
 *         raise ValueError("chiArr must be a 1d array; outputArray must be 2d.")
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__19, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 85, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 85, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":84
 *         raise ValueError("The number of input and output datapoints do not "
 *                 "agree.")
 *     if not len(radem.shape) == 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be a 3d array.")
 *     if not len(chiArr.shape) == 1 or not len(outputArray.shape) == 2:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":86
 *     if not len(radem.shape) == 3:
 *         raise ValueError("radem must be a 3d array.")
 *     if not len(chiArr.shape) == 1 or not len(outputArray.shape) == 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr must be a 1d array; outputArray must be 2d.")
 *     if not len(reshapedX.shape) == 3:
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 86, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = PyObject_Length(__pyx_t_2); if (unlikely(__pyx_t_7 == ((Py_ssize_t)-1))) __PYX_ERR(1, 86, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_8 = (!(__pyx_t_7 == 1));
  if (!__pyx_t_8) {
  } else {
    __pyx_t_6 = __pyx_t_8;
    goto __pyx_L7_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 86, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = PyObject_Length(__pyx_t_2); if (unlikely(__pyx_t_7 == ((Py_ssize_t)-1))) __PYX_ERR(1, 86, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_8 = (!(__pyx_t_7 == 2));
  __pyx_t_6 = __pyx_t_8;
  __pyx_L7_bool_binop_done:;
  if (unlikely(__pyx_t_6)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":87
 *         raise ValueError("radem must be a 3d array.")
 *     if not len(chiArr.shape) == 1 or not len(outputArray.shape) == 2:
 *         raise ValueError("chiArr must be a 1d array; outputArray must be 2d.")             # <<<<<<<<<<<<<<
 *     if not len(reshapedX.shape) == 3:
 *         raise ValueError("X must be a 3d array.")
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__20, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 87, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 87, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":86
 *     if not len(radem.shape) == 3:
 *         raise ValueError("radem must be a 3d array.")
 *     if not len(chiArr.shape) == 1 or not len(outputArray.shape) == 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr must be a 1d array; outputArray must be 2d.")
 *     if not len(reshapedX.shape) == 3:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":88
 *     if not len(chiArr.shape) == 1 or not len(outputArray.shape) == 2:
 *         raise ValueError("chiArr must be a 1d array; outputArray must be 2d.")
 *     if not len(reshapedX.shape) == 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("X must be a 3d array.")
 *     if not radem.dtype == "int8":
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 88, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = PyObject_Length(__pyx_t_2); if (unlikely(__pyx_t_7 == ((Py_ssize_t)-1))) __PYX_ERR(1, 88, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_6 = (!(__pyx_t_7 == 3));
  if (unlikely(__pyx_t_6)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":89
 *         raise ValueError("chiArr must be a 1d array; outputArray must be 2d.")
 *     if not len(reshapedX.shape) == 3:
 *         raise ValueError("X must be a 3d array.")             # <<<<<<<<<<<<<<
 *     if not radem.dtype == "int8":
 *         raise ValueError("radem must be int8.")
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__21, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 89, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 89, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":88
 *     if not len(chiArr.shape) == 1 or not len(outputArray.shape) == 2:
 *         raise ValueError("chiArr must be a 1d array; outputArray must be 2d.")
 *     if not len(reshapedX.shape) == 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("X must be a 3d array.")
 *     if not radem.dtype == "int8":
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":90
 *     if not len(reshapedX.shape) == 3:
 *         raise ValueError("X must be a 3d array.")
 *     if not radem.dtype == "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be int8.")
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_dtype); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 90, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_6 = (__Pyx_PyUnicode_Equals(__pyx_t_2, __pyx_n_u_int8, Py_EQ)); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(1, 90, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_8 = (!__pyx_t_6);
  if (unlikely(__pyx_t_8)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":91
 *         raise ValueError("X must be a 3d array.")
 *     if not radem.dtype == "int8":
 *         raise ValueError("radem must be int8.")             # <<<<<<<<<<<<<<
 * 
 * 
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__22, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 91, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 91, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":90
 *     if not len(reshapedX.shape) == 3:
 *         raise ValueError("X must be a 3d array.")
 *     if not radem.dtype == "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be int8.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":95
 * 
 *     #Check that shapes of radem, outputArray are correct.
 *     if radem.shape[0] != 3 or radem.shape[1] != 1:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")
 *     if outputArray.shape[1] != radem.shape[2]:
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_6 = (__Pyx_PyInt_BoolNeObjC(__pyx_t_3, __pyx_int_3, 3, 0)); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(1, 95, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (!__pyx_t_6) {
  } else {
    __pyx_t_8 = __pyx_t_6;
    goto __pyx_L12_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_6 = (__Pyx_PyInt_BoolNeObjC(__pyx_t_2, __pyx_int_1, 1, 0)); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(1, 95, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_8 = __pyx_t_6;
  __pyx_L12_bool_binop_done:;
  if (unlikely(__pyx_t_8)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":96
 *     #Check that shapes of radem, outputArray are correct.
 *     if radem.shape[0] != 3 or radem.shape[1] != 1:
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")             # <<<<<<<<<<<<<<
 *     if outputArray.shape[1] != radem.shape[2]:
 *         raise ValueError("outputArray.shape[1] must be an integer multiple of the next largest "
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__23, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 96, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 96, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":95
 * 
 *     #Check that shapes of radem, outputArray are correct.
 *     if radem.shape[0] != 3 or radem.shape[1] != 1:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")
 *     if outputArray.shape[1] != radem.shape[2]:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":97
 *     if radem.shape[0] != 3 or radem.shape[1] != 1:
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")
 *     if outputArray.shape[1] != radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("outputArray.shape[1] must be an integer multiple of the next largest "
 *                 "power of 2 greater than the kernel width * X.shape[2].")
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 97, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 97, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 97, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 97, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_3, __pyx_t_1, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 97, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_8 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_8 < 0))) __PYX_ERR(1, 97, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_8)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":98
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")
 *     if outputArray.shape[1] != radem.shape[2]:
 *         raise ValueError("outputArray.shape[1] must be an integer multiple of the next largest "             # <<<<<<<<<<<<<<
 *                 "power of 2 greater than the kernel width * X.shape[2].")
 * 
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__24, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 98, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 98, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":97
 *     if radem.shape[0] != 3 or radem.shape[1] != 1:
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")
 *     if outputArray.shape[1] != radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("outputArray.shape[1] must be an integer multiple of the next largest "
 *                 "power of 2 greater than the kernel width * X.shape[2].")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":102
 * 
 *     #Next, make sure that reshapedX and chiArr make sense.
 *     if chiArr.shape[0] != radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr.shape[0] must == radem.shape[2].")
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 102, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 102, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 102, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 102, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_1, __pyx_t_3, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 102, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_8 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_8 < 0))) __PYX_ERR(1, 102, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_8)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":103
 *     #Next, make sure that reshapedX and chiArr make sense.
 *     if chiArr.shape[0] != radem.shape[2]:
 *         raise ValueError("chiArr.shape[0] must == radem.shape[2].")             # <<<<<<<<<<<<<<
 * 
 *     logdim = np.log2(reshapedX.shape[2])
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__25, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 103, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 103, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":102
 * 
 *     #Next, make sure that reshapedX and chiArr make sense.
 *     if chiArr.shape[0] != radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr.shape[0] must == radem.shape[2].")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":105
 *         raise ValueError("chiArr.shape[0] must == radem.shape[2].")
 * 
 *     logdim = np.log2(reshapedX.shape[2])             # <<<<<<<<<<<<<<
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 */
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_np); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 105, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_log2); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 105, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 105, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_9 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 105, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_9);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = NULL;
  __pyx_t_4 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
      __pyx_t_4 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_3, __pyx_t_9};
    __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_1, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 105, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __pyx_v_logdim = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":106
 * 
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 106, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ceil); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 106, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_9);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  __pyx_t_4 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_9))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_9);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_9);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_9, function);
      __pyx_t_4 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_1, __pyx_v_logdim};
    __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_9, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 106, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
  }
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 106, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_floor); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 106, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  __pyx_t_4 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_1, __pyx_v_logdim};
    __pyx_t_9 = __Pyx_PyObject_FastCall(__pyx_t_3, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 106, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  }
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_2, __pyx_t_9, Py_NE); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 106, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(1, 106, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (!__pyx_t_6) {
  } else {
    __pyx_t_8 = __pyx_t_6;
    goto __pyx_L17_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 106, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_9 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 106, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_9);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_9, __pyx_int_2, Py_LT); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 106, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(1, 106, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_8 = __pyx_t_6;
  __pyx_L17_bool_binop_done:;
  if (unlikely(__pyx_t_8)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":107
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")             # <<<<<<<<<<<<<<
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__26, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 107, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(1, 107, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":106
 * 
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":108
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "
 *                 "reshapedX.shape[2].")
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 108, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_9 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 108, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_9);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 108, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 108, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyNumber_Remainder(__pyx_t_9, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 108, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_8 = (__Pyx_PyInt_BoolEqObjC(__pyx_t_3, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_8 < 0))) __PYX_ERR(1, 108, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_6 = (!__pyx_t_8);
  if (unlikely(__pyx_t_6)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":109
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "             # <<<<<<<<<<<<<<
 *                 "reshapedX.shape[2].")
 * 
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__27, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 109, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(1, 109, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":108
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "
 *                 "reshapedX.shape[2].")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":113
 * 
 *     #Make sure that all inputs are C-contiguous.
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *             or not radem.flags["C_CONTIGUOUS"] or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_flags); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 113, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_PyObject_Dict_GetItem(__pyx_t_3, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 113, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_8 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_8 < 0))) __PYX_ERR(1, 113, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_10 = (!__pyx_t_8);
  if (!__pyx_t_10) {
  } else {
    __pyx_t_6 = __pyx_t_10;
    goto __pyx_L21_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":114
 *     #Make sure that all inputs are C-contiguous.
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] \
 *             or not radem.flags["C_CONTIGUOUS"] or not chiArr.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_flags); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 113, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":113
 * 
 *     #Make sure that all inputs are C-contiguous.
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *             or not radem.flags["C_CONTIGUOUS"] or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  __pyx_t_3 = __Pyx_PyObject_Dict_GetItem(__pyx_t_2, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 113, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_10 < 0))) __PYX_ERR(1, 113, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_8 = (!__pyx_t_10);
  if (!__pyx_t_8) {
  } else {
    __pyx_t_6 = __pyx_t_8;
    goto __pyx_L21_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":114
 *     #Make sure that all inputs are C-contiguous.
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] \
 *             or not radem.flags["C_CONTIGUOUS"] or not chiArr.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_flags); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 114, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_PyObject_Dict_GetItem(__pyx_t_3, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 114, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_8 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_8 < 0))) __PYX_ERR(1, 114, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_10 = (!__pyx_t_8);
  if (!__pyx_t_10) {
  } else {
    __pyx_t_6 = __pyx_t_10;
    goto __pyx_L21_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_flags); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 114, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_Dict_GetItem(__pyx_t_2, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 114, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_10 < 0))) __PYX_ERR(1, 114, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_8 = (!__pyx_t_10);
  __pyx_t_6 = __pyx_t_8;
  __pyx_L21_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":113
 * 
 *     #Make sure that all inputs are C-contiguous.
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *             or not radem.flags["C_CONTIGUOUS"] or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  if (unlikely(__pyx_t_6)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":115
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] \
 *             or not radem.flags["C_CONTIGUOUS"] or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")             # <<<<<<<<<<<<<<
 * 
 * 
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__28, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 115, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(1, 115, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":113
 * 
 *     #Make sure that all inputs are C-contiguous.
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *             or not radem.flags["C_CONTIGUOUS"] or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":119
 * 
 * 
 *     startPosition, cutoff = 0, reshapedX.shape[2]             # <<<<<<<<<<<<<<
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \
 */
  __pyx_t_4 = 0;
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 119, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 119, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_11 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_11 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 119, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_startPosition = __pyx_t_4;
  __pyx_v_cutoff = __pyx_t_11;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":121
 *     startPosition, cutoff = 0, reshapedX.shape[2]
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         for i in range(num_repeats):
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 121, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = (__Pyx_PyUnicode_Equals(__pyx_t_2, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_8 < 0))) __PYX_ERR(1, 121, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (__pyx_t_8) {
  } else {
    __pyx_t_6 = __pyx_t_8;
    goto __pyx_L26_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_dtype); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 121, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = (__Pyx_PyUnicode_Equals(__pyx_t_2, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_8 < 0))) __PYX_ERR(1, 121, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (__pyx_t_8) {
  } else {
    __pyx_t_6 = __pyx_t_8;
    goto __pyx_L26_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":122
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \
 *             chiArr.dtype == "float32":             # <<<<<<<<<<<<<<
 *         for i in range(num_repeats):
 *             reshapedXCopy[:] = reshapedX
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_dtype); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 122, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = (__Pyx_PyUnicode_Equals(__pyx_t_2, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_8 < 0))) __PYX_ERR(1, 122, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_6 = __pyx_t_8;
  __pyx_L26_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":121
 *     startPosition, cutoff = 0, reshapedX.shape[2]
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         for i in range(num_repeats):
 */
  if (__pyx_t_6) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":123
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \
 *             chiArr.dtype == "float32":
 *         for i in range(num_repeats):             # <<<<<<<<<<<<<<
 *             reshapedXCopy[:] = reshapedX
 *             errCode = conv1dPrep[float](<int8_t*>addr_radem,
 */
    __pyx_t_11 = __pyx_v_num_repeats;
    __pyx_t_4 = __pyx_t_11;
    for (__pyx_t_12 = 0; __pyx_t_12 < __pyx_t_4; __pyx_t_12+=1) {
      __pyx_v_i = __pyx_t_12;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":124
 *             chiArr.dtype == "float32":
 *         for i in range(num_repeats):
 *             reshapedXCopy[:] = reshapedX             # <<<<<<<<<<<<<<
 *             errCode = conv1dPrep[float](<int8_t*>addr_radem,
 *                     <float*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],
 */
      if (__Pyx_PyObject_SetSlice(__pyx_v_reshapedXCopy, __pyx_v_reshapedX, 0, 0, NULL, NULL, &__pyx_slice__17, 0, 0, 0) < 0) __PYX_ERR(1, 124, __pyx_L1_error)

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":126
 *             reshapedXCopy[:] = reshapedX
 *             errCode = conv1dPrep[float](<int8_t*>addr_radem,
 *                     <float*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],             # <<<<<<<<<<<<<<
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 *                     radem.shape[2])
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 126, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 126, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_13 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_13 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 126, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 126, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 126, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_14 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_14 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 126, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":127
 *             errCode = conv1dPrep[float](<int8_t*>addr_radem,
 *                     <float*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], i * reshapedX.shape[2],             # <<<<<<<<<<<<<<
 *                     radem.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 127, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 127, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_15 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_15 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 127, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_i); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 127, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 127, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_9 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 127, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyNumber_Multiply(__pyx_t_3, __pyx_t_9); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 127, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_t_16 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_16 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 127, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":128
 *                     <float*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 *                     radem.shape[2])             # <<<<<<<<<<<<<<
 *             if errCode.decode("UTF-8") != "no_error":
 *                 raise Exception("Fatal error encountered in floatGpuConv1dTransform_.")
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 128, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_9 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 128, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_17 = __Pyx_PyInt_As_int(__pyx_t_9); if (unlikely((__pyx_t_17 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 128, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":125
 *         for i in range(num_repeats):
 *             reshapedXCopy[:] = reshapedX
 *             errCode = conv1dPrep[float](<int8_t*>addr_radem,             # <<<<<<<<<<<<<<
 *                     <float*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 */
      __pyx_v_errCode = conv1dPrep<float>(((int8_t *)__pyx_v_addr_radem), ((float *)__pyx_v_addr_reshapedCopy), __pyx_t_13, __pyx_t_14, __pyx_t_15, __pyx_t_16, __pyx_t_17);

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":129
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 *                     radem.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *                 raise Exception("Fatal error encountered in floatGpuConv1dTransform_.")
 * 
 */
      __pyx_t_7 = __Pyx_ssize_strlen(__pyx_v_errCode); if (unlikely(__pyx_t_7 == ((Py_ssize_t)-1))) __PYX_ERR(1, 129, __pyx_L1_error)
      __pyx_t_9 = __Pyx_decode_c_string(__pyx_v_errCode, 0, __pyx_t_7, NULL, NULL, PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 129, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_6 = (__Pyx_PyUnicode_Equals(__pyx_t_9, __pyx_n_u_no_error, Py_NE)); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(1, 129, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      if (unlikely(__pyx_t_6)) {

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":130
 *                     radem.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":
 *                 raise Exception("Fatal error encountered in floatGpuConv1dTransform_.")             # <<<<<<<<<<<<<<
 * 
 *             reshapedXCopy *= chiArr[None,None,(i * reshapedX.shape[2]):((i+1) * reshapedX.shape[2])]
 */
        __pyx_t_9 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__29, NULL); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 130, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_9);
        __Pyx_Raise(__pyx_t_9, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        __PYX_ERR(1, 130, __pyx_L1_error)

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":129
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 *                     radem.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *                 raise Exception("Fatal error encountered in floatGpuConv1dTransform_.")
 * 
 */
      }

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":132
 *                 raise Exception("Fatal error encountered in floatGpuConv1dTransform_.")
 * 
 *             reshapedXCopy *= chiArr[None,None,(i * reshapedX.shape[2]):((i+1) * reshapedX.shape[2])]             # <<<<<<<<<<<<<<
 *             outputArray[:,startPosition:cutoff] = reshapedXCopy.max(axis=1)
 * 
 */
      __pyx_t_9 = __Pyx_PyInt_From_int(__pyx_v_i); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 132, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 132, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 132, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyNumber_Multiply(__pyx_t_9, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 132, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = __Pyx_PyInt_From_long((__pyx_v_i + 1)); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 132, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 132, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_9, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 132, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_t_9 = PyNumber_Multiply(__pyx_t_3, __pyx_t_1); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 132, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = PySlice_New(__pyx_t_2, __pyx_t_9, Py_None); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 132, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_t_9 = PyTuple_New(3); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 132, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_INCREF(Py_None);
      __Pyx_GIVEREF(Py_None);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_9, 0, Py_None)) __PYX_ERR(1, 132, __pyx_L1_error);
      __Pyx_INCREF(Py_None);
      __Pyx_GIVEREF(Py_None);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_9, 1, Py_None)) __PYX_ERR(1, 132, __pyx_L1_error);
      __Pyx_GIVEREF(__pyx_t_1);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_9, 2, __pyx_t_1)) __PYX_ERR(1, 132, __pyx_L1_error);
      __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_PyObject_GetItem(__pyx_v_chiArr, __pyx_t_9); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 132, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_t_9 = PyNumber_InPlaceMultiply(__pyx_v_reshapedXCopy, __pyx_t_1); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 132, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF_SET(__pyx_v_reshapedXCopy, __pyx_t_9);
      __pyx_t_9 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":133
 * 
 *             reshapedXCopy *= chiArr[None,None,(i * reshapedX.shape[2]):((i+1) * reshapedX.shape[2])]
 *             outputArray[:,startPosition:cutoff] = reshapedXCopy.max(axis=1)             # <<<<<<<<<<<<<<
 * 
 *             cutoff += reshapedX.shape[2]
 */
      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedXCopy, __pyx_n_s_max); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 133, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_1 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 133, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_axis, __pyx_int_1) < 0) __PYX_ERR(1, 133, __pyx_L1_error)
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_9, __pyx_empty_tuple, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 133, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_startPosition); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 133, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_9 = __Pyx_PyInt_From_int(__pyx_v_cutoff); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 133, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_3 = PySlice_New(__pyx_t_1, __pyx_t_9, Py_None); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 133, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_t_9 = PyTuple_New(2); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 133, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_INCREF(__pyx_slice__17);
      __Pyx_GIVEREF(__pyx_slice__17);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_slice__17)) __PYX_ERR(1, 133, __pyx_L1_error);
      __Pyx_GIVEREF(__pyx_t_3);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_9, 1, __pyx_t_3)) __PYX_ERR(1, 133, __pyx_L1_error);
      __pyx_t_3 = 0;
      if (unlikely((PyObject_SetItem(__pyx_v_outputArray, __pyx_t_9, __pyx_t_2) < 0))) __PYX_ERR(1, 133, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":135
 *             outputArray[:,startPosition:cutoff] = reshapedXCopy.max(axis=1)
 * 
 *             cutoff += reshapedX.shape[2]             # <<<<<<<<<<<<<<
 *             startPosition += reshapedX.shape[2]
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 */
      __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_cutoff); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 135, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 135, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_9, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 135, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_t_9 = PyNumber_InPlaceAdd(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 135, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_17 = __Pyx_PyInt_As_int(__pyx_t_9); if (unlikely((__pyx_t_17 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 135, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_v_cutoff = __pyx_t_17;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":136
 * 
 *             cutoff += reshapedX.shape[2]
 *             startPosition += reshapedX.shape[2]             # <<<<<<<<<<<<<<
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 *             chiArr.dtype == "float64":
 */
      __pyx_t_9 = __Pyx_PyInt_From_int(__pyx_v_startPosition); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 136, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 136, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 136, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = PyNumber_InPlaceAdd(__pyx_t_9, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 136, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_17 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_17 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 136, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_v_startPosition = __pyx_t_17;
    }

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":121
 *     startPosition, cutoff = 0, reshapedX.shape[2]
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         for i in range(num_repeats):
 */
    goto __pyx_L25;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":137
 *             cutoff += reshapedX.shape[2]
 *             startPosition += reshapedX.shape[2]
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         for i in range(num_repeats):
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 137, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_8 = (__Pyx_PyUnicode_Equals(__pyx_t_3, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_8 < 0))) __PYX_ERR(1, 137, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_8) {
  } else {
    __pyx_t_6 = __pyx_t_8;
    goto __pyx_L32_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_dtype); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 137, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_8 = (__Pyx_PyUnicode_Equals(__pyx_t_3, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_8 < 0))) __PYX_ERR(1, 137, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_8) {
  } else {
    __pyx_t_6 = __pyx_t_8;
    goto __pyx_L32_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":138
 *             startPosition += reshapedX.shape[2]
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 *             chiArr.dtype == "float64":             # <<<<<<<<<<<<<<
 *         for i in range(num_repeats):
 *             reshapedXCopy[:] = reshapedX
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_dtype); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 138, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_8 = (__Pyx_PyUnicode_Equals(__pyx_t_3, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_8 < 0))) __PYX_ERR(1, 138, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_6 = __pyx_t_8;
  __pyx_L32_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":137
 *             cutoff += reshapedX.shape[2]
 *             startPosition += reshapedX.shape[2]
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         for i in range(num_repeats):
 */
  if (likely(__pyx_t_6)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":139
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 *             chiArr.dtype == "float64":
 *         for i in range(num_repeats):             # <<<<<<<<<<<<<<
 *             reshapedXCopy[:] = reshapedX
 *             errCode = conv1dPrep[double](<int8_t*>addr_radem,
 */
    __pyx_t_11 = __pyx_v_num_repeats;
    __pyx_t_4 = __pyx_t_11;
    for (__pyx_t_12 = 0; __pyx_t_12 < __pyx_t_4; __pyx_t_12+=1) {
      __pyx_v_i = __pyx_t_12;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":140
 *             chiArr.dtype == "float64":
 *         for i in range(num_repeats):
 *             reshapedXCopy[:] = reshapedX             # <<<<<<<<<<<<<<
 *             errCode = conv1dPrep[double](<int8_t*>addr_radem,
 *                     <double*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],
 */
      if (__Pyx_PyObject_SetSlice(__pyx_v_reshapedXCopy, __pyx_v_reshapedX, 0, 0, NULL, NULL, &__pyx_slice__17, 0, 0, 0) < 0) __PYX_ERR(1, 140, __pyx_L1_error)

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":142
 *             reshapedXCopy[:] = reshapedX
 *             errCode = conv1dPrep[double](<int8_t*>addr_radem,
 *                     <double*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],             # <<<<<<<<<<<<<<
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 *                     radem.shape[2])
 */
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 142, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 142, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_17 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_17 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 142, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 142, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 142, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_16 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_16 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 142, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":143
 *             errCode = conv1dPrep[double](<int8_t*>addr_radem,
 *                     <double*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], i * reshapedX.shape[2],             # <<<<<<<<<<<<<<
 *                     radem.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":
 */
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 143, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 143, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_15 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_15 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 143, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_i); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 143, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 143, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_9 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 143, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = PyNumber_Multiply(__pyx_t_2, __pyx_t_9); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 143, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_t_14 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_14 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 143, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":144
 *                     <double*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 *                     radem.shape[2])             # <<<<<<<<<<<<<<
 *             if errCode.decode("UTF-8") != "no_error":
 *                 raise Exception("Fatal error encountered in floatGpuConv1dTransform_.")
 */
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 144, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_9 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 144, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_13 = __Pyx_PyInt_As_int(__pyx_t_9); if (unlikely((__pyx_t_13 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 144, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":141
 *         for i in range(num_repeats):
 *             reshapedXCopy[:] = reshapedX
 *             errCode = conv1dPrep[double](<int8_t*>addr_radem,             # <<<<<<<<<<<<<<
 *                     <double*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 */
      __pyx_v_errCode = conv1dPrep<double>(((int8_t *)__pyx_v_addr_radem), ((double *)__pyx_v_addr_reshapedCopy), __pyx_t_17, __pyx_t_16, __pyx_t_15, __pyx_t_14, __pyx_t_13);

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":145
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 *                     radem.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *                 raise Exception("Fatal error encountered in floatGpuConv1dTransform_.")
 * 
 */
      __pyx_t_7 = __Pyx_ssize_strlen(__pyx_v_errCode); if (unlikely(__pyx_t_7 == ((Py_ssize_t)-1))) __PYX_ERR(1, 145, __pyx_L1_error)
      __pyx_t_9 = __Pyx_decode_c_string(__pyx_v_errCode, 0, __pyx_t_7, NULL, NULL, PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 145, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_6 = (__Pyx_PyUnicode_Equals(__pyx_t_9, __pyx_n_u_no_error, Py_NE)); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(1, 145, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      if (unlikely(__pyx_t_6)) {

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":146
 *                     radem.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":
 *                 raise Exception("Fatal error encountered in floatGpuConv1dTransform_.")             # <<<<<<<<<<<<<<
 * 
 *             reshapedXCopy *= chiArr[None,None,(i * reshapedX.shape[2]):((i+1) * reshapedX.shape[2])]
 */
        __pyx_t_9 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__29, NULL); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 146, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_9);
        __Pyx_Raise(__pyx_t_9, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        __PYX_ERR(1, 146, __pyx_L1_error)

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":145
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 *                     radem.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *                 raise Exception("Fatal error encountered in floatGpuConv1dTransform_.")
 * 
 */
      }

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":148
 *                 raise Exception("Fatal error encountered in floatGpuConv1dTransform_.")
 * 
 *             reshapedXCopy *= chiArr[None,None,(i * reshapedX.shape[2]):((i+1) * reshapedX.shape[2])]             # <<<<<<<<<<<<<<
 *             outputArray[:,startPosition:cutoff] = reshapedXCopy.max(axis=1)
 * 
 */
      __pyx_t_9 = __Pyx_PyInt_From_int(__pyx_v_i); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 148, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 148, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 148, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = PyNumber_Multiply(__pyx_t_9, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 148, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyInt_From_long((__pyx_v_i + 1)); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 148, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 148, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_9, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 148, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_t_9 = PyNumber_Multiply(__pyx_t_2, __pyx_t_1); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 148, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = PySlice_New(__pyx_t_3, __pyx_t_9, Py_None); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 148, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_t_9 = PyTuple_New(3); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 148, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_INCREF(Py_None);
      __Pyx_GIVEREF(Py_None);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_9, 0, Py_None)) __PYX_ERR(1, 148, __pyx_L1_error);
      __Pyx_INCREF(Py_None);
      __Pyx_GIVEREF(Py_None);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_9, 1, Py_None)) __PYX_ERR(1, 148, __pyx_L1_error);
      __Pyx_GIVEREF(__pyx_t_1);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_9, 2, __pyx_t_1)) __PYX_ERR(1, 148, __pyx_L1_error);
      __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_PyObject_GetItem(__pyx_v_chiArr, __pyx_t_9); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 148, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_t_9 = PyNumber_InPlaceMultiply(__pyx_v_reshapedXCopy, __pyx_t_1); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 148, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF_SET(__pyx_v_reshapedXCopy, __pyx_t_9);
      __pyx_t_9 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":149
 * 
 *             reshapedXCopy *= chiArr[None,None,(i * reshapedX.shape[2]):((i+1) * reshapedX.shape[2])]
 *             outputArray[:,startPosition:cutoff] = reshapedXCopy.max(axis=1)             # <<<<<<<<<<<<<<
 * 
 *             cutoff += reshapedX.shape[2]
 */
      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedXCopy, __pyx_n_s_max); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 149, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_1 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 149, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_axis, __pyx_int_1) < 0) __PYX_ERR(1, 149, __pyx_L1_error)
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_9, __pyx_empty_tuple, __pyx_t_1); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 149, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_startPosition); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 149, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_9 = __Pyx_PyInt_From_int(__pyx_v_cutoff); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 149, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_2 = PySlice_New(__pyx_t_1, __pyx_t_9, Py_None); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 149, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_t_9 = PyTuple_New(2); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 149, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_INCREF(__pyx_slice__17);
      __Pyx_GIVEREF(__pyx_slice__17);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_slice__17)) __PYX_ERR(1, 149, __pyx_L1_error);
      __Pyx_GIVEREF(__pyx_t_2);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_9, 1, __pyx_t_2)) __PYX_ERR(1, 149, __pyx_L1_error);
      __pyx_t_2 = 0;
      if (unlikely((PyObject_SetItem(__pyx_v_outputArray, __pyx_t_9, __pyx_t_3) < 0))) __PYX_ERR(1, 149, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":151
 *             outputArray[:,startPosition:cutoff] = reshapedXCopy.max(axis=1)
 * 
 *             cutoff += reshapedX.shape[2]             # <<<<<<<<<<<<<<
 *             startPosition += reshapedX.shape[2]
 *     else:
 */
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_cutoff); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 151, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 151, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_9, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 151, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_t_9 = PyNumber_InPlaceAdd(__pyx_t_3, __pyx_t_2); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 151, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_13 = __Pyx_PyInt_As_int(__pyx_t_9); if (unlikely((__pyx_t_13 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 151, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_v_cutoff = __pyx_t_13;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":152
 * 
 *             cutoff += reshapedX.shape[2]
 *             startPosition += reshapedX.shape[2]             # <<<<<<<<<<<<<<
 *     else:
 *         raise ValueError("Inconsistent types passed to a wrapped C++ function.")
 */
      __pyx_t_9 = __Pyx_PyInt_From_int(__pyx_v_startPosition); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 152, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 152, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 152, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyNumber_InPlaceAdd(__pyx_t_9, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 152, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_13 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_13 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 152, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_startPosition = __pyx_t_13;
    }

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":137
 *             cutoff += reshapedX.shape[2]
 *             startPosition += reshapedX.shape[2]
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         for i in range(num_repeats):
 */
    goto __pyx_L25;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":154
 *             startPosition += reshapedX.shape[2]
 *     else:
 *         raise ValueError("Inconsistent types passed to a wrapped C++ function.")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__30, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 154, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 154, __pyx_L1_error)
  }
  __pyx_L25:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":46
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuConv1dMaxpool(reshapedX, radem, outputArray, chiArr,
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("cuda_rf_gen_module.gpuConv1dMaxpool", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_reshapedXCopy);
  __Pyx_XDECREF(__pyx_v_logdim);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":159
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuConv1dFGen(reshapedX, radem, outputArray, chiArr,
 */

/* Python wrapper */
static PyObject *__pyx_pw_18cuda_rf_gen_module_7gpuConv1dFGen(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_18cuda_rf_gen_module_6gpuConv1dFGen, "Uses wrapped C functions to generate random features for FHTConv1d, GraphConv1d,\n    and related kernels. This function cannot be used to calculate the gradient\n    so is only used for forward pass only (during fitting, inference, non-gradient-based\n    optimization). It does not multiply by the lengthscales, so caller should do this.\n    (This enables this function to also be used for GraphARD kernels if desired.)\n\n    Args:\n        reshapedX (cp.ndarray): Raw data reshaped so that a convolution can be\n            performed on it using orthogonal random features with the SORF\n            operation. This array is not modified in place -- rather the features\n            that are generated are stored in outputArray. Shape is (N x D x C) for \n            N datapoints. C must be a power of 2.\n        radem (cp.ndarray): A stack of diagonal matrices with elements drawn from the\n            Rademacher distribution. Shape must be (3 x D x C).\n        outputArray (cp.ndarray): A numpy array in which the generated features will be\n            stored. Is modified in-place.\n        chiArr (cp.ndarray): A stack of diagonal matrices drawn from a chi distribution.\n        num_threads (int): Number of threads to use for FHT.\n        beta (float): The amplitude.\n        fitIntercept (bool): Whether to fit a y-intercept (in this case,\n            the first random feature generated should be set to 1).\n\n    Raises:\n        ValueError: A ValueError is raised if unexpected or invalid inputs are supplied.\n    ");
static PyMethodDef __pyx_mdef_18cuda_rf_gen_module_7gpuConv1dFGen = {"gpuConv1dFGen", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_18cuda_rf_gen_module_7gpuConv1dFGen, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_18cuda_rf_gen_module_6gpuConv1dFGen};
static PyObject *__pyx_pw_18cuda_rf_gen_module_7gpuConv1dFGen(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_reshapedX = 0;
  PyObject *__pyx_v_radem = 0;
  PyObject *__pyx_v_outputArray = 0;
  PyObject *__pyx_v_chiArr = 0;
  CYTHON_UNUSED int __pyx_v_numThreads;
  float __pyx_v_beta_;
  bool __pyx_v_fitIntercept;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[7] = {0,0,0,0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("gpuConv1dFGen (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_MACROS
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject **__pyx_pyargnames[] = {&__pyx_n_s_reshapedX,&__pyx_n_s_radem,&__pyx_n_s_outputArray,&__pyx_n_s_chiArr,&__pyx_n_s_numThreads,&__pyx_n_s_beta,&__pyx_n_s_fitIntercept,0};
    if (__pyx_kwds) {
      Py_ssize_t kw_args;
      switch (__pyx_nargs) {
        case  7: values[6] = __Pyx_Arg_FASTCALL(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = __Pyx_Arg_FASTCALL(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = __Pyx_NumKwargs_FASTCALL(__pyx_kwds);
      switch (__pyx_nargs) {
        case  0:
        if (likely((values[0] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_reshapedX)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[0]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 159, __pyx_L3_error)
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_radem)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[1]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 159, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConv1dFGen", 0, 6, 7, 1); __PYX_ERR(1, 159, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_outputArray)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[2]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 159, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConv1dFGen", 0, 6, 7, 2); __PYX_ERR(1, 159, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_chiArr)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[3]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 159, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConv1dFGen", 0, 6, 7, 3); __PYX_ERR(1, 159, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_numThreads)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[4]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 159, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConv1dFGen", 0, 6, 7, 4); __PYX_ERR(1, 159, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_beta)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[5]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 159, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConv1dFGen", 0, 6, 7, 5); __PYX_ERR(1, 159, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (kw_args > 0) {
          PyObject* value = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_fitIntercept);
          if (value) { values[6] = __Pyx_Arg_NewRef_FASTCALL(value); kw_args--; }
          else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 159, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        const Py_ssize_t kwd_pos_args = __pyx_nargs;
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "gpuConv1dFGen") < 0)) __PYX_ERR(1, 159, __pyx_L3_error)
      }
    } else {
      switch (__pyx_nargs) {
        case  7: values[6] = __Pyx_Arg_FASTCALL(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = __Pyx_Arg_FASTCALL(__pyx_args, 5);
        values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
        values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
        values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
        values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
        values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_reshapedX = values[0];
    __pyx_v_radem = values[1];
    __pyx_v_outputArray = values[2];
    __pyx_v_chiArr = values[3];
    __pyx_v_numThreads = __Pyx_PyInt_As_int(values[4]); if (unlikely((__pyx_v_numThreads == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 162, __pyx_L3_error)
    __pyx_v_beta_ = __pyx_PyFloat_AsFloat(values[5]); if (unlikely((__pyx_v_beta_ == (float)-1) && PyErr_Occurred())) __PYX_ERR(1, 162, __pyx_L3_error)
    if (values[6]) {
      __pyx_v_fitIntercept = __Pyx_PyObject_IsTrue(values[6]); if (unlikely((__pyx_v_fitIntercept == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(1, 162, __pyx_L3_error)
    } else {

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":162
 * @cython.wraparound(False)
 * def gpuConv1dFGen(reshapedX, radem, outputArray, chiArr,
 *                 int numThreads, float beta_, bool fitIntercept = False):             # <<<<<<<<<<<<<<
 *     """Uses wrapped C functions to generate random features for FHTConv1d, GraphConv1d,
 *     and related kernels. This function cannot be used to calculate the gradient
 */
      __pyx_v_fitIntercept = ((bool)((int)0));
    }
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("gpuConv1dFGen", 0, 6, 7, __pyx_nargs); __PYX_ERR(1, 159, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_AddTraceback("cuda_rf_gen_module.gpuConv1dFGen", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_18cuda_rf_gen_module_6gpuConv1dFGen(__pyx_self, __pyx_v_reshapedX, __pyx_v_radem, __pyx_v_outputArray, __pyx_v_chiArr, __pyx_v_numThreads, __pyx_v_beta_, __pyx_v_fitIntercept);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":159
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuConv1dFGen(reshapedX, radem, outputArray, chiArr,
 */

  /* function exit code */
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_18cuda_rf_gen_module_6gpuConv1dFGen(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_reshapedX, PyObject *__pyx_v_radem, PyObject *__pyx_v_outputArray, PyObject *__pyx_v_chiArr, CYTHON_UNUSED int __pyx_v_numThreads, float __pyx_v_beta_, bool __pyx_v_fitIntercept) {
  char const *__pyx_v_errCode;
  double __pyx_v_scalingTerm;
  PyObject *__pyx_v_logdim = NULL;
  PyObject *__pyx_v_featureArray = NULL;
  uintptr_t __pyx_v_addr_reshapedX;
  uintptr_t __pyx_v_addr_featureArray;
  uintptr_t __pyx_v_addr_radem;
  uintptr_t __pyx_v_addr_chi;
  uintptr_t __pyx_v_addr_output;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  Py_ssize_t __pyx_t_3;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_t_8;
  int __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  uintptr_t __pyx_t_11;
  double __pyx_t_12;
  double __pyx_t_13;
  int __pyx_t_14;
  int __pyx_t_15;
  int __pyx_t_16;
  int __pyx_t_17;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("gpuConv1dFGen", 1);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":191
 *     cdef double scalingTerm
 * 
 *     if len(chiArr.shape) != 1 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 191, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = PyObject_Length(__pyx_t_2); if (unlikely(__pyx_t_3 == ((Py_ssize_t)-1))) __PYX_ERR(1, 191, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__pyx_t_3 != 1);
  if (!__pyx_t_4) {
  } else {
    __pyx_t_1 = __pyx_t_4;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 191, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = PyObject_Length(__pyx_t_2); if (unlikely(__pyx_t_3 == ((Py_ssize_t)-1))) __PYX_ERR(1, 191, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__pyx_t_3 != 3);
  if (!__pyx_t_4) {
  } else {
    __pyx_t_1 = __pyx_t_4;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 191, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = PyObject_Length(__pyx_t_2); if (unlikely(__pyx_t_3 == ((Py_ssize_t)-1))) __PYX_ERR(1, 191, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__pyx_t_3 != 3);
  __pyx_t_1 = __pyx_t_4;
  __pyx_L4_bool_binop_done:;
  if (unlikely(__pyx_t_1)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":192
 * 
 *     if len(chiArr.shape) != 1 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")             # <<<<<<<<<<<<<<
 *     if len(outputArray.shape) != 2:
 *         raise ValueError("outputArray should be a 2d array.")
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__31, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 192, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 192, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":191
 *     cdef double scalingTerm
 * 
 *     if len(chiArr.shape) != 1 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":193
 *     if len(chiArr.shape) != 1 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("outputArray should be a 2d array.")
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 193, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = PyObject_Length(__pyx_t_2); if (unlikely(__pyx_t_3 == ((Py_ssize_t)-1))) __PYX_ERR(1, 193, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_1 = (__pyx_t_3 != 2);
  if (unlikely(__pyx_t_1)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":194
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:
 *         raise ValueError("outputArray should be a 2d array.")             # <<<<<<<<<<<<<<
 * 
 *     if reshapedX.shape[0] == 0:
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__32, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 194, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 194, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":193
 *     if len(chiArr.shape) != 1 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("outputArray should be a 2d array.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":196
 *         raise ValueError("outputArray should be a 2d array.")
 * 
 *     if reshapedX.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 196, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 196, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_1 = (__Pyx_PyInt_BoolEqObjC(__pyx_t_5, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 196, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(__pyx_t_1)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":197
 * 
 *     if reshapedX.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")             # <<<<<<<<<<<<<<
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 */
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__3, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 197, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(1, 197, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":196
 *         raise ValueError("outputArray should be a 2d array.")
 * 
 *     if reshapedX.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":198
 *     if reshapedX.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 198, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_5, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 198, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 198, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_5, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 198, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = PyObject_RichCompare(__pyx_t_2, __pyx_t_6, Py_NE); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 198, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 198, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(__pyx_t_1)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":199
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "             # <<<<<<<<<<<<<<
 *                 "not agree.")
 *     if radem.shape[0] != 3 or radem.shape[1] != 1:
 */
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__33, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 199, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(1, 199, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":198
 *     if reshapedX.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":201
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 *     if radem.shape[0] != 3 or radem.shape[1] != 1:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")
 * 
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 201, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_5, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 201, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_4 = (__Pyx_PyInt_BoolNeObjC(__pyx_t_6, __pyx_int_3, 3, 0)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(1, 201, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (!__pyx_t_4) {
  } else {
    __pyx_t_1 = __pyx_t_4;
    goto __pyx_L11_bool_binop_done;
  }
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 201, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_6, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 201, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_4 = (__Pyx_PyInt_BoolNeObjC(__pyx_t_5, __pyx_int_1, 1, 0)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(1, 201, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_1 = __pyx_t_4;
  __pyx_L11_bool_binop_done:;
  if (unlikely(__pyx_t_1)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":202
 *                 "not agree.")
 *     if radem.shape[0] != 3 or radem.shape[1] != 1:
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")             # <<<<<<<<<<<<<<
 * 
 *     if outputArray.shape[1] % 2 != 0 or outputArray.shape[1] < 2:
 */
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__23, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 202, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(1, 202, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":201
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 *     if radem.shape[0] != 3 or radem.shape[1] != 1:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":204
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")
 * 
 *     if outputArray.shape[1] % 2 != 0 or outputArray.shape[1] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("Shape of output array is not appropriate.")
 * 
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 204, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_5, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 204, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyInt_RemainderObjC(__pyx_t_6, __pyx_int_2, 2, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 204, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_4 = (__Pyx_PyInt_BoolNeObjC(__pyx_t_5, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(1, 204, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (!__pyx_t_4) {
  } else {
    __pyx_t_1 = __pyx_t_4;
    goto __pyx_L14_bool_binop_done;
  }
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 204, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_5, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 204, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = PyObject_RichCompare(__pyx_t_6, __pyx_int_2, Py_LT); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 204, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(1, 204, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_1 = __pyx_t_4;
  __pyx_L14_bool_binop_done:;
  if (unlikely(__pyx_t_1)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":205
 * 
 *     if outputArray.shape[1] % 2 != 0 or outputArray.shape[1] < 2:
 *         raise ValueError("Shape of output array is not appropriate.")             # <<<<<<<<<<<<<<
 * 
 *     if 2 * chiArr.shape[0] != outputArray.shape[1] or chiArr.shape[0] > radem.shape[2]:
 */
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__34, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 205, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(1, 205, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":204
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")
 * 
 *     if outputArray.shape[1] % 2 != 0 or outputArray.shape[1] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("Shape of output array is not appropriate.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":207
 *         raise ValueError("Shape of output array is not appropriate.")
 * 
 *     if 2 * chiArr.shape[0] != outputArray.shape[1] or chiArr.shape[0] > radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Shape of output array and / or chiArr is inappropriate.")
 * 
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 207, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_5, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 207, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyInt_MultiplyCObj(__pyx_int_2, __pyx_t_6, 2, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 207, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 207, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_6, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 207, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = PyObject_RichCompare(__pyx_t_5, __pyx_t_2, Py_NE); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 207, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(1, 207, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (!__pyx_t_4) {
  } else {
    __pyx_t_1 = __pyx_t_4;
    goto __pyx_L17_bool_binop_done;
  }
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 207, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_6, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 207, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 207, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_6, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 207, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = PyObject_RichCompare(__pyx_t_2, __pyx_t_5, Py_GT); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 207, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(1, 207, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_1 = __pyx_t_4;
  __pyx_L17_bool_binop_done:;
  if (unlikely(__pyx_t_1)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":208
 * 
 *     if 2 * chiArr.shape[0] != outputArray.shape[1] or chiArr.shape[0] > radem.shape[2]:
 *         raise ValueError("Shape of output array and / or chiArr is inappropriate.")             # <<<<<<<<<<<<<<
 * 
 *     logdim = np.log2(reshapedX.shape[2])
 */
    __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__35, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 208, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_Raise(__pyx_t_6, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __PYX_ERR(1, 208, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":207
 *         raise ValueError("Shape of output array is not appropriate.")
 * 
 *     if 2 * chiArr.shape[0] != outputArray.shape[1] or chiArr.shape[0] > radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Shape of output array and / or chiArr is inappropriate.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":210
 *         raise ValueError("Shape of output array and / or chiArr is inappropriate.")
 * 
 *     logdim = np.log2(reshapedX.shape[2])             # <<<<<<<<<<<<<<
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 */
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_np); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 210, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_log2); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 210, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 210, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_5, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 210, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = NULL;
  __pyx_t_8 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_8 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_5, __pyx_t_7};
    __pyx_t_6 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+1-__pyx_t_8, 1+__pyx_t_8);
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 210, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __pyx_v_logdim = __pyx_t_6;
  __pyx_t_6 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":211
 * 
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_np); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 211, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ceil); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 211, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_8 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_7))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_7);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_7, function);
      __pyx_t_8 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_v_logdim};
    __pyx_t_6 = __Pyx_PyObject_FastCall(__pyx_t_7, __pyx_callargs+1-__pyx_t_8, 1+__pyx_t_8);
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 211, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  }
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_np); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 211, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_floor); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 211, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_8 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_8 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_v_logdim};
    __pyx_t_7 = __Pyx_PyObject_FastCall(__pyx_t_5, __pyx_callargs+1-__pyx_t_8, 1+__pyx_t_8);
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 211, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __pyx_t_5 = PyObject_RichCompare(__pyx_t_6, __pyx_t_7, Py_NE); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 211, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(1, 211, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (!__pyx_t_4) {
  } else {
    __pyx_t_1 = __pyx_t_4;
    goto __pyx_L20_bool_binop_done;
  }
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 211, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_5, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 211, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = PyObject_RichCompare(__pyx_t_7, __pyx_int_2, Py_LT); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 211, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(1, 211, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_1 = __pyx_t_4;
  __pyx_L20_bool_binop_done:;
  if (unlikely(__pyx_t_1)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":212
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")             # <<<<<<<<<<<<<<
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "
 */
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__26, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 212, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(1, 212, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":211
 * 
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":213
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "
 *                 "reshapedX.shape[2].")
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 213, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_5, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 213, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 213, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_5, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 213, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = PyNumber_Remainder(__pyx_t_7, __pyx_t_6); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 213, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_1 = (__Pyx_PyInt_BoolEqObjC(__pyx_t_5, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 213, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_4 = (!__pyx_t_1);
  if (unlikely(__pyx_t_4)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":214
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "             # <<<<<<<<<<<<<<
 *                 "reshapedX.shape[2].")
 * 
 */
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__27, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 214, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(1, 214, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":213
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "
 *                 "reshapedX.shape[2].")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":217
 *                 "reshapedX.shape[2].")
 * 
 *     if not radem.dtype == "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be int8.")
 * 
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_dtype); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 217, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_t_5, __pyx_n_u_int8, Py_EQ)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(1, 217, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_1 = (!__pyx_t_4);
  if (unlikely(__pyx_t_1)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":218
 * 
 *     if not radem.dtype == "int8":
 *         raise ValueError("radem must be int8.")             # <<<<<<<<<<<<<<
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 */
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__22, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 218, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(1, 218, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":217
 *                 "reshapedX.shape[2].")
 * 
 *     if not radem.dtype == "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be int8.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":220
 *         raise ValueError("radem must be int8.")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_flags); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 220, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_PyObject_Dict_GetItem(__pyx_t_5, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 220, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(1, 220, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_9 = (!__pyx_t_4);
  if (!__pyx_t_9) {
  } else {
    __pyx_t_1 = __pyx_t_9;
    goto __pyx_L25_bool_binop_done;
  }
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_flags); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 220, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_5 = __Pyx_PyObject_Dict_GetItem(__pyx_t_6, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 220, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(1, 220, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_4 = (!__pyx_t_9);
  if (!__pyx_t_4) {
  } else {
    __pyx_t_1 = __pyx_t_4;
    goto __pyx_L25_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":221
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 *         or not chiArr.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_flags); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 220, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":220
 *         raise ValueError("radem must be int8.")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  __pyx_t_6 = __Pyx_PyObject_Dict_GetItem(__pyx_t_5, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 220, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(1, 220, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_9 = (!__pyx_t_4);
  if (!__pyx_t_9) {
  } else {
    __pyx_t_1 = __pyx_t_9;
    goto __pyx_L25_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":221
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 *         or not chiArr.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_flags); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 221, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_5 = __Pyx_PyObject_Dict_GetItem(__pyx_t_6, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 221, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(1, 221, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_4 = (!__pyx_t_9);
  __pyx_t_1 = __pyx_t_4;
  __pyx_L25_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":220
 *         raise ValueError("radem must be int8.")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  if (unlikely(__pyx_t_1)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":222
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")             # <<<<<<<<<<<<<<
 * 
 *     if reshapedX.dtype == "float32":
 */
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__28, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 222, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(1, 222, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":220
 *         raise ValueError("radem must be int8.")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":224
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 *     if reshapedX.dtype == "float32":             # <<<<<<<<<<<<<<
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),
 *                             dtype = cp.float32)
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_dtype); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 224, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_1 = (__Pyx_PyUnicode_Equals(__pyx_t_5, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 224, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (__pyx_t_1) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":225
 * 
 *     if reshapedX.dtype == "float32":
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),             # <<<<<<<<<<<<<<
 *                             dtype = cp.float32)
 *     else:
 */
    __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_cp); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 225, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_zeros); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 225, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 225, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_5, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 225, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 225, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_5, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 225, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 225, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_5, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 225, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = PyTuple_New(3); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 225, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_GIVEREF(__pyx_t_7);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_7)) __PYX_ERR(1, 225, __pyx_L1_error);
    __Pyx_GIVEREF(__pyx_t_2);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_5, 1, __pyx_t_2)) __PYX_ERR(1, 225, __pyx_L1_error);
    __Pyx_GIVEREF(__pyx_t_10);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_5, 2, __pyx_t_10)) __PYX_ERR(1, 225, __pyx_L1_error);
    __pyx_t_7 = 0;
    __pyx_t_2 = 0;
    __pyx_t_10 = 0;
    __pyx_t_10 = PyTuple_New(1); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 225, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_GIVEREF(__pyx_t_5);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_5)) __PYX_ERR(1, 225, __pyx_L1_error);
    __pyx_t_5 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":226
 *     if reshapedX.dtype == "float32":
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),
 *                             dtype = cp.float32)             # <<<<<<<<<<<<<<
 *     else:
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),
 */
    __pyx_t_5 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 226, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_cp); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 226, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_float32); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 226, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (PyDict_SetItem(__pyx_t_5, __pyx_n_s_dtype, __pyx_t_7) < 0) __PYX_ERR(1, 226, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":225
 * 
 *     if reshapedX.dtype == "float32":
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),             # <<<<<<<<<<<<<<
 *                             dtype = cp.float32)
 *     else:
 */
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_10, __pyx_t_5); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 225, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_v_featureArray = __pyx_t_7;
    __pyx_t_7 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":224
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 *     if reshapedX.dtype == "float32":             # <<<<<<<<<<<<<<
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),
 *                             dtype = cp.float32)
 */
    goto __pyx_L29;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":228
 *                             dtype = cp.float32)
 *     else:
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),             # <<<<<<<<<<<<<<
 *                             dtype = cp.float64)
 * 
 */
  /*else*/ {
    __Pyx_GetModuleGlobalName(__pyx_t_7, __pyx_n_s_cp); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 228, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_zeros); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 228, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 228, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_7, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 228, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 228, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_7, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 228, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 228, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_7, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 228, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = PyTuple_New(3); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 228, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_GIVEREF(__pyx_t_10);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_10)) __PYX_ERR(1, 228, __pyx_L1_error);
    __Pyx_GIVEREF(__pyx_t_6);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_t_6)) __PYX_ERR(1, 228, __pyx_L1_error);
    __Pyx_GIVEREF(__pyx_t_2);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_7, 2, __pyx_t_2)) __PYX_ERR(1, 228, __pyx_L1_error);
    __pyx_t_10 = 0;
    __pyx_t_6 = 0;
    __pyx_t_2 = 0;
    __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 228, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_7);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_7)) __PYX_ERR(1, 228, __pyx_L1_error);
    __pyx_t_7 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":229
 *     else:
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),
 *                             dtype = cp.float64)             # <<<<<<<<<<<<<<
 * 
 *     cdef uintptr_t addr_reshapedX = reshapedX.data.ptr
 */
    __pyx_t_7 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 229, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_cp); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 229, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_float64); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 229, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (PyDict_SetItem(__pyx_t_7, __pyx_n_s_dtype, __pyx_t_10) < 0) __PYX_ERR(1, 229, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":228
 *                             dtype = cp.float32)
 *     else:
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),             # <<<<<<<<<<<<<<
 *                             dtype = cp.float64)
 * 
 */
    __pyx_t_10 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_2, __pyx_t_7); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 228, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_v_featureArray = __pyx_t_10;
    __pyx_t_10 = 0;
  }
  __pyx_L29:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":231
 *                             dtype = cp.float64)
 * 
 *     cdef uintptr_t addr_reshapedX = reshapedX.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_featureArray = featureArray.data.ptr
 *     cdef uintptr_t addr_radem = radem.data.ptr
 */
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_data); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 231, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_n_s_ptr); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 231, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_t_11 = __Pyx_PyInt_As_size_t(__pyx_t_7); if (unlikely((__pyx_t_11 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 231, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_addr_reshapedX = __pyx_t_11;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":232
 * 
 *     cdef uintptr_t addr_reshapedX = reshapedX.data.ptr
 *     cdef uintptr_t addr_featureArray = featureArray.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_radem = radem.data.ptr
 *     cdef uintptr_t addr_chi = chiArr.data.ptr
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_featureArray, __pyx_n_s_data); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 232, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_ptr); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 232, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_11 = __Pyx_PyInt_As_size_t(__pyx_t_10); if (unlikely((__pyx_t_11 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 232, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_v_addr_featureArray = __pyx_t_11;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":233
 *     cdef uintptr_t addr_reshapedX = reshapedX.data.ptr
 *     cdef uintptr_t addr_featureArray = featureArray.data.ptr
 *     cdef uintptr_t addr_radem = radem.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_chi = chiArr.data.ptr
 *     cdef uintptr_t addr_output = outputArray.data.ptr
 */
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_data); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 233, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_n_s_ptr); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 233, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_t_11 = __Pyx_PyInt_As_size_t(__pyx_t_7); if (unlikely((__pyx_t_11 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 233, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_addr_radem = __pyx_t_11;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":234
 *     cdef uintptr_t addr_featureArray = featureArray.data.ptr
 *     cdef uintptr_t addr_radem = radem.data.ptr
 *     cdef uintptr_t addr_chi = chiArr.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_output = outputArray.data.ptr
 * 
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_data); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 234, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_ptr); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 234, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_11 = __Pyx_PyInt_As_size_t(__pyx_t_10); if (unlikely((__pyx_t_11 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 234, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_v_addr_chi = __pyx_t_11;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":235
 *     cdef uintptr_t addr_radem = radem.data.ptr
 *     cdef uintptr_t addr_chi = chiArr.data.ptr
 *     cdef uintptr_t addr_output = outputArray.data.ptr             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_data); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 235, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_n_s_ptr); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 235, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_t_11 = __Pyx_PyInt_As_size_t(__pyx_t_7); if (unlikely((__pyx_t_11 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 235, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_addr_output = __pyx_t_11;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":238
 * 
 * 
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         scalingTerm = np.sqrt(2.0 / (<double>chiArr.shape[0] - 0.5))
 *     else:
 */
  __pyx_t_1 = (__pyx_v_fitIntercept != 0);
  if (__pyx_t_1) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":239
 * 
 *     if fitIntercept:
 *         scalingTerm = np.sqrt(2.0 / (<double>chiArr.shape[0] - 0.5))             # <<<<<<<<<<<<<<
 *     else:
 *         scalingTerm = np.sqrt(2 / <double>chiArr.shape[0])
 */
    __Pyx_GetModuleGlobalName(__pyx_t_10, __pyx_n_s_np); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 239, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_n_s_sqrt); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 239, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 239, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_10, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 239, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_12 = __pyx_PyFloat_AsDouble(__pyx_t_5); if (unlikely((__pyx_t_12 == (double)-1) && PyErr_Occurred())) __PYX_ERR(1, 239, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_13 = (((double)__pyx_t_12) - 0.5);
    if (unlikely(__pyx_t_13 == 0)) {
      PyErr_SetString(PyExc_ZeroDivisionError, "float division");
      __PYX_ERR(1, 239, __pyx_L1_error)
    }
    __pyx_t_5 = PyFloat_FromDouble((2.0 / __pyx_t_13)); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 239, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_10 = NULL;
    __pyx_t_8 = 0;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_10)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_10);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
        __pyx_t_8 = 1;
      }
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_10, __pyx_t_5};
      __pyx_t_7 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+1-__pyx_t_8, 1+__pyx_t_8);
      __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 239, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    }
    __pyx_t_13 = __pyx_PyFloat_AsDouble(__pyx_t_7); if (unlikely((__pyx_t_13 == (double)-1) && PyErr_Occurred())) __PYX_ERR(1, 239, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_v_scalingTerm = __pyx_t_13;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":238
 * 
 * 
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         scalingTerm = np.sqrt(2.0 / (<double>chiArr.shape[0] - 0.5))
 *     else:
 */
    goto __pyx_L30;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":241
 *         scalingTerm = np.sqrt(2.0 / (<double>chiArr.shape[0] - 0.5))
 *     else:
 *         scalingTerm = np.sqrt(2 / <double>chiArr.shape[0])             # <<<<<<<<<<<<<<
 *     scalingTerm *= beta_
 * 
 */
  /*else*/ {
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_np); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 241, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_sqrt); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 241, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 241, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 241, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_13 = __pyx_PyFloat_AsDouble(__pyx_t_10); if (unlikely((__pyx_t_13 == (double)-1) && PyErr_Occurred())) __PYX_ERR(1, 241, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    if (unlikely(((double)__pyx_t_13) == 0)) {
      PyErr_SetString(PyExc_ZeroDivisionError, "float division");
      __PYX_ERR(1, 241, __pyx_L1_error)
    }
    __pyx_t_10 = PyFloat_FromDouble((2.0 / ((double)__pyx_t_13))); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 241, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_2 = NULL;
    __pyx_t_8 = 0;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_2)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
        __pyx_t_8 = 1;
      }
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_t_10};
      __pyx_t_7 = __Pyx_PyObject_FastCall(__pyx_t_5, __pyx_callargs+1-__pyx_t_8, 1+__pyx_t_8);
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 241, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    }
    __pyx_t_13 = __pyx_PyFloat_AsDouble(__pyx_t_7); if (unlikely((__pyx_t_13 == (double)-1) && PyErr_Occurred())) __PYX_ERR(1, 241, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_v_scalingTerm = __pyx_t_13;
  }
  __pyx_L30:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":242
 *     else:
 *         scalingTerm = np.sqrt(2 / <double>chiArr.shape[0])
 *     scalingTerm *= beta_             # <<<<<<<<<<<<<<
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \
 */
  __pyx_v_scalingTerm = (__pyx_v_scalingTerm * __pyx_v_beta_);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":244
 *     scalingTerm *= beta_
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         errCode = convRBFFeatureGen[float](<int8_t*>addr_radem, <float*>addr_reshapedX,
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 244, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_t_7, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(1, 244, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (__pyx_t_4) {
  } else {
    __pyx_t_1 = __pyx_t_4;
    goto __pyx_L32_bool_binop_done;
  }
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_dtype); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 244, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_t_7, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(1, 244, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (__pyx_t_4) {
  } else {
    __pyx_t_1 = __pyx_t_4;
    goto __pyx_L32_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":245
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \
 *             chiArr.dtype == "float32":             # <<<<<<<<<<<<<<
 *         errCode = convRBFFeatureGen[float](<int8_t*>addr_radem, <float*>addr_reshapedX,
 *                     <float*>addr_featureArray, <float*>addr_chi,
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_dtype); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 245, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_t_7, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(1, 245, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_1 = __pyx_t_4;
  __pyx_L32_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":244
 *     scalingTerm *= beta_
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         errCode = convRBFFeatureGen[float](<int8_t*>addr_radem, <float*>addr_reshapedX,
 */
  if (__pyx_t_1) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":248
 *         errCode = convRBFFeatureGen[float](<int8_t*>addr_radem, <float*>addr_reshapedX,
 *                     <float*>addr_featureArray, <float*>addr_chi,
 *                     <double*>addr_output, reshapedX.shape[0], reshapedX.shape[1],             # <<<<<<<<<<<<<<
 *                     reshapedX.shape[2], chiArr.shape[0], radem.shape[2], scalingTerm)
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 248, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_7, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 248, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_8 = __Pyx_PyInt_As_int(__pyx_t_5); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 248, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 248, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_5, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 248, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_14 = __Pyx_PyInt_As_int(__pyx_t_7); if (unlikely((__pyx_t_14 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 248, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":249
 *                     <float*>addr_featureArray, <float*>addr_chi,
 *                     <double*>addr_output, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], chiArr.shape[0], radem.shape[2], scalingTerm)             # <<<<<<<<<<<<<<
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 *             chiArr.dtype == "float64":
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 249, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_7, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 249, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_15 = __Pyx_PyInt_As_int(__pyx_t_5); if (unlikely((__pyx_t_15 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 249, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 249, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_5, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 249, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_16 = __Pyx_PyInt_As_int(__pyx_t_7); if (unlikely((__pyx_t_16 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 249, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 249, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_7, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 249, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_17 = __Pyx_PyInt_As_int(__pyx_t_5); if (unlikely((__pyx_t_17 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 249, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":246
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \
 *             chiArr.dtype == "float32":
 *         errCode = convRBFFeatureGen[float](<int8_t*>addr_radem, <float*>addr_reshapedX,             # <<<<<<<<<<<<<<
 *                     <float*>addr_featureArray, <float*>addr_chi,
 *                     <double*>addr_output, reshapedX.shape[0], reshapedX.shape[1],
 */
    __pyx_v_errCode = convRBFFeatureGen<float>(((int8_t *)__pyx_v_addr_radem), ((float *)__pyx_v_addr_reshapedX), ((float *)__pyx_v_addr_featureArray), ((float *)__pyx_v_addr_chi), ((double *)__pyx_v_addr_output), __pyx_t_8, __pyx_t_14, __pyx_t_15, __pyx_t_16, __pyx_t_17, __pyx_v_scalingTerm);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":244
 *     scalingTerm *= beta_
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         errCode = convRBFFeatureGen[float](<int8_t*>addr_radem, <float*>addr_reshapedX,
 */
    goto __pyx_L31;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":250
 *                     <double*>addr_output, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], chiArr.shape[0], radem.shape[2], scalingTerm)
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         errCode = convRBFFeatureGen[double](<int8_t*>addr_radem, <double*>addr_reshapedX,
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 250, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_t_5, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(1, 250, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (__pyx_t_4) {
  } else {
    __pyx_t_1 = __pyx_t_4;
    goto __pyx_L35_bool_binop_done;
  }
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_dtype); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 250, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_t_5, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(1, 250, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (__pyx_t_4) {
  } else {
    __pyx_t_1 = __pyx_t_4;
    goto __pyx_L35_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":251
 *                     reshapedX.shape[2], chiArr.shape[0], radem.shape[2], scalingTerm)
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 *             chiArr.dtype == "float64":             # <<<<<<<<<<<<<<
 *         errCode = convRBFFeatureGen[double](<int8_t*>addr_radem, <double*>addr_reshapedX,
 *                     <double*>addr_featureArray, <double*>addr_chi,
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_dtype); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 251, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_t_5, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(1, 251, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_1 = __pyx_t_4;
  __pyx_L35_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":250
 *                     <double*>addr_output, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], chiArr.shape[0], radem.shape[2], scalingTerm)
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         errCode = convRBFFeatureGen[double](<int8_t*>addr_radem, <double*>addr_reshapedX,
 */
  if (likely(__pyx_t_1)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":254
 *         errCode = convRBFFeatureGen[double](<int8_t*>addr_radem, <double*>addr_reshapedX,
 *                     <double*>addr_featureArray, <double*>addr_chi,
 *                     <double*>addr_output, reshapedX.shape[0], reshapedX.shape[1],             # <<<<<<<<<<<<<<
 *                     reshapedX.shape[2], chiArr.shape[0], radem.shape[2], scalingTerm)
 *     else:
 */
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 254, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_5, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 254, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_17 = __Pyx_PyInt_As_int(__pyx_t_7); if (unlikely((__pyx_t_17 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 254, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 254, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_7, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 254, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_16 = __Pyx_PyInt_As_int(__pyx_t_5); if (unlikely((__pyx_t_16 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 254, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":255
 *                     <double*>addr_featureArray, <double*>addr_chi,
 *                     <double*>addr_output, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], chiArr.shape[0], radem.shape[2], scalingTerm)             # <<<<<<<<<<<<<<
 *     else:
 *         raise ValueError("Incorrect data types supplied.")
 */
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 255, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_5, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 255, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_15 = __Pyx_PyInt_As_int(__pyx_t_7); if (unlikely((__pyx_t_15 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 255, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 255, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_7, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 255, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_14 = __Pyx_PyInt_As_int(__pyx_t_5); if (unlikely((__pyx_t_14 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 255, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 255, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_5, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 255, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_8 = __Pyx_PyInt_As_int(__pyx_t_7); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 255, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":252
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 *             chiArr.dtype == "float64":
 *         errCode = convRBFFeatureGen[double](<int8_t*>addr_radem, <double*>addr_reshapedX,             # <<<<<<<<<<<<<<
 *                     <double*>addr_featureArray, <double*>addr_chi,
 *                     <double*>addr_output, reshapedX.shape[0], reshapedX.shape[1],
 */
    __pyx_v_errCode = convRBFFeatureGen<double>(((int8_t *)__pyx_v_addr_radem), ((double *)__pyx_v_addr_reshapedX), ((double *)__pyx_v_addr_featureArray), ((double *)__pyx_v_addr_chi), ((double *)__pyx_v_addr_output), __pyx_t_17, __pyx_t_16, __pyx_t_15, __pyx_t_14, __pyx_t_8, __pyx_v_scalingTerm);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":250
 *                     <double*>addr_output, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], chiArr.shape[0], radem.shape[2], scalingTerm)
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         errCode = convRBFFeatureGen[double](<int8_t*>addr_radem, <double*>addr_reshapedX,
 */
    goto __pyx_L31;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":257
 *                     reshapedX.shape[2], chiArr.shape[0], radem.shape[2], scalingTerm)
 *     else:
 *         raise ValueError("Incorrect data types supplied.")             # <<<<<<<<<<<<<<
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")
 */
  /*else*/ {
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__36, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 257, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_Raise(__pyx_t_7, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __PYX_ERR(1, 257, __pyx_L1_error)
  }
  __pyx_L31:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":258
 *     else:
 *         raise ValueError("Incorrect data types supplied.")
 *     if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")
 * 
 */
  __pyx_t_3 = __Pyx_ssize_strlen(__pyx_v_errCode); if (unlikely(__pyx_t_3 == ((Py_ssize_t)-1))) __PYX_ERR(1, 258, __pyx_L1_error)
  __pyx_t_7 = __Pyx_decode_c_string(__pyx_v_errCode, 0, __pyx_t_3, NULL, NULL, PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 258, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_1 = (__Pyx_PyUnicode_Equals(__pyx_t_7, __pyx_n_u_no_error, Py_NE)); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 258, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (unlikely(__pyx_t_1)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":259
 *         raise ValueError("Incorrect data types supplied.")
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")             # <<<<<<<<<<<<<<
 * 
 *     if fitIntercept:
 */
    __pyx_t_7 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__37, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 259, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_Raise(__pyx_t_7, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __PYX_ERR(1, 259, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":258
 *     else:
 *         raise ValueError("Incorrect data types supplied.")
 *     if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":261
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")
 * 
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         outputArray[:,0] = beta_
 * 
 */
  __pyx_t_1 = (__pyx_v_fitIntercept != 0);
  if (__pyx_t_1) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":262
 * 
 *     if fitIntercept:
 *         outputArray[:,0] = beta_             # <<<<<<<<<<<<<<
 * 
 * 
 */
    __pyx_t_7 = PyFloat_FromDouble(__pyx_v_beta_); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 262, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    if (unlikely((PyObject_SetItem(__pyx_v_outputArray, __pyx_tuple__38, __pyx_t_7) < 0))) __PYX_ERR(1, 262, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":261
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")
 * 
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         outputArray[:,0] = beta_
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":159
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuConv1dFGen(reshapedX, radem, outputArray, chiArr,
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("cuda_rf_gen_module.gpuConv1dFGen", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_logdim);
  __Pyx_XDECREF(__pyx_v_featureArray);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":266
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuConvGrad(reshapedX, radem, outputArray, chiArr,
 */

/* Python wrapper */
static PyObject *__pyx_pw_18cuda_rf_gen_module_9gpuConvGrad(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_18cuda_rf_gen_module_8gpuConvGrad, "Performs feature generation for the GraphRBF kernel while also performing\n    gradient calculations.\n\n    Args:\n        reshapedX (cp.ndarray): Raw data reshaped so that a convolution can be\n            performed on it using orthogonal random features with the SORF\n            operation. This array is not modified in place -- rather the features\n            that are generated are stored in outputArray. Shape is (N x D x C) for \n            N datapoints. C must be a power of 2.\n        radem (cp.ndarray): A stack of diagonal matrices with elements drawn from the\n            Rademacher distribution. Shape must be (3 x D x C).\n        outputArray (cp.ndarray): A numpy array in which the generated features will be\n            stored. Is modified in-place.\n        chiArr (cp.ndarray): A stack of diagonal matrices drawn from a chi distribution.\n        num_threads (int): Number of threads to use for FHT.\n        sigma (float): The lengthscale.\n        beta (float): The amplitude.\n        fitIntercept (bool): Whether to fit a y-intercept (in this case,\n            the first random feature generated should be set to 1).\n\n    Raises:\n        ValueError: A ValueError is raised if unexpected or invalid inputs are supplied.\n\n    Returns:\n        gradient (cp.ndarray); An array of shape output.shape[0] x output.shape[1] x 1.\n    ");
static PyMethodDef __pyx_mdef_18cuda_rf_gen_module_9gpuConvGrad = {"gpuConvGrad", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_18cuda_rf_gen_module_9gpuConvGrad, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_18cuda_rf_gen_module_8gpuConvGrad};
static PyObject *__pyx_pw_18cuda_rf_gen_module_9gpuConvGrad(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_reshapedX = 0;
  PyObject *__pyx_v_radem = 0;
  PyObject *__pyx_v_outputArray = 0;
  PyObject *__pyx_v_chiArr = 0;
  CYTHON_UNUSED int __pyx_v_numThreads;
  float __pyx_v_sigma;
  float __pyx_v_beta_;
  bool __pyx_v_fitIntercept;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[8] = {0,0,0,0,0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("gpuConvGrad (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_MACROS
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject **__pyx_pyargnames[] = {&__pyx_n_s_reshapedX,&__pyx_n_s_radem,&__pyx_n_s_outputArray,&__pyx_n_s_chiArr,&__pyx_n_s_numThreads,&__pyx_n_s_sigma,&__pyx_n_s_beta,&__pyx_n_s_fitIntercept,0};
    if (__pyx_kwds) {
      Py_ssize_t kw_args;
      switch (__pyx_nargs) {
        case  8: values[7] = __Pyx_Arg_FASTCALL(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = __Pyx_Arg_FASTCALL(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = __Pyx_Arg_FASTCALL(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = __Pyx_NumKwargs_FASTCALL(__pyx_kwds);
      switch (__pyx_nargs) {
        case  0:
        if (likely((values[0] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_reshapedX)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[0]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 266, __pyx_L3_error)
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_radem)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[1]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 266, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConvGrad", 0, 7, 8, 1); __PYX_ERR(1, 266, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_outputArray)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[2]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 266, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConvGrad", 0, 7, 8, 2); __PYX_ERR(1, 266, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_chiArr)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[3]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 266, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConvGrad", 0, 7, 8, 3); __PYX_ERR(1, 266, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_numThreads)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[4]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 266, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConvGrad", 0, 7, 8, 4); __PYX_ERR(1, 266, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_sigma)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[5]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 266, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConvGrad", 0, 7, 8, 5); __PYX_ERR(1, 266, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (likely((values[6] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_beta)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[6]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 266, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConvGrad", 0, 7, 8, 6); __PYX_ERR(1, 266, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (kw_args > 0) {
          PyObject* value = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_fitIntercept);
          if (value) { values[7] = __Pyx_Arg_NewRef_FASTCALL(value); kw_args--; }
          else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 266, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        const Py_ssize_t kwd_pos_args = __pyx_nargs;
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "gpuConvGrad") < 0)) __PYX_ERR(1, 266, __pyx_L3_error)
      }
    } else {
      switch (__pyx_nargs) {
        case  8: values[7] = __Pyx_Arg_FASTCALL(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = __Pyx_Arg_FASTCALL(__pyx_args, 6);
        values[5] = __Pyx_Arg_FASTCALL(__pyx_args, 5);
        values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
        values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
        values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
        values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
        values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_reshapedX = values[0];
    __pyx_v_radem = values[1];
    __pyx_v_outputArray = values[2];
    __pyx_v_chiArr = values[3];
    __pyx_v_numThreads = __Pyx_PyInt_As_int(values[4]); if (unlikely((__pyx_v_numThreads == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 269, __pyx_L3_error)
    __pyx_v_sigma = __pyx_PyFloat_AsFloat(values[5]); if (unlikely((__pyx_v_sigma == (float)-1) && PyErr_Occurred())) __PYX_ERR(1, 269, __pyx_L3_error)
    __pyx_v_beta_ = __pyx_PyFloat_AsFloat(values[6]); if (unlikely((__pyx_v_beta_ == (float)-1) && PyErr_Occurred())) __PYX_ERR(1, 269, __pyx_L3_error)
    if (values[7]) {
      __pyx_v_fitIntercept = __Pyx_PyObject_IsTrue(values[7]); if (unlikely((__pyx_v_fitIntercept == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(1, 270, __pyx_L3_error)
    } else {

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":270
 * def gpuConvGrad(reshapedX, radem, outputArray, chiArr,
 *                 int numThreads, float sigma, float beta_,
 *                 bool fitIntercept = False):             # <<<<<<<<<<<<<<
 *     """Performs feature generation for the GraphRBF kernel while also performing
 *     gradient calculations.
 */
      __pyx_v_fitIntercept = ((bool)((int)0));
    }
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("gpuConvGrad", 0, 7, 8, __pyx_nargs); __PYX_ERR(1, 266, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_AddTraceback("cuda_rf_gen_module.gpuConvGrad", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_18cuda_rf_gen_module_8gpuConvGrad(__pyx_self, __pyx_v_reshapedX, __pyx_v_radem, __pyx_v_outputArray, __pyx_v_chiArr, __pyx_v_numThreads, __pyx_v_sigma, __pyx_v_beta_, __pyx_v_fitIntercept);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":266
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuConvGrad(reshapedX, radem, outputArray, chiArr,
 */

  /* function exit code */
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_18cuda_rf_gen_module_8gpuConvGrad(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_reshapedX, PyObject *__pyx_v_radem, PyObject *__pyx_v_outputArray, PyObject *__pyx_v_chiArr, CYTHON_UNUSED int __pyx_v_numThreads, float __pyx_v_sigma, float __pyx_v_beta_, bool __pyx_v_fitIntercept) {
  char const *__pyx_v_errCode;
  CYTHON_UNUSED PyObject *__pyx_v_reshapedXCopy = NULL;
  double __pyx_v_scalingTerm;
  CYTHON_UNUSED int __pyx_v_num_repeats;
  PyObject *__pyx_v_logdim = NULL;
  PyObject *__pyx_v_gradient = NULL;
  PyObject *__pyx_v_featureArray = NULL;
  uintptr_t __pyx_v_addr_reshapedX;
  uintptr_t __pyx_v_addr_featureArray;
  uintptr_t __pyx_v_addr_radem;
  uintptr_t __pyx_v_addr_chi;
  uintptr_t __pyx_v_addr_output;
  uintptr_t __pyx_v_addr_gradient;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  Py_ssize_t __pyx_t_6;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  uintptr_t __pyx_t_11;
  double __pyx_t_12;
  double __pyx_t_13;
  int __pyx_t_14;
  int __pyx_t_15;
  int __pyx_t_16;
  int __pyx_t_17;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("gpuConvGrad", 1);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":298
 *     """
 *     cdef const char *errCode
 *     reshapedXCopy = reshapedX.copy()             # <<<<<<<<<<<<<<
 *     cdef double scalingTerm
 *     cdef int num_repeats = (radem.shape[2] + reshapedX.shape[2] - 1) // reshapedX.shape[2]
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_copy); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 298, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  __pyx_t_4 = 0;
  #if CYTHON_UNPACK_METHODS
  if (likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_4 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_3, NULL};
    __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+1-__pyx_t_4, 0+__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 298, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __pyx_v_reshapedXCopy = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":300
 *     reshapedXCopy = reshapedX.copy()
 *     cdef double scalingTerm
 *     cdef int num_repeats = (radem.shape[2] + reshapedX.shape[2] - 1) // reshapedX.shape[2]             # <<<<<<<<<<<<<<
 *     cdef int startPosition, cutoff, startPos2, cutoff2, i, j
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Add(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyInt_SubtractObjC(__pyx_t_1, __pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_FloorDivide(__pyx_t_3, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 300, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_num_repeats = __pyx_t_4;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":303
 *     cdef int startPosition, cutoff, startPos2, cutoff2, i, j
 * 
 *     if len(chiArr.shape) != 1 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 303, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(1, 303, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__pyx_t_6 != 1);
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 303, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(1, 303, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__pyx_t_6 != 3);
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 303, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(1, 303, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__pyx_t_6 != 3);
  __pyx_t_5 = __pyx_t_7;
  __pyx_L4_bool_binop_done:;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":304
 * 
 *     if len(chiArr.shape) != 1 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")             # <<<<<<<<<<<<<<
 *     if len(outputArray.shape) != 2:
 *         raise ValueError("outputArray should be a 2d array.")
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__31, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 304, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(1, 304, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":303
 *     cdef int startPosition, cutoff, startPos2, cutoff2, i, j
 * 
 *     if len(chiArr.shape) != 1 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":305
 *     if len(chiArr.shape) != 1 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("outputArray should be a 2d array.")
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 305, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(1, 305, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = (__pyx_t_6 != 2);
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":306
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:
 *         raise ValueError("outputArray should be a 2d array.")             # <<<<<<<<<<<<<<
 * 
 *     if reshapedX.shape[0] == 0:
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__32, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 306, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(1, 306, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":305
 *     if len(chiArr.shape) != 1 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("outputArray should be a 2d array.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":308
 *         raise ValueError("outputArray should be a 2d array.")
 * 
 *     if reshapedX.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 308, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 308, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = (__Pyx_PyInt_BoolEqObjC(__pyx_t_2, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(1, 308, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":309
 * 
 *     if reshapedX.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")             # <<<<<<<<<<<<<<
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 309, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 309, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":308
 *         raise ValueError("outputArray should be a 2d array.")
 * 
 *     if reshapedX.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":310
 *     if reshapedX.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 310, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 310, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 310, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 310, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_1, __pyx_t_3, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 310, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(1, 310, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":311
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "             # <<<<<<<<<<<<<<
 *                 "not agree.")
 *     if radem.shape[0] != 3 or radem.shape[1] != 1:
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__33, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 311, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 311, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":310
 *     if reshapedX.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":313
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 *     if radem.shape[0] != 3 or radem.shape[1] != 1:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 313, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 313, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_7 = (__Pyx_PyInt_BoolNeObjC(__pyx_t_3, __pyx_int_3, 3, 0)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(1, 313, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L11_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 313, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 313, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_7 = (__Pyx_PyInt_BoolNeObjC(__pyx_t_2, __pyx_int_1, 1, 0)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(1, 313, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __pyx_t_7;
  __pyx_L11_bool_binop_done:;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":314
 *                 "not agree.")
 *     if radem.shape[0] != 3 or radem.shape[1] != 1:
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")             # <<<<<<<<<<<<<<
 * 
 *     if outputArray.shape[1] % 2 != 0 or outputArray.shape[1] < 2:
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__23, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 314, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 314, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":313
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 *     if radem.shape[0] != 3 or radem.shape[1] != 1:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":316
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")
 * 
 *     if outputArray.shape[1] % 2 != 0 or outputArray.shape[1] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("Shape of output array is not appropriate.")
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 316, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 316, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyInt_RemainderObjC(__pyx_t_3, __pyx_int_2, 2, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 316, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_7 = (__Pyx_PyInt_BoolNeObjC(__pyx_t_2, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(1, 316, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L14_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 316, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 316, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_3, __pyx_int_2, Py_LT); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 316, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(1, 316, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __pyx_t_7;
  __pyx_L14_bool_binop_done:;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":317
 * 
 *     if outputArray.shape[1] % 2 != 0 or outputArray.shape[1] < 2:
 *         raise ValueError("Shape of output array is not appropriate.")             # <<<<<<<<<<<<<<
 * 
 *     if 2 * chiArr.shape[0] != outputArray.shape[1] or chiArr.shape[0] > radem.shape[2]:
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__34, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 317, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 317, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":316
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")
 * 
 *     if outputArray.shape[1] % 2 != 0 or outputArray.shape[1] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("Shape of output array is not appropriate.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":319
 *         raise ValueError("Shape of output array is not appropriate.")
 * 
 *     if 2 * chiArr.shape[0] != outputArray.shape[1] or chiArr.shape[0] > radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Shape of output array and / or chiArr is inappropriate.")
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyInt_MultiplyCObj(__pyx_int_2, __pyx_t_3, 2, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_3, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_2, __pyx_t_1, Py_NE); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 319, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(1, 319, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L17_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_3, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_1, __pyx_t_2, Py_GT); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 319, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(1, 319, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_5 = __pyx_t_7;
  __pyx_L17_bool_binop_done:;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":320
 * 
 *     if 2 * chiArr.shape[0] != outputArray.shape[1] or chiArr.shape[0] > radem.shape[2]:
 *         raise ValueError("Shape of output array and / or chiArr is inappropriate.")             # <<<<<<<<<<<<<<
 * 
 *     logdim = np.log2(reshapedX.shape[2])
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__35, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 320, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(1, 320, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":319
 *         raise ValueError("Shape of output array is not appropriate.")
 * 
 *     if 2 * chiArr.shape[0] != outputArray.shape[1] or chiArr.shape[0] > radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Shape of output array and / or chiArr is inappropriate.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":322
 *         raise ValueError("Shape of output array and / or chiArr is inappropriate.")
 * 
 *     logdim = np.log2(reshapedX.shape[2])             # <<<<<<<<<<<<<<
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_np); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 322, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_log2); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 322, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 322, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 322, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
      __pyx_t_4 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_t_8};
    __pyx_t_3 = __Pyx_PyObject_FastCall(__pyx_t_1, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 322, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __pyx_v_logdim = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":323
 * 
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 323, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ceil); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 323, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  __pyx_t_4 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_8))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_8);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_8, function);
      __pyx_t_4 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_1, __pyx_v_logdim};
    __pyx_t_3 = __Pyx_PyObject_FastCall(__pyx_t_8, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 323, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  }
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 323, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_floor); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 323, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  __pyx_t_4 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_4 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_1, __pyx_v_logdim};
    __pyx_t_8 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 323, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_3, __pyx_t_8, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 323, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(1, 323, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L20_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 323, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 323, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_8, __pyx_int_2, Py_LT); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 323, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(1, 323, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __pyx_t_7;
  __pyx_L20_bool_binop_done:;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":324
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")             # <<<<<<<<<<<<<<
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__26, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 324, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 324, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":323
 * 
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":325
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "
 *                 "reshapedX.shape[2].")
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 325, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 325, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 325, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 325, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyNumber_Remainder(__pyx_t_8, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 325, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_5 = (__Pyx_PyInt_BoolEqObjC(__pyx_t_2, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(1, 325, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_7 = (!__pyx_t_5);
  if (unlikely(__pyx_t_7)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":326
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "             # <<<<<<<<<<<<<<
 *                 "reshapedX.shape[2].")
 * 
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__27, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 326, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 326, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":325
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "
 *                 "reshapedX.shape[2].")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":329
 *                 "reshapedX.shape[2].")
 * 
 *     if not radem.dtype == "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be int8.")
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_dtype); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 329, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_2, __pyx_n_u_int8, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(1, 329, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (!__pyx_t_7);
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":330
 * 
 *     if not radem.dtype == "int8":
 *         raise ValueError("radem must be int8.")             # <<<<<<<<<<<<<<
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__22, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 330, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 330, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":329
 *                 "reshapedX.shape[2].")
 * 
 *     if not radem.dtype == "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be int8.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":332
 *         raise ValueError("radem must be int8.")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_flags); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 332, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_Dict_GetItem(__pyx_t_2, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 332, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(1, 332, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_9 = (!__pyx_t_7);
  if (!__pyx_t_9) {
  } else {
    __pyx_t_5 = __pyx_t_9;
    goto __pyx_L25_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_flags); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 332, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_PyObject_Dict_GetItem(__pyx_t_3, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 332, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(1, 332, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_7 = (!__pyx_t_9);
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L25_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":333
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 *         or not chiArr.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_flags); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 332, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":332
 *         raise ValueError("radem must be int8.")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  __pyx_t_3 = __Pyx_PyObject_Dict_GetItem(__pyx_t_2, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 332, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(1, 332, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_9 = (!__pyx_t_7);
  if (!__pyx_t_9) {
  } else {
    __pyx_t_5 = __pyx_t_9;
    goto __pyx_L25_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":333
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 *         or not chiArr.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_flags); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 333, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_PyObject_Dict_GetItem(__pyx_t_3, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 333, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(1, 333, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_7 = (!__pyx_t_9);
  __pyx_t_5 = __pyx_t_7;
  __pyx_L25_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":332
 *         raise ValueError("radem must be int8.")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":334
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")             # <<<<<<<<<<<<<<
 * 
 * 
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__28, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 334, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(1, 334, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":332
 *         raise ValueError("radem must be int8.")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":337
 * 
 * 
 *     gradient = cp.zeros((outputArray.shape[0], outputArray.shape[1], 1), dtype=cp.float64)             # <<<<<<<<<<<<<<
 *     if reshapedX.dtype == "float32":
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_cp); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 337, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_zeros); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 337, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 337, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 337, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 337, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 337, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyTuple_New(3); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 337, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_8);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_8)) __PYX_ERR(1, 337, __pyx_L1_error);
  __Pyx_GIVEREF(__pyx_t_1);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_t_1)) __PYX_ERR(1, 337, __pyx_L1_error);
  __Pyx_INCREF(__pyx_int_1);
  __Pyx_GIVEREF(__pyx_int_1);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_2, 2, __pyx_int_1)) __PYX_ERR(1, 337, __pyx_L1_error);
  __pyx_t_8 = 0;
  __pyx_t_1 = 0;
  __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 337, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_2);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2)) __PYX_ERR(1, 337, __pyx_L1_error);
  __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 337, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GetModuleGlobalName(__pyx_t_8, __pyx_n_s_cp); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 337, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_float64); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 337, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_dtype, __pyx_t_10) < 0) __PYX_ERR(1, 337, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_t_10 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_1, __pyx_t_2); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 337, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_gradient = __pyx_t_10;
  __pyx_t_10 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":338
 * 
 *     gradient = cp.zeros((outputArray.shape[0], outputArray.shape[1], 1), dtype=cp.float64)
 *     if reshapedX.dtype == "float32":             # <<<<<<<<<<<<<<
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),
 *                             dtype = cp.float32)
 */
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_dtype); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 338, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_5 = (__Pyx_PyUnicode_Equals(__pyx_t_10, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(1, 338, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  if (__pyx_t_5) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":339
 *     gradient = cp.zeros((outputArray.shape[0], outputArray.shape[1], 1), dtype=cp.float64)
 *     if reshapedX.dtype == "float32":
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),             # <<<<<<<<<<<<<<
 *                             dtype = cp.float32)
 *     else:
 */
    __Pyx_GetModuleGlobalName(__pyx_t_10, __pyx_n_s_cp); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 339, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_n_s_zeros); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 339, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 339, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_10, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 339, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 339, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_10, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 339, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 339, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_10, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 339, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_10 = PyTuple_New(3); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 339, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_GIVEREF(__pyx_t_1);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_1)) __PYX_ERR(1, 339, __pyx_L1_error);
    __Pyx_GIVEREF(__pyx_t_3);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_10, 1, __pyx_t_3)) __PYX_ERR(1, 339, __pyx_L1_error);
    __Pyx_GIVEREF(__pyx_t_8);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_10, 2, __pyx_t_8)) __PYX_ERR(1, 339, __pyx_L1_error);
    __pyx_t_1 = 0;
    __pyx_t_3 = 0;
    __pyx_t_8 = 0;
    __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 339, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_GIVEREF(__pyx_t_10);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_10)) __PYX_ERR(1, 339, __pyx_L1_error);
    __pyx_t_10 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":340
 *     if reshapedX.dtype == "float32":
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),
 *                             dtype = cp.float32)             # <<<<<<<<<<<<<<
 *     else:
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),
 */
    __pyx_t_10 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 340, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_cp); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 340, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_float32); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 340, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (PyDict_SetItem(__pyx_t_10, __pyx_n_s_dtype, __pyx_t_1) < 0) __PYX_ERR(1, 340, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":339
 *     gradient = cp.zeros((outputArray.shape[0], outputArray.shape[1], 1), dtype=cp.float64)
 *     if reshapedX.dtype == "float32":
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),             # <<<<<<<<<<<<<<
 *                             dtype = cp.float32)
 *     else:
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_8, __pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 339, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_v_featureArray = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":338
 * 
 *     gradient = cp.zeros((outputArray.shape[0], outputArray.shape[1], 1), dtype=cp.float64)
 *     if reshapedX.dtype == "float32":             # <<<<<<<<<<<<<<
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),
 *                             dtype = cp.float32)
 */
    goto __pyx_L29;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":342
 *                             dtype = cp.float32)
 *     else:
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),             # <<<<<<<<<<<<<<
 *                             dtype = cp.float64)
 * 
 */
  /*else*/ {
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_cp); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 342, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_zeros); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 342, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 342, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 342, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 342, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 342, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 342, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 342, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 342, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_8);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_8)) __PYX_ERR(1, 342, __pyx_L1_error);
    __Pyx_GIVEREF(__pyx_t_2);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_t_2)) __PYX_ERR(1, 342, __pyx_L1_error);
    __Pyx_GIVEREF(__pyx_t_3);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_t_3)) __PYX_ERR(1, 342, __pyx_L1_error);
    __pyx_t_8 = 0;
    __pyx_t_2 = 0;
    __pyx_t_3 = 0;
    __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 342, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_1);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_1)) __PYX_ERR(1, 342, __pyx_L1_error);
    __pyx_t_1 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":343
 *     else:
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),
 *                             dtype = cp.float64)             # <<<<<<<<<<<<<<
 * 
 *     cdef uintptr_t addr_reshapedX = reshapedX.data.ptr
 */
    __pyx_t_1 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 343, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_cp); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 343, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_float64); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 343, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_dtype, __pyx_t_8) < 0) __PYX_ERR(1, 343, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":342
 *                             dtype = cp.float32)
 *     else:
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),             # <<<<<<<<<<<<<<
 *                             dtype = cp.float64)
 * 
 */
    __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_10, __pyx_t_3, __pyx_t_1); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 342, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_featureArray = __pyx_t_8;
    __pyx_t_8 = 0;
  }
  __pyx_L29:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":345
 *                             dtype = cp.float64)
 * 
 *     cdef uintptr_t addr_reshapedX = reshapedX.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_featureArray = featureArray.data.ptr
 *     cdef uintptr_t addr_radem = radem.data.ptr
 */
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_data); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 345, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 345, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_11 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_11 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 345, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_addr_reshapedX = __pyx_t_11;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":346
 * 
 *     cdef uintptr_t addr_reshapedX = reshapedX.data.ptr
 *     cdef uintptr_t addr_featureArray = featureArray.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_radem = radem.data.ptr
 *     cdef uintptr_t addr_chi = chiArr.data.ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_featureArray, __pyx_n_s_data); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 346, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 346, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_11 = __Pyx_PyInt_As_size_t(__pyx_t_8); if (unlikely((__pyx_t_11 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 346, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_v_addr_featureArray = __pyx_t_11;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":347
 *     cdef uintptr_t addr_reshapedX = reshapedX.data.ptr
 *     cdef uintptr_t addr_featureArray = featureArray.data.ptr
 *     cdef uintptr_t addr_radem = radem.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_chi = chiArr.data.ptr
 *     cdef uintptr_t addr_output = outputArray.data.ptr
 */
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_data); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 347, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 347, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_11 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_11 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 347, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_addr_radem = __pyx_t_11;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":348
 *     cdef uintptr_t addr_featureArray = featureArray.data.ptr
 *     cdef uintptr_t addr_radem = radem.data.ptr
 *     cdef uintptr_t addr_chi = chiArr.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_output = outputArray.data.ptr
 *     cdef uintptr_t addr_gradient = gradient.data.ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_data); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 348, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 348, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_11 = __Pyx_PyInt_As_size_t(__pyx_t_8); if (unlikely((__pyx_t_11 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 348, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_v_addr_chi = __pyx_t_11;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":349
 *     cdef uintptr_t addr_radem = radem.data.ptr
 *     cdef uintptr_t addr_chi = chiArr.data.ptr
 *     cdef uintptr_t addr_output = outputArray.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_gradient = gradient.data.ptr
 * 
 */
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_data); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 349, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 349, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_11 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_11 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 349, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_addr_output = __pyx_t_11;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":350
 *     cdef uintptr_t addr_chi = chiArr.data.ptr
 *     cdef uintptr_t addr_output = outputArray.data.ptr
 *     cdef uintptr_t addr_gradient = gradient.data.ptr             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gradient, __pyx_n_s_data); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 350, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 350, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_11 = __Pyx_PyInt_As_size_t(__pyx_t_8); if (unlikely((__pyx_t_11 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 350, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_v_addr_gradient = __pyx_t_11;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":353
 * 
 * 
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         scalingTerm = np.sqrt(2.0 / (<double>chiArr.shape[0] - 0.5))
 *     else:
 */
  __pyx_t_5 = (__pyx_v_fitIntercept != 0);
  if (__pyx_t_5) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":354
 * 
 *     if fitIntercept:
 *         scalingTerm = np.sqrt(2.0 / (<double>chiArr.shape[0] - 0.5))             # <<<<<<<<<<<<<<
 *     else:
 *         scalingTerm = np.sqrt(2 / <double>chiArr.shape[0])
 */
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 354, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_sqrt); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 354, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 354, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 354, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_12 = __pyx_PyFloat_AsDouble(__pyx_t_10); if (unlikely((__pyx_t_12 == (double)-1) && PyErr_Occurred())) __PYX_ERR(1, 354, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_13 = (((double)__pyx_t_12) - 0.5);
    if (unlikely(__pyx_t_13 == 0)) {
      PyErr_SetString(PyExc_ZeroDivisionError, "float division");
      __PYX_ERR(1, 354, __pyx_L1_error)
    }
    __pyx_t_10 = PyFloat_FromDouble((2.0 / __pyx_t_13)); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 354, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_1 = NULL;
    __pyx_t_4 = 0;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_3))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_3);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_3, function);
        __pyx_t_4 = 1;
      }
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_1, __pyx_t_10};
      __pyx_t_8 = __Pyx_PyObject_FastCall(__pyx_t_3, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 354, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    }
    __pyx_t_13 = __pyx_PyFloat_AsDouble(__pyx_t_8); if (unlikely((__pyx_t_13 == (double)-1) && PyErr_Occurred())) __PYX_ERR(1, 354, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_v_scalingTerm = __pyx_t_13;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":353
 * 
 * 
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         scalingTerm = np.sqrt(2.0 / (<double>chiArr.shape[0] - 0.5))
 *     else:
 */
    goto __pyx_L30;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":356
 *         scalingTerm = np.sqrt(2.0 / (<double>chiArr.shape[0] - 0.5))
 *     else:
 *         scalingTerm = np.sqrt(2 / <double>chiArr.shape[0])             # <<<<<<<<<<<<<<
 *     scalingTerm *= beta_
 * 
 */
  /*else*/ {
    __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_np); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 356, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_sqrt); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 356, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 356, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_3, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 356, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_13 = __pyx_PyFloat_AsDouble(__pyx_t_1); if (unlikely((__pyx_t_13 == (double)-1) && PyErr_Occurred())) __PYX_ERR(1, 356, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(((double)__pyx_t_13) == 0)) {
      PyErr_SetString(PyExc_ZeroDivisionError, "float division");
      __PYX_ERR(1, 356, __pyx_L1_error)
    }
    __pyx_t_1 = PyFloat_FromDouble((2.0 / ((double)__pyx_t_13))); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 356, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = NULL;
    __pyx_t_4 = 0;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_10))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_10);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_10);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_10, function);
        __pyx_t_4 = 1;
      }
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_3, __pyx_t_1};
      __pyx_t_8 = __Pyx_PyObject_FastCall(__pyx_t_10, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 356, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    }
    __pyx_t_13 = __pyx_PyFloat_AsDouble(__pyx_t_8); if (unlikely((__pyx_t_13 == (double)-1) && PyErr_Occurred())) __PYX_ERR(1, 356, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_v_scalingTerm = __pyx_t_13;
  }
  __pyx_L30:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":357
 *     else:
 *         scalingTerm = np.sqrt(2 / <double>chiArr.shape[0])
 *     scalingTerm *= beta_             # <<<<<<<<<<<<<<
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \
 */
  __pyx_v_scalingTerm = (__pyx_v_scalingTerm * __pyx_v_beta_);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":359
 *     scalingTerm *= beta_
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         errCode = convRBFFeatureGrad[float](<int8_t*>addr_radem, <float*>addr_reshapedX,
 */
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 359, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_8, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(1, 359, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L32_bool_binop_done;
  }
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_dtype); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 359, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_8, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(1, 359, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L32_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":360
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \
 *             chiArr.dtype == "float32":             # <<<<<<<<<<<<<<
 *         errCode = convRBFFeatureGrad[float](<int8_t*>addr_radem, <float*>addr_reshapedX,
 *             <float*>addr_featureArray, <float*>addr_chi,
 */
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_dtype); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 360, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_8, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(1, 360, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_5 = __pyx_t_7;
  __pyx_L32_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":359
 *     scalingTerm *= beta_
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         errCode = convRBFFeatureGrad[float](<int8_t*>addr_radem, <float*>addr_reshapedX,
 */
  if (__pyx_t_5) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":364
 *             <float*>addr_featureArray, <float*>addr_chi,
 *             <double*>addr_output, <double*>addr_gradient, sigma,
 *             reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2],             # <<<<<<<<<<<<<<
 *             chiArr.shape[0], radem.shape[2], scalingTerm)
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 */
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 364, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_8, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 364, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_10); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 364, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 364, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_10, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 364, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_14 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_14 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 364, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 364, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_8, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 364, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_15 = __Pyx_PyInt_As_int(__pyx_t_10); if (unlikely((__pyx_t_15 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 364, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":365
 *             <double*>addr_output, <double*>addr_gradient, sigma,
 *             reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2],
 *             chiArr.shape[0], radem.shape[2], scalingTerm)             # <<<<<<<<<<<<<<
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 *             chiArr.dtype == "float64":
 */
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 365, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_10, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 365, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_16 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_16 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 365, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 365, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_8, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 365, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_17 = __Pyx_PyInt_As_int(__pyx_t_10); if (unlikely((__pyx_t_17 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 365, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":361
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \
 *             chiArr.dtype == "float32":
 *         errCode = convRBFFeatureGrad[float](<int8_t*>addr_radem, <float*>addr_reshapedX,             # <<<<<<<<<<<<<<
 *             <float*>addr_featureArray, <float*>addr_chi,
 *             <double*>addr_output, <double*>addr_gradient, sigma,
 */
    __pyx_v_errCode = convRBFFeatureGrad<float>(((int8_t *)__pyx_v_addr_radem), ((float *)__pyx_v_addr_reshapedX), ((float *)__pyx_v_addr_featureArray), ((float *)__pyx_v_addr_chi), ((double *)__pyx_v_addr_output), ((double *)__pyx_v_addr_gradient), __pyx_v_sigma, __pyx_t_4, __pyx_t_14, __pyx_t_15, __pyx_t_16, __pyx_t_17, __pyx_v_scalingTerm);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":359
 *     scalingTerm *= beta_
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         errCode = convRBFFeatureGrad[float](<int8_t*>addr_radem, <float*>addr_reshapedX,
 */
    goto __pyx_L31;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":366
 *             reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2],
 *             chiArr.shape[0], radem.shape[2], scalingTerm)
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         errCode = convRBFFeatureGrad[double](<int8_t*>addr_radem,
 */
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 366, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_10, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(1, 366, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  if (__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L35_bool_binop_done;
  }
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_dtype); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 366, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_10, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(1, 366, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  if (__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L35_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":367
 *             chiArr.shape[0], radem.shape[2], scalingTerm)
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 *             chiArr.dtype == "float64":             # <<<<<<<<<<<<<<
 *         errCode = convRBFFeatureGrad[double](<int8_t*>addr_radem,
 *             <double*>addr_reshapedX, <double*>addr_featureArray,
 */
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_dtype); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 367, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_10, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(1, 367, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_t_5 = __pyx_t_7;
  __pyx_L35_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":366
 *             reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2],
 *             chiArr.shape[0], radem.shape[2], scalingTerm)
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         errCode = convRBFFeatureGrad[double](<int8_t*>addr_radem,
 */
  if (likely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":372
 *             <double*>addr_chi, <double*>addr_output,
 *             <double*>addr_gradient, sigma,
 *             reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2],             # <<<<<<<<<<<<<<
 *             chiArr.shape[0], radem.shape[2], scalingTerm)
 *     else:
 */
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 372, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_10, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 372, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_17 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_17 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 372, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 372, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_8, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 372, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_16 = __Pyx_PyInt_As_int(__pyx_t_10); if (unlikely((__pyx_t_16 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 372, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 372, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_10, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 372, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_15 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_15 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 372, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":373
 *             <double*>addr_gradient, sigma,
 *             reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2],
 *             chiArr.shape[0], radem.shape[2], scalingTerm)             # <<<<<<<<<<<<<<
 *     else:
 *         raise ValueError("Incorrect data types supplied.")
 */
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 373, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_8, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 373, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_14 = __Pyx_PyInt_As_int(__pyx_t_10); if (unlikely((__pyx_t_14 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 373, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 373, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_10, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 373, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 373, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":368
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 *             chiArr.dtype == "float64":
 *         errCode = convRBFFeatureGrad[double](<int8_t*>addr_radem,             # <<<<<<<<<<<<<<
 *             <double*>addr_reshapedX, <double*>addr_featureArray,
 *             <double*>addr_chi, <double*>addr_output,
 */
    __pyx_v_errCode = convRBFFeatureGrad<double>(((int8_t *)__pyx_v_addr_radem), ((double *)__pyx_v_addr_reshapedX), ((double *)__pyx_v_addr_featureArray), ((double *)__pyx_v_addr_chi), ((double *)__pyx_v_addr_output), ((double *)__pyx_v_addr_gradient), __pyx_v_sigma, __pyx_t_17, __pyx_t_16, __pyx_t_15, __pyx_t_14, __pyx_t_4, __pyx_v_scalingTerm);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":366
 *             reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2],
 *             chiArr.shape[0], radem.shape[2], scalingTerm)
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         errCode = convRBFFeatureGrad[double](<int8_t*>addr_radem,
 */
    goto __pyx_L31;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":375
 *             chiArr.shape[0], radem.shape[2], scalingTerm)
 *     else:
 *         raise ValueError("Incorrect data types supplied.")             # <<<<<<<<<<<<<<
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")
 */
  /*else*/ {
    __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__36, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 375, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_Raise(__pyx_t_8, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __PYX_ERR(1, 375, __pyx_L1_error)
  }
  __pyx_L31:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":376
 *     else:
 *         raise ValueError("Incorrect data types supplied.")
 *     if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")
 * 
 */
  __pyx_t_6 = __Pyx_ssize_strlen(__pyx_v_errCode); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(1, 376, __pyx_L1_error)
  __pyx_t_8 = __Pyx_decode_c_string(__pyx_v_errCode, 0, __pyx_t_6, NULL, NULL, PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 376, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_5 = (__Pyx_PyUnicode_Equals(__pyx_t_8, __pyx_n_u_no_error, Py_NE)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(1, 376, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":377
 *         raise ValueError("Incorrect data types supplied.")
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")             # <<<<<<<<<<<<<<
 * 
 *     if fitIntercept:
 */
    __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__37, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 377, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_Raise(__pyx_t_8, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __PYX_ERR(1, 377, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":376
 *     else:
 *         raise ValueError("Incorrect data types supplied.")
 *     if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":379
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")
 * 
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         outputArray[:,0] = beta_
 *         gradient[:,0] = 0
 */
  __pyx_t_5 = (__pyx_v_fitIntercept != 0);
  if (__pyx_t_5) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":380
 * 
 *     if fitIntercept:
 *         outputArray[:,0] = beta_             # <<<<<<<<<<<<<<
 *         gradient[:,0] = 0
 *     return gradient
 */
    __pyx_t_8 = PyFloat_FromDouble(__pyx_v_beta_); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 380, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    if (unlikely((PyObject_SetItem(__pyx_v_outputArray, __pyx_tuple__38, __pyx_t_8) < 0))) __PYX_ERR(1, 380, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":381
 *     if fitIntercept:
 *         outputArray[:,0] = beta_
 *         gradient[:,0] = 0             # <<<<<<<<<<<<<<
 *     return gradient
 * 
 */
    if (unlikely((PyObject_SetItem(__pyx_v_gradient, __pyx_tuple__38, __pyx_int_0) < 0))) __PYX_ERR(1, 381, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":379
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")
 * 
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         outputArray[:,0] = beta_
 *         gradient[:,0] = 0
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":382
 *         outputArray[:,0] = beta_
 *         gradient[:,0] = 0
 *     return gradient             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_gradient);
  __pyx_r = __pyx_v_gradient;
  goto __pyx_L0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":266
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuConvGrad(reshapedX, radem, outputArray, chiArr,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("cuda_rf_gen_module.gpuConvGrad", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_reshapedXCopy);
  __Pyx_XDECREF(__pyx_v_logdim);
  __Pyx_XDECREF(__pyx_v_gradient);
  __Pyx_XDECREF(__pyx_v_featureArray);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":386
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuConv1dArcCosFGen(reshapedX, radem, outputArray, chiArr,
 */

/* Python wrapper */
static PyObject *__pyx_pw_18cuda_rf_gen_module_11gpuConv1dArcCosFGen(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_18cuda_rf_gen_module_10gpuConv1dArcCosFGen, "Uses wrapped C functions to generate random features for arccosine kernels\n    for sequences and graphs.\n\n    Args:\n        reshapedX (cp.ndarray): Raw data reshaped so that a convolution can be\n            performed on it using orthogonal random features with the SORF\n            operation. This array is not modified in place -- rather the features\n            that are generated are stored in outputArray. Shape is (N x D x C) for \n            N datapoints. C must be a power of 2.\n        radem (cp.ndarray): A stack of diagonal matrices with elements drawn from the\n            Rademacher distribution. Shape must be (3 x D x C).\n        outputArray (cp.ndarray): A numpy array in which the generated features will be\n            stored. Is modified in-place.\n        chiArr (cp.ndarray): A stack of diagonal matrices drawn from a chi distribution.\n        num_threads (int): Number of threads to use for FHT. Supplied for consistency\n            with CPU-wrapper functions, since it is not actually used.\n        beta (float): The amplitude.\n        kernelOrder (int): The order of the arccosine kernel.\n        fitIntercept (bool): Whether to fit a y-intercept (in this case,\n            the first random feature generated should be set to 1).\n\n    Raises:\n        ValueError: A ValueError is raised if unexpected or invalid inputs are supplied.\n    ");
static PyMethodDef __pyx_mdef_18cuda_rf_gen_module_11gpuConv1dArcCosFGen = {"gpuConv1dArcCosFGen", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_18cuda_rf_gen_module_11gpuConv1dArcCosFGen, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_18cuda_rf_gen_module_10gpuConv1dArcCosFGen};
static PyObject *__pyx_pw_18cuda_rf_gen_module_11gpuConv1dArcCosFGen(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_reshapedX = 0;
  PyObject *__pyx_v_radem = 0;
  PyObject *__pyx_v_outputArray = 0;
  PyObject *__pyx_v_chiArr = 0;
  CYTHON_UNUSED int __pyx_v_numThreads;
  float __pyx_v_beta_;
  int __pyx_v_kernelOrder;
  bool __pyx_v_fitIntercept;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[8] = {0,0,0,0,0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("gpuConv1dArcCosFGen (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_MACROS
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject **__pyx_pyargnames[] = {&__pyx_n_s_reshapedX,&__pyx_n_s_radem,&__pyx_n_s_outputArray,&__pyx_n_s_chiArr,&__pyx_n_s_numThreads,&__pyx_n_s_beta,&__pyx_n_s_kernelOrder,&__pyx_n_s_fitIntercept,0};
    if (__pyx_kwds) {
      Py_ssize_t kw_args;
      switch (__pyx_nargs) {
        case  8: values[7] = __Pyx_Arg_FASTCALL(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = __Pyx_Arg_FASTCALL(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = __Pyx_Arg_FASTCALL(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = __Pyx_NumKwargs_FASTCALL(__pyx_kwds);
      switch (__pyx_nargs) {
        case  0:
        if (likely((values[0] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_reshapedX)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[0]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 386, __pyx_L3_error)
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_radem)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[1]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 386, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConv1dArcCosFGen", 0, 7, 8, 1); __PYX_ERR(1, 386, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_outputArray)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[2]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 386, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConv1dArcCosFGen", 0, 7, 8, 2); __PYX_ERR(1, 386, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_chiArr)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[3]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 386, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConv1dArcCosFGen", 0, 7, 8, 3); __PYX_ERR(1, 386, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_numThreads)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[4]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 386, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConv1dArcCosFGen", 0, 7, 8, 4); __PYX_ERR(1, 386, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_beta)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[5]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 386, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConv1dArcCosFGen", 0, 7, 8, 5); __PYX_ERR(1, 386, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (likely((values[6] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_kernelOrder)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[6]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 386, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuConv1dArcCosFGen", 0, 7, 8, 6); __PYX_ERR(1, 386, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (kw_args > 0) {
          PyObject* value = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_fitIntercept);
          if (value) { values[7] = __Pyx_Arg_NewRef_FASTCALL(value); kw_args--; }
          else if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 386, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        const Py_ssize_t kwd_pos_args = __pyx_nargs;
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "gpuConv1dArcCosFGen") < 0)) __PYX_ERR(1, 386, __pyx_L3_error)
      }
    } else {
      switch (__pyx_nargs) {
        case  8: values[7] = __Pyx_Arg_FASTCALL(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = __Pyx_Arg_FASTCALL(__pyx_args, 6);
        values[5] = __Pyx_Arg_FASTCALL(__pyx_args, 5);
        values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
        values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
        values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
        values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
        values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_reshapedX = values[0];
    __pyx_v_radem = values[1];
    __pyx_v_outputArray = values[2];
    __pyx_v_chiArr = values[3];
    __pyx_v_numThreads = __Pyx_PyInt_As_int(values[4]); if (unlikely((__pyx_v_numThreads == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 389, __pyx_L3_error)
    __pyx_v_beta_ = __pyx_PyFloat_AsFloat(values[5]); if (unlikely((__pyx_v_beta_ == (float)-1) && PyErr_Occurred())) __PYX_ERR(1, 389, __pyx_L3_error)
    __pyx_v_kernelOrder = __Pyx_PyInt_As_int(values[6]); if (unlikely((__pyx_v_kernelOrder == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 389, __pyx_L3_error)
    if (values[7]) {
      __pyx_v_fitIntercept = __Pyx_PyObject_IsTrue(values[7]); if (unlikely((__pyx_v_fitIntercept == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(1, 390, __pyx_L3_error)
    } else {

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":390
 * def gpuConv1dArcCosFGen(reshapedX, radem, outputArray, chiArr,
 *                 int numThreads, float beta_, int kernelOrder,
 *                 bool fitIntercept = False):             # <<<<<<<<<<<<<<
 *     """Uses wrapped C functions to generate random features for arccosine kernels
 *     for sequences and graphs.
 */
      __pyx_v_fitIntercept = ((bool)((int)0));
    }
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("gpuConv1dArcCosFGen", 0, 7, 8, __pyx_nargs); __PYX_ERR(1, 386, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_AddTraceback("cuda_rf_gen_module.gpuConv1dArcCosFGen", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_18cuda_rf_gen_module_10gpuConv1dArcCosFGen(__pyx_self, __pyx_v_reshapedX, __pyx_v_radem, __pyx_v_outputArray, __pyx_v_chiArr, __pyx_v_numThreads, __pyx_v_beta_, __pyx_v_kernelOrder, __pyx_v_fitIntercept);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":386
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuConv1dArcCosFGen(reshapedX, radem, outputArray, chiArr,
 */

  /* function exit code */
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_18cuda_rf_gen_module_10gpuConv1dArcCosFGen(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_reshapedX, PyObject *__pyx_v_radem, PyObject *__pyx_v_outputArray, PyObject *__pyx_v_chiArr, CYTHON_UNUSED int __pyx_v_numThreads, float __pyx_v_beta_, int __pyx_v_kernelOrder, bool __pyx_v_fitIntercept) {
  char const *__pyx_v_errCode;
  double __pyx_v_scalingTerm;
  PyObject *__pyx_v_logdim = NULL;
  PyObject *__pyx_v_featureArray = NULL;
  uintptr_t __pyx_v_addr_reshapedX;
  uintptr_t __pyx_v_addr_featureArray;
  uintptr_t __pyx_v_addr_radem;
  uintptr_t __pyx_v_addr_chi;
  uintptr_t __pyx_v_addr_output;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  Py_ssize_t __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_t_8;
  int __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  uintptr_t __pyx_t_11;
  double __pyx_t_12;
  int __pyx_t_13;
  int __pyx_t_14;
  int __pyx_t_15;
  int __pyx_t_16;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("gpuConv1dArcCosFGen", 1);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":418
 *     cdef double scalingTerm
 * 
 *     if kernelOrder not in [1,2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Unexpected kernel order supplied.")
 * 
 */
  switch (__pyx_v_kernelOrder) {
    case 1:
    case 2:
    __pyx_t_1 = 0;
    break;
    default:
    __pyx_t_1 = 1;
    break;
  }
  __pyx_t_2 = __pyx_t_1;
  if (unlikely(__pyx_t_2)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":419
 * 
 *     if kernelOrder not in [1,2]:
 *         raise ValueError("Unexpected kernel order supplied.")             # <<<<<<<<<<<<<<
 * 
 *     if len(chiArr.shape) != 1 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__39, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 419, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(1, 419, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":418
 *     cdef double scalingTerm
 * 
 *     if kernelOrder not in [1,2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Unexpected kernel order supplied.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":421
 *         raise ValueError("Unexpected kernel order supplied.")
 * 
 *     if len(chiArr.shape) != 1 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 421, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = PyObject_Length(__pyx_t_3); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(1, 421, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_1 = (__pyx_t_4 != 1);
  if (!__pyx_t_1) {
  } else {
    __pyx_t_2 = __pyx_t_1;
    goto __pyx_L5_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 421, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = PyObject_Length(__pyx_t_3); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(1, 421, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_1 = (__pyx_t_4 != 3);
  if (!__pyx_t_1) {
  } else {
    __pyx_t_2 = __pyx_t_1;
    goto __pyx_L5_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 421, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = PyObject_Length(__pyx_t_3); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(1, 421, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_1 = (__pyx_t_4 != 3);
  __pyx_t_2 = __pyx_t_1;
  __pyx_L5_bool_binop_done:;
  if (unlikely(__pyx_t_2)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":422
 * 
 *     if len(chiArr.shape) != 1 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")             # <<<<<<<<<<<<<<
 *     if len(outputArray.shape) != 2:
 *         raise ValueError("outputArray should be a 2d array.")
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__31, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 422, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(1, 422, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":421
 *         raise ValueError("Unexpected kernel order supplied.")
 * 
 *     if len(chiArr.shape) != 1 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":423
 *     if len(chiArr.shape) != 1 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("outputArray should be a 2d array.")
 * 
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 423, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = PyObject_Length(__pyx_t_3); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(1, 423, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_2 = (__pyx_t_4 != 2);
  if (unlikely(__pyx_t_2)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":424
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:
 *         raise ValueError("outputArray should be a 2d array.")             # <<<<<<<<<<<<<<
 * 
 *     if reshapedX.shape[0] == 0:
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__32, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 424, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(1, 424, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":423
 *     if len(chiArr.shape) != 1 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("outputArray should be a 2d array.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":426
 *         raise ValueError("outputArray should be a 2d array.")
 * 
 *     if reshapedX.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 426, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_3, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 426, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_2 = (__Pyx_PyInt_BoolEqObjC(__pyx_t_5, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_2 < 0))) __PYX_ERR(1, 426, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(__pyx_t_2)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":427
 * 
 *     if reshapedX.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")             # <<<<<<<<<<<<<<
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 */
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__3, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 427, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(1, 427, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":426
 *         raise ValueError("outputArray should be a 2d array.")
 * 
 *     if reshapedX.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":428
 *     if reshapedX.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 428, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_5, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 428, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 428, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_5, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 428, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = PyObject_RichCompare(__pyx_t_3, __pyx_t_6, Py_NE); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 428, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely((__pyx_t_2 < 0))) __PYX_ERR(1, 428, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(__pyx_t_2)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":429
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "             # <<<<<<<<<<<<<<
 *                 "not agree.")
 *     if radem.shape[0] != 3 or radem.shape[1] != 1:
 */
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__33, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 429, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(1, 429, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":428
 *     if reshapedX.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":431
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 *     if radem.shape[0] != 3 or radem.shape[1] != 1:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")
 * 
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 431, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_5, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 431, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_1 = (__Pyx_PyInt_BoolNeObjC(__pyx_t_6, __pyx_int_3, 3, 0)); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 431, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (!__pyx_t_1) {
  } else {
    __pyx_t_2 = __pyx_t_1;
    goto __pyx_L12_bool_binop_done;
  }
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 431, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_6, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 431, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_1 = (__Pyx_PyInt_BoolNeObjC(__pyx_t_5, __pyx_int_1, 1, 0)); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 431, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_2 = __pyx_t_1;
  __pyx_L12_bool_binop_done:;
  if (unlikely(__pyx_t_2)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":432
 *                 "not agree.")
 *     if radem.shape[0] != 3 or radem.shape[1] != 1:
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")             # <<<<<<<<<<<<<<
 * 
 *     if outputArray.shape[1] % 2 != 0 or outputArray.shape[1] < 2:
 */
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__23, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 432, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(1, 432, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":431
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 *     if radem.shape[0] != 3 or radem.shape[1] != 1:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":434
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")
 * 
 *     if outputArray.shape[1] % 2 != 0 or outputArray.shape[1] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("Shape of output array is not appropriate.")
 * 
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 434, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_5, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 434, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyInt_RemainderObjC(__pyx_t_6, __pyx_int_2, 2, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 434, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_1 = (__Pyx_PyInt_BoolNeObjC(__pyx_t_5, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 434, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (!__pyx_t_1) {
  } else {
    __pyx_t_2 = __pyx_t_1;
    goto __pyx_L15_bool_binop_done;
  }
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 434, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_5, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 434, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = PyObject_RichCompare(__pyx_t_6, __pyx_int_2, Py_LT); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 434, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 434, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_2 = __pyx_t_1;
  __pyx_L15_bool_binop_done:;
  if (unlikely(__pyx_t_2)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":435
 * 
 *     if outputArray.shape[1] % 2 != 0 or outputArray.shape[1] < 2:
 *         raise ValueError("Shape of output array is not appropriate.")             # <<<<<<<<<<<<<<
 * 
 *     if chiArr.shape[0] != outputArray.shape[1] or chiArr.shape[0] > radem.shape[2]:
 */
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__34, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 435, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(1, 435, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":434
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")
 * 
 *     if outputArray.shape[1] % 2 != 0 or outputArray.shape[1] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("Shape of output array is not appropriate.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":437
 *         raise ValueError("Shape of output array is not appropriate.")
 * 
 *     if chiArr.shape[0] != outputArray.shape[1] or chiArr.shape[0] > radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Shape of output array and / or chiArr is inappropriate.")
 * 
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 437, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_5, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 437, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 437, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_5, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 437, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = PyObject_RichCompare(__pyx_t_6, __pyx_t_3, Py_NE); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 437, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 437, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (!__pyx_t_1) {
  } else {
    __pyx_t_2 = __pyx_t_1;
    goto __pyx_L18_bool_binop_done;
  }
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 437, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_5, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 437, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 437, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_5, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 437, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = PyObject_RichCompare(__pyx_t_3, __pyx_t_6, Py_GT); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 437, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 437, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_2 = __pyx_t_1;
  __pyx_L18_bool_binop_done:;
  if (unlikely(__pyx_t_2)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":438
 * 
 *     if chiArr.shape[0] != outputArray.shape[1] or chiArr.shape[0] > radem.shape[2]:
 *         raise ValueError("Shape of output array and / or chiArr is inappropriate.")             # <<<<<<<<<<<<<<
 * 
 *     logdim = np.log2(reshapedX.shape[2])
 */
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__35, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 438, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(1, 438, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":437
 *         raise ValueError("Shape of output array is not appropriate.")
 * 
 *     if chiArr.shape[0] != outputArray.shape[1] or chiArr.shape[0] > radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Shape of output array and / or chiArr is inappropriate.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":440
 *         raise ValueError("Shape of output array and / or chiArr is inappropriate.")
 * 
 *     logdim = np.log2(reshapedX.shape[2])             # <<<<<<<<<<<<<<
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 */
  __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_np); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 440, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_log2); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 440, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 440, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_6, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 440, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = NULL;
  __pyx_t_8 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_8 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_6, __pyx_t_7};
    __pyx_t_5 = __Pyx_PyObject_FastCall(__pyx_t_3, __pyx_callargs+1-__pyx_t_8, 1+__pyx_t_8);
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 440, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  }
  __pyx_v_logdim = __pyx_t_5;
  __pyx_t_5 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":441
 * 
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 */
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_np); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 441, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_ceil); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 441, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = NULL;
  __pyx_t_8 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_7))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_7);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_7, function);
      __pyx_t_8 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_3, __pyx_v_logdim};
    __pyx_t_5 = __Pyx_PyObject_FastCall(__pyx_t_7, __pyx_callargs+1-__pyx_t_8, 1+__pyx_t_8);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 441, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  }
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_np); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 441, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_floor); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 441, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = NULL;
  __pyx_t_8 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
      __pyx_t_8 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_3, __pyx_v_logdim};
    __pyx_t_7 = __Pyx_PyObject_FastCall(__pyx_t_6, __pyx_callargs+1-__pyx_t_8, 1+__pyx_t_8);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 441, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __pyx_t_6 = PyObject_RichCompare(__pyx_t_5, __pyx_t_7, Py_NE); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 441, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 441, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (!__pyx_t_1) {
  } else {
    __pyx_t_2 = __pyx_t_1;
    goto __pyx_L21_bool_binop_done;
  }
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 441, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_6, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 441, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = PyObject_RichCompare(__pyx_t_7, __pyx_int_2, Py_LT); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 441, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 441, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_2 = __pyx_t_1;
  __pyx_L21_bool_binop_done:;
  if (unlikely(__pyx_t_2)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":442
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")             # <<<<<<<<<<<<<<
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "
 */
    __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__26, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 442, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_Raise(__pyx_t_6, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __PYX_ERR(1, 442, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":441
 * 
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":443
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "
 *                 "reshapedX.shape[2].")
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 443, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_6, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 443, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 443, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_6, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 443, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = PyNumber_Remainder(__pyx_t_7, __pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 443, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_2 = (__Pyx_PyInt_BoolEqObjC(__pyx_t_6, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_2 < 0))) __PYX_ERR(1, 443, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_1 = (!__pyx_t_2);
  if (unlikely(__pyx_t_1)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":444
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "             # <<<<<<<<<<<<<<
 *                 "reshapedX.shape[2].")
 * 
 */
    __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__27, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 444, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_Raise(__pyx_t_6, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __PYX_ERR(1, 444, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":443
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "
 *                 "reshapedX.shape[2].")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":447
 *                 "reshapedX.shape[2].")
 * 
 *     if not radem.dtype == "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be int8.")
 * 
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_dtype); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 447, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_1 = (__Pyx_PyUnicode_Equals(__pyx_t_6, __pyx_n_u_int8, Py_EQ)); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 447, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_2 = (!__pyx_t_1);
  if (unlikely(__pyx_t_2)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":448
 * 
 *     if not radem.dtype == "int8":
 *         raise ValueError("radem must be int8.")             # <<<<<<<<<<<<<<
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 */
    __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__22, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 448, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_Raise(__pyx_t_6, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __PYX_ERR(1, 448, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":447
 *                 "reshapedX.shape[2].")
 * 
 *     if not radem.dtype == "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be int8.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":450
 *         raise ValueError("radem must be int8.")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_flags); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 450, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_5 = __Pyx_PyObject_Dict_GetItem(__pyx_t_6, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 450, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 450, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_9 = (!__pyx_t_1);
  if (!__pyx_t_9) {
  } else {
    __pyx_t_2 = __pyx_t_9;
    goto __pyx_L26_bool_binop_done;
  }
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_flags); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 450, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_PyObject_Dict_GetItem(__pyx_t_5, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 450, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(1, 450, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_1 = (!__pyx_t_9);
  if (!__pyx_t_1) {
  } else {
    __pyx_t_2 = __pyx_t_1;
    goto __pyx_L26_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":451
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 *         or not chiArr.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_flags); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 450, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":450
 *         raise ValueError("radem must be int8.")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  __pyx_t_5 = __Pyx_PyObject_Dict_GetItem(__pyx_t_6, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 450, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 450, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_9 = (!__pyx_t_1);
  if (!__pyx_t_9) {
  } else {
    __pyx_t_2 = __pyx_t_9;
    goto __pyx_L26_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":451
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 *         or not chiArr.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_flags); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 451, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_PyObject_Dict_GetItem(__pyx_t_5, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 451, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(1, 451, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_1 = (!__pyx_t_9);
  __pyx_t_2 = __pyx_t_1;
  __pyx_L26_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":450
 *         raise ValueError("radem must be int8.")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  if (unlikely(__pyx_t_2)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":452
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")             # <<<<<<<<<<<<<<
 * 
 *     if reshapedX.dtype == "float32":
 */
    __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__28, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 452, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_Raise(__pyx_t_6, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __PYX_ERR(1, 452, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":450
 *         raise ValueError("radem must be int8.")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":454
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 *     if reshapedX.dtype == "float32":             # <<<<<<<<<<<<<<
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),
 *                             dtype = cp.float32)
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_dtype); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 454, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_2 = (__Pyx_PyUnicode_Equals(__pyx_t_6, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_2 < 0))) __PYX_ERR(1, 454, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (__pyx_t_2) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":455
 * 
 *     if reshapedX.dtype == "float32":
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),             # <<<<<<<<<<<<<<
 *                             dtype = cp.float32)
 *     else:
 */
    __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_cp); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 455, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_zeros); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 455, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 455, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_6, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 455, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 455, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_6, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 455, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 455, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_6, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 455, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = PyTuple_New(3); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 455, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_GIVEREF(__pyx_t_7);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_7)) __PYX_ERR(1, 455, __pyx_L1_error);
    __Pyx_GIVEREF(__pyx_t_3);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_t_3)) __PYX_ERR(1, 455, __pyx_L1_error);
    __Pyx_GIVEREF(__pyx_t_10);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 2, __pyx_t_10)) __PYX_ERR(1, 455, __pyx_L1_error);
    __pyx_t_7 = 0;
    __pyx_t_3 = 0;
    __pyx_t_10 = 0;
    __pyx_t_10 = PyTuple_New(1); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 455, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_GIVEREF(__pyx_t_6);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_6)) __PYX_ERR(1, 455, __pyx_L1_error);
    __pyx_t_6 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":456
 *     if reshapedX.dtype == "float32":
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),
 *                             dtype = cp.float32)             # <<<<<<<<<<<<<<
 *     else:
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),
 */
    __pyx_t_6 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 456, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_cp); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 456, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_float32); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 456, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (PyDict_SetItem(__pyx_t_6, __pyx_n_s_dtype, __pyx_t_7) < 0) __PYX_ERR(1, 456, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":455
 * 
 *     if reshapedX.dtype == "float32":
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),             # <<<<<<<<<<<<<<
 *                             dtype = cp.float32)
 *     else:
 */
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_10, __pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 455, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_v_featureArray = __pyx_t_7;
    __pyx_t_7 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":454
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 *     if reshapedX.dtype == "float32":             # <<<<<<<<<<<<<<
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),
 *                             dtype = cp.float32)
 */
    goto __pyx_L30;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":458
 *                             dtype = cp.float32)
 *     else:
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),             # <<<<<<<<<<<<<<
 *                             dtype = cp.float64)
 * 
 */
  /*else*/ {
    __Pyx_GetModuleGlobalName(__pyx_t_7, __pyx_n_s_cp); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 458, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_zeros); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 458, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 458, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_7, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 458, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 458, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_7, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 458, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 458, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_7, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 458, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = PyTuple_New(3); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 458, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_GIVEREF(__pyx_t_10);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_10)) __PYX_ERR(1, 458, __pyx_L1_error);
    __Pyx_GIVEREF(__pyx_t_5);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_t_5)) __PYX_ERR(1, 458, __pyx_L1_error);
    __Pyx_GIVEREF(__pyx_t_3);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_7, 2, __pyx_t_3)) __PYX_ERR(1, 458, __pyx_L1_error);
    __pyx_t_10 = 0;
    __pyx_t_5 = 0;
    __pyx_t_3 = 0;
    __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 458, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_7);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_7)) __PYX_ERR(1, 458, __pyx_L1_error);
    __pyx_t_7 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":459
 *     else:
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),
 *                             dtype = cp.float64)             # <<<<<<<<<<<<<<
 * 
 *     cdef uintptr_t addr_reshapedX = reshapedX.data.ptr
 */
    __pyx_t_7 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 459, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_cp); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 459, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_float64); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 459, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (PyDict_SetItem(__pyx_t_7, __pyx_n_s_dtype, __pyx_t_10) < 0) __PYX_ERR(1, 459, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":458
 *                             dtype = cp.float32)
 *     else:
 *         featureArray = cp.zeros((reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2]),             # <<<<<<<<<<<<<<
 *                             dtype = cp.float64)
 * 
 */
    __pyx_t_10 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_3, __pyx_t_7); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 458, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_v_featureArray = __pyx_t_10;
    __pyx_t_10 = 0;
  }
  __pyx_L30:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":461
 *                             dtype = cp.float64)
 * 
 *     cdef uintptr_t addr_reshapedX = reshapedX.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_featureArray = featureArray.data.ptr
 *     cdef uintptr_t addr_radem = radem.data.ptr
 */
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_data); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 461, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_n_s_ptr); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 461, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_t_11 = __Pyx_PyInt_As_size_t(__pyx_t_7); if (unlikely((__pyx_t_11 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 461, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_addr_reshapedX = __pyx_t_11;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":462
 * 
 *     cdef uintptr_t addr_reshapedX = reshapedX.data.ptr
 *     cdef uintptr_t addr_featureArray = featureArray.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_radem = radem.data.ptr
 *     cdef uintptr_t addr_chi = chiArr.data.ptr
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_featureArray, __pyx_n_s_data); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 462, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_ptr); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 462, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_11 = __Pyx_PyInt_As_size_t(__pyx_t_10); if (unlikely((__pyx_t_11 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 462, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_v_addr_featureArray = __pyx_t_11;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":463
 *     cdef uintptr_t addr_reshapedX = reshapedX.data.ptr
 *     cdef uintptr_t addr_featureArray = featureArray.data.ptr
 *     cdef uintptr_t addr_radem = radem.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_chi = chiArr.data.ptr
 *     cdef uintptr_t addr_output = outputArray.data.ptr
 */
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_data); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 463, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_n_s_ptr); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 463, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_t_11 = __Pyx_PyInt_As_size_t(__pyx_t_7); if (unlikely((__pyx_t_11 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 463, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_addr_radem = __pyx_t_11;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":464
 *     cdef uintptr_t addr_featureArray = featureArray.data.ptr
 *     cdef uintptr_t addr_radem = radem.data.ptr
 *     cdef uintptr_t addr_chi = chiArr.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_output = outputArray.data.ptr
 * 
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_data); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 464, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_ptr); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 464, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_11 = __Pyx_PyInt_As_size_t(__pyx_t_10); if (unlikely((__pyx_t_11 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 464, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_v_addr_chi = __pyx_t_11;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":465
 *     cdef uintptr_t addr_radem = radem.data.ptr
 *     cdef uintptr_t addr_chi = chiArr.data.ptr
 *     cdef uintptr_t addr_output = outputArray.data.ptr             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_data); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 465, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_n_s_ptr); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 465, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_t_11 = __Pyx_PyInt_As_size_t(__pyx_t_7); if (unlikely((__pyx_t_11 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 465, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_addr_output = __pyx_t_11;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":468
 * 
 * 
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         scalingTerm = np.sqrt(1 / <double>(chiArr.shape[0] - 1))
 *     else:
 */
  __pyx_t_2 = (__pyx_v_fitIntercept != 0);
  if (__pyx_t_2) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":469
 * 
 *     if fitIntercept:
 *         scalingTerm = np.sqrt(1 / <double>(chiArr.shape[0] - 1))             # <<<<<<<<<<<<<<
 *     else:
 *         scalingTerm = np.sqrt(1 / <double>chiArr.shape[0])
 */
    __Pyx_GetModuleGlobalName(__pyx_t_10, __pyx_n_s_np); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 469, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_n_s_sqrt); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 469, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 469, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_10, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 469, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_10 = __Pyx_PyInt_SubtractObjC(__pyx_t_6, __pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 469, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_12 = __pyx_PyFloat_AsDouble(__pyx_t_10); if (unlikely((__pyx_t_12 == (double)-1) && PyErr_Occurred())) __PYX_ERR(1, 469, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    if (unlikely(((double)__pyx_t_12) == 0)) {
      PyErr_SetString(PyExc_ZeroDivisionError, "float division");
      __PYX_ERR(1, 469, __pyx_L1_error)
    }
    __pyx_t_10 = PyFloat_FromDouble((1.0 / ((double)__pyx_t_12))); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 469, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_6 = NULL;
    __pyx_t_8 = 0;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_3))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_3);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_3, function);
        __pyx_t_8 = 1;
      }
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_6, __pyx_t_10};
      __pyx_t_7 = __Pyx_PyObject_FastCall(__pyx_t_3, __pyx_callargs+1-__pyx_t_8, 1+__pyx_t_8);
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 469, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    }
    __pyx_t_12 = __pyx_PyFloat_AsDouble(__pyx_t_7); if (unlikely((__pyx_t_12 == (double)-1) && PyErr_Occurred())) __PYX_ERR(1, 469, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_v_scalingTerm = __pyx_t_12;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":468
 * 
 * 
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         scalingTerm = np.sqrt(1 / <double>(chiArr.shape[0] - 1))
 *     else:
 */
    goto __pyx_L31;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":471
 *         scalingTerm = np.sqrt(1 / <double>(chiArr.shape[0] - 1))
 *     else:
 *         scalingTerm = np.sqrt(1 / <double>chiArr.shape[0])             # <<<<<<<<<<<<<<
 *     scalingTerm *= beta_
 * 
 */
  /*else*/ {
    __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_np); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 471, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_sqrt); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 471, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 471, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_3, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 471, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_12 = __pyx_PyFloat_AsDouble(__pyx_t_6); if (unlikely((__pyx_t_12 == (double)-1) && PyErr_Occurred())) __PYX_ERR(1, 471, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(((double)__pyx_t_12) == 0)) {
      PyErr_SetString(PyExc_ZeroDivisionError, "float division");
      __PYX_ERR(1, 471, __pyx_L1_error)
    }
    __pyx_t_6 = PyFloat_FromDouble((1.0 / ((double)__pyx_t_12))); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 471, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_3 = NULL;
    __pyx_t_8 = 0;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_10))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_10);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_10);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_10, function);
        __pyx_t_8 = 1;
      }
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_3, __pyx_t_6};
      __pyx_t_7 = __Pyx_PyObject_FastCall(__pyx_t_10, __pyx_callargs+1-__pyx_t_8, 1+__pyx_t_8);
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 471, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    }
    __pyx_t_12 = __pyx_PyFloat_AsDouble(__pyx_t_7); if (unlikely((__pyx_t_12 == (double)-1) && PyErr_Occurred())) __PYX_ERR(1, 471, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_v_scalingTerm = __pyx_t_12;
  }
  __pyx_L31:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":472
 *     else:
 *         scalingTerm = np.sqrt(1 / <double>chiArr.shape[0])
 *     scalingTerm *= beta_             # <<<<<<<<<<<<<<
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \
 */
  __pyx_v_scalingTerm = (__pyx_v_scalingTerm * __pyx_v_beta_);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":474
 *     scalingTerm *= beta_
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         errCode = convArcCosFeatureGen[float](<int8_t*>addr_radem, <float*>addr_reshapedX,
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 474, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_1 = (__Pyx_PyUnicode_Equals(__pyx_t_7, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 474, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (__pyx_t_1) {
  } else {
    __pyx_t_2 = __pyx_t_1;
    goto __pyx_L33_bool_binop_done;
  }
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_dtype); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 474, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_1 = (__Pyx_PyUnicode_Equals(__pyx_t_7, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 474, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (__pyx_t_1) {
  } else {
    __pyx_t_2 = __pyx_t_1;
    goto __pyx_L33_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":475
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \
 *             chiArr.dtype == "float32":             # <<<<<<<<<<<<<<
 *         errCode = convArcCosFeatureGen[float](<int8_t*>addr_radem, <float*>addr_reshapedX,
 *             <float*>addr_featureArray, <float*>addr_chi, <double*>addr_output,
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_dtype); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 475, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_1 = (__Pyx_PyUnicode_Equals(__pyx_t_7, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 475, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_2 = __pyx_t_1;
  __pyx_L33_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":474
 *     scalingTerm *= beta_
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         errCode = convArcCosFeatureGen[float](<int8_t*>addr_radem, <float*>addr_reshapedX,
 */
  if (__pyx_t_2) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":478
 *         errCode = convArcCosFeatureGen[float](<int8_t*>addr_radem, <float*>addr_reshapedX,
 *             <float*>addr_featureArray, <float*>addr_chi, <double*>addr_output,
 *             reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2],             # <<<<<<<<<<<<<<
 *             chiArr.shape[0], radem.shape[2], scalingTerm, kernelOrder)
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 478, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_7, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 478, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_8 = __Pyx_PyInt_As_int(__pyx_t_10); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 478, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 478, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_10, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 478, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_13 = __Pyx_PyInt_As_int(__pyx_t_7); if (unlikely((__pyx_t_13 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 478, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 478, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_7, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 478, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_14 = __Pyx_PyInt_As_int(__pyx_t_10); if (unlikely((__pyx_t_14 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 478, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":479
 *             <float*>addr_featureArray, <float*>addr_chi, <double*>addr_output,
 *             reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2],
 *             chiArr.shape[0], radem.shape[2], scalingTerm, kernelOrder)             # <<<<<<<<<<<<<<
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 *             chiArr.dtype == "float64":
 */
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 479, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_10, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 479, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_15 = __Pyx_PyInt_As_int(__pyx_t_7); if (unlikely((__pyx_t_15 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 479, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 479, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_7, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 479, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_16 = __Pyx_PyInt_As_int(__pyx_t_10); if (unlikely((__pyx_t_16 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 479, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":476
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \
 *             chiArr.dtype == "float32":
 *         errCode = convArcCosFeatureGen[float](<int8_t*>addr_radem, <float*>addr_reshapedX,             # <<<<<<<<<<<<<<
 *             <float*>addr_featureArray, <float*>addr_chi, <double*>addr_output,
 *             reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2],
 */
    __pyx_v_errCode = convArcCosFeatureGen<float>(((int8_t *)__pyx_v_addr_radem), ((float *)__pyx_v_addr_reshapedX), ((float *)__pyx_v_addr_featureArray), ((float *)__pyx_v_addr_chi), ((double *)__pyx_v_addr_output), __pyx_t_8, __pyx_t_13, __pyx_t_14, __pyx_t_15, __pyx_t_16, __pyx_v_scalingTerm, __pyx_v_kernelOrder);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":474
 *     scalingTerm *= beta_
 * 
 *     if outputArray.dtype == "float64" and reshapedX.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         errCode = convArcCosFeatureGen[float](<int8_t*>addr_radem, <float*>addr_reshapedX,
 */
    goto __pyx_L32;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":480
 *             reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2],
 *             chiArr.shape[0], radem.shape[2], scalingTerm, kernelOrder)
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         errCode = convArcCosFeatureGen[double](<int8_t*>addr_radem, <double*>addr_reshapedX,
 */
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 480, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_1 = (__Pyx_PyUnicode_Equals(__pyx_t_10, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 480, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  if (__pyx_t_1) {
  } else {
    __pyx_t_2 = __pyx_t_1;
    goto __pyx_L36_bool_binop_done;
  }
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_dtype); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 480, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_1 = (__Pyx_PyUnicode_Equals(__pyx_t_10, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 480, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  if (__pyx_t_1) {
  } else {
    __pyx_t_2 = __pyx_t_1;
    goto __pyx_L36_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":481
 *             chiArr.shape[0], radem.shape[2], scalingTerm, kernelOrder)
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 *             chiArr.dtype == "float64":             # <<<<<<<<<<<<<<
 *         errCode = convArcCosFeatureGen[double](<int8_t*>addr_radem, <double*>addr_reshapedX,
 *             <double*>addr_featureArray, <double*>addr_chi, <double*>addr_output,
 */
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_dtype); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 481, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_1 = (__Pyx_PyUnicode_Equals(__pyx_t_10, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(1, 481, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_t_2 = __pyx_t_1;
  __pyx_L36_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":480
 *             reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2],
 *             chiArr.shape[0], radem.shape[2], scalingTerm, kernelOrder)
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         errCode = convArcCosFeatureGen[double](<int8_t*>addr_radem, <double*>addr_reshapedX,
 */
  if (likely(__pyx_t_2)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":484
 *         errCode = convArcCosFeatureGen[double](<int8_t*>addr_radem, <double*>addr_reshapedX,
 *             <double*>addr_featureArray, <double*>addr_chi, <double*>addr_output,
 *             reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2],             # <<<<<<<<<<<<<<
 *             chiArr.shape[0], radem.shape[2], scalingTerm, kernelOrder)
 *     else:
 */
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 484, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_10, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 484, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_16 = __Pyx_PyInt_As_int(__pyx_t_7); if (unlikely((__pyx_t_16 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 484, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 484, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_7, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 484, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_15 = __Pyx_PyInt_As_int(__pyx_t_10); if (unlikely((__pyx_t_15 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 484, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 484, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_10, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 484, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_14 = __Pyx_PyInt_As_int(__pyx_t_7); if (unlikely((__pyx_t_14 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 484, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":485
 *             <double*>addr_featureArray, <double*>addr_chi, <double*>addr_output,
 *             reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2],
 *             chiArr.shape[0], radem.shape[2], scalingTerm, kernelOrder)             # <<<<<<<<<<<<<<
 *     else:
 *         raise ValueError("Incorrect data types supplied.")
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 485, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_10 = __Pyx_GetItemInt(__pyx_t_7, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 485, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_13 = __Pyx_PyInt_As_int(__pyx_t_10); if (unlikely((__pyx_t_13 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 485, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 485, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_10, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 485, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_8 = __Pyx_PyInt_As_int(__pyx_t_7); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 485, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":482
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 *             chiArr.dtype == "float64":
 *         errCode = convArcCosFeatureGen[double](<int8_t*>addr_radem, <double*>addr_reshapedX,             # <<<<<<<<<<<<<<
 *             <double*>addr_featureArray, <double*>addr_chi, <double*>addr_output,
 *             reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2],
 */
    __pyx_v_errCode = convArcCosFeatureGen<double>(((int8_t *)__pyx_v_addr_radem), ((double *)__pyx_v_addr_reshapedX), ((double *)__pyx_v_addr_featureArray), ((double *)__pyx_v_addr_chi), ((double *)__pyx_v_addr_output), __pyx_t_16, __pyx_t_15, __pyx_t_14, __pyx_t_13, __pyx_t_8, __pyx_v_scalingTerm, __pyx_v_kernelOrder);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":480
 *             reshapedX.shape[0], reshapedX.shape[1], reshapedX.shape[2],
 *             chiArr.shape[0], radem.shape[2], scalingTerm, kernelOrder)
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         errCode = convArcCosFeatureGen[double](<int8_t*>addr_radem, <double*>addr_reshapedX,
 */
    goto __pyx_L32;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":487
 *             chiArr.shape[0], radem.shape[2], scalingTerm, kernelOrder)
 *     else:
 *         raise ValueError("Incorrect data types supplied.")             # <<<<<<<<<<<<<<
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")
 */
  /*else*/ {
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__36, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 487, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_Raise(__pyx_t_7, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __PYX_ERR(1, 487, __pyx_L1_error)
  }
  __pyx_L32:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":488
 *     else:
 *         raise ValueError("Incorrect data types supplied.")
 *     if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")
 * 
 */
  __pyx_t_4 = __Pyx_ssize_strlen(__pyx_v_errCode); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(1, 488, __pyx_L1_error)
  __pyx_t_7 = __Pyx_decode_c_string(__pyx_v_errCode, 0, __pyx_t_4, NULL, NULL, PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 488, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_2 = (__Pyx_PyUnicode_Equals(__pyx_t_7, __pyx_n_u_no_error, Py_NE)); if (unlikely((__pyx_t_2 < 0))) __PYX_ERR(1, 488, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (unlikely(__pyx_t_2)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":489
 *         raise ValueError("Incorrect data types supplied.")
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")             # <<<<<<<<<<<<<<
 * 
 *     if fitIntercept:
 */
    __pyx_t_7 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__37, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 489, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_Raise(__pyx_t_7, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __PYX_ERR(1, 489, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":488
 *     else:
 *         raise ValueError("Incorrect data types supplied.")
 *     if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":491
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")
 * 
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         outputArray[:,0] = beta_
 */
  __pyx_t_2 = (__pyx_v_fitIntercept != 0);
  if (__pyx_t_2) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":492
 * 
 *     if fitIntercept:
 *         outputArray[:,0] = beta_             # <<<<<<<<<<<<<<
 */
    __pyx_t_7 = PyFloat_FromDouble(__pyx_v_beta_); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 492, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    if (unlikely((PyObject_SetItem(__pyx_v_outputArray, __pyx_tuple__38, __pyx_t_7) < 0))) __PYX_ERR(1, 492, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":491
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")
 * 
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         outputArray[:,0] = beta_
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":386
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuConv1dArcCosFGen(reshapedX, radem, outputArray, chiArr,
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("cuda_rf_gen_module.gpuConv1dArcCosFGen", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_logdim);
  __Pyx_XDECREF(__pyx_v_featureArray);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":35
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuGraphPolyFHT(reshapedX, radem, chiArr, outputArray, int polydegree,
 */

/* Python wrapper */
static PyObject *__pyx_pw_18cuda_rf_gen_module_13gpuGraphPolyFHT(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_18cuda_rf_gen_module_12gpuGraphPolyFHT, "Uses the wrapped PolyFHT_ and numpy operations to apply a pairwise\n    polynomial kernel for graphs to float32 arrays.\n\n    Args:\n        reshapedX (cp.ndarray): Raw data reshaped so that the random features\n            transformation can be applied. This array is not modified in place --\n            rather the features that are generated are stored in outputArray. Shape is (N x D x C)\n            for N datapoints. C must be a power of 2.\n        radem (cp.ndarray): A stack of diagonal matrices with elements drawn from the\n            Rademacher distribution. Shape must be (polydegree x 1 x C).\n        chiArr (np.ndarray): A stack of diagonal matrices stored as an\n            array of shape (polydegree, m * C) drawn from a chi distribution.\n        outputArray (cp.ndarray): An array in which the generated features will be\n            stored. Is modified in-place.\n        polydegree (int): The degree of the polynomial kernel that we approximate. Should\n            be <= 4 (for very high-degree polynomial kernels we are probably better off\n            switching to an RBF or convolution kernel).\n        num_threads (int): Number of threads to use for FHT. Not used for gpu,\n            merely kept here for consistency with CPU version.\n\n    Raises:\n        ValueError: A ValueError is raised if unexpected or invalid inputs are supplied.\n    ");
static PyMethodDef __pyx_mdef_18cuda_rf_gen_module_13gpuGraphPolyFHT = {"gpuGraphPolyFHT", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_18cuda_rf_gen_module_13gpuGraphPolyFHT, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_18cuda_rf_gen_module_12gpuGraphPolyFHT};
static PyObject *__pyx_pw_18cuda_rf_gen_module_13gpuGraphPolyFHT(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_reshapedX = 0;
  PyObject *__pyx_v_radem = 0;
  PyObject *__pyx_v_chiArr = 0;
  PyObject *__pyx_v_outputArray = 0;
  int __pyx_v_polydegree;
  CYTHON_UNUSED int __pyx_v_numThreads;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[6] = {0,0,0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("gpuGraphPolyFHT (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_MACROS
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject **__pyx_pyargnames[] = {&__pyx_n_s_reshapedX,&__pyx_n_s_radem,&__pyx_n_s_chiArr,&__pyx_n_s_outputArray,&__pyx_n_s_polydegree,&__pyx_n_s_numThreads,0};
    if (__pyx_kwds) {
      Py_ssize_t kw_args;
      switch (__pyx_nargs) {
        case  6: values[5] = __Pyx_Arg_FASTCALL(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = __Pyx_NumKwargs_FASTCALL(__pyx_kwds);
      switch (__pyx_nargs) {
        case  0:
        if (likely((values[0] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_reshapedX)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[0]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(3, 35, __pyx_L3_error)
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_radem)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[1]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(3, 35, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuGraphPolyFHT", 1, 6, 6, 1); __PYX_ERR(3, 35, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_chiArr)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[2]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(3, 35, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuGraphPolyFHT", 1, 6, 6, 2); __PYX_ERR(3, 35, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_outputArray)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[3]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(3, 35, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuGraphPolyFHT", 1, 6, 6, 3); __PYX_ERR(3, 35, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_polydegree)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[4]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(3, 35, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuGraphPolyFHT", 1, 6, 6, 4); __PYX_ERR(3, 35, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_numThreads)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[5]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(3, 35, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuGraphPolyFHT", 1, 6, 6, 5); __PYX_ERR(3, 35, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        const Py_ssize_t kwd_pos_args = __pyx_nargs;
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "gpuGraphPolyFHT") < 0)) __PYX_ERR(3, 35, __pyx_L3_error)
      }
    } else if (unlikely(__pyx_nargs != 6)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
      values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
      values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
      values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
      values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
      values[5] = __Pyx_Arg_FASTCALL(__pyx_args, 5);
    }
    __pyx_v_reshapedX = values[0];
    __pyx_v_radem = values[1];
    __pyx_v_chiArr = values[2];
    __pyx_v_outputArray = values[3];
    __pyx_v_polydegree = __Pyx_PyInt_As_int(values[4]); if (unlikely((__pyx_v_polydegree == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 37, __pyx_L3_error)
    __pyx_v_numThreads = __Pyx_PyInt_As_int(values[5]); if (unlikely((__pyx_v_numThreads == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 38, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("gpuGraphPolyFHT", 1, 6, 6, __pyx_nargs); __PYX_ERR(3, 35, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_AddTraceback("cuda_rf_gen_module.gpuGraphPolyFHT", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_18cuda_rf_gen_module_12gpuGraphPolyFHT(__pyx_self, __pyx_v_reshapedX, __pyx_v_radem, __pyx_v_chiArr, __pyx_v_outputArray, __pyx_v_polydegree, __pyx_v_numThreads);

  /* function exit code */
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_18cuda_rf_gen_module_12gpuGraphPolyFHT(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_reshapedX, PyObject *__pyx_v_radem, PyObject *__pyx_v_chiArr, PyObject *__pyx_v_outputArray, int __pyx_v_polydegree, CYTHON_UNUSED int __pyx_v_numThreads) {
  char const *__pyx_v_errCode;
  PyObject *__pyx_v_reshapedXCopy = NULL;
  PyObject *__pyx_v_preSumFeats = NULL;
  int __pyx_v_num_repeats;
  int __pyx_v_startPosition;
  int __pyx_v_cutoff;
  int __pyx_v_i;
  int __pyx_v_j;
  PyObject *__pyx_v_logdim = NULL;
  uintptr_t __pyx_v_addr_reshapedCopy;
  uintptr_t __pyx_v_addr_preSumFeats;
  uintptr_t __pyx_v_addr_radem;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  Py_ssize_t __pyx_t_6;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_t_9;
  uintptr_t __pyx_t_10;
  int __pyx_t_11;
  int __pyx_t_12;
  int __pyx_t_13;
  int __pyx_t_14;
  int __pyx_t_15;
  int __pyx_t_16;
  int __pyx_t_17;
  int __pyx_t_18;
  int __pyx_t_19;
  int __pyx_t_20;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("gpuGraphPolyFHT", 1);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":63
 *     """
 *     cdef const char *errCode
 *     reshapedXCopy = reshapedX.copy()             # <<<<<<<<<<<<<<
 *     preSumFeats = reshapedX.copy()
 *     cdef int num_repeats = (radem.shape[2] + reshapedX.shape[2] - 1) // reshapedX.shape[2]
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_copy); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 63, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  __pyx_t_4 = 0;
  #if CYTHON_UNPACK_METHODS
  if (likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_4 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_3, NULL};
    __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+1-__pyx_t_4, 0+__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 63, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __pyx_v_reshapedXCopy = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":64
 *     cdef const char *errCode
 *     reshapedXCopy = reshapedX.copy()
 *     preSumFeats = reshapedX.copy()             # <<<<<<<<<<<<<<
 *     cdef int num_repeats = (radem.shape[2] + reshapedX.shape[2] - 1) // reshapedX.shape[2]
 *     cdef int startPosition, cutoff, i, j
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_copy); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 64, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  __pyx_t_4 = 0;
  #if CYTHON_UNPACK_METHODS
  if (likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_4 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_3, NULL};
    __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+1-__pyx_t_4, 0+__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 64, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __pyx_v_preSumFeats = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":65
 *     reshapedXCopy = reshapedX.copy()
 *     preSumFeats = reshapedX.copy()
 *     cdef int num_repeats = (radem.shape[2] + reshapedX.shape[2] - 1) // reshapedX.shape[2]             # <<<<<<<<<<<<<<
 *     cdef int startPosition, cutoff, i, j
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 65, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 65, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 65, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 65, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Add(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 65, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyInt_SubtractObjC(__pyx_t_1, __pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 65, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 65, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 65, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_FloorDivide(__pyx_t_3, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 65, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 65, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_num_repeats = __pyx_t_4;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":68
 *     cdef int startPosition, cutoff, i, j
 * 
 *     if len(chiArr.shape) != 2 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr should be a 2d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 68, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(3, 68, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__pyx_t_6 != 2);
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 68, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(3, 68, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__pyx_t_6 != 3);
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 68, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(3, 68, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__pyx_t_6 != 3);
  __pyx_t_5 = __pyx_t_7;
  __pyx_L4_bool_binop_done:;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":69
 * 
 *     if len(chiArr.shape) != 2 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 *         raise ValueError("chiArr should be a 2d array. radem and reshapedX should be 3d arrays.")             # <<<<<<<<<<<<<<
 *     if len(outputArray.shape) != 2:
 *         raise ValueError("outputArray should be a 2d array.")
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__40, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 69, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(3, 69, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":68
 *     cdef int startPosition, cutoff, i, j
 * 
 *     if len(chiArr.shape) != 2 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr should be a 2d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":70
 *     if len(chiArr.shape) != 2 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 *         raise ValueError("chiArr should be a 2d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("outputArray should be a 2d array.")
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 70, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(3, 70, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = (__pyx_t_6 != 2);
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":71
 *         raise ValueError("chiArr should be a 2d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:
 *         raise ValueError("outputArray should be a 2d array.")             # <<<<<<<<<<<<<<
 * 
 *     if reshapedX.shape[0] == 0:
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__32, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 71, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(3, 71, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":70
 *     if len(chiArr.shape) != 2 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 *         raise ValueError("chiArr should be a 2d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("outputArray should be a 2d array.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":73
 *         raise ValueError("outputArray should be a 2d array.")
 * 
 *     if reshapedX.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 73, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 73, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = (__Pyx_PyInt_BoolEqObjC(__pyx_t_2, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(3, 73, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":74
 * 
 *     if reshapedX.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")             # <<<<<<<<<<<<<<
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 74, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(3, 74, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":73
 *         raise ValueError("outputArray should be a 2d array.")
 * 
 *     if reshapedX.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":75
 *     if reshapedX.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 75, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 75, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 75, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 75, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_1, __pyx_t_3, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 75, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(3, 75, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":76
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "             # <<<<<<<<<<<<<<
 *                 "not agree.")
 *     if radem.shape[0] != 3 * polydegree or radem.shape[1] != 1:
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__33, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 76, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(3, 76, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":75
 *     if reshapedX.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":78
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 *     if radem.shape[0] != 3 * polydegree or radem.shape[1] != 1:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must have length polydegree for dim 0 and length 1 for dim1.")
 *     if outputArray.shape[1] != radem.shape[2]:
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 78, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 78, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyInt_From_long((3 * __pyx_v_polydegree)); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 78, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = PyObject_RichCompare(__pyx_t_3, __pyx_t_2, Py_NE); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 78, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 78, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L11_bool_binop_done;
  }
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 78, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 78, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__Pyx_PyInt_BoolNeObjC(__pyx_t_2, __pyx_int_1, 1, 0)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 78, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __pyx_t_7;
  __pyx_L11_bool_binop_done:;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":79
 *                 "not agree.")
 *     if radem.shape[0] != 3 * polydegree or radem.shape[1] != 1:
 *         raise ValueError("radem must have length polydegree for dim 0 and length 1 for dim1.")             # <<<<<<<<<<<<<<
 *     if outputArray.shape[1] != radem.shape[2]:
 *         raise ValueError("outputArray.shape[1] must be radem.shape[2], which must be an integer multiple of "
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__41, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 79, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(3, 79, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":78
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 *     if radem.shape[0] != 3 * polydegree or radem.shape[1] != 1:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must have length polydegree for dim 0 and length 1 for dim1.")
 *     if outputArray.shape[1] != radem.shape[2]:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":80
 *     if radem.shape[0] != 3 * polydegree or radem.shape[1] != 1:
 *         raise ValueError("radem must have length polydegree for dim 0 and length 1 for dim1.")
 *     if outputArray.shape[1] != radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("outputArray.shape[1] must be radem.shape[2], which must be an integer multiple of "
 *                     "the next power of 2 greater than the kernel width * X.shape[2].")
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 80, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 80, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 80, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 80, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_1, __pyx_t_3, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 80, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(3, 80, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":81
 *         raise ValueError("radem must have length polydegree for dim 0 and length 1 for dim1.")
 *     if outputArray.shape[1] != radem.shape[2]:
 *         raise ValueError("outputArray.shape[1] must be radem.shape[2], which must be an integer multiple of "             # <<<<<<<<<<<<<<
 *                     "the next power of 2 greater than the kernel width * X.shape[2].")
 * 
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__42, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 81, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(3, 81, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":80
 *     if radem.shape[0] != 3 * polydegree or radem.shape[1] != 1:
 *         raise ValueError("radem must have length polydegree for dim 0 and length 1 for dim1.")
 *     if outputArray.shape[1] != radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("outputArray.shape[1] must be radem.shape[2], which must be an integer multiple of "
 *                     "the next power of 2 greater than the kernel width * X.shape[2].")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":84
 *                     "the next power of 2 greater than the kernel width * X.shape[2].")
 * 
 *     if chiArr.shape[1] != radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr.shape[1] must == radem.shape[2].")
 *     if chiArr.shape[0] != polydegree:
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 84, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 84, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 84, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 84, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_3, __pyx_t_1, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 84, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(3, 84, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":85
 * 
 *     if chiArr.shape[1] != radem.shape[2]:
 *         raise ValueError("chiArr.shape[1] must == radem.shape[2].")             # <<<<<<<<<<<<<<
 *     if chiArr.shape[0] != polydegree:
 *         raise ValueError("chiArr.shape[0] must == polydegree.")
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__43, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 85, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(3, 85, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":84
 *                     "the next power of 2 greater than the kernel width * X.shape[2].")
 * 
 *     if chiArr.shape[1] != radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr.shape[1] must == radem.shape[2].")
 *     if chiArr.shape[0] != polydegree:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":86
 *     if chiArr.shape[1] != radem.shape[2]:
 *         raise ValueError("chiArr.shape[1] must == radem.shape[2].")
 *     if chiArr.shape[0] != polydegree:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr.shape[0] must == polydegree.")
 *     logdim = np.log2(reshapedX.shape[2])
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 86, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 86, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_polydegree); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 86, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_1, __pyx_t_2, Py_NE); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 86, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(3, 86, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":87
 *         raise ValueError("chiArr.shape[1] must == radem.shape[2].")
 *     if chiArr.shape[0] != polydegree:
 *         raise ValueError("chiArr.shape[0] must == polydegree.")             # <<<<<<<<<<<<<<
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__44, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 87, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(3, 87, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":86
 *     if chiArr.shape[1] != radem.shape[2]:
 *         raise ValueError("chiArr.shape[1] must == radem.shape[2].")
 *     if chiArr.shape[0] != polydegree:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr.shape[0] must == polydegree.")
 *     logdim = np.log2(reshapedX.shape[2])
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":88
 *     if chiArr.shape[0] != polydegree:
 *         raise ValueError("chiArr.shape[0] must == polydegree.")
 *     logdim = np.log2(reshapedX.shape[2])             # <<<<<<<<<<<<<<
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_np); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 88, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_log2); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 88, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 88, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 88, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
      __pyx_t_4 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_t_8};
    __pyx_t_3 = __Pyx_PyObject_FastCall(__pyx_t_1, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 88, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __pyx_v_logdim = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":89
 *         raise ValueError("chiArr.shape[0] must == polydegree.")
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 89, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ceil); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 89, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  __pyx_t_4 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_8))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_8);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_8, function);
      __pyx_t_4 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_1, __pyx_v_logdim};
    __pyx_t_3 = __Pyx_PyObject_FastCall(__pyx_t_8, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 89, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  }
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 89, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_floor); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 89, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  __pyx_t_4 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_4 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_1, __pyx_v_logdim};
    __pyx_t_8 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 89, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_3, __pyx_t_8, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 89, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 89, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L17_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 89, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 89, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_8, __pyx_int_2, Py_LT); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 89, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 89, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __pyx_t_7;
  __pyx_L17_bool_binop_done:;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":90
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")             # <<<<<<<<<<<<<<
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__26, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 90, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(3, 90, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":89
 *         raise ValueError("chiArr.shape[0] must == polydegree.")
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":91
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "
 *                 "reshapedX.shape[2].")
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 91, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 91, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 91, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 91, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyNumber_Remainder(__pyx_t_8, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 91, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_5 = (__Pyx_PyInt_BoolEqObjC(__pyx_t_2, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(3, 91, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_7 = (!__pyx_t_5);
  if (unlikely(__pyx_t_7)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":92
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "             # <<<<<<<<<<<<<<
 *                 "reshapedX.shape[2].")
 * 
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__27, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 92, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(3, 92, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":91
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "
 *                 "reshapedX.shape[2].")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":95
 *                 "reshapedX.shape[2].")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_flags); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_Dict_GetItem(__pyx_t_2, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(3, 95, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_9 = (!__pyx_t_5);
  if (!__pyx_t_9) {
  } else {
    __pyx_t_7 = __pyx_t_9;
    goto __pyx_L21_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_flags); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_PyObject_Dict_GetItem(__pyx_t_3, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(3, 95, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (!__pyx_t_9);
  if (!__pyx_t_5) {
  } else {
    __pyx_t_7 = __pyx_t_5;
    goto __pyx_L21_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":96
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 *         or not chiArr.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_flags); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":95
 *                 "reshapedX.shape[2].")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  __pyx_t_3 = __Pyx_PyObject_Dict_GetItem(__pyx_t_2, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(3, 95, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_9 = (!__pyx_t_5);
  if (!__pyx_t_9) {
  } else {
    __pyx_t_7 = __pyx_t_9;
    goto __pyx_L21_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":96
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 *         or not chiArr.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_flags); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 96, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_PyObject_Dict_GetItem(__pyx_t_3, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 96, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(3, 96, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (!__pyx_t_9);
  __pyx_t_7 = __pyx_t_5;
  __pyx_L21_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":95
 *                 "reshapedX.shape[2].")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  if (unlikely(__pyx_t_7)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":97
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")             # <<<<<<<<<<<<<<
 * 
 *     if not radem.dtype == "int8":
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__28, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 97, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(3, 97, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":95
 *                 "reshapedX.shape[2].")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":99
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 *     if not radem.dtype == "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be int8.")
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_dtype); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 99, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_2, __pyx_n_u_int8, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 99, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (!__pyx_t_7);
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":100
 * 
 *     if not radem.dtype == "int8":
 *         raise ValueError("radem must be int8.")             # <<<<<<<<<<<<<<
 * 
 *     cdef uintptr_t addr_reshapedCopy = reshapedXCopy.data.ptr
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__22, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 100, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(3, 100, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":99
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 *     if not radem.dtype == "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be int8.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":102
 *         raise ValueError("radem must be int8.")
 * 
 *     cdef uintptr_t addr_reshapedCopy = reshapedXCopy.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_preSumFeats = preSumFeats.data.ptr
 *     cdef uintptr_t addr_radem = radem.data.ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedXCopy, __pyx_n_s_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 102, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 102, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_10 = __Pyx_PyInt_As_size_t(__pyx_t_3); if (unlikely((__pyx_t_10 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(3, 102, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_addr_reshapedCopy = __pyx_t_10;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":103
 * 
 *     cdef uintptr_t addr_reshapedCopy = reshapedXCopy.data.ptr
 *     cdef uintptr_t addr_preSumFeats = preSumFeats.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_radem = radem.data.ptr
 * 
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_preSumFeats, __pyx_n_s_data); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 103, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 103, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_10 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_10 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(3, 103, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_addr_preSumFeats = __pyx_t_10;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":104
 *     cdef uintptr_t addr_reshapedCopy = reshapedXCopy.data.ptr
 *     cdef uintptr_t addr_preSumFeats = preSumFeats.data.ptr
 *     cdef uintptr_t addr_radem = radem.data.ptr             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 104, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 104, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_10 = __Pyx_PyInt_As_size_t(__pyx_t_3); if (unlikely((__pyx_t_10 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(3, 104, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_addr_radem = __pyx_t_10;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":107
 * 
 * 
 *     startPosition, cutoff = 0, reshapedX.shape[2]             # <<<<<<<<<<<<<<
 * 
 *     if outputArray.dtype == "float32" and reshapedX.dtype == "float32" and \
 */
  __pyx_t_4 = 0;
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 107, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 107, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_11 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_11 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 107, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_startPosition = __pyx_t_4;
  __pyx_v_cutoff = __pyx_t_11;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":109
 *     startPosition, cutoff = 0, reshapedX.shape[2]
 * 
 *     if outputArray.dtype == "float32" and reshapedX.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         for i in range(num_repeats):
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 109, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_2, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 109, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L27_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_dtype); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 109, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_2, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 109, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L27_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":110
 * 
 *     if outputArray.dtype == "float32" and reshapedX.dtype == "float32" and \
 *             chiArr.dtype == "float32":             # <<<<<<<<<<<<<<
 *         for i in range(num_repeats):
 *             preSumFeats[:] = reshapedX
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_dtype); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 110, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_2, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 110, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __pyx_t_7;
  __pyx_L27_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":109
 *     startPosition, cutoff = 0, reshapedX.shape[2]
 * 
 *     if outputArray.dtype == "float32" and reshapedX.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         for i in range(num_repeats):
 */
  if (__pyx_t_5) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":111
 *     if outputArray.dtype == "float32" and reshapedX.dtype == "float32" and \
 *             chiArr.dtype == "float32":
 *         for i in range(num_repeats):             # <<<<<<<<<<<<<<
 *             preSumFeats[:] = reshapedX
 *             errCode = conv1dPrep[float](<int8_t*>addr_radem,
 */
    __pyx_t_11 = __pyx_v_num_repeats;
    __pyx_t_4 = __pyx_t_11;
    for (__pyx_t_12 = 0; __pyx_t_12 < __pyx_t_4; __pyx_t_12+=1) {
      __pyx_v_i = __pyx_t_12;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":112
 *             chiArr.dtype == "float32":
 *         for i in range(num_repeats):
 *             preSumFeats[:] = reshapedX             # <<<<<<<<<<<<<<
 *             errCode = conv1dPrep[float](<int8_t*>addr_radem,
 *                     <float*>addr_preSumFeats, reshapedX.shape[0], reshapedX.shape[1],
 */
      if (__Pyx_PyObject_SetSlice(__pyx_v_preSumFeats, __pyx_v_reshapedX, 0, 0, NULL, NULL, &__pyx_slice__17, 0, 0, 0) < 0) __PYX_ERR(3, 112, __pyx_L1_error)

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":114
 *             preSumFeats[:] = reshapedX
 *             errCode = conv1dPrep[float](<int8_t*>addr_radem,
 *                     <float*>addr_preSumFeats, reshapedX.shape[0], reshapedX.shape[1],             # <<<<<<<<<<<<<<
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 *                     radem.shape[2])
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 114, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 114, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_13 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_13 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 114, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 114, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 114, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_14 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_14 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 114, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":115
 *             errCode = conv1dPrep[float](<int8_t*>addr_radem,
 *                     <float*>addr_preSumFeats, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], i * reshapedX.shape[2],             # <<<<<<<<<<<<<<
 *                     radem.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 115, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 115, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_15 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_15 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 115, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_i); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 115, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 115, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 115, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyNumber_Multiply(__pyx_t_3, __pyx_t_8); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 115, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_16 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_16 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 115, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":116
 *                     <float*>addr_preSumFeats, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 *                     radem.shape[2])             # <<<<<<<<<<<<<<
 *             if errCode.decode("UTF-8") != "no_error":
 *                 raise Exception("Fatal error encountered while performing FHT RF generation.")
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 116, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 116, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_17 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_17 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 116, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":113
 *         for i in range(num_repeats):
 *             preSumFeats[:] = reshapedX
 *             errCode = conv1dPrep[float](<int8_t*>addr_radem,             # <<<<<<<<<<<<<<
 *                     <float*>addr_preSumFeats, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 */
      __pyx_v_errCode = conv1dPrep<float>(((int8_t *)__pyx_v_addr_radem), ((float *)__pyx_v_addr_preSumFeats), __pyx_t_13, __pyx_t_14, __pyx_t_15, __pyx_t_16, __pyx_t_17);

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":117
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 *                     radem.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *                 raise Exception("Fatal error encountered while performing FHT RF generation.")
 *             preSumFeats *= chiArr[0:1, None, startPosition:cutoff]
 */
      __pyx_t_6 = __Pyx_ssize_strlen(__pyx_v_errCode); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(3, 117, __pyx_L1_error)
      __pyx_t_8 = __Pyx_decode_c_string(__pyx_v_errCode, 0, __pyx_t_6, NULL, NULL, PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 117, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_5 = (__Pyx_PyUnicode_Equals(__pyx_t_8, __pyx_n_u_no_error, Py_NE)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(3, 117, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      if (unlikely(__pyx_t_5)) {

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":118
 *                     radem.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":
 *                 raise Exception("Fatal error encountered while performing FHT RF generation.")             # <<<<<<<<<<<<<<
 *             preSumFeats *= chiArr[0:1, None, startPosition:cutoff]
 * 
 */
        __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__37, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 118, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_Raise(__pyx_t_8, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __PYX_ERR(3, 118, __pyx_L1_error)

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":117
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 *                     radem.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *                 raise Exception("Fatal error encountered while performing FHT RF generation.")
 *             preSumFeats *= chiArr[0:1, None, startPosition:cutoff]
 */
      }

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":119
 *             if errCode.decode("UTF-8") != "no_error":
 *                 raise Exception("Fatal error encountered while performing FHT RF generation.")
 *             preSumFeats *= chiArr[0:1, None, startPosition:cutoff]             # <<<<<<<<<<<<<<
 * 
 *             for j in range(1, polydegree):
 */
      __pyx_t_8 = __Pyx_PyInt_From_int(__pyx_v_startPosition); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 119, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_cutoff); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 119, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = PySlice_New(__pyx_t_8, __pyx_t_2, Py_None); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 119, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyTuple_New(3); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 119, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_INCREF(__pyx_slice__45);
      __Pyx_GIVEREF(__pyx_slice__45);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_slice__45)) __PYX_ERR(3, 119, __pyx_L1_error);
      __Pyx_INCREF(Py_None);
      __Pyx_GIVEREF(Py_None);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_2, 1, Py_None)) __PYX_ERR(3, 119, __pyx_L1_error);
      __Pyx_GIVEREF(__pyx_t_3);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_2, 2, __pyx_t_3)) __PYX_ERR(3, 119, __pyx_L1_error);
      __pyx_t_3 = 0;
      __pyx_t_3 = __Pyx_PyObject_GetItem(__pyx_v_chiArr, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 119, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyNumber_InPlaceMultiply(__pyx_v_preSumFeats, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 119, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF_SET(__pyx_v_preSumFeats, __pyx_t_2);
      __pyx_t_2 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":121
 *             preSumFeats *= chiArr[0:1, None, startPosition:cutoff]
 * 
 *             for j in range(1, polydegree):             # <<<<<<<<<<<<<<
 *                 reshapedXCopy[:] = reshapedX
 *                 errCode = conv1dPrep[float](<int8_t*>addr_radem,
 */
      __pyx_t_17 = __pyx_v_polydegree;
      __pyx_t_16 = __pyx_t_17;
      for (__pyx_t_15 = 1; __pyx_t_15 < __pyx_t_16; __pyx_t_15+=1) {
        __pyx_v_j = __pyx_t_15;

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":122
 * 
 *             for j in range(1, polydegree):
 *                 reshapedXCopy[:] = reshapedX             # <<<<<<<<<<<<<<
 *                 errCode = conv1dPrep[float](<int8_t*>addr_radem,
 *                     <float*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],
 */
        if (__Pyx_PyObject_SetSlice(__pyx_v_reshapedXCopy, __pyx_v_reshapedX, 0, 0, NULL, NULL, &__pyx_slice__17, 0, 0, 0) < 0) __PYX_ERR(3, 122, __pyx_L1_error)

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":124
 *                 reshapedXCopy[:] = reshapedX
 *                 errCode = conv1dPrep[float](<int8_t*>addr_radem,
 *                     <float*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],             # <<<<<<<<<<<<<<
 *                     reshapedX.shape[2], i * reshapedX.shape[2] + (3 * j) * radem.shape[2],
 *                     radem.shape[2])
 */
        __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 124, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 124, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_14 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_14 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 124, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 124, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 124, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __pyx_t_13 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_13 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 124, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":125
 *                 errCode = conv1dPrep[float](<int8_t*>addr_radem,
 *                     <float*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], i * reshapedX.shape[2] + (3 * j) * radem.shape[2],             # <<<<<<<<<<<<<<
 *                     radem.shape[2])
 *                 reshapedXCopy *= chiArr[j:(j+1), None, startPosition:cutoff]
 */
        __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 125, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 125, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_18 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_18 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 125, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_i); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 125, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 125, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 125, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_2 = PyNumber_Multiply(__pyx_t_3, __pyx_t_8); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 125, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __pyx_t_8 = __Pyx_PyInt_From_long((3 * __pyx_v_j)); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 125, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 125, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 125, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __pyx_t_3 = PyNumber_Multiply(__pyx_t_8, __pyx_t_1); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 125, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_1 = PyNumber_Add(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 125, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __pyx_t_19 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_19 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 125, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":126
 *                     <float*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], i * reshapedX.shape[2] + (3 * j) * radem.shape[2],
 *                     radem.shape[2])             # <<<<<<<<<<<<<<
 *                 reshapedXCopy *= chiArr[j:(j+1), None, startPosition:cutoff]
 *                 preSumFeats *= reshapedXCopy
 */
        __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 126, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 126, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_20 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_20 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 126, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":123
 *             for j in range(1, polydegree):
 *                 reshapedXCopy[:] = reshapedX
 *                 errCode = conv1dPrep[float](<int8_t*>addr_radem,             # <<<<<<<<<<<<<<
 *                     <float*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], i * reshapedX.shape[2] + (3 * j) * radem.shape[2],
 */
        __pyx_v_errCode = conv1dPrep<float>(((int8_t *)__pyx_v_addr_radem), ((float *)__pyx_v_addr_reshapedCopy), __pyx_t_14, __pyx_t_13, __pyx_t_18, __pyx_t_19, __pyx_t_20);

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":127
 *                     reshapedX.shape[2], i * reshapedX.shape[2] + (3 * j) * radem.shape[2],
 *                     radem.shape[2])
 *                 reshapedXCopy *= chiArr[j:(j+1), None, startPosition:cutoff]             # <<<<<<<<<<<<<<
 *                 preSumFeats *= reshapedXCopy
 *             outputArray[:,startPosition:cutoff] = cp.sum(preSumFeats, axis=1)
 */
        __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_j); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 127, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_1 = __Pyx_PyInt_From_long((__pyx_v_j + 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 127, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_2 = PySlice_New(__pyx_t_3, __pyx_t_1, Py_None); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 127, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_startPosition); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 127, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_cutoff); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 127, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_8 = PySlice_New(__pyx_t_1, __pyx_t_3, Py_None); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 127, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 127, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_2);
        if (__Pyx_PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_2)) __PYX_ERR(3, 127, __pyx_L1_error);
        __Pyx_INCREF(Py_None);
        __Pyx_GIVEREF(Py_None);
        if (__Pyx_PyTuple_SET_ITEM(__pyx_t_3, 1, Py_None)) __PYX_ERR(3, 127, __pyx_L1_error);
        __Pyx_GIVEREF(__pyx_t_8);
        if (__Pyx_PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_t_8)) __PYX_ERR(3, 127, __pyx_L1_error);
        __pyx_t_2 = 0;
        __pyx_t_8 = 0;
        __pyx_t_8 = __Pyx_PyObject_GetItem(__pyx_v_chiArr, __pyx_t_3); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 127, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __pyx_t_3 = PyNumber_InPlaceMultiply(__pyx_v_reshapedXCopy, __pyx_t_8); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 127, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __Pyx_DECREF_SET(__pyx_v_reshapedXCopy, __pyx_t_3);
        __pyx_t_3 = 0;

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":128
 *                     radem.shape[2])
 *                 reshapedXCopy *= chiArr[j:(j+1), None, startPosition:cutoff]
 *                 preSumFeats *= reshapedXCopy             # <<<<<<<<<<<<<<
 *             outputArray[:,startPosition:cutoff] = cp.sum(preSumFeats, axis=1)
 * 
 */
        __pyx_t_3 = PyNumber_InPlaceMultiply(__pyx_v_preSumFeats, __pyx_v_reshapedXCopy); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 128, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF_SET(__pyx_v_preSumFeats, __pyx_t_3);
        __pyx_t_3 = 0;
      }

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":129
 *                 reshapedXCopy *= chiArr[j:(j+1), None, startPosition:cutoff]
 *                 preSumFeats *= reshapedXCopy
 *             outputArray[:,startPosition:cutoff] = cp.sum(preSumFeats, axis=1)             # <<<<<<<<<<<<<<
 * 
 *             cutoff += reshapedX.shape[2]
 */
      __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_cp); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 129, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_sum); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 129, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 129, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_INCREF(__pyx_v_preSumFeats);
      __Pyx_GIVEREF(__pyx_v_preSumFeats);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_preSumFeats)) __PYX_ERR(3, 129, __pyx_L1_error);
      __pyx_t_2 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 129, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_axis, __pyx_int_1) < 0) __PYX_ERR(3, 129, __pyx_L1_error)
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_t_3, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 129, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_startPosition); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 129, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_cutoff); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 129, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_8 = PySlice_New(__pyx_t_2, __pyx_t_3, Py_None); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 129, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 129, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_INCREF(__pyx_slice__17);
      __Pyx_GIVEREF(__pyx_slice__17);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_slice__17)) __PYX_ERR(3, 129, __pyx_L1_error);
      __Pyx_GIVEREF(__pyx_t_8);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_8)) __PYX_ERR(3, 129, __pyx_L1_error);
      __pyx_t_8 = 0;
      if (unlikely((PyObject_SetItem(__pyx_v_outputArray, __pyx_t_3, __pyx_t_1) < 0))) __PYX_ERR(3, 129, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":131
 *             outputArray[:,startPosition:cutoff] = cp.sum(preSumFeats, axis=1)
 * 
 *             cutoff += reshapedX.shape[2]             # <<<<<<<<<<<<<<
 *             startPosition += reshapedX.shape[2]
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 */
      __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_cutoff); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 131, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 131, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 131, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = PyNumber_InPlaceAdd(__pyx_t_1, __pyx_t_8); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 131, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_17 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_17 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 131, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_v_cutoff = __pyx_t_17;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":132
 * 
 *             cutoff += reshapedX.shape[2]
 *             startPosition += reshapedX.shape[2]             # <<<<<<<<<<<<<<
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 *             chiArr.dtype == "float64":
 */
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_startPosition); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 132, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 132, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_8, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 132, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_InPlaceAdd(__pyx_t_3, __pyx_t_1); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 132, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_17 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_17 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 132, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_v_startPosition = __pyx_t_17;
    }

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":109
 *     startPosition, cutoff = 0, reshapedX.shape[2]
 * 
 *     if outputArray.dtype == "float32" and reshapedX.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         for i in range(num_repeats):
 */
    goto __pyx_L26;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":133
 *             cutoff += reshapedX.shape[2]
 *             startPosition += reshapedX.shape[2]
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         for i in range(num_repeats):
 */
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 133, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_8, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 133, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L35_bool_binop_done;
  }
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_dtype); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 133, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_8, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 133, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L35_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":134
 *             startPosition += reshapedX.shape[2]
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 *             chiArr.dtype == "float64":             # <<<<<<<<<<<<<<
 *         for i in range(num_repeats):
 *             preSumFeats[:] = reshapedX
 */
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_dtype); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 134, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_8, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 134, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_5 = __pyx_t_7;
  __pyx_L35_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":133
 *             cutoff += reshapedX.shape[2]
 *             startPosition += reshapedX.shape[2]
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         for i in range(num_repeats):
 */
  if (likely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":135
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 *             chiArr.dtype == "float64":
 *         for i in range(num_repeats):             # <<<<<<<<<<<<<<
 *             preSumFeats[:] = reshapedX
 *             errCode = conv1dPrep[double](<int8_t*>addr_radem,
 */
    __pyx_t_11 = __pyx_v_num_repeats;
    __pyx_t_4 = __pyx_t_11;
    for (__pyx_t_12 = 0; __pyx_t_12 < __pyx_t_4; __pyx_t_12+=1) {
      __pyx_v_i = __pyx_t_12;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":136
 *             chiArr.dtype == "float64":
 *         for i in range(num_repeats):
 *             preSumFeats[:] = reshapedX             # <<<<<<<<<<<<<<
 *             errCode = conv1dPrep[double](<int8_t*>addr_radem,
 *                     <double*>addr_preSumFeats, reshapedX.shape[0], reshapedX.shape[1],
 */
      if (__Pyx_PyObject_SetSlice(__pyx_v_preSumFeats, __pyx_v_reshapedX, 0, 0, NULL, NULL, &__pyx_slice__17, 0, 0, 0) < 0) __PYX_ERR(3, 136, __pyx_L1_error)

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":138
 *             preSumFeats[:] = reshapedX
 *             errCode = conv1dPrep[double](<int8_t*>addr_radem,
 *                     <double*>addr_preSumFeats, reshapedX.shape[0], reshapedX.shape[1],             # <<<<<<<<<<<<<<
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 *                     radem.shape[2])
 */
      __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 138, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_8, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 138, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_17 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_17 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 138, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 138, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 138, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_16 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_16 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 138, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":139
 *             errCode = conv1dPrep[double](<int8_t*>addr_radem,
 *                     <double*>addr_preSumFeats, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], i * reshapedX.shape[2],             # <<<<<<<<<<<<<<
 *                     radem.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":
 */
      __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 139, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_8, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 139, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_15 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_15 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 139, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_i); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 139, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 139, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_8, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 139, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_Multiply(__pyx_t_1, __pyx_t_3); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 139, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_20 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_20 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 139, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":140
 *                     <double*>addr_preSumFeats, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 *                     radem.shape[2])             # <<<<<<<<<<<<<<
 *             if errCode.decode("UTF-8") != "no_error":
 *                 raise Exception("Fatal error encountered while performing FHT RF generation.")
 */
      __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 140, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_8, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 140, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_19 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_19 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 140, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":137
 *         for i in range(num_repeats):
 *             preSumFeats[:] = reshapedX
 *             errCode = conv1dPrep[double](<int8_t*>addr_radem,             # <<<<<<<<<<<<<<
 *                     <double*>addr_preSumFeats, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 */
      __pyx_v_errCode = conv1dPrep<double>(((int8_t *)__pyx_v_addr_radem), ((double *)__pyx_v_addr_preSumFeats), __pyx_t_17, __pyx_t_16, __pyx_t_15, __pyx_t_20, __pyx_t_19);

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":141
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 *                     radem.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *                 raise Exception("Fatal error encountered while performing FHT RF generation.")
 *             preSumFeats *= chiArr[0:1, None, startPosition:cutoff]
 */
      __pyx_t_6 = __Pyx_ssize_strlen(__pyx_v_errCode); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(3, 141, __pyx_L1_error)
      __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_errCode, 0, __pyx_t_6, NULL, NULL, PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 141, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_5 = (__Pyx_PyUnicode_Equals(__pyx_t_3, __pyx_n_u_no_error, Py_NE)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(3, 141, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (unlikely(__pyx_t_5)) {

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":142
 *                     radem.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":
 *                 raise Exception("Fatal error encountered while performing FHT RF generation.")             # <<<<<<<<<<<<<<
 *             preSumFeats *= chiArr[0:1, None, startPosition:cutoff]
 * 
 */
        __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__37, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 142, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_Raise(__pyx_t_3, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __PYX_ERR(3, 142, __pyx_L1_error)

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":141
 *                     reshapedX.shape[2], i * reshapedX.shape[2],
 *                     radem.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *                 raise Exception("Fatal error encountered while performing FHT RF generation.")
 *             preSumFeats *= chiArr[0:1, None, startPosition:cutoff]
 */
      }

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":143
 *             if errCode.decode("UTF-8") != "no_error":
 *                 raise Exception("Fatal error encountered while performing FHT RF generation.")
 *             preSumFeats *= chiArr[0:1, None, startPosition:cutoff]             # <<<<<<<<<<<<<<
 * 
 *             for j in range(1, polydegree):
 */
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_startPosition); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 143, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_8 = __Pyx_PyInt_From_int(__pyx_v_cutoff); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 143, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_1 = PySlice_New(__pyx_t_3, __pyx_t_8, Py_None); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 143, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyTuple_New(3); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 143, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_INCREF(__pyx_slice__45);
      __Pyx_GIVEREF(__pyx_slice__45);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_slice__45)) __PYX_ERR(3, 143, __pyx_L1_error);
      __Pyx_INCREF(Py_None);
      __Pyx_GIVEREF(Py_None);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_8, 1, Py_None)) __PYX_ERR(3, 143, __pyx_L1_error);
      __Pyx_GIVEREF(__pyx_t_1);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_8, 2, __pyx_t_1)) __PYX_ERR(3, 143, __pyx_L1_error);
      __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_PyObject_GetItem(__pyx_v_chiArr, __pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 143, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_InPlaceMultiply(__pyx_v_preSumFeats, __pyx_t_1); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 143, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF_SET(__pyx_v_preSumFeats, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":145
 *             preSumFeats *= chiArr[0:1, None, startPosition:cutoff]
 * 
 *             for j in range(1, polydegree):             # <<<<<<<<<<<<<<
 *                 reshapedXCopy[:] = reshapedX
 *                 errCode = conv1dPrep[double](<int8_t*>addr_radem,
 */
      __pyx_t_19 = __pyx_v_polydegree;
      __pyx_t_20 = __pyx_t_19;
      for (__pyx_t_15 = 1; __pyx_t_15 < __pyx_t_20; __pyx_t_15+=1) {
        __pyx_v_j = __pyx_t_15;

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":146
 * 
 *             for j in range(1, polydegree):
 *                 reshapedXCopy[:] = reshapedX             # <<<<<<<<<<<<<<
 *                 errCode = conv1dPrep[double](<int8_t*>addr_radem,
 *                     <double*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],
 */
        if (__Pyx_PyObject_SetSlice(__pyx_v_reshapedXCopy, __pyx_v_reshapedX, 0, 0, NULL, NULL, &__pyx_slice__17, 0, 0, 0) < 0) __PYX_ERR(3, 146, __pyx_L1_error)

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":148
 *                 reshapedXCopy[:] = reshapedX
 *                 errCode = conv1dPrep[double](<int8_t*>addr_radem,
 *                     <double*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],             # <<<<<<<<<<<<<<
 *                     reshapedX.shape[2], i * reshapedX.shape[2] + (3 * j) * radem.shape[2],
 *                     radem.shape[2])
 */
        __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 148, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_8, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 148, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __pyx_t_16 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_16 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 148, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 148, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 148, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_17 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_17 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 148, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":149
 *                 errCode = conv1dPrep[double](<int8_t*>addr_radem,
 *                     <double*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], i * reshapedX.shape[2] + (3 * j) * radem.shape[2],             # <<<<<<<<<<<<<<
 *                     radem.shape[2])
 *                 if errCode.decode("UTF-8") != "no_error":
 */
        __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 149, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_8, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 149, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __pyx_t_18 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_18 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 149, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_i); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 149, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 149, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_8, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 149, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __pyx_t_8 = PyNumber_Multiply(__pyx_t_1, __pyx_t_3); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 149, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __pyx_t_3 = __Pyx_PyInt_From_long((3 * __pyx_v_j)); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 149, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 149, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 149, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_1 = PyNumber_Multiply(__pyx_t_3, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 149, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_2 = PyNumber_Add(__pyx_t_8, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 149, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_13 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_13 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 149, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":150
 *                     <double*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], i * reshapedX.shape[2] + (3 * j) * radem.shape[2],
 *                     radem.shape[2])             # <<<<<<<<<<<<<<
 *                 if errCode.decode("UTF-8") != "no_error":
 *                     raise Exception("Fatal error encountered while performing FHT RF generation.")
 */
        __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 150, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 150, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_14 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_14 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 150, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":147
 *             for j in range(1, polydegree):
 *                 reshapedXCopy[:] = reshapedX
 *                 errCode = conv1dPrep[double](<int8_t*>addr_radem,             # <<<<<<<<<<<<<<
 *                     <double*>addr_reshapedCopy, reshapedX.shape[0], reshapedX.shape[1],
 *                     reshapedX.shape[2], i * reshapedX.shape[2] + (3 * j) * radem.shape[2],
 */
        __pyx_v_errCode = conv1dPrep<double>(((int8_t *)__pyx_v_addr_radem), ((double *)__pyx_v_addr_reshapedCopy), __pyx_t_16, __pyx_t_17, __pyx_t_18, __pyx_t_13, __pyx_t_14);

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":151
 *                     reshapedX.shape[2], i * reshapedX.shape[2] + (3 * j) * radem.shape[2],
 *                     radem.shape[2])
 *                 if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *                     raise Exception("Fatal error encountered while performing FHT RF generation.")
 *                 reshapedXCopy *= chiArr[j:(j+1), None, startPosition:cutoff]
 */
        __pyx_t_6 = __Pyx_ssize_strlen(__pyx_v_errCode); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(3, 151, __pyx_L1_error)
        __pyx_t_1 = __Pyx_decode_c_string(__pyx_v_errCode, 0, __pyx_t_6, NULL, NULL, PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 151, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_5 = (__Pyx_PyUnicode_Equals(__pyx_t_1, __pyx_n_u_no_error, Py_NE)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(3, 151, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        if (unlikely(__pyx_t_5)) {

          /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":152
 *                     radem.shape[2])
 *                 if errCode.decode("UTF-8") != "no_error":
 *                     raise Exception("Fatal error encountered while performing FHT RF generation.")             # <<<<<<<<<<<<<<
 *                 reshapedXCopy *= chiArr[j:(j+1), None, startPosition:cutoff]
 *                 preSumFeats *= reshapedXCopy
 */
          __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__37, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 152, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_Raise(__pyx_t_1, 0, 0, 0);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __PYX_ERR(3, 152, __pyx_L1_error)

          /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":151
 *                     reshapedX.shape[2], i * reshapedX.shape[2] + (3 * j) * radem.shape[2],
 *                     radem.shape[2])
 *                 if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *                     raise Exception("Fatal error encountered while performing FHT RF generation.")
 *                 reshapedXCopy *= chiArr[j:(j+1), None, startPosition:cutoff]
 */
        }

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":153
 *                 if errCode.decode("UTF-8") != "no_error":
 *                     raise Exception("Fatal error encountered while performing FHT RF generation.")
 *                 reshapedXCopy *= chiArr[j:(j+1), None, startPosition:cutoff]             # <<<<<<<<<<<<<<
 *                 preSumFeats *= reshapedXCopy
 *             outputArray[:,startPosition:cutoff] = cp.sum(preSumFeats, axis=1)
 */
        __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_j); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 153, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_2 = __Pyx_PyInt_From_long((__pyx_v_j + 1)); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 153, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_8 = PySlice_New(__pyx_t_1, __pyx_t_2, Py_None); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 153, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_startPosition); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 153, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_cutoff); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 153, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_3 = PySlice_New(__pyx_t_2, __pyx_t_1, Py_None); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 153, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 153, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_GIVEREF(__pyx_t_8);
        if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_8)) __PYX_ERR(3, 153, __pyx_L1_error);
        __Pyx_INCREF(Py_None);
        __Pyx_GIVEREF(Py_None);
        if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 1, Py_None)) __PYX_ERR(3, 153, __pyx_L1_error);
        __Pyx_GIVEREF(__pyx_t_3);
        if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_t_3)) __PYX_ERR(3, 153, __pyx_L1_error);
        __pyx_t_8 = 0;
        __pyx_t_3 = 0;
        __pyx_t_3 = __Pyx_PyObject_GetItem(__pyx_v_chiArr, __pyx_t_1); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 153, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_1 = PyNumber_InPlaceMultiply(__pyx_v_reshapedXCopy, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 153, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF_SET(__pyx_v_reshapedXCopy, __pyx_t_1);
        __pyx_t_1 = 0;

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":154
 *                     raise Exception("Fatal error encountered while performing FHT RF generation.")
 *                 reshapedXCopy *= chiArr[j:(j+1), None, startPosition:cutoff]
 *                 preSumFeats *= reshapedXCopy             # <<<<<<<<<<<<<<
 *             outputArray[:,startPosition:cutoff] = cp.sum(preSumFeats, axis=1)
 * 
 */
        __pyx_t_1 = PyNumber_InPlaceMultiply(__pyx_v_preSumFeats, __pyx_v_reshapedXCopy); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 154, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF_SET(__pyx_v_preSumFeats, __pyx_t_1);
        __pyx_t_1 = 0;
      }

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":155
 *                 reshapedXCopy *= chiArr[j:(j+1), None, startPosition:cutoff]
 *                 preSumFeats *= reshapedXCopy
 *             outputArray[:,startPosition:cutoff] = cp.sum(preSumFeats, axis=1)             # <<<<<<<<<<<<<<
 * 
 *             cutoff += reshapedX.shape[2]
 */
      __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_cp); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 155, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_sum); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 155, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 155, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_INCREF(__pyx_v_preSumFeats);
      __Pyx_GIVEREF(__pyx_v_preSumFeats);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_v_preSumFeats)) __PYX_ERR(3, 155, __pyx_L1_error);
      __pyx_t_8 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 155, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      if (PyDict_SetItem(__pyx_t_8, __pyx_n_s_axis, __pyx_int_1) < 0) __PYX_ERR(3, 155, __pyx_L1_error)
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_1, __pyx_t_8); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 155, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = __Pyx_PyInt_From_int(__pyx_v_startPosition); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 155, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_cutoff); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 155, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_3 = PySlice_New(__pyx_t_8, __pyx_t_1, Py_None); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 155, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 155, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_INCREF(__pyx_slice__17);
      __Pyx_GIVEREF(__pyx_slice__17);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_slice__17)) __PYX_ERR(3, 155, __pyx_L1_error);
      __Pyx_GIVEREF(__pyx_t_3);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_t_3)) __PYX_ERR(3, 155, __pyx_L1_error);
      __pyx_t_3 = 0;
      if (unlikely((PyObject_SetItem(__pyx_v_outputArray, __pyx_t_1, __pyx_t_2) < 0))) __PYX_ERR(3, 155, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":157
 *             outputArray[:,startPosition:cutoff] = cp.sum(preSumFeats, axis=1)
 * 
 *             cutoff += reshapedX.shape[2]             # <<<<<<<<<<<<<<
 *             startPosition += reshapedX.shape[2]
 *     else:
 */
      __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_cutoff); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 157, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 157, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 157, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = PyNumber_InPlaceAdd(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 157, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_19 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_19 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 157, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_v_cutoff = __pyx_t_19;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":158
 * 
 *             cutoff += reshapedX.shape[2]
 *             startPosition += reshapedX.shape[2]             # <<<<<<<<<<<<<<
 *     else:
 *         raise ValueError("Inconsistent array types passed to wrapped C++ function.")
 */
      __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_startPosition); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 158, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 158, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 158, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = PyNumber_InPlaceAdd(__pyx_t_1, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 158, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_19 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_19 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 158, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_v_startPosition = __pyx_t_19;
    }

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":133
 *             cutoff += reshapedX.shape[2]
 *             startPosition += reshapedX.shape[2]
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         for i in range(num_repeats):
 */
    goto __pyx_L26;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":160
 *             startPosition += reshapedX.shape[2]
 *     else:
 *         raise ValueError("Inconsistent array types passed to wrapped C++ function.")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__46, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 160, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(3, 160, __pyx_L1_error)
  }
  __pyx_L26:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":35
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuGraphPolyFHT(reshapedX, radem, chiArr, outputArray, int polydegree,
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("cuda_rf_gen_module.gpuGraphPolyFHT", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_reshapedXCopy);
  __Pyx_XDECREF(__pyx_v_preSumFeats);
  __Pyx_XDECREF(__pyx_v_logdim);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":165
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuPolyFHT(reshapedX, radem, chiArr, outputArray, int polydegree,
 */

/* Python wrapper */
static PyObject *__pyx_pw_18cuda_rf_gen_module_15gpuPolyFHT(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_18cuda_rf_gen_module_14gpuPolyFHT, "Polynomial kernel for fixed vector data to float32 arrays.\n\n    Args:\n        reshapedX (cp.ndarray): Raw data reshaped so that the random features\n            transformation can be applied. This array is not modified in place --\n            rather the features that are generated are stored in outputArray. Shape is (N x D x C)\n            for N datapoints. C must be a power of 2.\n        radem (cp.ndarray): A stack of diagonal matrices with elements drawn from the\n            Rademacher distribution. Shape must be (3 * polydegree x D x C).\n        chiArr (cp.ndarray): A stack of diagonal matrices stored as an\n            array of shape (polydegree, D, C) drawn from a chi distribution.\n        outputArray (cp.ndarray): An array in which the generated features will be\n            stored. Is modified in-place.\n        polydegree (int): The degree of the polynomial kernel that we approximate. Should\n            be <= 4 (for very high-degree polynomial kernels we are probably better off\n            switching to an RBF or convolution kernel).\n        num_threads (int): Number of threads to use for FHT. Not used for gpu,\n            merely kept here for consistency with CPU version.\n\n    Raises:\n        ValueError: A ValueError is raised if unexpected or invalid inputs are supplied.\n    ");
static PyMethodDef __pyx_mdef_18cuda_rf_gen_module_15gpuPolyFHT = {"gpuPolyFHT", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_18cuda_rf_gen_module_15gpuPolyFHT, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_18cuda_rf_gen_module_14gpuPolyFHT};
static PyObject *__pyx_pw_18cuda_rf_gen_module_15gpuPolyFHT(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_reshapedX = 0;
  PyObject *__pyx_v_radem = 0;
  PyObject *__pyx_v_chiArr = 0;
  PyObject *__pyx_v_outputArray = 0;
  int __pyx_v_polydegree;
  CYTHON_UNUSED int __pyx_v_numThreads;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[6] = {0,0,0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("gpuPolyFHT (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_MACROS
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject **__pyx_pyargnames[] = {&__pyx_n_s_reshapedX,&__pyx_n_s_radem,&__pyx_n_s_chiArr,&__pyx_n_s_outputArray,&__pyx_n_s_polydegree,&__pyx_n_s_numThreads,0};
    if (__pyx_kwds) {
      Py_ssize_t kw_args;
      switch (__pyx_nargs) {
        case  6: values[5] = __Pyx_Arg_FASTCALL(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = __Pyx_NumKwargs_FASTCALL(__pyx_kwds);
      switch (__pyx_nargs) {
        case  0:
        if (likely((values[0] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_reshapedX)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[0]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(3, 165, __pyx_L3_error)
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_radem)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[1]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(3, 165, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuPolyFHT", 1, 6, 6, 1); __PYX_ERR(3, 165, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_chiArr)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[2]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(3, 165, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuPolyFHT", 1, 6, 6, 2); __PYX_ERR(3, 165, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_outputArray)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[3]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(3, 165, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuPolyFHT", 1, 6, 6, 3); __PYX_ERR(3, 165, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_polydegree)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[4]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(3, 165, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuPolyFHT", 1, 6, 6, 4); __PYX_ERR(3, 165, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_numThreads)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[5]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(3, 165, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("gpuPolyFHT", 1, 6, 6, 5); __PYX_ERR(3, 165, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        const Py_ssize_t kwd_pos_args = __pyx_nargs;
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "gpuPolyFHT") < 0)) __PYX_ERR(3, 165, __pyx_L3_error)
      }
    } else if (unlikely(__pyx_nargs != 6)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
      values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
      values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
      values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
      values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
      values[5] = __Pyx_Arg_FASTCALL(__pyx_args, 5);
    }
    __pyx_v_reshapedX = values[0];
    __pyx_v_radem = values[1];
    __pyx_v_chiArr = values[2];
    __pyx_v_outputArray = values[3];
    __pyx_v_polydegree = __Pyx_PyInt_As_int(values[4]); if (unlikely((__pyx_v_polydegree == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 167, __pyx_L3_error)
    __pyx_v_numThreads = __Pyx_PyInt_As_int(values[5]); if (unlikely((__pyx_v_numThreads == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 168, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("gpuPolyFHT", 1, 6, 6, __pyx_nargs); __PYX_ERR(3, 165, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_AddTraceback("cuda_rf_gen_module.gpuPolyFHT", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_18cuda_rf_gen_module_14gpuPolyFHT(__pyx_self, __pyx_v_reshapedX, __pyx_v_radem, __pyx_v_chiArr, __pyx_v_outputArray, __pyx_v_polydegree, __pyx_v_numThreads);

  /* function exit code */
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_18cuda_rf_gen_module_14gpuPolyFHT(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_reshapedX, PyObject *__pyx_v_radem, PyObject *__pyx_v_chiArr, PyObject *__pyx_v_outputArray, int __pyx_v_polydegree, CYTHON_UNUSED int __pyx_v_numThreads) {
  char const *__pyx_v_errCode;
  PyObject *__pyx_v_reshapedXCopy = NULL;
  int __pyx_v_j;
  PyObject *__pyx_v_logdim = NULL;
  uintptr_t __pyx_v_addr_reshapedCopy;
  uintptr_t __pyx_v_addr_output;
  uintptr_t __pyx_v_addr_radem;
  int8_t *__pyx_v_radem_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  Py_ssize_t __pyx_t_6;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_t_9;
  uintptr_t __pyx_t_10;
  int __pyx_t_11;
  int __pyx_t_12;
  int __pyx_t_13;
  int __pyx_t_14;
  int __pyx_t_15;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("gpuPolyFHT", 0);
  __Pyx_INCREF(__pyx_v_outputArray);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":192
 *     """
 *     cdef const char *errCode
 *     reshapedXCopy = reshapedX.copy()             # <<<<<<<<<<<<<<
 *     cdef int j, k
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_copy); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 192, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  __pyx_t_4 = 0;
  #if CYTHON_UNPACK_METHODS
  if (likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_4 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_3, NULL};
    __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+1-__pyx_t_4, 0+__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 192, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __pyx_v_reshapedXCopy = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":195
 *     cdef int j, k
 * 
 *     if len(chiArr.shape) != 3 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr, radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 3:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 195, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(3, 195, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__pyx_t_6 != 3);
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 195, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(3, 195, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__pyx_t_6 != 3);
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 195, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(3, 195, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__pyx_t_6 != 3);
  __pyx_t_5 = __pyx_t_7;
  __pyx_L4_bool_binop_done:;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":196
 * 
 *     if len(chiArr.shape) != 3 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 *         raise ValueError("chiArr, radem and reshapedX should be 3d arrays.")             # <<<<<<<<<<<<<<
 *     if len(outputArray.shape) != 3:
 *         raise ValueError("outputArray should be a 3d array.")
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__47, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 196, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(3, 196, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":195
 *     cdef int j, k
 * 
 *     if len(chiArr.shape) != 3 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr, radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 3:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":197
 *     if len(chiArr.shape) != 3 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 *         raise ValueError("chiArr, radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("outputArray should be a 3d array.")
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 197, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(3, 197, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = (__pyx_t_6 != 3);
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":198
 *         raise ValueError("chiArr, radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 3:
 *         raise ValueError("outputArray should be a 3d array.")             # <<<<<<<<<<<<<<
 * 
 *     if reshapedX.shape[0] == 0:
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__48, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 198, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(3, 198, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":197
 *     if len(chiArr.shape) != 3 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 *         raise ValueError("chiArr, radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("outputArray should be a 3d array.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":200
 *         raise ValueError("outputArray should be a 3d array.")
 * 
 *     if reshapedX.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0] or reshapedX.shape[1] != outputArray.shape[1] or\
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 200, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 200, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = (__Pyx_PyInt_BoolEqObjC(__pyx_t_2, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(3, 200, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":201
 * 
 *     if reshapedX.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")             # <<<<<<<<<<<<<<
 *     if reshapedX.shape[0] != outputArray.shape[0] or reshapedX.shape[1] != outputArray.shape[1] or\
 *             reshapedX.shape[2] != outputArray.shape[2]:
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 201, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(3, 201, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":200
 *         raise ValueError("outputArray should be a 3d array.")
 * 
 *     if reshapedX.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0] or reshapedX.shape[1] != outputArray.shape[1] or\
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":202
 *     if reshapedX.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0] or reshapedX.shape[1] != outputArray.shape[1] or\             # <<<<<<<<<<<<<<
 *             reshapedX.shape[2] != outputArray.shape[2]:
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 202, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 202, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 202, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 202, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_1, __pyx_t_3, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 202, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 202, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L10_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 202, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 202, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 202, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 202, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_3, __pyx_t_1, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 202, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 202, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L10_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":203
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0] or reshapedX.shape[1] != outputArray.shape[1] or\
 *             reshapedX.shape[2] != outputArray.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 203, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 203, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 203, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 203, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_1, __pyx_t_3, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 203, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 203, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __pyx_t_7;
  __pyx_L10_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":202
 *     if reshapedX.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0] or reshapedX.shape[1] != outputArray.shape[1] or\             # <<<<<<<<<<<<<<
 *             reshapedX.shape[2] != outputArray.shape[2]:
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 */
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":204
 *     if reshapedX.shape[0] != outputArray.shape[0] or reshapedX.shape[1] != outputArray.shape[1] or\
 *             reshapedX.shape[2] != outputArray.shape[2]:
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "             # <<<<<<<<<<<<<<
 *                 "not agree.")
 *     if radem.shape[0] != 3 * polydegree or chiArr.shape[0] != polydegree:
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__33, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 204, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(3, 204, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":202
 *     if reshapedX.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0] or reshapedX.shape[1] != outputArray.shape[1] or\             # <<<<<<<<<<<<<<
 *             reshapedX.shape[2] != outputArray.shape[2]:
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":206
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 *     if radem.shape[0] != 3 * polydegree or chiArr.shape[0] != polydegree:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem & chiArr must have length polydegree for dim 0.")
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 206, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 206, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyInt_From_long((3 * __pyx_v_polydegree)); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 206, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = PyObject_RichCompare(__pyx_t_3, __pyx_t_2, Py_NE); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 206, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 206, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L14_bool_binop_done;
  }
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 206, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 206, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_polydegree); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 206, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_2, __pyx_t_1, Py_NE); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 206, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 206, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_5 = __pyx_t_7;
  __pyx_L14_bool_binop_done:;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":207
 *                 "not agree.")
 *     if radem.shape[0] != 3 * polydegree or chiArr.shape[0] != polydegree:
 *         raise ValueError("radem & chiArr must have length polydegree for dim 0.")             # <<<<<<<<<<<<<<
 * 
 *     if chiArr.shape[2] != radem.shape[2] or chiArr.shape[1] != radem.shape[1]:
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__49, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 207, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(3, 207, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":206
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 *     if radem.shape[0] != 3 * polydegree or chiArr.shape[0] != polydegree:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem & chiArr must have length polydegree for dim 0.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":209
 *         raise ValueError("radem & chiArr must have length polydegree for dim 0.")
 * 
 *     if chiArr.shape[2] != radem.shape[2] or chiArr.shape[1] != radem.shape[1]:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr must have same shape[1] and shape[2] as radem.")
 *     logdim = np.log2(reshapedX.shape[2])
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 209, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 209, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 209, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 209, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_1, __pyx_t_2, Py_NE); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 209, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 209, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L17_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 209, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 209, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 209, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_3, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 209, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_2, __pyx_t_1, Py_NE); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 209, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 209, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_5 = __pyx_t_7;
  __pyx_L17_bool_binop_done:;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":210
 * 
 *     if chiArr.shape[2] != radem.shape[2] or chiArr.shape[1] != radem.shape[1]:
 *         raise ValueError("chiArr must have same shape[1] and shape[2] as radem.")             # <<<<<<<<<<<<<<
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__50, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 210, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(3, 210, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":209
 *         raise ValueError("radem & chiArr must have length polydegree for dim 0.")
 * 
 *     if chiArr.shape[2] != radem.shape[2] or chiArr.shape[1] != radem.shape[1]:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr must have same shape[1] and shape[2] as radem.")
 *     logdim = np.log2(reshapedX.shape[2])
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":211
 *     if chiArr.shape[2] != radem.shape[2] or chiArr.shape[1] != radem.shape[1]:
 *         raise ValueError("chiArr must have same shape[1] and shape[2] as radem.")
 *     logdim = np.log2(reshapedX.shape[2])             # <<<<<<<<<<<<<<
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 211, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_log2); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 211, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 211, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 211, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  __pyx_t_4 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_4 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_1, __pyx_t_8};
    __pyx_t_3 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 211, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __pyx_v_logdim = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":212
 *         raise ValueError("chiArr must have same shape[1] and shape[2] as radem.")
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if radem.shape[2] != reshapedX.shape[2] or radem.shape[1] != reshapedX.shape[1]:
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_np); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 212, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ceil); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 212, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_8))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_8);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_8, function);
      __pyx_t_4 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_v_logdim};
    __pyx_t_3 = __Pyx_PyObject_FastCall(__pyx_t_8, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 212, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  }
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_np); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 212, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_floor); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 212, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
      __pyx_t_4 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_v_logdim};
    __pyx_t_8 = __Pyx_PyObject_FastCall(__pyx_t_1, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 212, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __pyx_t_1 = PyObject_RichCompare(__pyx_t_3, __pyx_t_8, Py_NE); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 212, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 212, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L20_bool_binop_done;
  }
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 212, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 212, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyObject_RichCompare(__pyx_t_8, __pyx_int_2, Py_LT); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 212, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 212, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = __pyx_t_7;
  __pyx_L20_bool_binop_done:;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":213
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")             # <<<<<<<<<<<<<<
 *     if radem.shape[2] != reshapedX.shape[2] or radem.shape[1] != reshapedX.shape[1]:
 *         raise ValueError("reshapedX shape[1] and shape[2] must == radem shape[1] and shape[2].")
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__26, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 213, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(3, 213, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":212
 *         raise ValueError("chiArr must have same shape[1] and shape[2] as radem.")
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if radem.shape[2] != reshapedX.shape[2] or radem.shape[1] != reshapedX.shape[1]:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":214
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if radem.shape[2] != reshapedX.shape[2] or radem.shape[1] != reshapedX.shape[1]:             # <<<<<<<<<<<<<<
 *         raise ValueError("reshapedX shape[1] and shape[2] must == radem shape[1] and shape[2].")
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 214, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 214, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 214, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 214, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyObject_RichCompare(__pyx_t_8, __pyx_t_3, Py_NE); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 214, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 214, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L23_bool_binop_done;
  }
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 214, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 214, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 214, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 214, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyObject_RichCompare(__pyx_t_3, __pyx_t_8, Py_NE); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 214, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 214, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = __pyx_t_7;
  __pyx_L23_bool_binop_done:;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":215
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if radem.shape[2] != reshapedX.shape[2] or radem.shape[1] != reshapedX.shape[1]:
 *         raise ValueError("reshapedX shape[1] and shape[2] must == radem shape[1] and shape[2].")             # <<<<<<<<<<<<<<
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__51, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 215, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(3, 215, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":214
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if radem.shape[2] != reshapedX.shape[2] or radem.shape[1] != reshapedX.shape[1]:             # <<<<<<<<<<<<<<
 *         raise ValueError("reshapedX shape[1] and shape[2] must == radem shape[1] and shape[2].")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":217
 *         raise ValueError("reshapedX shape[1] and shape[2] must == radem shape[1] and shape[2].")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_flags); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 217, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_8 = __Pyx_PyObject_Dict_GetItem(__pyx_t_1, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 217, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_8); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 217, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_9 = (!__pyx_t_7);
  if (!__pyx_t_9) {
  } else {
    __pyx_t_5 = __pyx_t_9;
    goto __pyx_L26_bool_binop_done;
  }
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_flags); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 217, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_1 = __Pyx_PyObject_Dict_GetItem(__pyx_t_8, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 217, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(3, 217, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (!__pyx_t_9);
  if (!__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L26_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":218
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 *         or not chiArr.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_flags); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 217, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":217
 *         raise ValueError("reshapedX shape[1] and shape[2] must == radem shape[1] and shape[2].")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  __pyx_t_8 = __Pyx_PyObject_Dict_GetItem(__pyx_t_1, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 217, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_8); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 217, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_9 = (!__pyx_t_7);
  if (!__pyx_t_9) {
  } else {
    __pyx_t_5 = __pyx_t_9;
    goto __pyx_L26_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":218
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 *         or not chiArr.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 */
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_flags); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 218, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_1 = __Pyx_PyObject_Dict_GetItem(__pyx_t_8, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 218, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(3, 218, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (!__pyx_t_9);
  __pyx_t_5 = __pyx_t_7;
  __pyx_L26_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":217
 *         raise ValueError("reshapedX shape[1] and shape[2] must == radem shape[1] and shape[2].")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":219
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")             # <<<<<<<<<<<<<<
 * 
 *     if not radem.dtype == "int8":
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__28, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 219, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(3, 219, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":217
 *         raise ValueError("reshapedX shape[1] and shape[2] must == radem shape[1] and shape[2].")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \             # <<<<<<<<<<<<<<
 *         or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":221
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 *     if not radem.dtype == "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be int8.")
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_dtype); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 221, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = (__Pyx_PyUnicode_Equals(__pyx_t_1, __pyx_n_u_int8, Py_EQ)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(3, 221, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (!__pyx_t_5);
  if (unlikely(__pyx_t_7)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":222
 * 
 *     if not radem.dtype == "int8":
 *         raise ValueError("radem must be int8.")             # <<<<<<<<<<<<<<
 * 
 *     cdef uintptr_t addr_reshapedCopy = reshapedXCopy.data.ptr
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__22, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 222, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(3, 222, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":221
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 *     if not radem.dtype == "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be int8.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":224
 *         raise ValueError("radem must be int8.")
 * 
 *     cdef uintptr_t addr_reshapedCopy = reshapedXCopy.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_output = outputArray.data.ptr
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedXCopy, __pyx_n_s_data); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 224, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 224, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_10 = __Pyx_PyInt_As_size_t(__pyx_t_8); if (unlikely((__pyx_t_10 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(3, 224, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_v_addr_reshapedCopy = __pyx_t_10;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":225
 * 
 *     cdef uintptr_t addr_reshapedCopy = reshapedXCopy.data.ptr
 *     cdef uintptr_t addr_output = outputArray.data.ptr             # <<<<<<<<<<<<<<
 * 
 *     cdef uintptr_t addr_radem = radem.data.ptr
 */
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_data); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 225, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 225, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_10 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_10 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(3, 225, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_addr_output = __pyx_t_10;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":227
 *     cdef uintptr_t addr_output = outputArray.data.ptr
 * 
 *     cdef uintptr_t addr_radem = radem.data.ptr             # <<<<<<<<<<<<<<
 *     cdef int8_t *radem_ptr = <int8_t*>addr_radem
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_data); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 227, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 227, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_10 = __Pyx_PyInt_As_size_t(__pyx_t_8); if (unlikely((__pyx_t_10 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(3, 227, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_v_addr_radem = __pyx_t_10;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":228
 * 
 *     cdef uintptr_t addr_radem = radem.data.ptr
 *     cdef int8_t *radem_ptr = <int8_t*>addr_radem             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_v_radem_ptr = ((int8_t *)__pyx_v_addr_radem);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":231
 * 
 * 
 *     outputArray[:] = reshapedX             # <<<<<<<<<<<<<<
 *     if outputArray.dtype == "float32" and reshapedX.dtype == "float32" and \
 *             chiArr.dtype == "float32":
 */
  if (__Pyx_PyObject_SetSlice(__pyx_v_outputArray, __pyx_v_reshapedX, 0, 0, NULL, NULL, &__pyx_slice__17, 0, 0, 0) < 0) __PYX_ERR(3, 231, __pyx_L1_error)

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":232
 * 
 *     outputArray[:] = reshapedX
 *     if outputArray.dtype == "float32" and reshapedX.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         errCode = cudaSORF3d[float](<float*>addr_output, radem_ptr,
 */
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 232, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_5 = (__Pyx_PyUnicode_Equals(__pyx_t_8, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(3, 232, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (__pyx_t_5) {
  } else {
    __pyx_t_7 = __pyx_t_5;
    goto __pyx_L32_bool_binop_done;
  }
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_dtype); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 232, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_5 = (__Pyx_PyUnicode_Equals(__pyx_t_8, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(3, 232, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (__pyx_t_5) {
  } else {
    __pyx_t_7 = __pyx_t_5;
    goto __pyx_L32_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":233
 *     outputArray[:] = reshapedX
 *     if outputArray.dtype == "float32" and reshapedX.dtype == "float32" and \
 *             chiArr.dtype == "float32":             # <<<<<<<<<<<<<<
 *         errCode = cudaSORF3d[float](<float*>addr_output, radem_ptr,
 *                 outputArray.shape[0], outputArray.shape[1], outputArray.shape[2])
 */
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_dtype); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 233, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_5 = (__Pyx_PyUnicode_Equals(__pyx_t_8, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(3, 233, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_7 = __pyx_t_5;
  __pyx_L32_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":232
 * 
 *     outputArray[:] = reshapedX
 *     if outputArray.dtype == "float32" and reshapedX.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         errCode = cudaSORF3d[float](<float*>addr_output, radem_ptr,
 */
  if (__pyx_t_7) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":235
 *             chiArr.dtype == "float32":
 *         errCode = cudaSORF3d[float](<float*>addr_output, radem_ptr,
 *                 outputArray.shape[0], outputArray.shape[1], outputArray.shape[2])             # <<<<<<<<<<<<<<
 *         if errCode.decode("UTF-8") != "no_error":
 *             raise Exception("Fatal error encountered while performing graph convolution.")
 */
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 235, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_8, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 235, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 235, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 235, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 235, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_11 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_11 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 235, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 235, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_8, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 235, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_12 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_12 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 235, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":234
 *     if outputArray.dtype == "float32" and reshapedX.dtype == "float32" and \
 *             chiArr.dtype == "float32":
 *         errCode = cudaSORF3d[float](<float*>addr_output, radem_ptr,             # <<<<<<<<<<<<<<
 *                 outputArray.shape[0], outputArray.shape[1], outputArray.shape[2])
 *         if errCode.decode("UTF-8") != "no_error":
 */
    __pyx_v_errCode = cudaSORF3d<float>(((float *)__pyx_v_addr_output), __pyx_v_radem_ptr, __pyx_t_4, __pyx_t_11, __pyx_t_12);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":236
 *         errCode = cudaSORF3d[float](<float*>addr_output, radem_ptr,
 *                 outputArray.shape[0], outputArray.shape[1], outputArray.shape[2])
 *         if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *             raise Exception("Fatal error encountered while performing graph convolution.")
 *         outputArray *= chiArr[0:1, :, :]
 */
    __pyx_t_6 = __Pyx_ssize_strlen(__pyx_v_errCode); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(3, 236, __pyx_L1_error)
    __pyx_t_1 = __Pyx_decode_c_string(__pyx_v_errCode, 0, __pyx_t_6, NULL, NULL, PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 236, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_1, __pyx_n_u_no_error, Py_NE)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 236, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(__pyx_t_7)) {

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":237
 *                 outputArray.shape[0], outputArray.shape[1], outputArray.shape[2])
 *         if errCode.decode("UTF-8") != "no_error":
 *             raise Exception("Fatal error encountered while performing graph convolution.")             # <<<<<<<<<<<<<<
 *         outputArray *= chiArr[0:1, :, :]
 * 
 */
      __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__52, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 237, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_Raise(__pyx_t_1, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __PYX_ERR(3, 237, __pyx_L1_error)

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":236
 *         errCode = cudaSORF3d[float](<float*>addr_output, radem_ptr,
 *                 outputArray.shape[0], outputArray.shape[1], outputArray.shape[2])
 *         if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *             raise Exception("Fatal error encountered while performing graph convolution.")
 *         outputArray *= chiArr[0:1, :, :]
 */
    }

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":238
 *         if errCode.decode("UTF-8") != "no_error":
 *             raise Exception("Fatal error encountered while performing graph convolution.")
 *         outputArray *= chiArr[0:1, :, :]             # <<<<<<<<<<<<<<
 * 
 *         for j in range(1, polydegree):
 */
    __pyx_t_1 = __Pyx_PyObject_GetItem(__pyx_v_chiArr, __pyx_tuple__53); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 238, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_8 = PyNumber_InPlaceMultiply(__pyx_v_outputArray, __pyx_t_1); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 238, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF_SET(__pyx_v_outputArray, __pyx_t_8);
    __pyx_t_8 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":240
 *         outputArray *= chiArr[0:1, :, :]
 * 
 *         for j in range(1, polydegree):             # <<<<<<<<<<<<<<
 *             reshapedXCopy[:] = reshapedX
 *             radem_ptr += 3 * radem.shape[2] * radem.shape[1]
 */
    __pyx_t_12 = __pyx_v_polydegree;
    __pyx_t_11 = __pyx_t_12;
    for (__pyx_t_4 = 1; __pyx_t_4 < __pyx_t_11; __pyx_t_4+=1) {
      __pyx_v_j = __pyx_t_4;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":241
 * 
 *         for j in range(1, polydegree):
 *             reshapedXCopy[:] = reshapedX             # <<<<<<<<<<<<<<
 *             radem_ptr += 3 * radem.shape[2] * radem.shape[1]
 *             errCode = cudaSORF3d[float](<float*>addr_reshapedCopy,
 */
      if (__Pyx_PyObject_SetSlice(__pyx_v_reshapedXCopy, __pyx_v_reshapedX, 0, 0, NULL, NULL, &__pyx_slice__17, 0, 0, 0) < 0) __PYX_ERR(3, 241, __pyx_L1_error)

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":242
 *         for j in range(1, polydegree):
 *             reshapedXCopy[:] = reshapedX
 *             radem_ptr += 3 * radem.shape[2] * radem.shape[1]             # <<<<<<<<<<<<<<
 *             errCode = cudaSORF3d[float](<float*>addr_reshapedCopy,
 *                 radem_ptr, outputArray.shape[0], outputArray.shape[1],
 */
      __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 242, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_8, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 242, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = __Pyx_PyInt_MultiplyCObj(__pyx_int_3, __pyx_t_1, 3, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 242, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 242, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 242, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = PyNumber_Multiply(__pyx_t_8, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 242, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_6 = __Pyx_PyIndex_AsSsize_t(__pyx_t_1); if (unlikely((__pyx_t_6 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(3, 242, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_v_radem_ptr = (__pyx_v_radem_ptr + __pyx_t_6);

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":244
 *             radem_ptr += 3 * radem.shape[2] * radem.shape[1]
 *             errCode = cudaSORF3d[float](<float*>addr_reshapedCopy,
 *                 radem_ptr, outputArray.shape[0], outputArray.shape[1],             # <<<<<<<<<<<<<<
 *                 outputArray.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":
 */
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 244, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 244, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_13 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_13 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 244, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 244, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_3, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 244, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_14 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_14 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 244, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":245
 *             errCode = cudaSORF3d[float](<float*>addr_reshapedCopy,
 *                 radem_ptr, outputArray.shape[0], outputArray.shape[1],
 *                 outputArray.shape[2])             # <<<<<<<<<<<<<<
 *             if errCode.decode("UTF-8") != "no_error":
 *                 raise Exception("Fatal error encountered while performing graph convolution.")
 */
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 245, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 245, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_15 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_15 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 245, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":243
 *             reshapedXCopy[:] = reshapedX
 *             radem_ptr += 3 * radem.shape[2] * radem.shape[1]
 *             errCode = cudaSORF3d[float](<float*>addr_reshapedCopy,             # <<<<<<<<<<<<<<
 *                 radem_ptr, outputArray.shape[0], outputArray.shape[1],
 *                 outputArray.shape[2])
 */
      __pyx_v_errCode = cudaSORF3d<float>(((float *)__pyx_v_addr_reshapedCopy), __pyx_v_radem_ptr, __pyx_t_13, __pyx_t_14, __pyx_t_15);

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":246
 *                 radem_ptr, outputArray.shape[0], outputArray.shape[1],
 *                 outputArray.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *                 raise Exception("Fatal error encountered while performing graph convolution.")
 *             reshapedXCopy *= chiArr[j:j+1, :, :]
 */
      __pyx_t_6 = __Pyx_ssize_strlen(__pyx_v_errCode); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(3, 246, __pyx_L1_error)
      __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_errCode, 0, __pyx_t_6, NULL, NULL, PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 246, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_3, __pyx_n_u_no_error, Py_NE)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 246, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (unlikely(__pyx_t_7)) {

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":247
 *                 outputArray.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":
 *                 raise Exception("Fatal error encountered while performing graph convolution.")             # <<<<<<<<<<<<<<
 *             reshapedXCopy *= chiArr[j:j+1, :, :]
 *             outputArray *= reshapedXCopy
 */
        __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__52, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 247, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_Raise(__pyx_t_3, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __PYX_ERR(3, 247, __pyx_L1_error)

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":246
 *                 radem_ptr, outputArray.shape[0], outputArray.shape[1],
 *                 outputArray.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *                 raise Exception("Fatal error encountered while performing graph convolution.")
 *             reshapedXCopy *= chiArr[j:j+1, :, :]
 */
      }

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":248
 *             if errCode.decode("UTF-8") != "no_error":
 *                 raise Exception("Fatal error encountered while performing graph convolution.")
 *             reshapedXCopy *= chiArr[j:j+1, :, :]             # <<<<<<<<<<<<<<
 *             outputArray *= reshapedXCopy
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 */
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_j); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 248, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_1 = __Pyx_PyInt_From_long((__pyx_v_j + 1)); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 248, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_8 = PySlice_New(__pyx_t_3, __pyx_t_1, Py_None); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 248, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 248, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_GIVEREF(__pyx_t_8);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_8)) __PYX_ERR(3, 248, __pyx_L1_error);
      __Pyx_INCREF(__pyx_slice__17);
      __Pyx_GIVEREF(__pyx_slice__17);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_slice__17)) __PYX_ERR(3, 248, __pyx_L1_error);
      __Pyx_INCREF(__pyx_slice__17);
      __Pyx_GIVEREF(__pyx_slice__17);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_slice__17)) __PYX_ERR(3, 248, __pyx_L1_error);
      __pyx_t_8 = 0;
      __pyx_t_8 = __Pyx_PyObject_GetItem(__pyx_v_chiArr, __pyx_t_1); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 248, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = PyNumber_InPlaceMultiply(__pyx_v_reshapedXCopy, __pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 248, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF_SET(__pyx_v_reshapedXCopy, __pyx_t_1);
      __pyx_t_1 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":249
 *                 raise Exception("Fatal error encountered while performing graph convolution.")
 *             reshapedXCopy *= chiArr[j:j+1, :, :]
 *             outputArray *= reshapedXCopy             # <<<<<<<<<<<<<<
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 *             chiArr.dtype == "float64":
 */
      __pyx_t_1 = PyNumber_InPlaceMultiply(__pyx_v_outputArray, __pyx_v_reshapedXCopy); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 249, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF_SET(__pyx_v_outputArray, __pyx_t_1);
      __pyx_t_1 = 0;
    }

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":232
 * 
 *     outputArray[:] = reshapedX
 *     if outputArray.dtype == "float32" and reshapedX.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         errCode = cudaSORF3d[float](<float*>addr_output, radem_ptr,
 */
    goto __pyx_L31;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":250
 *             reshapedXCopy *= chiArr[j:j+1, :, :]
 *             outputArray *= reshapedXCopy
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         errCode = cudaSORF3d[double](<double*>addr_output, radem_ptr,
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 250, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = (__Pyx_PyUnicode_Equals(__pyx_t_1, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(3, 250, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (__pyx_t_5) {
  } else {
    __pyx_t_7 = __pyx_t_5;
    goto __pyx_L39_bool_binop_done;
  }
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_reshapedX, __pyx_n_s_dtype); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 250, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = (__Pyx_PyUnicode_Equals(__pyx_t_1, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(3, 250, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (__pyx_t_5) {
  } else {
    __pyx_t_7 = __pyx_t_5;
    goto __pyx_L39_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":251
 *             outputArray *= reshapedXCopy
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 *             chiArr.dtype == "float64":             # <<<<<<<<<<<<<<
 *         errCode = cudaSORF3d[double](<double*>addr_output, radem_ptr,
 *                 outputArray.shape[0], outputArray.shape[1], outputArray.shape[2])
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_dtype); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 251, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = (__Pyx_PyUnicode_Equals(__pyx_t_1, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(3, 251, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = __pyx_t_5;
  __pyx_L39_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":250
 *             reshapedXCopy *= chiArr[j:j+1, :, :]
 *             outputArray *= reshapedXCopy
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         errCode = cudaSORF3d[double](<double*>addr_output, radem_ptr,
 */
  if (likely(__pyx_t_7)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":253
 *             chiArr.dtype == "float64":
 *         errCode = cudaSORF3d[double](<double*>addr_output, radem_ptr,
 *                 outputArray.shape[0], outputArray.shape[1], outputArray.shape[2])             # <<<<<<<<<<<<<<
 *         if errCode.decode("UTF-8") != "no_error":
 *             raise Exception("Fatal error encountered while performing graph convolution.")
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 253, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 253, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_12 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_12 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 253, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 253, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_8, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 253, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_11 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_11 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 253, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 253, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 253, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 253, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":252
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \
 *             chiArr.dtype == "float64":
 *         errCode = cudaSORF3d[double](<double*>addr_output, radem_ptr,             # <<<<<<<<<<<<<<
 *                 outputArray.shape[0], outputArray.shape[1], outputArray.shape[2])
 *         if errCode.decode("UTF-8") != "no_error":
 */
    __pyx_v_errCode = cudaSORF3d<double>(((double *)__pyx_v_addr_output), __pyx_v_radem_ptr, __pyx_t_12, __pyx_t_11, __pyx_t_4);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":254
 *         errCode = cudaSORF3d[double](<double*>addr_output, radem_ptr,
 *                 outputArray.shape[0], outputArray.shape[1], outputArray.shape[2])
 *         if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *             raise Exception("Fatal error encountered while performing graph convolution.")
 *         outputArray *= chiArr[0:1, :, :]
 */
    __pyx_t_6 = __Pyx_ssize_strlen(__pyx_v_errCode); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(3, 254, __pyx_L1_error)
    __pyx_t_8 = __Pyx_decode_c_string(__pyx_v_errCode, 0, __pyx_t_6, NULL, NULL, PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 254, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_8, __pyx_n_u_no_error, Py_NE)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 254, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (unlikely(__pyx_t_7)) {

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":255
 *                 outputArray.shape[0], outputArray.shape[1], outputArray.shape[2])
 *         if errCode.decode("UTF-8") != "no_error":
 *             raise Exception("Fatal error encountered while performing graph convolution.")             # <<<<<<<<<<<<<<
 *         outputArray *= chiArr[0:1, :, :]
 * 
 */
      __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__52, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 255, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_Raise(__pyx_t_8, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __PYX_ERR(3, 255, __pyx_L1_error)

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":254
 *         errCode = cudaSORF3d[double](<double*>addr_output, radem_ptr,
 *                 outputArray.shape[0], outputArray.shape[1], outputArray.shape[2])
 *         if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *             raise Exception("Fatal error encountered while performing graph convolution.")
 *         outputArray *= chiArr[0:1, :, :]
 */
    }

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":256
 *         if errCode.decode("UTF-8") != "no_error":
 *             raise Exception("Fatal error encountered while performing graph convolution.")
 *         outputArray *= chiArr[0:1, :, :]             # <<<<<<<<<<<<<<
 * 
 *         for j in range(1, polydegree):
 */
    __pyx_t_8 = __Pyx_PyObject_GetItem(__pyx_v_chiArr, __pyx_tuple__53); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 256, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_1 = PyNumber_InPlaceMultiply(__pyx_v_outputArray, __pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 256, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_DECREF_SET(__pyx_v_outputArray, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":258
 *         outputArray *= chiArr[0:1, :, :]
 * 
 *         for j in range(1, polydegree):             # <<<<<<<<<<<<<<
 *             reshapedXCopy[:] = reshapedX
 *             radem_ptr += 3 * radem.shape[2] * radem.shape[1]
 */
    __pyx_t_4 = __pyx_v_polydegree;
    __pyx_t_11 = __pyx_t_4;
    for (__pyx_t_12 = 1; __pyx_t_12 < __pyx_t_11; __pyx_t_12+=1) {
      __pyx_v_j = __pyx_t_12;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":259
 * 
 *         for j in range(1, polydegree):
 *             reshapedXCopy[:] = reshapedX             # <<<<<<<<<<<<<<
 *             radem_ptr += 3 * radem.shape[2] * radem.shape[1]
 *             errCode = cudaSORF3d[double](<double*>addr_reshapedCopy,
 */
      if (__Pyx_PyObject_SetSlice(__pyx_v_reshapedXCopy, __pyx_v_reshapedX, 0, 0, NULL, NULL, &__pyx_slice__17, 0, 0, 0) < 0) __PYX_ERR(3, 259, __pyx_L1_error)

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":260
 *         for j in range(1, polydegree):
 *             reshapedXCopy[:] = reshapedX
 *             radem_ptr += 3 * radem.shape[2] * radem.shape[1]             # <<<<<<<<<<<<<<
 *             errCode = cudaSORF3d[double](<double*>addr_reshapedCopy,
 *                 radem_ptr, outputArray.shape[0], outputArray.shape[1],
 */
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 260, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 260, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_PyInt_MultiplyCObj(__pyx_int_3, __pyx_t_8, 3, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 260, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 260, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_8, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 260, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_Multiply(__pyx_t_1, __pyx_t_3); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 260, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_6 = __Pyx_PyIndex_AsSsize_t(__pyx_t_8); if (unlikely((__pyx_t_6 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(3, 260, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_v_radem_ptr = (__pyx_v_radem_ptr + __pyx_t_6);

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":262
 *             radem_ptr += 3 * radem.shape[2] * radem.shape[1]
 *             errCode = cudaSORF3d[double](<double*>addr_reshapedCopy,
 *                 radem_ptr, outputArray.shape[0], outputArray.shape[1],             # <<<<<<<<<<<<<<
 *                 outputArray.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":
 */
      __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 262, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_8, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 262, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_15 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_15 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 262, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 262, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_3, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 262, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_14 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_14 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 262, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":263
 *             errCode = cudaSORF3d[double](<double*>addr_reshapedCopy,
 *                 radem_ptr, outputArray.shape[0], outputArray.shape[1],
 *                 outputArray.shape[2])             # <<<<<<<<<<<<<<
 *             if errCode.decode("UTF-8") != "no_error":
 *                 raise Exception("Fatal error encountered while performing graph convolution.")
 */
      __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 263, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_8, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 263, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_13 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_13 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 263, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":261
 *             reshapedXCopy[:] = reshapedX
 *             radem_ptr += 3 * radem.shape[2] * radem.shape[1]
 *             errCode = cudaSORF3d[double](<double*>addr_reshapedCopy,             # <<<<<<<<<<<<<<
 *                 radem_ptr, outputArray.shape[0], outputArray.shape[1],
 *                 outputArray.shape[2])
 */
      __pyx_v_errCode = cudaSORF3d<double>(((double *)__pyx_v_addr_reshapedCopy), __pyx_v_radem_ptr, __pyx_t_15, __pyx_t_14, __pyx_t_13);

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":264
 *                 radem_ptr, outputArray.shape[0], outputArray.shape[1],
 *                 outputArray.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *                 raise Exception("Fatal error encountered while performing graph convolution.")
 *             reshapedXCopy *= chiArr[j:j+1, :, :]
 */
      __pyx_t_6 = __Pyx_ssize_strlen(__pyx_v_errCode); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(3, 264, __pyx_L1_error)
      __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_errCode, 0, __pyx_t_6, NULL, NULL, PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 264, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_3, __pyx_n_u_no_error, Py_NE)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(3, 264, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (unlikely(__pyx_t_7)) {

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":265
 *                 outputArray.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":
 *                 raise Exception("Fatal error encountered while performing graph convolution.")             # <<<<<<<<<<<<<<
 *             reshapedXCopy *= chiArr[j:j+1, :, :]
 *             outputArray *= reshapedXCopy
 */
        __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__52, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 265, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_Raise(__pyx_t_3, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __PYX_ERR(3, 265, __pyx_L1_error)

        /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":264
 *                 radem_ptr, outputArray.shape[0], outputArray.shape[1],
 *                 outputArray.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *                 raise Exception("Fatal error encountered while performing graph convolution.")
 *             reshapedXCopy *= chiArr[j:j+1, :, :]
 */
      }

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":266
 *             if errCode.decode("UTF-8") != "no_error":
 *                 raise Exception("Fatal error encountered while performing graph convolution.")
 *             reshapedXCopy *= chiArr[j:j+1, :, :]             # <<<<<<<<<<<<<<
 *             outputArray *= reshapedXCopy
 *     else:
 */
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_j); if (unlikely(!__pyx_t_3)) __PYX_ERR(3, 266, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_8 = __Pyx_PyInt_From_long((__pyx_v_j + 1)); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 266, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_1 = PySlice_New(__pyx_t_3, __pyx_t_8, Py_None); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 266, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyTuple_New(3); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 266, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_GIVEREF(__pyx_t_1);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_1)) __PYX_ERR(3, 266, __pyx_L1_error);
      __Pyx_INCREF(__pyx_slice__17);
      __Pyx_GIVEREF(__pyx_slice__17);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_8, 1, __pyx_slice__17)) __PYX_ERR(3, 266, __pyx_L1_error);
      __Pyx_INCREF(__pyx_slice__17);
      __Pyx_GIVEREF(__pyx_slice__17);
      if (__Pyx_PyTuple_SET_ITEM(__pyx_t_8, 2, __pyx_slice__17)) __PYX_ERR(3, 266, __pyx_L1_error);
      __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_PyObject_GetItem(__pyx_v_chiArr, __pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 266, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyNumber_InPlaceMultiply(__pyx_v_reshapedXCopy, __pyx_t_1); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 266, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF_SET(__pyx_v_reshapedXCopy, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":267
 *                 raise Exception("Fatal error encountered while performing graph convolution.")
 *             reshapedXCopy *= chiArr[j:j+1, :, :]
 *             outputArray *= reshapedXCopy             # <<<<<<<<<<<<<<
 *     else:
 *         raise ValueError("Inconsistent array types passed to wrapped C++ function.")
 */
      __pyx_t_8 = PyNumber_InPlaceMultiply(__pyx_v_outputArray, __pyx_v_reshapedXCopy); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 267, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF_SET(__pyx_v_outputArray, __pyx_t_8);
      __pyx_t_8 = 0;
    }

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":250
 *             reshapedXCopy *= chiArr[j:j+1, :, :]
 *             outputArray *= reshapedXCopy
 *     elif outputArray.dtype == "float64" and reshapedX.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         errCode = cudaSORF3d[double](<double*>addr_output, radem_ptr,
 */
    goto __pyx_L31;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":269
 *             outputArray *= reshapedXCopy
 *     else:
 *         raise ValueError("Inconsistent array types passed to wrapped C++ function.")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__46, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(3, 269, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_Raise(__pyx_t_8, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __PYX_ERR(3, 269, __pyx_L1_error)
  }
  __pyx_L31:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":165
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuPolyFHT(reshapedX, radem, chiArr, outputArray, int polydegree,
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("cuda_rf_gen_module.gpuPolyFHT", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_reshapedXCopy);
  __Pyx_XDECREF(__pyx_v_logdim);
  __Pyx_XDECREF(__pyx_v_outputArray);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":273
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaExactQuadratic(inputArray, outputArray,
 */

/* Python wrapper */
static PyObject *__pyx_pw_18cuda_rf_gen_module_17cudaExactQuadratic(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_18cuda_rf_gen_module_16cudaExactQuadratic, "Wraps C++ operations for generating features for an exact\n    quadratic.\n\n    Args:\n        inputArray (ndarray): The input data. This is not modified.\n        outputArray (ndarray): The output array. Must have the appropriate\n            shape such that all of the quadratic polynomial features can\n            be written to it. The last column is assumed to be saved for 1\n            for a y-intercept term.\n        num_threads (int): Number of threads to use for FHT. Not used for gpu,\n            merely kept here for consistency with CPU version.\n\n    Raises:\n        ValueError: A ValueError is raised if unexpected or invalid inputs are supplied.\n    ");
static PyMethodDef __pyx_mdef_18cuda_rf_gen_module_17cudaExactQuadratic = {"cudaExactQuadratic", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_18cuda_rf_gen_module_17cudaExactQuadratic, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_18cuda_rf_gen_module_16cudaExactQuadratic};
static PyObject *__pyx_pw_18cuda_rf_gen_module_17cudaExactQuadratic(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_inputArray = 0;
  PyObject *__pyx_v_outputArray = 0;
  CYTHON_UNUSED int __pyx_v_numThreads;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[3] = {0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cudaExactQuadratic (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_MACROS
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject **__pyx_pyargnames[] = {&__pyx_n_s_inputArray,&__pyx_n_s_outputArray,&__pyx_n_s_numThreads,0};
    if (__pyx_kwds) {
      Py_ssize_t kw_args;
      switch (__pyx_nargs) {
        case  3: values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = __Pyx_NumKwargs_FASTCALL(__pyx_kwds);
      switch (__pyx_nargs) {
        case  0:
        if (likely((values[0] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_inputArray)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[0]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(3, 273, __pyx_L3_error)
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_outputArray)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[1]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(3, 273, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaExactQuadratic", 1, 3, 3, 1); __PYX_ERR(3, 273, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_numThreads)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[2]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(3, 273, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaExactQuadratic", 1, 3, 3, 2); __PYX_ERR(3, 273, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        const Py_ssize_t kwd_pos_args = __pyx_nargs;
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "cudaExactQuadratic") < 0)) __PYX_ERR(3, 273, __pyx_L3_error)
      }
    } else if (unlikely(__pyx_nargs != 3)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
      values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
      values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
    }
    __pyx_v_inputArray = values[0];
    __pyx_v_outputArray = values[1];
    __pyx_v_numThreads = __Pyx_PyInt_As_int(values[2]); if (unlikely((__pyx_v_numThreads == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 276, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cudaExactQuadratic", 1, 3, 3, __pyx_nargs); __PYX_ERR(3, 273, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_AddTraceback("cuda_rf_gen_module.cudaExactQuadratic", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_18cuda_rf_gen_module_16cudaExactQuadratic(__pyx_self, __pyx_v_inputArray, __pyx_v_outputArray, __pyx_v_numThreads);

  /* function exit code */
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_18cuda_rf_gen_module_16cudaExactQuadratic(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_inputArray, PyObject *__pyx_v_outputArray, CYTHON_UNUSED int __pyx_v_numThreads) {
  char const *__pyx_v_errCode;
  uintptr_t __pyx_v_addr_output;
  uintptr_t __pyx_v_addr_input;
  int __pyx_v_numExpectedFeats;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  uintptr_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  int __pyx_t_6;
  Py_ssize_t __pyx_t_7;
  int __pyx_t_8;
  int __pyx_t_9;
  int __pyx_t_10;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("cudaExactQuadratic", 1);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":293
 *     """
 *     cdef const char *errCode
 *     cdef uintptr_t addr_output = outputArray.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_input = inputArray.data.ptr
 *     cdef int numExpectedFeats = int( inputArray.shape[1] * (inputArray.shape[1] - 1) / 2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_data); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 293, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 293, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(3, 293, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_addr_output = __pyx_t_3;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":294
 *     cdef const char *errCode
 *     cdef uintptr_t addr_output = outputArray.data.ptr
 *     cdef uintptr_t addr_input = inputArray.data.ptr             # <<<<<<<<<<<<<<
 *     cdef int numExpectedFeats = int( inputArray.shape[1] * (inputArray.shape[1] - 1) / 2)
 *     numExpectedFeats += 2 * inputArray.shape[1] + 1
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 294, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 294, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(3, 294, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_addr_input = __pyx_t_3;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":295
 *     cdef uintptr_t addr_output = outputArray.data.ptr
 *     cdef uintptr_t addr_input = inputArray.data.ptr
 *     cdef int numExpectedFeats = int( inputArray.shape[1] * (inputArray.shape[1] - 1) / 2)             # <<<<<<<<<<<<<<
 *     numExpectedFeats += 2 * inputArray.shape[1] + 1
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 295, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 295, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 295, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(3, 295, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyInt_SubtractObjC(__pyx_t_4, __pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 295, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = PyNumber_Multiply(__pyx_t_2, __pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(3, 295, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyInt_TrueDivideObjC(__pyx_t_4, __pyx_int_2, 2, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 295, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyNumber_Int(__pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(3, 295, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_4); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 295, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_numExpectedFeats = __pyx_t_5;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":296
 *     cdef uintptr_t addr_input = inputArray.data.ptr
 *     cdef int numExpectedFeats = int( inputArray.shape[1] * (inputArray.shape[1] - 1) / 2)
 *     numExpectedFeats += 2 * inputArray.shape[1] + 1             # <<<<<<<<<<<<<<
 * 
 *     if len(inputArray.shape) != 2 or len(outputArray.shape) != 2:
 */
  __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_numExpectedFeats); if (unlikely(!__pyx_t_4)) __PYX_ERR(3, 296, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 296, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 296, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyInt_MultiplyCObj(__pyx_int_2, __pyx_t_2, 2, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 296, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyInt_AddObjC(__pyx_t_1, __pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 296, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_InPlaceAdd(__pyx_t_4, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 296, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 296, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_numExpectedFeats = __pyx_t_5;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":298
 *     numExpectedFeats += 2 * inputArray.shape[1] + 1
 * 
 *     if len(inputArray.shape) != 2 or len(outputArray.shape) != 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("Both inputArray and outputArray for the exact quadratic "
 *                 "must be 2d arrays.")
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 298, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_7 == ((Py_ssize_t)-1))) __PYX_ERR(3, 298, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_8 = (__pyx_t_7 != 2);
  if (!__pyx_t_8) {
  } else {
    __pyx_t_6 = __pyx_t_8;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 298, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_7 == ((Py_ssize_t)-1))) __PYX_ERR(3, 298, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_8 = (__pyx_t_7 != 2);
  __pyx_t_6 = __pyx_t_8;
  __pyx_L4_bool_binop_done:;
  if (unlikely(__pyx_t_6)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":299
 * 
 *     if len(inputArray.shape) != 2 or len(outputArray.shape) != 2:
 *         raise ValueError("Both inputArray and outputArray for the exact quadratic "             # <<<<<<<<<<<<<<
 *                 "must be 2d arrays.")
 * 
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__54, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 299, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(3, 299, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":298
 *     numExpectedFeats += 2 * inputArray.shape[1] + 1
 * 
 *     if len(inputArray.shape) != 2 or len(outputArray.shape) != 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("Both inputArray and outputArray for the exact quadratic "
 *                 "must be 2d arrays.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":302
 *                 "must be 2d arrays.")
 * 
 *     if inputArray.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputArray.shape[0] != outputArray.shape[0]:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 302, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 302, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_6 = (__Pyx_PyInt_BoolEqObjC(__pyx_t_2, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(3, 302, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_6)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":303
 * 
 *     if inputArray.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")             # <<<<<<<<<<<<<<
 *     if inputArray.shape[0] != outputArray.shape[0]:
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 303, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(3, 303, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":302
 *                 "must be 2d arrays.")
 * 
 *     if inputArray.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputArray.shape[0] != outputArray.shape[0]:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":304
 *     if inputArray.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputArray.shape[0] != outputArray.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 304, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 304, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 304, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(3, 304, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_1, __pyx_t_4, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 304, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(3, 304, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_6)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":305
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputArray.shape[0] != outputArray.shape[0]:
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "             # <<<<<<<<<<<<<<
 *                 "not agree.")
 *     if outputArray.shape[1] != numExpectedFeats:
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__33, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 305, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(3, 305, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":304
 *     if inputArray.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputArray.shape[0] != outputArray.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":307
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 *     if outputArray.shape[1] != numExpectedFeats:             # <<<<<<<<<<<<<<
 *         raise ValueError("The shape of the output array is incorrect for a quadratic.")
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 307, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(3, 307, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_numExpectedFeats); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 307, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = PyObject_RichCompare(__pyx_t_4, __pyx_t_2, Py_NE); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 307, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(3, 307, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (unlikely(__pyx_t_6)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":308
 *                 "not agree.")
 *     if outputArray.shape[1] != numExpectedFeats:
 *         raise ValueError("The shape of the output array is incorrect for a quadratic.")             # <<<<<<<<<<<<<<
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not inputArray.flags["C_CONTIGUOUS"]:
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__55, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 308, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(3, 308, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":307
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "
 *                 "not agree.")
 *     if outputArray.shape[1] != numExpectedFeats:             # <<<<<<<<<<<<<<
 *         raise ValueError("The shape of the output array is incorrect for a quadratic.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":310
 *         raise ValueError("The shape of the output array is incorrect for a quadratic.")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not inputArray.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_flags); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 310, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_Dict_GetItem(__pyx_t_1, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 310, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_8 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_8 < 0))) __PYX_ERR(3, 310, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_9 = (!__pyx_t_8);
  if (!__pyx_t_9) {
  } else {
    __pyx_t_6 = __pyx_t_9;
    goto __pyx_L10_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_flags); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 310, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_Dict_GetItem(__pyx_t_2, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 310, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(3, 310, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_8 = (!__pyx_t_9);
  __pyx_t_6 = __pyx_t_8;
  __pyx_L10_bool_binop_done:;
  if (unlikely(__pyx_t_6)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":311
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not inputArray.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")             # <<<<<<<<<<<<<<
 * 
 *     if inputArray.dtype == "float32":
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__28, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 311, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(3, 311, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":310
 *         raise ValueError("The shape of the output array is incorrect for a quadratic.")
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not inputArray.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":313
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 *     if inputArray.dtype == "float32":             # <<<<<<<<<<<<<<
 *         errCode = cudaExactQuadratic_[float](<float*>addr_input, <double*>addr_output,
 *                         inputArray.shape[0], inputArray.shape[1])
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 313, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = (__Pyx_PyUnicode_Equals(__pyx_t_1, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(3, 313, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (__pyx_t_6) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":315
 *     if inputArray.dtype == "float32":
 *         errCode = cudaExactQuadratic_[float](<float*>addr_input, <double*>addr_output,
 *                         inputArray.shape[0], inputArray.shape[1])             # <<<<<<<<<<<<<<
 * 
 *     elif inputArray.dtype == "float64":
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 315, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 315, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 315, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 315, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 315, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_10 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_10 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 315, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":314
 * 
 *     if inputArray.dtype == "float32":
 *         errCode = cudaExactQuadratic_[float](<float*>addr_input, <double*>addr_output,             # <<<<<<<<<<<<<<
 *                         inputArray.shape[0], inputArray.shape[1])
 * 
 */
    __pyx_v_errCode = cudaExactQuadratic_<float>(((float *)__pyx_v_addr_input), ((double *)__pyx_v_addr_output), __pyx_t_5, __pyx_t_10);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":313
 *         raise ValueError("One or more arguments is not C contiguous.")
 * 
 *     if inputArray.dtype == "float32":             # <<<<<<<<<<<<<<
 *         errCode = cudaExactQuadratic_[float](<float*>addr_input, <double*>addr_output,
 *                         inputArray.shape[0], inputArray.shape[1])
 */
    goto __pyx_L12;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":317
 *                         inputArray.shape[0], inputArray.shape[1])
 * 
 *     elif inputArray.dtype == "float64":             # <<<<<<<<<<<<<<
 *         errCode = cudaExactQuadratic_[double](<double*>addr_input, <double*>addr_output,
 *                         inputArray.shape[0], inputArray.shape[1])
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 317, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = (__Pyx_PyUnicode_Equals(__pyx_t_1, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(3, 317, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (likely(__pyx_t_6)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":319
 *     elif inputArray.dtype == "float64":
 *         errCode = cudaExactQuadratic_[double](<double*>addr_input, <double*>addr_output,
 *                         inputArray.shape[0], inputArray.shape[1])             # <<<<<<<<<<<<<<
 * 
 *     else:
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 319, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 319, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_10 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_10 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 319, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 319, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 319, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(3, 319, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":318
 * 
 *     elif inputArray.dtype == "float64":
 *         errCode = cudaExactQuadratic_[double](<double*>addr_input, <double*>addr_output,             # <<<<<<<<<<<<<<
 *                         inputArray.shape[0], inputArray.shape[1])
 * 
 */
    __pyx_v_errCode = cudaExactQuadratic_<double>(((double *)__pyx_v_addr_input), ((double *)__pyx_v_addr_output), __pyx_t_10, __pyx_t_5);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":317
 *                         inputArray.shape[0], inputArray.shape[1])
 * 
 *     elif inputArray.dtype == "float64":             # <<<<<<<<<<<<<<
 *         errCode = cudaExactQuadratic_[double](<double*>addr_input, <double*>addr_output,
 *                         inputArray.shape[0], inputArray.shape[1])
 */
    goto __pyx_L12;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":322
 * 
 *     else:
 *         raise ValueError("Unexpected types passed to wrapped C++ function.")             # <<<<<<<<<<<<<<
 * 
 *     if errCode.decode("UTF-8") != "no_error":
 */
  /*else*/ {
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__56, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 322, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(3, 322, __pyx_L1_error)
  }
  __pyx_L12:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":324
 *         raise ValueError("Unexpected types passed to wrapped C++ function.")
 * 
 *     if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *         raise Exception("Fatal error encountered while performing graph convolution.")
 */
  __pyx_t_7 = __Pyx_ssize_strlen(__pyx_v_errCode); if (unlikely(__pyx_t_7 == ((Py_ssize_t)-1))) __PYX_ERR(3, 324, __pyx_L1_error)
  __pyx_t_1 = __Pyx_decode_c_string(__pyx_v_errCode, 0, __pyx_t_7, NULL, NULL, PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 324, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = (__Pyx_PyUnicode_Equals(__pyx_t_1, __pyx_n_u_no_error, Py_NE)); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(3, 324, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (unlikely(__pyx_t_6)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":325
 * 
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered while performing graph convolution.")             # <<<<<<<<<<<<<<
 */
    __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__52, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 325, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(3, 325, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":324
 *         raise ValueError("Unexpected types passed to wrapped C++ function.")
 * 
 *     if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *         raise Exception("Fatal error encountered while performing graph convolution.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":273
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaExactQuadratic(inputArray, outputArray,
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("cuda_rf_gen_module.cudaExactQuadratic", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":39
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaRBFFeatureGen(inputArray, outputArray, radem,
 */

/* Python wrapper */
static PyObject *__pyx_pw_18cuda_rf_gen_module_19cudaRBFFeatureGen(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_18cuda_rf_gen_module_18cudaRBFFeatureGen, "Wraps RBFFeatureGen from double_specialized_ops and uses\n    it to to generate random features for an RBF kernel (this same routine\n    can also be used for Matern, ARD and MiniARD). This wrapper performs all\n    of the bounds checks, type checks etc and should not be bypassed.\n\n    Args:\n        inputArray (cp.ndarray): The array on which the SORF transform will be performed.\n            Transform is in place so nothing is returned. Shape is (N x C).\n            C must be a power of 2.\n        outputArray (cp.ndarray): The output array in which the generated features will\n            be stored. Must be of shape (N, numRffs) where numRffs is 2x numFreqs.\n        radem (cp.ndarray): A stack of diagonal matrices of type int8_t\n            of shape (3 x D x C).\n        chiArr (cp.ndarray): A matrix of shape (numFreqs).\n        betaHparam (double): The amplitude hyperparameter.\n        numThreads (int): Not currently used, accepted only to preserve\n            shared interface with CPU functions.\n        fitIntercept (bool): Whether to fit a y-intercept (in this case,\n            the first random feature generated should be set to 1).\n\n    Raises:\n        ValueError: A ValueError is raised if unexpected or invalid inputs are supplied.\n    ");
static PyMethodDef __pyx_mdef_18cuda_rf_gen_module_19cudaRBFFeatureGen = {"cudaRBFFeatureGen", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_18cuda_rf_gen_module_19cudaRBFFeatureGen, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_18cuda_rf_gen_module_18cudaRBFFeatureGen};
static PyObject *__pyx_pw_18cuda_rf_gen_module_19cudaRBFFeatureGen(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_inputArray = 0;
  PyObject *__pyx_v_outputArray = 0;
  PyObject *__pyx_v_radem = 0;
  PyObject *__pyx_v_chiArr = 0;
  double __pyx_v_betaHparam;
  CYTHON_UNUSED int __pyx_v_numThreads;
  PyObject *__pyx_v_fitIntercept = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[7] = {0,0,0,0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cudaRBFFeatureGen (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_MACROS
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject **__pyx_pyargnames[] = {&__pyx_n_s_inputArray,&__pyx_n_s_outputArray,&__pyx_n_s_radem,&__pyx_n_s_chiArr,&__pyx_n_s_betaHparam,&__pyx_n_s_numThreads,&__pyx_n_s_fitIntercept,0};

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":43
 * def cudaRBFFeatureGen(inputArray, outputArray, radem,
 *                 chiArr, double betaHparam, int numThreads,
 *                 fitIntercept = False):             # <<<<<<<<<<<<<<
 *     """Wraps RBFFeatureGen from double_specialized_ops and uses
 *     it to to generate random features for an RBF kernel (this same routine
 */
    values[6] = __Pyx_Arg_NewRef_FASTCALL(((PyObject *)((PyObject *)Py_False)));
    if (__pyx_kwds) {
      Py_ssize_t kw_args;
      switch (__pyx_nargs) {
        case  7: values[6] = __Pyx_Arg_FASTCALL(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = __Pyx_Arg_FASTCALL(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = __Pyx_NumKwargs_FASTCALL(__pyx_kwds);
      switch (__pyx_nargs) {
        case  0:
        if (likely((values[0] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_inputArray)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[0]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 39, __pyx_L3_error)
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_outputArray)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[1]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 39, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaRBFFeatureGen", 0, 6, 7, 1); __PYX_ERR(4, 39, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_radem)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[2]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 39, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaRBFFeatureGen", 0, 6, 7, 2); __PYX_ERR(4, 39, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_chiArr)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[3]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 39, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaRBFFeatureGen", 0, 6, 7, 3); __PYX_ERR(4, 39, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_betaHparam)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[4]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 39, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaRBFFeatureGen", 0, 6, 7, 4); __PYX_ERR(4, 39, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_numThreads)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[5]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 39, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaRBFFeatureGen", 0, 6, 7, 5); __PYX_ERR(4, 39, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (kw_args > 0) {
          PyObject* value = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_fitIntercept);
          if (value) { values[6] = __Pyx_Arg_NewRef_FASTCALL(value); kw_args--; }
          else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 39, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        const Py_ssize_t kwd_pos_args = __pyx_nargs;
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "cudaRBFFeatureGen") < 0)) __PYX_ERR(4, 39, __pyx_L3_error)
      }
    } else {
      switch (__pyx_nargs) {
        case  7: values[6] = __Pyx_Arg_FASTCALL(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = __Pyx_Arg_FASTCALL(__pyx_args, 5);
        values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
        values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
        values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
        values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
        values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_inputArray = values[0];
    __pyx_v_outputArray = values[1];
    __pyx_v_radem = values[2];
    __pyx_v_chiArr = values[3];
    __pyx_v_betaHparam = __pyx_PyFloat_AsDouble(values[4]); if (unlikely((__pyx_v_betaHparam == (double)-1) && PyErr_Occurred())) __PYX_ERR(4, 42, __pyx_L3_error)
    __pyx_v_numThreads = __Pyx_PyInt_As_int(values[5]); if (unlikely((__pyx_v_numThreads == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 42, __pyx_L3_error)
    __pyx_v_fitIntercept = values[6];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cudaRBFFeatureGen", 0, 6, 7, __pyx_nargs); __PYX_ERR(4, 39, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_AddTraceback("cuda_rf_gen_module.cudaRBFFeatureGen", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_18cuda_rf_gen_module_18cudaRBFFeatureGen(__pyx_self, __pyx_v_inputArray, __pyx_v_outputArray, __pyx_v_radem, __pyx_v_chiArr, __pyx_v_betaHparam, __pyx_v_numThreads, __pyx_v_fitIntercept);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":39
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaRBFFeatureGen(inputArray, outputArray, radem,
 */

  /* function exit code */
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_18cuda_rf_gen_module_18cudaRBFFeatureGen(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_inputArray, PyObject *__pyx_v_outputArray, PyObject *__pyx_v_radem, PyObject *__pyx_v_chiArr, double __pyx_v_betaHparam, CYTHON_UNUSED int __pyx_v_numThreads, PyObject *__pyx_v_fitIntercept) {
  char const *__pyx_v_errCode;
  float __pyx_v_logdim;
  double __pyx_v_rbfNormConstant;
  uintptr_t __pyx_v_addr_input;
  uintptr_t __pyx_v_addr_output;
  uintptr_t __pyx_v_addr_chi;
  uintptr_t __pyx_v_addr_radem;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  uintptr_t __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_t_9;
  float __pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  double __pyx_t_12;
  double __pyx_t_13;
  int __pyx_t_14;
  int __pyx_t_15;
  int __pyx_t_16;
  Py_ssize_t __pyx_t_17;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("cudaRBFFeatureGen", 1);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":70
 *     cdef float logdim
 *     cdef double rbfNormConstant
 *     cdef uintptr_t addr_input = inputArray.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_output = outputArray.data.ptr
 *     cdef uintptr_t addr_chi = chiArr.data.ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_data); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 70, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 70, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(4, 70, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_addr_input = __pyx_t_3;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":71
 *     cdef double rbfNormConstant
 *     cdef uintptr_t addr_input = inputArray.data.ptr
 *     cdef uintptr_t addr_output = outputArray.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_chi = chiArr.data.ptr
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 71, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 71, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(4, 71, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_addr_output = __pyx_t_3;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":72
 *     cdef uintptr_t addr_input = inputArray.data.ptr
 *     cdef uintptr_t addr_output = outputArray.data.ptr
 *     cdef uintptr_t addr_chi = chiArr.data.ptr             # <<<<<<<<<<<<<<
 * 
 *     cdef uintptr_t addr_radem = radem.data.ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_data); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 72, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 72, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(4, 72, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_addr_chi = __pyx_t_3;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":74
 *     cdef uintptr_t addr_chi = chiArr.data.ptr
 * 
 *     cdef uintptr_t addr_radem = radem.data.ptr             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 74, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 74, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(4, 74, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_addr_radem = __pyx_t_3;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":77
 * 
 * 
 *     if not radem.dtype == "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be of type int8.")
 *     if not inputArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] or not \
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_dtype); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 77, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_t_1, __pyx_n_u_int8, Py_EQ)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(4, 77, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = (!__pyx_t_4);
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":78
 * 
 *     if not radem.dtype == "int8":
 *         raise ValueError("radem must be of type int8.")             # <<<<<<<<<<<<<<
 *     if not inputArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] or not \
 *             chiArr.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"]:
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 78, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(4, 78, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":77
 * 
 * 
 *     if not radem.dtype == "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be of type int8.")
 *     if not inputArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] or not \
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":79
 *     if not radem.dtype == "int8":
 *         raise ValueError("radem must be of type int8.")
 *     if not inputArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] or not \             # <<<<<<<<<<<<<<
 *             chiArr.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_flags); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 79, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_Dict_GetItem(__pyx_t_1, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 79, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(4, 79, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_6 = (!__pyx_t_4);
  if (!__pyx_t_6) {
  } else {
    __pyx_t_5 = __pyx_t_6;
    goto __pyx_L5_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_flags); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 79, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_Dict_GetItem(__pyx_t_2, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 79, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(4, 79, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = (!__pyx_t_6);
  if (!__pyx_t_4) {
  } else {
    __pyx_t_5 = __pyx_t_4;
    goto __pyx_L5_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":80
 *         raise ValueError("radem must be of type int8.")
 *     if not inputArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] or not \
 *             chiArr.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "
 *                 "C contiguous.")
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_flags); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 80, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_Dict_GetItem(__pyx_t_1, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 80, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(4, 80, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":79
 *     if not radem.dtype == "int8":
 *         raise ValueError("radem must be of type int8.")
 *     if not inputArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] or not \             # <<<<<<<<<<<<<<
 *             chiArr.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "
 */
  __pyx_t_6 = (!__pyx_t_4);
  if (!__pyx_t_6) {
  } else {
    __pyx_t_5 = __pyx_t_6;
    goto __pyx_L5_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":80
 *         raise ValueError("radem must be of type int8.")
 *     if not inputArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] or not \
 *             chiArr.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "
 *                 "C contiguous.")
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_flags); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 80, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_Dict_GetItem(__pyx_t_2, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 80, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely((__pyx_t_6 < 0))) __PYX_ERR(4, 80, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = (!__pyx_t_6);
  __pyx_t_5 = __pyx_t_4;
  __pyx_L5_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":79
 *     if not radem.dtype == "int8":
 *         raise ValueError("radem must be of type int8.")
 *     if not inputArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] or not \             # <<<<<<<<<<<<<<
 *             chiArr.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "
 */
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":81
 *     if not inputArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] or not \
 *             chiArr.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "             # <<<<<<<<<<<<<<
 *                 "C contiguous.")
 * 
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__57, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 81, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(4, 81, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":79
 *     if not radem.dtype == "int8":
 *         raise ValueError("radem must be of type int8.")
 *     if not inputArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] or not \             # <<<<<<<<<<<<<<
 *             chiArr.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":84
 *                 "C contiguous.")
 * 
 *     if inputArray.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputArray.shape[1] != radem.shape[1] or inputArray.shape[2] != radem.shape[2]:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 84, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 84, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = (__Pyx_PyInt_BoolEqObjC(__pyx_t_2, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(4, 84, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":85
 * 
 *     if inputArray.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")             # <<<<<<<<<<<<<<
 *     if inputArray.shape[1] != radem.shape[1] or inputArray.shape[2] != radem.shape[2]:
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF feature gen function.")
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 85, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(4, 85, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":84
 *                 "C contiguous.")
 * 
 *     if inputArray.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputArray.shape[1] != radem.shape[1] or inputArray.shape[2] != radem.shape[2]:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":86
 *     if inputArray.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputArray.shape[1] != radem.shape[1] or inputArray.shape[2] != radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF feature gen function.")
 *     if radem.shape[0] != 3:
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 86, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 86, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 86, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 86, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_1, __pyx_t_7, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 86, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(4, 86, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!__pyx_t_4) {
  } else {
    __pyx_t_5 = __pyx_t_4;
    goto __pyx_L11_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 86, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 86, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 86, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 86, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_7, __pyx_t_1, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 86, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(4, 86, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __pyx_t_4;
  __pyx_L11_bool_binop_done:;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":87
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputArray.shape[1] != radem.shape[1] or inputArray.shape[2] != radem.shape[2]:
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF feature gen function.")             # <<<<<<<<<<<<<<
 *     if radem.shape[0] != 3:
 *         raise ValueError("radem must have length 3 for dim 0.")
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__58, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 87, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(4, 87, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":86
 *     if inputArray.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputArray.shape[1] != radem.shape[1] or inputArray.shape[2] != radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF feature gen function.")
 *     if radem.shape[0] != 3:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":88
 *     if inputArray.shape[1] != radem.shape[1] or inputArray.shape[2] != radem.shape[2]:
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF feature gen function.")
 *     if radem.shape[0] != 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must have length 3 for dim 0.")
 *     if inputArray.shape[0] != outputArray.shape[0]:
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 88, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 88, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = (__Pyx_PyInt_BoolNeObjC(__pyx_t_1, __pyx_int_3, 3, 0)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(4, 88, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":89
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF feature gen function.")
 *     if radem.shape[0] != 3:
 *         raise ValueError("radem must have length 3 for dim 0.")             # <<<<<<<<<<<<<<
 *     if inputArray.shape[0] != outputArray.shape[0]:
 *         raise ValueError("inputArray and outputArray to RBF feature gen must have same number "
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 89, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(4, 89, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":88
 *     if inputArray.shape[1] != radem.shape[1] or inputArray.shape[2] != radem.shape[2]:
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF feature gen function.")
 *     if radem.shape[0] != 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must have length 3 for dim 0.")
 *     if inputArray.shape[0] != outputArray.shape[0]:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":90
 *     if radem.shape[0] != 3:
 *         raise ValueError("radem must have length 3 for dim 0.")
 *     if inputArray.shape[0] != outputArray.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("inputArray and outputArray to RBF feature gen must have same number "
 *                     "of datapoints.")
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 90, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 90, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 90, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 90, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyObject_RichCompare(__pyx_t_2, __pyx_t_7, Py_NE); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 90, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(4, 90, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":91
 *         raise ValueError("radem must have length 3 for dim 0.")
 *     if inputArray.shape[0] != outputArray.shape[0]:
 *         raise ValueError("inputArray and outputArray to RBF feature gen must have same number "             # <<<<<<<<<<<<<<
 *                     "of datapoints.")
 *     if outputArray.shape[1] != 2 * chiArr.shape[0]:
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__59, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 91, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(4, 91, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":90
 *     if radem.shape[0] != 3:
 *         raise ValueError("radem must have length 3 for dim 0.")
 *     if inputArray.shape[0] != outputArray.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("inputArray and outputArray to RBF feature gen must have same number "
 *                     "of datapoints.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":93
 *         raise ValueError("inputArray and outputArray to RBF feature gen must have same number "
 *                     "of datapoints.")
 *     if outputArray.shape[1] != 2 * chiArr.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr input to RBF feature gen is of incorrect size.")
 *     if 2 * inputArray.shape[1] * inputArray.shape[2] < outputArray.shape[1]:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 93, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 93, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 93, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 93, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyInt_MultiplyCObj(__pyx_int_2, __pyx_t_2, 2, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 93, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_7, __pyx_t_1, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 93, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(4, 93, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":94
 *                     "of datapoints.")
 *     if outputArray.shape[1] != 2 * chiArr.shape[0]:
 *         raise ValueError("chiArr input to RBF feature gen is of incorrect size.")             # <<<<<<<<<<<<<<
 *     if 2 * inputArray.shape[1] * inputArray.shape[2] < outputArray.shape[1]:
 *         raise ValueError("Sizes on input and output arrays to RBF feature gen are inappropriate.")
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__60, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 94, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(4, 94, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":93
 *         raise ValueError("inputArray and outputArray to RBF feature gen must have same number "
 *                     "of datapoints.")
 *     if outputArray.shape[1] != 2 * chiArr.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr input to RBF feature gen is of incorrect size.")
 *     if 2 * inputArray.shape[1] * inputArray.shape[2] < outputArray.shape[1]:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":95
 *     if outputArray.shape[1] != 2 * chiArr.shape[0]:
 *         raise ValueError("chiArr input to RBF feature gen is of incorrect size.")
 *     if 2 * inputArray.shape[1] * inputArray.shape[2] < outputArray.shape[1]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Sizes on input and output arrays to RBF feature gen are inappropriate.")
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyInt_MultiplyCObj(__pyx_int_2, __pyx_t_1, 2, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Multiply(__pyx_t_2, __pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_7, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_7 = PyObject_RichCompare(__pyx_t_1, __pyx_t_2, Py_LT); __Pyx_XGOTREF(__pyx_t_7); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 95, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_7); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(4, 95, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":96
 *         raise ValueError("chiArr input to RBF feature gen is of incorrect size.")
 *     if 2 * inputArray.shape[1] * inputArray.shape[2] < outputArray.shape[1]:
 *         raise ValueError("Sizes on input and output arrays to RBF feature gen are inappropriate.")             # <<<<<<<<<<<<<<
 * 
 *     logdim = np.log2(inputArray.shape[2])
 */
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__61, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 96, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_Raise(__pyx_t_7, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __PYX_ERR(4, 96, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":95
 *     if outputArray.shape[1] != 2 * chiArr.shape[0]:
 *         raise ValueError("chiArr input to RBF feature gen is of incorrect size.")
 *     if 2 * inputArray.shape[1] * inputArray.shape[2] < outputArray.shape[1]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Sizes on input and output arrays to RBF feature gen are inappropriate.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":98
 *         raise ValueError("Sizes on input and output arrays to RBF feature gen are inappropriate.")
 * 
 *     logdim = np.log2(inputArray.shape[2])             # <<<<<<<<<<<<<<
 *     if np.ceil(logdim) != np.floor(logdim) or inputArray.shape[2] < 2:
 *         raise ValueError("dim2 of the input array to RBF feature gen functions "
 */
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_np); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 98, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_log2); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 98, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 98, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(4, 98, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_9 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
      __pyx_t_9 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_t_8};
    __pyx_t_7 = __Pyx_PyObject_FastCall(__pyx_t_1, __pyx_callargs+1-__pyx_t_9, 1+__pyx_t_9);
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 98, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __pyx_t_10 = __pyx_PyFloat_AsFloat(__pyx_t_7); if (unlikely((__pyx_t_10 == (float)-1) && PyErr_Occurred())) __PYX_ERR(4, 98, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_logdim = __pyx_t_10;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":99
 * 
 *     logdim = np.log2(inputArray.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or inputArray.shape[2] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim2 of the input array to RBF feature gen functions "
 *                             "must be a power of 2 >= 2.")
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 99, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ceil); if (unlikely(!__pyx_t_8)) __PYX_ERR(4, 99, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyFloat_FromDouble(__pyx_v_logdim); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 99, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = NULL;
  __pyx_t_9 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_8))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_8);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_8, function);
      __pyx_t_9 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_t_1};
    __pyx_t_7 = __Pyx_PyObject_FastCall(__pyx_t_8, __pyx_callargs+1-__pyx_t_9, 1+__pyx_t_9);
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 99, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  }
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 99, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_floor); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 99, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyFloat_FromDouble(__pyx_v_logdim); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 99, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_11 = NULL;
  __pyx_t_9 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_11 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_11)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_11);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_9 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_11, __pyx_t_1};
    __pyx_t_8 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+1-__pyx_t_9, 1+__pyx_t_9);
    __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_8)) __PYX_ERR(4, 99, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_7, __pyx_t_8, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 99, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(4, 99, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!__pyx_t_4) {
  } else {
    __pyx_t_5 = __pyx_t_4;
    goto __pyx_L18_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 99, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_2, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(4, 99, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_8, __pyx_int_2, Py_LT); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 99, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(4, 99, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __pyx_t_4;
  __pyx_L18_bool_binop_done:;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":100
 *     logdim = np.log2(inputArray.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or inputArray.shape[2] < 2:
 *         raise ValueError("dim2 of the input array to RBF feature gen functions "             # <<<<<<<<<<<<<<
 *                             "must be a power of 2 >= 2.")
 * 
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__62, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 100, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(4, 100, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":99
 * 
 *     logdim = np.log2(inputArray.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or inputArray.shape[2] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim2 of the input array to RBF feature gen functions "
 *                             "must be a power of 2 >= 2.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":103
 *                             "must be a power of 2 >= 2.")
 * 
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         rbfNormConstant = betaHparam * np.sqrt(2.0 / (<double>chiArr.shape[0] - 0.5))
 *     else:
 */
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_v_fitIntercept); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(4, 103, __pyx_L1_error)
  if (__pyx_t_5) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":104
 * 
 *     if fitIntercept:
 *         rbfNormConstant = betaHparam * np.sqrt(2.0 / (<double>chiArr.shape[0] - 0.5))             # <<<<<<<<<<<<<<
 *     else:
 *         rbfNormConstant = betaHparam * np.sqrt(2 / <double>chiArr.shape[0])
 */
    __pyx_t_2 = PyFloat_FromDouble(__pyx_v_betaHparam); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 104, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_GetModuleGlobalName(__pyx_t_7, __pyx_n_s_np); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 104, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_sqrt); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 104, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 104, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_11 = __Pyx_GetItemInt(__pyx_t_7, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 104, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_12 = __pyx_PyFloat_AsDouble(__pyx_t_11); if (unlikely((__pyx_t_12 == (double)-1) && PyErr_Occurred())) __PYX_ERR(4, 104, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    __pyx_t_13 = (((double)__pyx_t_12) - 0.5);
    if (unlikely(__pyx_t_13 == 0)) {
      PyErr_SetString(PyExc_ZeroDivisionError, "float division");
      __PYX_ERR(4, 104, __pyx_L1_error)
    }
    __pyx_t_11 = PyFloat_FromDouble((2.0 / __pyx_t_13)); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 104, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __pyx_t_7 = NULL;
    __pyx_t_9 = 0;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_7)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_7);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
        __pyx_t_9 = 1;
      }
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_7, __pyx_t_11};
      __pyx_t_8 = __Pyx_PyObject_FastCall(__pyx_t_1, __pyx_callargs+1-__pyx_t_9, 1+__pyx_t_9);
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
      if (unlikely(!__pyx_t_8)) __PYX_ERR(4, 104, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    }
    __pyx_t_1 = PyNumber_Multiply(__pyx_t_2, __pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 104, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_13 = __pyx_PyFloat_AsDouble(__pyx_t_1); if (unlikely((__pyx_t_13 == (double)-1) && PyErr_Occurred())) __PYX_ERR(4, 104, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_rbfNormConstant = __pyx_t_13;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":103
 *                             "must be a power of 2 >= 2.")
 * 
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         rbfNormConstant = betaHparam * np.sqrt(2.0 / (<double>chiArr.shape[0] - 0.5))
 *     else:
 */
    goto __pyx_L20;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":106
 *         rbfNormConstant = betaHparam * np.sqrt(2.0 / (<double>chiArr.shape[0] - 0.5))
 *     else:
 *         rbfNormConstant = betaHparam * np.sqrt(2 / <double>chiArr.shape[0])             # <<<<<<<<<<<<<<
 * 
 *     if inputArray.dtype == "float32" and outputArray.dtype == "float64" and \
 */
  /*else*/ {
    __pyx_t_1 = PyFloat_FromDouble(__pyx_v_betaHparam); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 106, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_np); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 106, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_sqrt); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 106, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 106, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 106, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_13 = __pyx_PyFloat_AsDouble(__pyx_t_7); if (unlikely((__pyx_t_13 == (double)-1) && PyErr_Occurred())) __PYX_ERR(4, 106, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    if (unlikely(((double)__pyx_t_13) == 0)) {
      PyErr_SetString(PyExc_ZeroDivisionError, "float division");
      __PYX_ERR(4, 106, __pyx_L1_error)
    }
    __pyx_t_7 = PyFloat_FromDouble((2.0 / ((double)__pyx_t_13))); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 106, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_2 = NULL;
    __pyx_t_9 = 0;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_11))) {
      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_11);
      if (likely(__pyx_t_2)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_11);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_11, function);
        __pyx_t_9 = 1;
      }
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_t_7};
      __pyx_t_8 = __Pyx_PyObject_FastCall(__pyx_t_11, __pyx_callargs+1-__pyx_t_9, 1+__pyx_t_9);
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      if (unlikely(!__pyx_t_8)) __PYX_ERR(4, 106, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    }
    __pyx_t_11 = PyNumber_Multiply(__pyx_t_1, __pyx_t_8); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 106, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_13 = __pyx_PyFloat_AsDouble(__pyx_t_11); if (unlikely((__pyx_t_13 == (double)-1) && PyErr_Occurred())) __PYX_ERR(4, 106, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    __pyx_v_rbfNormConstant = __pyx_t_13;
  }
  __pyx_L20:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":108
 *         rbfNormConstant = betaHparam * np.sqrt(2 / <double>chiArr.shape[0])
 * 
 *     if inputArray.dtype == "float32" and outputArray.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         errCode = RBFFeatureGen[float](<float*>addr_input, <int8_t*>addr_radem,
 */
  __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 108, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_t_11, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(4, 108, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
  if (__pyx_t_4) {
  } else {
    __pyx_t_5 = __pyx_t_4;
    goto __pyx_L22_bool_binop_done;
  }
  __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 108, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_t_11, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(4, 108, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
  if (__pyx_t_4) {
  } else {
    __pyx_t_5 = __pyx_t_4;
    goto __pyx_L22_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":109
 * 
 *     if inputArray.dtype == "float32" and outputArray.dtype == "float64" and \
 *             chiArr.dtype == "float32":             # <<<<<<<<<<<<<<
 *         errCode = RBFFeatureGen[float](<float*>addr_input, <int8_t*>addr_radem,
 *                 <float*>addr_chi, <double*>addr_output, rbfNormConstant,
 */
  __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_dtype); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 109, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_t_11, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(4, 109, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
  __pyx_t_5 = __pyx_t_4;
  __pyx_L22_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":108
 *         rbfNormConstant = betaHparam * np.sqrt(2 / <double>chiArr.shape[0])
 * 
 *     if inputArray.dtype == "float32" and outputArray.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         errCode = RBFFeatureGen[float](<float*>addr_input, <int8_t*>addr_radem,
 */
  if (__pyx_t_5) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":112
 *         errCode = RBFFeatureGen[float](<float*>addr_input, <int8_t*>addr_radem,
 *                 <float*>addr_chi, <double*>addr_output, rbfNormConstant,
 *                 inputArray.shape[0], inputArray.shape[1],             # <<<<<<<<<<<<<<
 *                 inputArray.shape[2], chiArr.shape[0]);
 *     elif inputArray.dtype == "float64" and outputArray.dtype == "float64" and \
 */
    __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 112, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_11, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(4, 112, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    __pyx_t_9 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_9 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 112, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(4, 112, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_11 = __Pyx_GetItemInt(__pyx_t_8, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 112, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_14 = __Pyx_PyInt_As_int(__pyx_t_11); if (unlikely((__pyx_t_14 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 112, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":113
 *                 <float*>addr_chi, <double*>addr_output, rbfNormConstant,
 *                 inputArray.shape[0], inputArray.shape[1],
 *                 inputArray.shape[2], chiArr.shape[0]);             # <<<<<<<<<<<<<<
 *     elif inputArray.dtype == "float64" and outputArray.dtype == "float64" and \
 *             chiArr.dtype == "float64":
 */
    __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 113, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_11, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(4, 113, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    __pyx_t_15 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_15 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 113, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(4, 113, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_11 = __Pyx_GetItemInt(__pyx_t_8, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 113, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_16 = __Pyx_PyInt_As_int(__pyx_t_11); if (unlikely((__pyx_t_16 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 113, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":110
 *     if inputArray.dtype == "float32" and outputArray.dtype == "float64" and \
 *             chiArr.dtype == "float32":
 *         errCode = RBFFeatureGen[float](<float*>addr_input, <int8_t*>addr_radem,             # <<<<<<<<<<<<<<
 *                 <float*>addr_chi, <double*>addr_output, rbfNormConstant,
 *                 inputArray.shape[0], inputArray.shape[1],
 */
    __pyx_v_errCode = RBFFeatureGen<float>(((float *)__pyx_v_addr_input), ((int8_t *)__pyx_v_addr_radem), ((float *)__pyx_v_addr_chi), ((double *)__pyx_v_addr_output), __pyx_v_rbfNormConstant, __pyx_t_9, __pyx_t_14, __pyx_t_15, __pyx_t_16);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":108
 *         rbfNormConstant = betaHparam * np.sqrt(2 / <double>chiArr.shape[0])
 * 
 *     if inputArray.dtype == "float32" and outputArray.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         errCode = RBFFeatureGen[float](<float*>addr_input, <int8_t*>addr_radem,
 */
    goto __pyx_L21;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":114
 *                 inputArray.shape[0], inputArray.shape[1],
 *                 inputArray.shape[2], chiArr.shape[0]);
 *     elif inputArray.dtype == "float64" and outputArray.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         errCode = RBFFeatureGen[double](<double*>addr_input, <int8_t*>addr_radem,
 */
  __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 114, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_t_11, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(4, 114, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
  if (__pyx_t_4) {
  } else {
    __pyx_t_5 = __pyx_t_4;
    goto __pyx_L25_bool_binop_done;
  }
  __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 114, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_t_11, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(4, 114, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
  if (__pyx_t_4) {
  } else {
    __pyx_t_5 = __pyx_t_4;
    goto __pyx_L25_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":115
 *                 inputArray.shape[2], chiArr.shape[0]);
 *     elif inputArray.dtype == "float64" and outputArray.dtype == "float64" and \
 *             chiArr.dtype == "float64":             # <<<<<<<<<<<<<<
 *         errCode = RBFFeatureGen[double](<double*>addr_input, <int8_t*>addr_radem,
 *                 <double*>addr_chi, <double*>addr_output, rbfNormConstant,
 */
  __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_dtype); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 115, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_t_11, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(4, 115, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
  __pyx_t_5 = __pyx_t_4;
  __pyx_L25_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":114
 *                 inputArray.shape[0], inputArray.shape[1],
 *                 inputArray.shape[2], chiArr.shape[0]);
 *     elif inputArray.dtype == "float64" and outputArray.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         errCode = RBFFeatureGen[double](<double*>addr_input, <int8_t*>addr_radem,
 */
  if (likely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":118
 *         errCode = RBFFeatureGen[double](<double*>addr_input, <int8_t*>addr_radem,
 *                 <double*>addr_chi, <double*>addr_output, rbfNormConstant,
 *                 inputArray.shape[0], inputArray.shape[1],             # <<<<<<<<<<<<<<
 *                 inputArray.shape[2], chiArr.shape[0]);
 *     else:
 */
    __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 118, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_11, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(4, 118, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    __pyx_t_16 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_16 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 118, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(4, 118, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_11 = __Pyx_GetItemInt(__pyx_t_8, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 118, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_15 = __Pyx_PyInt_As_int(__pyx_t_11); if (unlikely((__pyx_t_15 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 118, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":119
 *                 <double*>addr_chi, <double*>addr_output, rbfNormConstant,
 *                 inputArray.shape[0], inputArray.shape[1],
 *                 inputArray.shape[2], chiArr.shape[0]);             # <<<<<<<<<<<<<<
 *     else:
 *         raise ValueError("The input and chiArr arrays are of inconsistent types.")
 */
    __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 119, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_t_11, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(4, 119, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    __pyx_t_14 = __Pyx_PyInt_As_int(__pyx_t_8); if (unlikely((__pyx_t_14 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 119, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(4, 119, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_11 = __Pyx_GetItemInt(__pyx_t_8, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 119, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_9 = __Pyx_PyInt_As_int(__pyx_t_11); if (unlikely((__pyx_t_9 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 119, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":116
 *     elif inputArray.dtype == "float64" and outputArray.dtype == "float64" and \
 *             chiArr.dtype == "float64":
 *         errCode = RBFFeatureGen[double](<double*>addr_input, <int8_t*>addr_radem,             # <<<<<<<<<<<<<<
 *                 <double*>addr_chi, <double*>addr_output, rbfNormConstant,
 *                 inputArray.shape[0], inputArray.shape[1],
 */
    __pyx_v_errCode = RBFFeatureGen<double>(((double *)__pyx_v_addr_input), ((int8_t *)__pyx_v_addr_radem), ((double *)__pyx_v_addr_chi), ((double *)__pyx_v_addr_output), __pyx_v_rbfNormConstant, __pyx_t_16, __pyx_t_15, __pyx_t_14, __pyx_t_9);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":114
 *                 inputArray.shape[0], inputArray.shape[1],
 *                 inputArray.shape[2], chiArr.shape[0]);
 *     elif inputArray.dtype == "float64" and outputArray.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         errCode = RBFFeatureGen[double](<double*>addr_input, <int8_t*>addr_radem,
 */
    goto __pyx_L21;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":121
 *                 inputArray.shape[2], chiArr.shape[0]);
 *     else:
 *         raise ValueError("The input and chiArr arrays are of inconsistent types.")             # <<<<<<<<<<<<<<
 * 
 *     if errCode.decode("UTF-8") != "no_error":
 */
  /*else*/ {
    __pyx_t_11 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__63, NULL); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 121, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __Pyx_Raise(__pyx_t_11, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    __PYX_ERR(4, 121, __pyx_L1_error)
  }
  __pyx_L21:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":123
 *         raise ValueError("The input and chiArr arrays are of inconsistent types.")
 * 
 *     if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *         raise Exception("Fatal error encountered in CudaRBFFeatureGen.")
 *     if fitIntercept:
 */
  __pyx_t_17 = __Pyx_ssize_strlen(__pyx_v_errCode); if (unlikely(__pyx_t_17 == ((Py_ssize_t)-1))) __PYX_ERR(4, 123, __pyx_L1_error)
  __pyx_t_11 = __Pyx_decode_c_string(__pyx_v_errCode, 0, __pyx_t_17, NULL, NULL, PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 123, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  __pyx_t_5 = (__Pyx_PyUnicode_Equals(__pyx_t_11, __pyx_n_u_no_error, Py_NE)); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(4, 123, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
  if (unlikely(__pyx_t_5)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":124
 * 
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered in CudaRBFFeatureGen.")             # <<<<<<<<<<<<<<
 *     if fitIntercept:
 *         outputArray[:,0] = betaHparam
 */
    __pyx_t_11 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__64, NULL); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 124, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __Pyx_Raise(__pyx_t_11, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    __PYX_ERR(4, 124, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":123
 *         raise ValueError("The input and chiArr arrays are of inconsistent types.")
 * 
 *     if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *         raise Exception("Fatal error encountered in CudaRBFFeatureGen.")
 *     if fitIntercept:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":125
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered in CudaRBFFeatureGen.")
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         outputArray[:,0] = betaHparam
 * 
 */
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_v_fitIntercept); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(4, 125, __pyx_L1_error)
  if (__pyx_t_5) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":126
 *         raise Exception("Fatal error encountered in CudaRBFFeatureGen.")
 *     if fitIntercept:
 *         outputArray[:,0] = betaHparam             # <<<<<<<<<<<<<<
 * 
 * 
 */
    __pyx_t_11 = PyFloat_FromDouble(__pyx_v_betaHparam); if (unlikely(!__pyx_t_11)) __PYX_ERR(4, 126, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    if (unlikely((PyObject_SetItem(__pyx_v_outputArray, __pyx_tuple__38, __pyx_t_11) < 0))) __PYX_ERR(4, 126, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":125
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered in CudaRBFFeatureGen.")
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         outputArray[:,0] = betaHparam
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":39
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaRBFFeatureGen(inputArray, outputArray, radem,
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_AddTraceback("cuda_rf_gen_module.cudaRBFFeatureGen", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":130
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaRBFGrad(inputArray, outputArray, radem,
 */

/* Python wrapper */
static PyObject *__pyx_pw_18cuda_rf_gen_module_21cudaRBFGrad(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_18cuda_rf_gen_module_20cudaRBFGrad, "Wraps RBFFeatureGen and uses\n    it to to generate random features for an RBF kernel\n    together with the gradient. This wrapper performs all\n    of the bounds checks, type checks etc and should not be bypassed.\n\n    Args:\n        inputArray (cp.ndarray): The array on which the SORF transform will be performed.\n            Shape is (N x C). C must be a power of 2.\n        outputArray (cp.ndarray): The output array in which the generated features will\n            be stored. Must be of shape (N, numRffs) where numRffs is 2x numFreqs.\n        radem (cp.ndarray): A stack of diagonal matrices of type int8_t\n            of shape (3 x D x C).\n        chiArr (cp.ndarray): A matrix of shape (numFreqs).\n        betaHparam (double): The amplitude hyperparameter.\n        sigmaHparam (double): The sigma hyperparameter.\n        numThreads (int): Not currently used, accepted only to preserve\n            shared interface with CPU functions.\n        fitIntercept (bool): Whether to fit a y-intercept (in this case,\n            the first random feature generated should be set to 1).\n\n    Raises:\n        ValueError: A ValueError is raised if unexpected or invalid inputs are supplied.\n\n    Returns:\n        gradient (cp.ndarray): An array containing the gradient values.\n    ");
static PyMethodDef __pyx_mdef_18cuda_rf_gen_module_21cudaRBFGrad = {"cudaRBFGrad", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_18cuda_rf_gen_module_21cudaRBFGrad, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_18cuda_rf_gen_module_20cudaRBFGrad};
static PyObject *__pyx_pw_18cuda_rf_gen_module_21cudaRBFGrad(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_inputArray = 0;
  PyObject *__pyx_v_outputArray = 0;
  PyObject *__pyx_v_radem = 0;
  PyObject *__pyx_v_chiArr = 0;
  double __pyx_v_betaHparam;
  double __pyx_v_sigmaHparam;
  CYTHON_UNUSED int __pyx_v_numThreads;
  bool __pyx_v_fitIntercept;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[8] = {0,0,0,0,0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cudaRBFGrad (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_MACROS
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject **__pyx_pyargnames[] = {&__pyx_n_s_inputArray,&__pyx_n_s_outputArray,&__pyx_n_s_radem,&__pyx_n_s_chiArr,&__pyx_n_s_betaHparam,&__pyx_n_s_sigmaHparam,&__pyx_n_s_numThreads,&__pyx_n_s_fitIntercept,0};
    if (__pyx_kwds) {
      Py_ssize_t kw_args;
      switch (__pyx_nargs) {
        case  8: values[7] = __Pyx_Arg_FASTCALL(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = __Pyx_Arg_FASTCALL(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = __Pyx_Arg_FASTCALL(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = __Pyx_NumKwargs_FASTCALL(__pyx_kwds);
      switch (__pyx_nargs) {
        case  0:
        if (likely((values[0] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_inputArray)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[0]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 130, __pyx_L3_error)
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_outputArray)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[1]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 130, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaRBFGrad", 0, 7, 8, 1); __PYX_ERR(4, 130, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_radem)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[2]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 130, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaRBFGrad", 0, 7, 8, 2); __PYX_ERR(4, 130, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_chiArr)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[3]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 130, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaRBFGrad", 0, 7, 8, 3); __PYX_ERR(4, 130, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_betaHparam)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[4]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 130, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaRBFGrad", 0, 7, 8, 4); __PYX_ERR(4, 130, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_sigmaHparam)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[5]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 130, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaRBFGrad", 0, 7, 8, 5); __PYX_ERR(4, 130, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (likely((values[6] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_numThreads)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[6]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 130, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaRBFGrad", 0, 7, 8, 6); __PYX_ERR(4, 130, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (kw_args > 0) {
          PyObject* value = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_fitIntercept);
          if (value) { values[7] = __Pyx_Arg_NewRef_FASTCALL(value); kw_args--; }
          else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 130, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        const Py_ssize_t kwd_pos_args = __pyx_nargs;
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "cudaRBFGrad") < 0)) __PYX_ERR(4, 130, __pyx_L3_error)
      }
    } else {
      switch (__pyx_nargs) {
        case  8: values[7] = __Pyx_Arg_FASTCALL(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = __Pyx_Arg_FASTCALL(__pyx_args, 6);
        values[5] = __Pyx_Arg_FASTCALL(__pyx_args, 5);
        values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
        values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
        values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
        values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
        values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_inputArray = values[0];
    __pyx_v_outputArray = values[1];
    __pyx_v_radem = values[2];
    __pyx_v_chiArr = values[3];
    __pyx_v_betaHparam = __pyx_PyFloat_AsDouble(values[4]); if (unlikely((__pyx_v_betaHparam == (double)-1) && PyErr_Occurred())) __PYX_ERR(4, 133, __pyx_L3_error)
    __pyx_v_sigmaHparam = __pyx_PyFloat_AsDouble(values[5]); if (unlikely((__pyx_v_sigmaHparam == (double)-1) && PyErr_Occurred())) __PYX_ERR(4, 133, __pyx_L3_error)
    __pyx_v_numThreads = __Pyx_PyInt_As_int(values[6]); if (unlikely((__pyx_v_numThreads == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 134, __pyx_L3_error)
    if (values[7]) {
      __pyx_v_fitIntercept = __Pyx_PyObject_IsTrue(values[7]); if (unlikely((__pyx_v_fitIntercept == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(4, 134, __pyx_L3_error)
    } else {

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":134
 * def cudaRBFGrad(inputArray, outputArray, radem,
 *                 chiArr, double betaHparam, double sigmaHparam,
 *                 int numThreads, bool fitIntercept = False):             # <<<<<<<<<<<<<<
 *     """Wraps RBFFeatureGen and uses
 *     it to to generate random features for an RBF kernel
 */
      __pyx_v_fitIntercept = ((bool)((int)0));
    }
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cudaRBFGrad", 0, 7, 8, __pyx_nargs); __PYX_ERR(4, 130, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_AddTraceback("cuda_rf_gen_module.cudaRBFGrad", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_18cuda_rf_gen_module_20cudaRBFGrad(__pyx_self, __pyx_v_inputArray, __pyx_v_outputArray, __pyx_v_radem, __pyx_v_chiArr, __pyx_v_betaHparam, __pyx_v_sigmaHparam, __pyx_v_numThreads, __pyx_v_fitIntercept);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":130
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaRBFGrad(inputArray, outputArray, radem,
 */

  /* function exit code */
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_18cuda_rf_gen_module_20cudaRBFGrad(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_inputArray, PyObject *__pyx_v_outputArray, PyObject *__pyx_v_radem, PyObject *__pyx_v_chiArr, double __pyx_v_betaHparam, double __pyx_v_sigmaHparam, CYTHON_UNUSED int __pyx_v_numThreads, bool __pyx_v_fitIntercept) {
  char const *__pyx_v_errCode;
  float __pyx_v_logdim;
  double __pyx_v_rbfNormConstant;
  uintptr_t __pyx_v_addr_input;
  uintptr_t __pyx_v_addr_output;
  uintptr_t __pyx_v_addr_chi;
  uintptr_t __pyx_v_addr_radem;
  PyObject *__pyx_v_gradient = NULL;
  uintptr_t __pyx_v_addr_gradient;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  uintptr_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  int __pyx_t_8;
  int __pyx_t_9;
  int __pyx_t_10;
  float __pyx_t_11;
  double __pyx_t_12;
  double __pyx_t_13;
  int __pyx_t_14;
  int __pyx_t_15;
  int __pyx_t_16;
  Py_ssize_t __pyx_t_17;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("cudaRBFGrad", 1);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":164
 *     cdef float logdim
 *     cdef double rbfNormConstant
 *     cdef uintptr_t addr_input = inputArray.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_output = outputArray.data.ptr
 *     cdef uintptr_t addr_chi = chiArr.data.ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_data); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 164, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 164, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(4, 164, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_addr_input = __pyx_t_3;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":165
 *     cdef double rbfNormConstant
 *     cdef uintptr_t addr_input = inputArray.data.ptr
 *     cdef uintptr_t addr_output = outputArray.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_chi = chiArr.data.ptr
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 165, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 165, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(4, 165, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_addr_output = __pyx_t_3;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":166
 *     cdef uintptr_t addr_input = inputArray.data.ptr
 *     cdef uintptr_t addr_output = outputArray.data.ptr
 *     cdef uintptr_t addr_chi = chiArr.data.ptr             # <<<<<<<<<<<<<<
 * 
 *     cdef uintptr_t addr_radem = radem.data.ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_data); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 166, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 166, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(4, 166, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_addr_chi = __pyx_t_3;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":168
 *     cdef uintptr_t addr_chi = chiArr.data.ptr
 * 
 *     cdef uintptr_t addr_radem = radem.data.ptr             # <<<<<<<<<<<<<<
 * 
 *     gradient = cp.zeros((outputArray.shape[0], outputArray.shape[1], 1),
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 168, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 168, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(4, 168, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_addr_radem = __pyx_t_3;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":170
 *     cdef uintptr_t addr_radem = radem.data.ptr
 * 
 *     gradient = cp.zeros((outputArray.shape[0], outputArray.shape[1], 1),             # <<<<<<<<<<<<<<
 *             dtype=cp.float64)
 *     cdef uintptr_t addr_gradient = gradient.data.ptr
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_cp); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 170, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_zeros); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 170, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 170, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 170, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 170, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 170, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 170, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_4);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_4)) __PYX_ERR(4, 170, __pyx_L1_error);
  __Pyx_GIVEREF(__pyx_t_5);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_t_5)) __PYX_ERR(4, 170, __pyx_L1_error);
  __Pyx_INCREF(__pyx_int_1);
  __Pyx_GIVEREF(__pyx_int_1);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_int_1)) __PYX_ERR(4, 170, __pyx_L1_error);
  __pyx_t_4 = 0;
  __pyx_t_5 = 0;
  __pyx_t_5 = PyTuple_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 170, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_GIVEREF(__pyx_t_1);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_1)) __PYX_ERR(4, 170, __pyx_L1_error);
  __pyx_t_1 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":171
 * 
 *     gradient = cp.zeros((outputArray.shape[0], outputArray.shape[1], 1),
 *             dtype=cp.float64)             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_gradient = gradient.data.ptr
 * 
 */
  __pyx_t_1 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 171, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_n_s_cp); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 171, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_float64); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 171, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_dtype, __pyx_t_6) < 0) __PYX_ERR(4, 171, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":170
 *     cdef uintptr_t addr_radem = radem.data.ptr
 * 
 *     gradient = cp.zeros((outputArray.shape[0], outputArray.shape[1], 1),             # <<<<<<<<<<<<<<
 *             dtype=cp.float64)
 *     cdef uintptr_t addr_gradient = gradient.data.ptr
 */
  __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, __pyx_t_1); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 170, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_gradient = __pyx_t_6;
  __pyx_t_6 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":172
 *     gradient = cp.zeros((outputArray.shape[0], outputArray.shape[1], 1),
 *             dtype=cp.float64)
 *     cdef uintptr_t addr_gradient = gradient.data.ptr             # <<<<<<<<<<<<<<
 * 
 *     if inputArray.shape[0] == 0:
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_gradient, __pyx_n_s_data); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 172, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 172, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(4, 172, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_addr_gradient = __pyx_t_3;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":174
 *     cdef uintptr_t addr_gradient = gradient.data.ptr
 * 
 *     if inputArray.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputArray.shape[1] != radem.shape[1] or inputArray.shape[2] != radem.shape[2]:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 174, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 174, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__Pyx_PyInt_BoolEqObjC(__pyx_t_6, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(4, 174, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (unlikely(__pyx_t_7)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":175
 * 
 *     if inputArray.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")             # <<<<<<<<<<<<<<
 *     if inputArray.shape[1] != radem.shape[1] or inputArray.shape[2] != radem.shape[2]:
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF feature gen function.")
 */
    __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__3, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 175, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_Raise(__pyx_t_6, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __PYX_ERR(4, 175, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":174
 *     cdef uintptr_t addr_gradient = gradient.data.ptr
 * 
 *     if inputArray.shape[0] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputArray.shape[1] != radem.shape[1] or inputArray.shape[2] != radem.shape[2]:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":176
 *     if inputArray.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputArray.shape[1] != radem.shape[1] or inputArray.shape[2] != radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF feature gen function.")
 *     if radem.shape[0] != 3:
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 176, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_6, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 176, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 176, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_6, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 176, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = PyObject_RichCompare(__pyx_t_1, __pyx_t_5, Py_NE); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 176, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_8 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely((__pyx_t_8 < 0))) __PYX_ERR(4, 176, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (!__pyx_t_8) {
  } else {
    __pyx_t_7 = __pyx_t_8;
    goto __pyx_L5_bool_binop_done;
  }
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 176, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_6, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 176, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 176, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_6, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 176, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = PyObject_RichCompare(__pyx_t_5, __pyx_t_1, Py_NE); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 176, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_8 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely((__pyx_t_8 < 0))) __PYX_ERR(4, 176, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_7 = __pyx_t_8;
  __pyx_L5_bool_binop_done:;
  if (unlikely(__pyx_t_7)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":177
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputArray.shape[1] != radem.shape[1] or inputArray.shape[2] != radem.shape[2]:
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF feature gen function.")             # <<<<<<<<<<<<<<
 *     if radem.shape[0] != 3:
 *         raise ValueError("radem must have length 3 for dim 0.")
 */
    __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__58, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 177, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_Raise(__pyx_t_6, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __PYX_ERR(4, 177, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":176
 *     if inputArray.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputArray.shape[1] != radem.shape[1] or inputArray.shape[2] != radem.shape[2]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF feature gen function.")
 *     if radem.shape[0] != 3:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":178
 *     if inputArray.shape[1] != radem.shape[1] or inputArray.shape[2] != radem.shape[2]:
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF feature gen function.")
 *     if radem.shape[0] != 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must have length 3 for dim 0.")
 *     if inputArray.shape[0] != outputArray.shape[0]:
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 178, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_6, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 178, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_7 = (__Pyx_PyInt_BoolNeObjC(__pyx_t_1, __pyx_int_3, 3, 0)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(4, 178, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (unlikely(__pyx_t_7)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":179
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF feature gen function.")
 *     if radem.shape[0] != 3:
 *         raise ValueError("radem must have length 3 for dim 0.")             # <<<<<<<<<<<<<<
 *     if inputArray.shape[0] != outputArray.shape[0]:
 *         raise ValueError("inputArray and outputArray to RBF feature gen must have same number "
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 179, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(4, 179, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":178
 *     if inputArray.shape[1] != radem.shape[1] or inputArray.shape[2] != radem.shape[2]:
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF feature gen function.")
 *     if radem.shape[0] != 3:             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must have length 3 for dim 0.")
 *     if inputArray.shape[0] != outputArray.shape[0]:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":180
 *     if radem.shape[0] != 3:
 *         raise ValueError("radem must have length 3 for dim 0.")
 *     if inputArray.shape[0] != outputArray.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("inputArray and outputArray to RBF feature gen must have same number "
 *                     "of datapoints.")
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 180, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 180, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 180, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 180, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyObject_RichCompare(__pyx_t_6, __pyx_t_5, Py_NE); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 180, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(4, 180, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (unlikely(__pyx_t_7)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":181
 *         raise ValueError("radem must have length 3 for dim 0.")
 *     if inputArray.shape[0] != outputArray.shape[0]:
 *         raise ValueError("inputArray and outputArray to RBF feature gen must have same number "             # <<<<<<<<<<<<<<
 *                     "of datapoints.")
 *     if outputArray.shape[1] != 2 * chiArr.shape[0]:
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__59, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 181, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(4, 181, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":180
 *     if radem.shape[0] != 3:
 *         raise ValueError("radem must have length 3 for dim 0.")
 *     if inputArray.shape[0] != outputArray.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("inputArray and outputArray to RBF feature gen must have same number "
 *                     "of datapoints.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":183
 *         raise ValueError("inputArray and outputArray to RBF feature gen must have same number "
 *                     "of datapoints.")
 *     if outputArray.shape[1] != 2 * chiArr.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr input to RBF feature gen is of incorrect size.")
 *     if 2 * inputArray.shape[1] * inputArray.shape[2] < outputArray.shape[1]:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 183, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 183, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 183, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 183, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyInt_MultiplyCObj(__pyx_int_2, __pyx_t_6, 2, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 183, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = PyObject_RichCompare(__pyx_t_5, __pyx_t_1, Py_NE); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 183, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(4, 183, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (unlikely(__pyx_t_7)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":184
 *                     "of datapoints.")
 *     if outputArray.shape[1] != 2 * chiArr.shape[0]:
 *         raise ValueError("chiArr input to RBF feature gen is of incorrect size.")             # <<<<<<<<<<<<<<
 *     if 2 * inputArray.shape[1] * inputArray.shape[2] < outputArray.shape[1]:
 *         raise ValueError("Sizes on input and output arrays to RBF feature gen are inappropriate.")
 */
    __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__60, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 184, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_Raise(__pyx_t_6, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __PYX_ERR(4, 184, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":183
 *         raise ValueError("inputArray and outputArray to RBF feature gen must have same number "
 *                     "of datapoints.")
 *     if outputArray.shape[1] != 2 * chiArr.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("chiArr input to RBF feature gen is of incorrect size.")
 *     if 2 * inputArray.shape[1] * inputArray.shape[2] < outputArray.shape[1]:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":185
 *     if outputArray.shape[1] != 2 * chiArr.shape[0]:
 *         raise ValueError("chiArr input to RBF feature gen is of incorrect size.")
 *     if 2 * inputArray.shape[1] * inputArray.shape[2] < outputArray.shape[1]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Sizes on input and output arrays to RBF feature gen are inappropriate.")
 * 
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 185, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_6, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 185, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = __Pyx_PyInt_MultiplyCObj(__pyx_int_2, __pyx_t_1, 2, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 185, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 185, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 185, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Multiply(__pyx_t_6, __pyx_t_5); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 185, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 185, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_5, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 185, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = PyObject_RichCompare(__pyx_t_1, __pyx_t_6, Py_LT); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 185, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(4, 185, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(__pyx_t_7)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":186
 *         raise ValueError("chiArr input to RBF feature gen is of incorrect size.")
 *     if 2 * inputArray.shape[1] * inputArray.shape[2] < outputArray.shape[1]:
 *         raise ValueError("Sizes on input and output arrays to RBF feature gen are inappropriate.")             # <<<<<<<<<<<<<<
 * 
 *     if not inputArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] or not \
 */
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__61, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 186, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(4, 186, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":185
 *     if outputArray.shape[1] != 2 * chiArr.shape[0]:
 *         raise ValueError("chiArr input to RBF feature gen is of incorrect size.")
 *     if 2 * inputArray.shape[1] * inputArray.shape[2] < outputArray.shape[1]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Sizes on input and output arrays to RBF feature gen are inappropriate.")
 * 
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":188
 *         raise ValueError("Sizes on input and output arrays to RBF feature gen are inappropriate.")
 * 
 *     if not inputArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] or not \             # <<<<<<<<<<<<<<
 *             chiArr.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_flags); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 188, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_PyObject_Dict_GetItem(__pyx_t_5, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 188, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_8 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely((__pyx_t_8 < 0))) __PYX_ERR(4, 188, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_9 = (!__pyx_t_8);
  if (!__pyx_t_9) {
  } else {
    __pyx_t_7 = __pyx_t_9;
    goto __pyx_L12_bool_binop_done;
  }
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_flags); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 188, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_5 = __Pyx_PyObject_Dict_GetItem(__pyx_t_6, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 188, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(4, 188, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_8 = (!__pyx_t_9);
  if (!__pyx_t_8) {
  } else {
    __pyx_t_7 = __pyx_t_8;
    goto __pyx_L12_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":189
 * 
 *     if not inputArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] or not \
 *             chiArr.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "
 *                 "C contiguous.")
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_flags); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 189, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_PyObject_Dict_GetItem(__pyx_t_5, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 189, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_8 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely((__pyx_t_8 < 0))) __PYX_ERR(4, 189, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":188
 *         raise ValueError("Sizes on input and output arrays to RBF feature gen are inappropriate.")
 * 
 *     if not inputArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] or not \             # <<<<<<<<<<<<<<
 *             chiArr.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "
 */
  __pyx_t_9 = (!__pyx_t_8);
  if (!__pyx_t_9) {
  } else {
    __pyx_t_7 = __pyx_t_9;
    goto __pyx_L12_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":189
 * 
 *     if not inputArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] or not \
 *             chiArr.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "
 *                 "C contiguous.")
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_flags); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 189, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_5 = __Pyx_PyObject_Dict_GetItem(__pyx_t_6, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 189, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(4, 189, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_8 = (!__pyx_t_9);
  __pyx_t_7 = __pyx_t_8;
  __pyx_L12_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":188
 *         raise ValueError("Sizes on input and output arrays to RBF feature gen are inappropriate.")
 * 
 *     if not inputArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] or not \             # <<<<<<<<<<<<<<
 *             chiArr.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "
 */
  if (unlikely(__pyx_t_7)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":190
 *     if not inputArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] or not \
 *             chiArr.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "             # <<<<<<<<<<<<<<
 *                 "C contiguous.")
 *     if not radem.dtype == "int8":
 */
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__57, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 190, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(4, 190, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":188
 *         raise ValueError("Sizes on input and output arrays to RBF feature gen are inappropriate.")
 * 
 *     if not inputArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] or not \             # <<<<<<<<<<<<<<
 *             chiArr.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":192
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "
 *                 "C contiguous.")
 *     if not radem.dtype == "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be of type int8.")
 *     logdim = np.log2(inputArray.shape[2])
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_radem, __pyx_n_s_dtype); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 192, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_5, __pyx_n_u_int8, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(4, 192, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_8 = (!__pyx_t_7);
  if (unlikely(__pyx_t_8)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":193
 *                 "C contiguous.")
 *     if not radem.dtype == "int8":
 *         raise ValueError("radem must be of type int8.")             # <<<<<<<<<<<<<<
 *     logdim = np.log2(inputArray.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or inputArray.shape[2] < 2:
 */
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__7, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 193, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(4, 193, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":192
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "
 *                 "C contiguous.")
 *     if not radem.dtype == "int8":             # <<<<<<<<<<<<<<
 *         raise ValueError("radem must be of type int8.")
 *     logdim = np.log2(inputArray.shape[2])
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":194
 *     if not radem.dtype == "int8":
 *         raise ValueError("radem must be of type int8.")
 *     logdim = np.log2(inputArray.shape[2])             # <<<<<<<<<<<<<<
 *     if np.ceil(logdim) != np.floor(logdim) or inputArray.shape[2] < 2:
 *         raise ValueError("dim2 of the input array to RBF feature gen functions "
 */
  __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_np); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 194, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_log2); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 194, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 194, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_6, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 194, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = NULL;
  __pyx_t_10 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
      __pyx_t_10 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_6, __pyx_t_2};
    __pyx_t_5 = __Pyx_PyObject_FastCall(__pyx_t_1, __pyx_callargs+1-__pyx_t_10, 1+__pyx_t_10);
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 194, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __pyx_t_11 = __pyx_PyFloat_AsFloat(__pyx_t_5); if (unlikely((__pyx_t_11 == (float)-1) && PyErr_Occurred())) __PYX_ERR(4, 194, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_logdim = __pyx_t_11;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":195
 *         raise ValueError("radem must be of type int8.")
 *     logdim = np.log2(inputArray.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or inputArray.shape[2] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim2 of the input array to RBF feature gen functions "
 *                             "must be a power of 2 >= 2.")
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 195, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ceil); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 195, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyFloat_FromDouble(__pyx_v_logdim); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 195, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = NULL;
  __pyx_t_10 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_10 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_6, __pyx_t_1};
    __pyx_t_5 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+1-__pyx_t_10, 1+__pyx_t_10);
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 195, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 195, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_floor); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 195, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyFloat_FromDouble(__pyx_v_logdim); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 195, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = NULL;
  __pyx_t_10 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
      __pyx_t_10 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_4, __pyx_t_1};
    __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_6, __pyx_callargs+1-__pyx_t_10, 1+__pyx_t_10);
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 195, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __pyx_t_6 = PyObject_RichCompare(__pyx_t_5, __pyx_t_2, Py_NE); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 195, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(4, 195, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (!__pyx_t_7) {
  } else {
    __pyx_t_8 = __pyx_t_7;
    goto __pyx_L18_bool_binop_done;
  }
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 195, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_6, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 195, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = PyObject_RichCompare(__pyx_t_2, __pyx_int_2, Py_LT); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 195, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(4, 195, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_8 = __pyx_t_7;
  __pyx_L18_bool_binop_done:;
  if (unlikely(__pyx_t_8)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":196
 *     logdim = np.log2(inputArray.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or inputArray.shape[2] < 2:
 *         raise ValueError("dim2 of the input array to RBF feature gen functions "             # <<<<<<<<<<<<<<
 *                             "must be a power of 2 >= 2.")
 * 
 */
    __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__62, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 196, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_Raise(__pyx_t_6, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __PYX_ERR(4, 196, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":195
 *         raise ValueError("radem must be of type int8.")
 *     logdim = np.log2(inputArray.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or inputArray.shape[2] < 2:             # <<<<<<<<<<<<<<
 *         raise ValueError("dim2 of the input array to RBF feature gen functions "
 *                             "must be a power of 2 >= 2.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":200
 * 
 * 
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         rbfNormConstant = betaHparam * np.sqrt(2.0 / (<double>chiArr.shape[0] - 0.5))
 *     else:
 */
  __pyx_t_8 = (__pyx_v_fitIntercept != 0);
  if (__pyx_t_8) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":201
 * 
 *     if fitIntercept:
 *         rbfNormConstant = betaHparam * np.sqrt(2.0 / (<double>chiArr.shape[0] - 0.5))             # <<<<<<<<<<<<<<
 *     else:
 *         rbfNormConstant = betaHparam * np.sqrt(2 / <double>chiArr.shape[0])
 */
    __pyx_t_6 = PyFloat_FromDouble(__pyx_v_betaHparam); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 201, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_n_s_np); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 201, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_sqrt); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 201, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 201, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_4 = __Pyx_GetItemInt(__pyx_t_5, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 201, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_12 = __pyx_PyFloat_AsDouble(__pyx_t_4); if (unlikely((__pyx_t_12 == (double)-1) && PyErr_Occurred())) __PYX_ERR(4, 201, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_13 = (((double)__pyx_t_12) - 0.5);
    if (unlikely(__pyx_t_13 == 0)) {
      PyErr_SetString(PyExc_ZeroDivisionError, "float division");
      __PYX_ERR(4, 201, __pyx_L1_error)
    }
    __pyx_t_4 = PyFloat_FromDouble((2.0 / __pyx_t_13)); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 201, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = NULL;
    __pyx_t_10 = 0;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
        __pyx_t_10 = 1;
      }
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_5, __pyx_t_4};
      __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_1, __pyx_callargs+1-__pyx_t_10, 1+__pyx_t_10);
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 201, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    }
    __pyx_t_1 = PyNumber_Multiply(__pyx_t_6, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 201, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_13 = __pyx_PyFloat_AsDouble(__pyx_t_1); if (unlikely((__pyx_t_13 == (double)-1) && PyErr_Occurred())) __PYX_ERR(4, 201, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_rbfNormConstant = __pyx_t_13;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":200
 * 
 * 
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         rbfNormConstant = betaHparam * np.sqrt(2.0 / (<double>chiArr.shape[0] - 0.5))
 *     else:
 */
    goto __pyx_L20;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":203
 *         rbfNormConstant = betaHparam * np.sqrt(2.0 / (<double>chiArr.shape[0] - 0.5))
 *     else:
 *         rbfNormConstant = betaHparam * np.sqrt(2 / <double>chiArr.shape[0])             # <<<<<<<<<<<<<<
 * 
 *     if inputArray.dtype == "float32" and outputArray.dtype == "float64" and \
 */
  /*else*/ {
    __pyx_t_1 = PyFloat_FromDouble(__pyx_v_betaHparam); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 203, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_n_s_np); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 203, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_sqrt); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 203, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 203, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_6, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 203, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_13 = __pyx_PyFloat_AsDouble(__pyx_t_5); if (unlikely((__pyx_t_13 == (double)-1) && PyErr_Occurred())) __PYX_ERR(4, 203, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(((double)__pyx_t_13) == 0)) {
      PyErr_SetString(PyExc_ZeroDivisionError, "float division");
      __PYX_ERR(4, 203, __pyx_L1_error)
    }
    __pyx_t_5 = PyFloat_FromDouble((2.0 / ((double)__pyx_t_13))); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 203, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = NULL;
    __pyx_t_10 = 0;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
        __pyx_t_10 = 1;
      }
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_6, __pyx_t_5};
      __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_4, __pyx_callargs+1-__pyx_t_10, 1+__pyx_t_10);
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 203, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    }
    __pyx_t_4 = PyNumber_Multiply(__pyx_t_1, __pyx_t_2); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 203, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_13 = __pyx_PyFloat_AsDouble(__pyx_t_4); if (unlikely((__pyx_t_13 == (double)-1) && PyErr_Occurred())) __PYX_ERR(4, 203, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_v_rbfNormConstant = __pyx_t_13;
  }
  __pyx_L20:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":205
 *         rbfNormConstant = betaHparam * np.sqrt(2 / <double>chiArr.shape[0])
 * 
 *     if inputArray.dtype == "float32" and outputArray.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         errCode = RBFFeatureGrad[float](<float*>addr_input, <int8_t*>addr_radem,
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 205, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_4, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(4, 205, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (__pyx_t_7) {
  } else {
    __pyx_t_8 = __pyx_t_7;
    goto __pyx_L22_bool_binop_done;
  }
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 205, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_4, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(4, 205, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (__pyx_t_7) {
  } else {
    __pyx_t_8 = __pyx_t_7;
    goto __pyx_L22_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":206
 * 
 *     if inputArray.dtype == "float32" and outputArray.dtype == "float64" and \
 *             chiArr.dtype == "float32":             # <<<<<<<<<<<<<<
 *         errCode = RBFFeatureGrad[float](<float*>addr_input, <int8_t*>addr_radem,
 *                 <float*>addr_chi, <double*>addr_output, <double*>addr_gradient,
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_dtype); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 206, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_4, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(4, 206, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_8 = __pyx_t_7;
  __pyx_L22_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":205
 *         rbfNormConstant = betaHparam * np.sqrt(2 / <double>chiArr.shape[0])
 * 
 *     if inputArray.dtype == "float32" and outputArray.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         errCode = RBFFeatureGrad[float](<float*>addr_input, <int8_t*>addr_radem,
 */
  if (__pyx_t_8) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":210
 *                 <float*>addr_chi, <double*>addr_output, <double*>addr_gradient,
 *                 rbfNormConstant, sigmaHparam,
 *                 inputArray.shape[0], inputArray.shape[1],             # <<<<<<<<<<<<<<
 *                 inputArray.shape[2], chiArr.shape[0]);
 *     elif inputArray.dtype == "float64" and outputArray.dtype == "float64" and \
 */
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 210, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_4, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 210, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_10 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_10 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 210, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 210, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 210, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_14 = __Pyx_PyInt_As_int(__pyx_t_4); if (unlikely((__pyx_t_14 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 210, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":211
 *                 rbfNormConstant, sigmaHparam,
 *                 inputArray.shape[0], inputArray.shape[1],
 *                 inputArray.shape[2], chiArr.shape[0]);             # <<<<<<<<<<<<<<
 *     elif inputArray.dtype == "float64" and outputArray.dtype == "float64" and \
 *             chiArr.dtype == "float64":
 */
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 211, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_4, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 211, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_15 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_15 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 211, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 211, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 211, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_16 = __Pyx_PyInt_As_int(__pyx_t_4); if (unlikely((__pyx_t_16 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 211, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":207
 *     if inputArray.dtype == "float32" and outputArray.dtype == "float64" and \
 *             chiArr.dtype == "float32":
 *         errCode = RBFFeatureGrad[float](<float*>addr_input, <int8_t*>addr_radem,             # <<<<<<<<<<<<<<
 *                 <float*>addr_chi, <double*>addr_output, <double*>addr_gradient,
 *                 rbfNormConstant, sigmaHparam,
 */
    __pyx_v_errCode = RBFFeatureGrad<float>(((float *)__pyx_v_addr_input), ((int8_t *)__pyx_v_addr_radem), ((float *)__pyx_v_addr_chi), ((double *)__pyx_v_addr_output), ((double *)__pyx_v_addr_gradient), __pyx_v_rbfNormConstant, __pyx_v_sigmaHparam, __pyx_t_10, __pyx_t_14, __pyx_t_15, __pyx_t_16);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":205
 *         rbfNormConstant = betaHparam * np.sqrt(2 / <double>chiArr.shape[0])
 * 
 *     if inputArray.dtype == "float32" and outputArray.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float32":
 *         errCode = RBFFeatureGrad[float](<float*>addr_input, <int8_t*>addr_radem,
 */
    goto __pyx_L21;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":212
 *                 inputArray.shape[0], inputArray.shape[1],
 *                 inputArray.shape[2], chiArr.shape[0]);
 *     elif inputArray.dtype == "float64" and outputArray.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         errCode = RBFFeatureGrad[double](<double*>addr_input, <int8_t*>addr_radem,
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 212, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_4, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(4, 212, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (__pyx_t_7) {
  } else {
    __pyx_t_8 = __pyx_t_7;
    goto __pyx_L25_bool_binop_done;
  }
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 212, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_4, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(4, 212, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (__pyx_t_7) {
  } else {
    __pyx_t_8 = __pyx_t_7;
    goto __pyx_L25_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":213
 *                 inputArray.shape[2], chiArr.shape[0]);
 *     elif inputArray.dtype == "float64" and outputArray.dtype == "float64" and \
 *             chiArr.dtype == "float64":             # <<<<<<<<<<<<<<
 *         errCode = RBFFeatureGrad[double](<double*>addr_input, <int8_t*>addr_radem,
 *                 <double*>addr_chi, <double*>addr_output, <double*>addr_gradient,
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_dtype); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 213, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_4, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(4, 213, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_8 = __pyx_t_7;
  __pyx_L25_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":212
 *                 inputArray.shape[0], inputArray.shape[1],
 *                 inputArray.shape[2], chiArr.shape[0]);
 *     elif inputArray.dtype == "float64" and outputArray.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         errCode = RBFFeatureGrad[double](<double*>addr_input, <int8_t*>addr_radem,
 */
  if (likely(__pyx_t_8)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":217
 *                 <double*>addr_chi, <double*>addr_output, <double*>addr_gradient,
 *                 rbfNormConstant, sigmaHparam,
 *                 inputArray.shape[0], inputArray.shape[1],             # <<<<<<<<<<<<<<
 *                 inputArray.shape[2], chiArr.shape[0]);
 *     else:
 */
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 217, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_4, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 217, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_16 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_16 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 217, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 217, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 217, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_15 = __Pyx_PyInt_As_int(__pyx_t_4); if (unlikely((__pyx_t_15 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 217, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":218
 *                 rbfNormConstant, sigmaHparam,
 *                 inputArray.shape[0], inputArray.shape[1],
 *                 inputArray.shape[2], chiArr.shape[0]);             # <<<<<<<<<<<<<<
 *     else:
 *         raise ValueError("The input and chiArr arrays are of inconsistent types.")
 */
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 218, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_4, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 218, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_14 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_14 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 218, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_chiArr, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 218, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 218, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_10 = __Pyx_PyInt_As_int(__pyx_t_4); if (unlikely((__pyx_t_10 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 218, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":214
 *     elif inputArray.dtype == "float64" and outputArray.dtype == "float64" and \
 *             chiArr.dtype == "float64":
 *         errCode = RBFFeatureGrad[double](<double*>addr_input, <int8_t*>addr_radem,             # <<<<<<<<<<<<<<
 *                 <double*>addr_chi, <double*>addr_output, <double*>addr_gradient,
 *                 rbfNormConstant, sigmaHparam,
 */
    __pyx_v_errCode = RBFFeatureGrad<double>(((double *)__pyx_v_addr_input), ((int8_t *)__pyx_v_addr_radem), ((double *)__pyx_v_addr_chi), ((double *)__pyx_v_addr_output), ((double *)__pyx_v_addr_gradient), __pyx_v_rbfNormConstant, __pyx_v_sigmaHparam, __pyx_t_16, __pyx_t_15, __pyx_t_14, __pyx_t_10);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":212
 *                 inputArray.shape[0], inputArray.shape[1],
 *                 inputArray.shape[2], chiArr.shape[0]);
 *     elif inputArray.dtype == "float64" and outputArray.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             chiArr.dtype == "float64":
 *         errCode = RBFFeatureGrad[double](<double*>addr_input, <int8_t*>addr_radem,
 */
    goto __pyx_L21;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":220
 *                 inputArray.shape[2], chiArr.shape[0]);
 *     else:
 *         raise ValueError("The input and chiArr arrays are of inconsistent types.")             # <<<<<<<<<<<<<<
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered in doubleCudaRBFFeatureGen.")
 */
  /*else*/ {
    __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__63, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 220, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_Raise(__pyx_t_4, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __PYX_ERR(4, 220, __pyx_L1_error)
  }
  __pyx_L21:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":221
 *     else:
 *         raise ValueError("The input and chiArr arrays are of inconsistent types.")
 *     if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *         raise Exception("Fatal error encountered in doubleCudaRBFFeatureGen.")
 *     if fitIntercept:
 */
  __pyx_t_17 = __Pyx_ssize_strlen(__pyx_v_errCode); if (unlikely(__pyx_t_17 == ((Py_ssize_t)-1))) __PYX_ERR(4, 221, __pyx_L1_error)
  __pyx_t_4 = __Pyx_decode_c_string(__pyx_v_errCode, 0, __pyx_t_17, NULL, NULL, PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 221, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_8 = (__Pyx_PyUnicode_Equals(__pyx_t_4, __pyx_n_u_no_error, Py_NE)); if (unlikely((__pyx_t_8 < 0))) __PYX_ERR(4, 221, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (unlikely(__pyx_t_8)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":222
 *         raise ValueError("The input and chiArr arrays are of inconsistent types.")
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered in doubleCudaRBFFeatureGen.")             # <<<<<<<<<<<<<<
 *     if fitIntercept:
 *         outputArray[:,0] = betaHparam
 */
    __pyx_t_4 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__65, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 222, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_Raise(__pyx_t_4, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __PYX_ERR(4, 222, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":221
 *     else:
 *         raise ValueError("The input and chiArr arrays are of inconsistent types.")
 *     if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *         raise Exception("Fatal error encountered in doubleCudaRBFFeatureGen.")
 *     if fitIntercept:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":223
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered in doubleCudaRBFFeatureGen.")
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         outputArray[:,0] = betaHparam
 *         gradient[:,0] = 0
 */
  __pyx_t_8 = (__pyx_v_fitIntercept != 0);
  if (__pyx_t_8) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":224
 *         raise Exception("Fatal error encountered in doubleCudaRBFFeatureGen.")
 *     if fitIntercept:
 *         outputArray[:,0] = betaHparam             # <<<<<<<<<<<<<<
 *         gradient[:,0] = 0
 *     return gradient
 */
    __pyx_t_4 = PyFloat_FromDouble(__pyx_v_betaHparam); if (unlikely(!__pyx_t_4)) __PYX_ERR(4, 224, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    if (unlikely((PyObject_SetItem(__pyx_v_outputArray, __pyx_tuple__38, __pyx_t_4) < 0))) __PYX_ERR(4, 224, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":225
 *     if fitIntercept:
 *         outputArray[:,0] = betaHparam
 *         gradient[:,0] = 0             # <<<<<<<<<<<<<<
 *     return gradient
 * 
 */
    if (unlikely((PyObject_SetItem(__pyx_v_gradient, __pyx_tuple__38, __pyx_int_0) < 0))) __PYX_ERR(4, 225, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":223
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered in doubleCudaRBFFeatureGen.")
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         outputArray[:,0] = betaHparam
 *         gradient[:,0] = 0
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":226
 *         outputArray[:,0] = betaHparam
 *         gradient[:,0] = 0
 *     return gradient             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_gradient);
  __pyx_r = __pyx_v_gradient;
  goto __pyx_L0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":130
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaRBFGrad(inputArray, outputArray, radem,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("cuda_rf_gen_module.cudaRBFGrad", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_gradient);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":232
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaMiniARDGrad(inputX, outputArray, precompWeights,
 */

/* Python wrapper */
static PyObject *__pyx_pw_18cuda_rf_gen_module_23cudaMiniARDGrad(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_18cuda_rf_gen_module_22cudaMiniARDGrad, "Performs gradient calculations for the MiniARD kernel, using\n    pregenerated features and precomputed weights.\n\n    Args:\n        inputX (np.ndarray): The original input data.\n        outputArray (np.ndarray): The random features generated using the FHT-\n            based procedure.\n        precompWeights (np.ndarray): The FHT-rf gen procedure applied to an\n            identity matrix.\n        sigmaMap (np.ndarray): An array mapping which lengthscales correspond\n            to which positions in the input.\n        sigmaVals (cp.ndarray): The lengthscale values, in an array of the same\n            dimensionality as the input.\n        betaHparam (double): The amplitude hyperparameter.\n        numThreads (int): Number of threads to run.\n        fitIntercept (bool): Whether to fit a y-intercept (in this case,\n            the first random feature generated should be set to 1).\n\n    Raises:\n        ValueError: A ValueError is raised if unexpected or unacceptable inputs\n            are supplied.\n\n    Returns:\n        gradient (np.ndarray): An array of shape (N x 2 * numFreqs x 1) containing\n            the gradient w/r/t sigma.\n    ");
static PyMethodDef __pyx_mdef_18cuda_rf_gen_module_23cudaMiniARDGrad = {"cudaMiniARDGrad", (PyCFunction)(void*)(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_18cuda_rf_gen_module_23cudaMiniARDGrad, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_18cuda_rf_gen_module_22cudaMiniARDGrad};
static PyObject *__pyx_pw_18cuda_rf_gen_module_23cudaMiniARDGrad(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_inputX = 0;
  PyObject *__pyx_v_outputArray = 0;
  PyObject *__pyx_v_precompWeights = 0;
  PyObject *__pyx_v_sigmaMap = 0;
  PyObject *__pyx_v_sigmaVals = 0;
  double __pyx_v_betaHparam;
  CYTHON_UNUSED int __pyx_v_numThreads;
  bool __pyx_v_fitIntercept;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[8] = {0,0,0,0,0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cudaMiniARDGrad (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_MACROS
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject **__pyx_pyargnames[] = {&__pyx_n_s_inputX,&__pyx_n_s_outputArray,&__pyx_n_s_precompWeights,&__pyx_n_s_sigmaMap,&__pyx_n_s_sigmaVals,&__pyx_n_s_betaHparam,&__pyx_n_s_numThreads,&__pyx_n_s_fitIntercept,0};
    if (__pyx_kwds) {
      Py_ssize_t kw_args;
      switch (__pyx_nargs) {
        case  8: values[7] = __Pyx_Arg_FASTCALL(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = __Pyx_Arg_FASTCALL(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = __Pyx_Arg_FASTCALL(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = __Pyx_NumKwargs_FASTCALL(__pyx_kwds);
      switch (__pyx_nargs) {
        case  0:
        if (likely((values[0] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_inputX)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[0]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 232, __pyx_L3_error)
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_outputArray)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[1]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 232, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaMiniARDGrad", 0, 7, 8, 1); __PYX_ERR(4, 232, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_precompWeights)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[2]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 232, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaMiniARDGrad", 0, 7, 8, 2); __PYX_ERR(4, 232, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_sigmaMap)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[3]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 232, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaMiniARDGrad", 0, 7, 8, 3); __PYX_ERR(4, 232, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_sigmaVals)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[4]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 232, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaMiniARDGrad", 0, 7, 8, 4); __PYX_ERR(4, 232, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_betaHparam)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[5]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 232, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaMiniARDGrad", 0, 7, 8, 5); __PYX_ERR(4, 232, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (likely((values[6] = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_numThreads)) != 0)) {
          (void)__Pyx_Arg_NewRef_FASTCALL(values[6]);
          kw_args--;
        }
        else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 232, __pyx_L3_error)
        else {
          __Pyx_RaiseArgtupleInvalid("cudaMiniARDGrad", 0, 7, 8, 6); __PYX_ERR(4, 232, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (kw_args > 0) {
          PyObject* value = __Pyx_GetKwValue_FASTCALL(__pyx_kwds, __pyx_kwvalues, __pyx_n_s_fitIntercept);
          if (value) { values[7] = __Pyx_Arg_NewRef_FASTCALL(value); kw_args--; }
          else if (unlikely(PyErr_Occurred())) __PYX_ERR(4, 232, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        const Py_ssize_t kwd_pos_args = __pyx_nargs;
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values + 0, kwd_pos_args, "cudaMiniARDGrad") < 0)) __PYX_ERR(4, 232, __pyx_L3_error)
      }
    } else {
      switch (__pyx_nargs) {
        case  8: values[7] = __Pyx_Arg_FASTCALL(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = __Pyx_Arg_FASTCALL(__pyx_args, 6);
        values[5] = __Pyx_Arg_FASTCALL(__pyx_args, 5);
        values[4] = __Pyx_Arg_FASTCALL(__pyx_args, 4);
        values[3] = __Pyx_Arg_FASTCALL(__pyx_args, 3);
        values[2] = __Pyx_Arg_FASTCALL(__pyx_args, 2);
        values[1] = __Pyx_Arg_FASTCALL(__pyx_args, 1);
        values[0] = __Pyx_Arg_FASTCALL(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_inputX = values[0];
    __pyx_v_outputArray = values[1];
    __pyx_v_precompWeights = values[2];
    __pyx_v_sigmaMap = values[3];
    __pyx_v_sigmaVals = values[4];
    __pyx_v_betaHparam = __pyx_PyFloat_AsDouble(values[5]); if (unlikely((__pyx_v_betaHparam == (double)-1) && PyErr_Occurred())) __PYX_ERR(4, 235, __pyx_L3_error)
    __pyx_v_numThreads = __Pyx_PyInt_As_int(values[6]); if (unlikely((__pyx_v_numThreads == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 235, __pyx_L3_error)
    if (values[7]) {
      __pyx_v_fitIntercept = __Pyx_PyObject_IsTrue(values[7]); if (unlikely((__pyx_v_fitIntercept == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(4, 236, __pyx_L3_error)
    } else {

      /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":236
 * def cudaMiniARDGrad(inputX, outputArray, precompWeights,
 *                 sigmaMap, sigmaVals, double betaHparam, int numThreads,
 *                 bool fitIntercept = False):             # <<<<<<<<<<<<<<
 *     """Performs gradient calculations for the MiniARD kernel, using
 *     pregenerated features and precomputed weights.
 */
      __pyx_v_fitIntercept = ((bool)((int)0));
    }
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cudaMiniARDGrad", 0, 7, 8, __pyx_nargs); __PYX_ERR(4, 232, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_AddTraceback("cuda_rf_gen_module.cudaMiniARDGrad", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_18cuda_rf_gen_module_22cudaMiniARDGrad(__pyx_self, __pyx_v_inputX, __pyx_v_outputArray, __pyx_v_precompWeights, __pyx_v_sigmaMap, __pyx_v_sigmaVals, __pyx_v_betaHparam, __pyx_v_numThreads, __pyx_v_fitIntercept);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":232
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaMiniARDGrad(inputX, outputArray, precompWeights,
 */

  /* function exit code */
  {
    Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
      __Pyx_Arg_XDECREF_FASTCALL(values[__pyx_temp]);
    }
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_18cuda_rf_gen_module_22cudaMiniARDGrad(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_inputX, PyObject *__pyx_v_outputArray, PyObject *__pyx_v_precompWeights, PyObject *__pyx_v_sigmaMap, PyObject *__pyx_v_sigmaVals, double __pyx_v_betaHparam, CYTHON_UNUSED int __pyx_v_numThreads, bool __pyx_v_fitIntercept) {
  char const *__pyx_v_errCode;
  double __pyx_v_rbfNormConstant;
  int __pyx_v_numLengthscales;
  PyObject *__pyx_v_gradient = NULL;
  uintptr_t __pyx_v_addr_input;
  uintptr_t __pyx_v_addr_random_feats;
  uintptr_t __pyx_v_addr_sigma_map;
  CYTHON_UNUSED int32_t *__pyx_v_sigmaMap_ptr;
  uintptr_t __pyx_v_addr_sigma_vals;
  uintptr_t __pyx_v_addr_grad;
  uintptr_t __pyx_v_addr_precomp_weights;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_t_8;
  Py_ssize_t __pyx_t_9;
  int __pyx_t_10;
  int __pyx_t_11;
  uintptr_t __pyx_t_12;
  double __pyx_t_13;
  double __pyx_t_14;
  int __pyx_t_15;
  int __pyx_t_16;
  int __pyx_t_17;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("cudaMiniARDGrad", 1);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":266
 *     cdef float logdim
 *     cdef double rbfNormConstant
 *     cdef int numLengthscales = sigmaMap.max() + 1             # <<<<<<<<<<<<<<
 *     gradient = cp.zeros((outputArray.shape[0],
 *                         outputArray.shape[1], numLengthscales))
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_sigmaMap, __pyx_n_s_max); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 266, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  __pyx_t_4 = 0;
  #if CYTHON_UNPACK_METHODS
  if (likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_4 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_3, NULL};
    __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+1-__pyx_t_4, 0+__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 266, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __pyx_t_2 = __Pyx_PyInt_AddObjC(__pyx_t_1, __pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 266, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 266, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_numLengthscales = __pyx_t_4;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":267
 *     cdef double rbfNormConstant
 *     cdef int numLengthscales = sigmaMap.max() + 1
 *     gradient = cp.zeros((outputArray.shape[0],             # <<<<<<<<<<<<<<
 *                         outputArray.shape[1], numLengthscales))
 * 
 */
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_n_s_cp); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 267, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_zeros); if (unlikely(!__pyx_t_3)) __PYX_ERR(4, 267, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 267, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(4, 267, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":268
 *     cdef int numLengthscales = sigmaMap.max() + 1
 *     gradient = cp.zeros((outputArray.shape[0],
 *                         outputArray.shape[1], numLengthscales))             # <<<<<<<<<<<<<<
 * 
 *     if len(inputX.shape) != 2 or len(outputArray.shape) != 2 or \
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 268, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 268, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_numLengthscales); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 268, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":267
 *     cdef double rbfNormConstant
 *     cdef int numLengthscales = sigmaMap.max() + 1
 *     gradient = cp.zeros((outputArray.shape[0],             # <<<<<<<<<<<<<<
 *                         outputArray.shape[1], numLengthscales))
 * 
 */
  __pyx_t_7 = PyTuple_New(3); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 267, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_GIVEREF(__pyx_t_5);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_5)) __PYX_ERR(4, 267, __pyx_L1_error);
  __Pyx_GIVEREF(__pyx_t_6);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_t_6)) __PYX_ERR(4, 267, __pyx_L1_error);
  __Pyx_GIVEREF(__pyx_t_1);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_7, 2, __pyx_t_1)) __PYX_ERR(4, 267, __pyx_L1_error);
  __pyx_t_5 = 0;
  __pyx_t_6 = 0;
  __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  __pyx_t_4 = 0;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_1, __pyx_t_7};
    __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_3, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 267, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  }
  __pyx_v_gradient = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":270
 *                         outputArray.shape[1], numLengthscales))
 * 
 *     if len(inputX.shape) != 2 or len(outputArray.shape) != 2 or \             # <<<<<<<<<<<<<<
 *             len(precompWeights.shape) != 2 or len(sigmaMap.shape) != 1:
 *         raise ValueError("The input arrays to a wrapped RBF feature gen function have incorrect "
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 270, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_9 = PyObject_Length(__pyx_t_2); if (unlikely(__pyx_t_9 == ((Py_ssize_t)-1))) __PYX_ERR(4, 270, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_10 = (__pyx_t_9 != 2);
  if (!__pyx_t_10) {
  } else {
    __pyx_t_8 = __pyx_t_10;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 270, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_9 = PyObject_Length(__pyx_t_2); if (unlikely(__pyx_t_9 == ((Py_ssize_t)-1))) __PYX_ERR(4, 270, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_10 = (__pyx_t_9 != 2);
  if (!__pyx_t_10) {
  } else {
    __pyx_t_8 = __pyx_t_10;
    goto __pyx_L4_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":271
 * 
 *     if len(inputX.shape) != 2 or len(outputArray.shape) != 2 or \
 *             len(precompWeights.shape) != 2 or len(sigmaMap.shape) != 1:             # <<<<<<<<<<<<<<
 *         raise ValueError("The input arrays to a wrapped RBF feature gen function have incorrect "
 *                 "shapes.")
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_precompWeights, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 271, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_9 = PyObject_Length(__pyx_t_2); if (unlikely(__pyx_t_9 == ((Py_ssize_t)-1))) __PYX_ERR(4, 271, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_10 = (__pyx_t_9 != 2);
  if (!__pyx_t_10) {
  } else {
    __pyx_t_8 = __pyx_t_10;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_sigmaMap, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 271, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_9 = PyObject_Length(__pyx_t_2); if (unlikely(__pyx_t_9 == ((Py_ssize_t)-1))) __PYX_ERR(4, 271, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_10 = (__pyx_t_9 != 1);
  __pyx_t_8 = __pyx_t_10;
  __pyx_L4_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":270
 *                         outputArray.shape[1], numLengthscales))
 * 
 *     if len(inputX.shape) != 2 or len(outputArray.shape) != 2 or \             # <<<<<<<<<<<<<<
 *             len(precompWeights.shape) != 2 or len(sigmaMap.shape) != 1:
 *         raise ValueError("The input arrays to a wrapped RBF feature gen function have incorrect "
 */
  if (unlikely(__pyx_t_8)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":272
 *     if len(inputX.shape) != 2 or len(outputArray.shape) != 2 or \
 *             len(precompWeights.shape) != 2 or len(sigmaMap.shape) != 1:
 *         raise ValueError("The input arrays to a wrapped RBF feature gen function have incorrect "             # <<<<<<<<<<<<<<
 *                 "shapes.")
 * 
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__66, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 272, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(4, 272, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":270
 *                         outputArray.shape[1], numLengthscales))
 * 
 *     if len(inputX.shape) != 2 or len(outputArray.shape) != 2 or \             # <<<<<<<<<<<<<<
 *             len(precompWeights.shape) != 2 or len(sigmaMap.shape) != 1:
 *         raise ValueError("The input arrays to a wrapped RBF feature gen function have incorrect "
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":275
 *                 "shapes.")
 * 
 *     if inputX.shape[0] == 0 or inputX.shape[1] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputX.shape[0] != outputArray.shape[0] or precompWeights.shape[1] != inputX.shape[1]:
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 275, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(4, 275, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_10 = (__Pyx_PyInt_BoolEqObjC(__pyx_t_3, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_10 < 0))) __PYX_ERR(4, 275, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (!__pyx_t_10) {
  } else {
    __pyx_t_8 = __pyx_t_10;
    goto __pyx_L9_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputX, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(4, 275, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 275, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_10 = (__Pyx_PyInt_BoolEqObjC(__pyx_t_2, __pyx_int_0, 0, 0)); if (unlikely((__pyx_t_10 < 0))) __PYX_ERR(4, 275, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_8 = __pyx_t_10;
  __pyx_L9_bool_binop_done:;
  if (unlikely(__pyx_t_8)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":276
 * 
 *     if inputX.shape[0] == 0 or inputX.shape[1] == 0:
 *         raise ValueError("There must be at least one datapoint.")             # <<<<<<<<<<<<<<
 *     if inputX.shape[0] != outputArray.shape[0] or precompWeights.shape[1] != inputX.shape[1]:
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF "
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 276, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(4, 276, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":275
 *                 "shapes.")
 * 
 *     if inputX.shape[0] == 0 or inputX.shape[1] == 0:             # <<<<<<<<<<<<<<
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputX.shape[0] != outputArray.shape[0] or precompWeights.shape[1] != inputX.shape[1]:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":277
 *     if inputX.shape[0] == 0 or inputX.shape[1] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputX.shape[0] != outputArray.shape[0] or precompWeights.shape[1] != inputX.shape[1]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF "
 *                     "feature gen function.")
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 277, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(4, 277, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 277, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 277, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_3, __pyx_t_7, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 277, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_10 < 0))) __PYX_ERR(4, 277, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!__pyx_t_10) {
  } else {
    __pyx_t_8 = __pyx_t_10;
    goto __pyx_L12_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_precompWeights, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 277, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 277, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputX, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 277, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(4, 277, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_7, __pyx_t_3, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 277, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_10 < 0))) __PYX_ERR(4, 277, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_8 = __pyx_t_10;
  __pyx_L12_bool_binop_done:;
  if (unlikely(__pyx_t_8)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":278
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputX.shape[0] != outputArray.shape[0] or precompWeights.shape[1] != inputX.shape[1]:
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF "             # <<<<<<<<<<<<<<
 *                     "feature gen function.")
 *     if outputArray.shape[1] != 2 * precompWeights.shape[0] or sigmaMap.shape[0] != \
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__58, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 278, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(4, 278, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":277
 *     if inputX.shape[0] == 0 or inputX.shape[1] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputX.shape[0] != outputArray.shape[0] or precompWeights.shape[1] != inputX.shape[1]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF "
 *                     "feature gen function.")
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":280
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF "
 *                     "feature gen function.")
 *     if outputArray.shape[1] != 2 * precompWeights.shape[0] or sigmaMap.shape[0] != \             # <<<<<<<<<<<<<<
 *             precompWeights.shape[1] or sigmaVals.shape[0] != sigmaMap.shape[0]:
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF "
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 280, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(4, 280, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_precompWeights, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 280, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 280, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyInt_MultiplyCObj(__pyx_int_2, __pyx_t_7, 2, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 280, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_7 = PyObject_RichCompare(__pyx_t_3, __pyx_t_2, Py_NE); __Pyx_XGOTREF(__pyx_t_7); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 280, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_7); if (unlikely((__pyx_t_10 < 0))) __PYX_ERR(4, 280, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (!__pyx_t_10) {
  } else {
    __pyx_t_8 = __pyx_t_10;
    goto __pyx_L15_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":281
 *                     "feature gen function.")
 *     if outputArray.shape[1] != 2 * precompWeights.shape[0] or sigmaMap.shape[0] != \
 *             precompWeights.shape[1] or sigmaVals.shape[0] != sigmaMap.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF "
 *                     "feature gen function.")
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_sigmaMap, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 280, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":280
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF "
 *                     "feature gen function.")
 *     if outputArray.shape[1] != 2 * precompWeights.shape[0] or sigmaMap.shape[0] != \             # <<<<<<<<<<<<<<
 *             precompWeights.shape[1] or sigmaVals.shape[0] != sigmaMap.shape[0]:
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF "
 */
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_7, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 280, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":281
 *                     "feature gen function.")
 *     if outputArray.shape[1] != 2 * precompWeights.shape[0] or sigmaMap.shape[0] != \
 *             precompWeights.shape[1] or sigmaVals.shape[0] != sigmaMap.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF "
 *                     "feature gen function.")
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_precompWeights, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 281, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_7, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(4, 281, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_7 = PyObject_RichCompare(__pyx_t_2, __pyx_t_3, Py_NE); __Pyx_XGOTREF(__pyx_t_7); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 280, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":280
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF "
 *                     "feature gen function.")
 *     if outputArray.shape[1] != 2 * precompWeights.shape[0] or sigmaMap.shape[0] != \             # <<<<<<<<<<<<<<
 *             precompWeights.shape[1] or sigmaVals.shape[0] != sigmaMap.shape[0]:
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF "
 */
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_7); if (unlikely((__pyx_t_10 < 0))) __PYX_ERR(4, 280, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (!__pyx_t_10) {
  } else {
    __pyx_t_8 = __pyx_t_10;
    goto __pyx_L15_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":281
 *                     "feature gen function.")
 *     if outputArray.shape[1] != 2 * precompWeights.shape[0] or sigmaMap.shape[0] != \
 *             precompWeights.shape[1] or sigmaVals.shape[0] != sigmaMap.shape[0]:             # <<<<<<<<<<<<<<
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF "
 *                     "feature gen function.")
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_sigmaVals, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 281, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_7, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(4, 281, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_sigmaMap, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 281, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_7, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 281, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_7 = PyObject_RichCompare(__pyx_t_3, __pyx_t_2, Py_NE); __Pyx_XGOTREF(__pyx_t_7); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 281, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_7); if (unlikely((__pyx_t_10 < 0))) __PYX_ERR(4, 281, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_8 = __pyx_t_10;
  __pyx_L15_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":280
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF "
 *                     "feature gen function.")
 *     if outputArray.shape[1] != 2 * precompWeights.shape[0] or sigmaMap.shape[0] != \             # <<<<<<<<<<<<<<
 *             precompWeights.shape[1] or sigmaVals.shape[0] != sigmaMap.shape[0]:
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF "
 */
  if (unlikely(__pyx_t_8)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":282
 *     if outputArray.shape[1] != 2 * precompWeights.shape[0] or sigmaMap.shape[0] != \
 *             precompWeights.shape[1] or sigmaVals.shape[0] != sigmaMap.shape[0]:
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF "             # <<<<<<<<<<<<<<
 *                     "feature gen function.")
 * 
 */
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__58, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 282, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_Raise(__pyx_t_7, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __PYX_ERR(4, 282, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":280
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF "
 *                     "feature gen function.")
 *     if outputArray.shape[1] != 2 * precompWeights.shape[0] or sigmaMap.shape[0] != \             # <<<<<<<<<<<<<<
 *             precompWeights.shape[1] or sigmaVals.shape[0] != sigmaMap.shape[0]:
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF "
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":285
 *                     "feature gen function.")
 * 
 *     if not inputX.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"] or not \             # <<<<<<<<<<<<<<
 *             precompWeights.flags["C_CONTIGUOUS"] or not sigmaMap.flags["C_CONTIGUOUS"] or \
 *             not sigmaVals.flags["C_CONTIGUOUS"]:
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputX, __pyx_n_s_flags); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 285, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_2 = __Pyx_PyObject_Dict_GetItem(__pyx_t_7, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 285, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_10 < 0))) __PYX_ERR(4, 285, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_11 = (!__pyx_t_10);
  if (!__pyx_t_11) {
  } else {
    __pyx_t_8 = __pyx_t_11;
    goto __pyx_L19_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_flags); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 285, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_PyObject_Dict_GetItem(__pyx_t_2, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 285, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_11 = __Pyx_PyObject_IsTrue(__pyx_t_7); if (unlikely((__pyx_t_11 < 0))) __PYX_ERR(4, 285, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_10 = (!__pyx_t_11);
  if (!__pyx_t_10) {
  } else {
    __pyx_t_8 = __pyx_t_10;
    goto __pyx_L19_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":286
 * 
 *     if not inputX.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"] or not \
 *             precompWeights.flags["C_CONTIGUOUS"] or not sigmaMap.flags["C_CONTIGUOUS"] or \             # <<<<<<<<<<<<<<
 *             not sigmaVals.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_precompWeights, __pyx_n_s_flags); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 286, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_2 = __Pyx_PyObject_Dict_GetItem(__pyx_t_7, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 286, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_10 < 0))) __PYX_ERR(4, 286, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":285
 *                     "feature gen function.")
 * 
 *     if not inputX.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"] or not \             # <<<<<<<<<<<<<<
 *             precompWeights.flags["C_CONTIGUOUS"] or not sigmaMap.flags["C_CONTIGUOUS"] or \
 *             not sigmaVals.flags["C_CONTIGUOUS"]:
 */
  __pyx_t_11 = (!__pyx_t_10);
  if (!__pyx_t_11) {
  } else {
    __pyx_t_8 = __pyx_t_11;
    goto __pyx_L19_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":286
 * 
 *     if not inputX.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"] or not \
 *             precompWeights.flags["C_CONTIGUOUS"] or not sigmaMap.flags["C_CONTIGUOUS"] or \             # <<<<<<<<<<<<<<
 *             not sigmaVals.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_sigmaMap, __pyx_n_s_flags); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 286, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_PyObject_Dict_GetItem(__pyx_t_2, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 286, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_11 = __Pyx_PyObject_IsTrue(__pyx_t_7); if (unlikely((__pyx_t_11 < 0))) __PYX_ERR(4, 286, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_10 = (!__pyx_t_11);
  if (!__pyx_t_10) {
  } else {
    __pyx_t_8 = __pyx_t_10;
    goto __pyx_L19_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":287
 *     if not inputX.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"] or not \
 *             precompWeights.flags["C_CONTIGUOUS"] or not sigmaMap.flags["C_CONTIGUOUS"] or \
 *             not sigmaVals.flags["C_CONTIGUOUS"]:             # <<<<<<<<<<<<<<
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "
 *                 "C contiguous.")
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_sigmaVals, __pyx_n_s_flags); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 287, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_2 = __Pyx_PyObject_Dict_GetItem(__pyx_t_7, __pyx_n_u_C_CONTIGUOUS); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 287, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_10 < 0))) __PYX_ERR(4, 287, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_11 = (!__pyx_t_10);
  __pyx_t_8 = __pyx_t_11;
  __pyx_L19_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":285
 *                     "feature gen function.")
 * 
 *     if not inputX.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"] or not \             # <<<<<<<<<<<<<<
 *             precompWeights.flags["C_CONTIGUOUS"] or not sigmaMap.flags["C_CONTIGUOUS"] or \
 *             not sigmaVals.flags["C_CONTIGUOUS"]:
 */
  if (unlikely(__pyx_t_8)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":288
 *             precompWeights.flags["C_CONTIGUOUS"] or not sigmaMap.flags["C_CONTIGUOUS"] or \
 *             not sigmaVals.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "             # <<<<<<<<<<<<<<
 *                 "C contiguous.")
 * 
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__57, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 288, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(4, 288, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":285
 *                     "feature gen function.")
 * 
 *     if not inputX.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"] or not \             # <<<<<<<<<<<<<<
 *             precompWeights.flags["C_CONTIGUOUS"] or not sigmaMap.flags["C_CONTIGUOUS"] or \
 *             not sigmaVals.flags["C_CONTIGUOUS"]:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":292
 * 
 * 
 *     cdef uintptr_t addr_input = inputX.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_random_feats = outputArray.data.ptr
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputX, __pyx_n_s_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 292, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 292, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_12 = __Pyx_PyInt_As_size_t(__pyx_t_7); if (unlikely((__pyx_t_12 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(4, 292, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_addr_input = __pyx_t_12;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":293
 * 
 *     cdef uintptr_t addr_input = inputX.data.ptr
 *     cdef uintptr_t addr_random_feats = outputArray.data.ptr             # <<<<<<<<<<<<<<
 * 
 *     cdef uintptr_t addr_sigma_map = sigmaMap.data.ptr
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_data); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 293, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 293, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_12 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_12 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(4, 293, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_addr_random_feats = __pyx_t_12;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":295
 *     cdef uintptr_t addr_random_feats = outputArray.data.ptr
 * 
 *     cdef uintptr_t addr_sigma_map = sigmaMap.data.ptr             # <<<<<<<<<<<<<<
 *     cdef int32_t *sigmaMap_ptr = <int32_t*>addr_sigma_map
 *     cdef uintptr_t addr_sigma_vals = sigmaVals.data.ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_sigmaMap, __pyx_n_s_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 295, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 295, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_12 = __Pyx_PyInt_As_size_t(__pyx_t_7); if (unlikely((__pyx_t_12 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(4, 295, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_addr_sigma_map = __pyx_t_12;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":296
 * 
 *     cdef uintptr_t addr_sigma_map = sigmaMap.data.ptr
 *     cdef int32_t *sigmaMap_ptr = <int32_t*>addr_sigma_map             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_sigma_vals = sigmaVals.data.ptr
 * 
 */
  __pyx_v_sigmaMap_ptr = ((int32_t *)__pyx_v_addr_sigma_map);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":297
 *     cdef uintptr_t addr_sigma_map = sigmaMap.data.ptr
 *     cdef int32_t *sigmaMap_ptr = <int32_t*>addr_sigma_map
 *     cdef uintptr_t addr_sigma_vals = sigmaVals.data.ptr             # <<<<<<<<<<<<<<
 * 
 *     cdef uintptr_t addr_grad = gradient.data.ptr
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_sigmaVals, __pyx_n_s_data); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 297, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 297, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_12 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_12 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(4, 297, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_addr_sigma_vals = __pyx_t_12;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":299
 *     cdef uintptr_t addr_sigma_vals = sigmaVals.data.ptr
 * 
 *     cdef uintptr_t addr_grad = gradient.data.ptr             # <<<<<<<<<<<<<<
 *     cdef uintptr_t addr_precomp_weights = precompWeights.data.ptr
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_gradient, __pyx_n_s_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 299, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 299, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_12 = __Pyx_PyInt_As_size_t(__pyx_t_7); if (unlikely((__pyx_t_12 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(4, 299, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_addr_grad = __pyx_t_12;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":300
 * 
 *     cdef uintptr_t addr_grad = gradient.data.ptr
 *     cdef uintptr_t addr_precomp_weights = precompWeights.data.ptr             # <<<<<<<<<<<<<<
 * 
 *     if fitIntercept:
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_precompWeights, __pyx_n_s_data); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_12 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_12 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(4, 300, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_addr_precomp_weights = __pyx_t_12;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":302
 *     cdef uintptr_t addr_precomp_weights = precompWeights.data.ptr
 * 
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         rbfNormConstant = betaHparam * np.sqrt(2.0 / (<double>precompWeights.shape[0] - 0.5))
 *     else:
 */
  __pyx_t_8 = (__pyx_v_fitIntercept != 0);
  if (__pyx_t_8) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":303
 * 
 *     if fitIntercept:
 *         rbfNormConstant = betaHparam * np.sqrt(2.0 / (<double>precompWeights.shape[0] - 0.5))             # <<<<<<<<<<<<<<
 *     else:
 *         rbfNormConstant = betaHparam * np.sqrt(2 / <double>precompWeights.shape[0])
 */
    __pyx_t_2 = PyFloat_FromDouble(__pyx_v_betaHparam); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 303, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_n_s_np); if (unlikely(!__pyx_t_3)) __PYX_ERR(4, 303, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_sqrt); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 303, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_precompWeights, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(4, 303, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_3, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 303, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_13 = __pyx_PyFloat_AsDouble(__pyx_t_6); if (unlikely((__pyx_t_13 == (double)-1) && PyErr_Occurred())) __PYX_ERR(4, 303, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_14 = (((double)__pyx_t_13) - 0.5);
    if (unlikely(__pyx_t_14 == 0)) {
      PyErr_SetString(PyExc_ZeroDivisionError, "float division");
      __PYX_ERR(4, 303, __pyx_L1_error)
    }
    __pyx_t_6 = PyFloat_FromDouble((2.0 / __pyx_t_14)); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 303, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_3 = NULL;
    __pyx_t_4 = 0;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
        __pyx_t_4 = 1;
      }
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_3, __pyx_t_6};
      __pyx_t_7 = __Pyx_PyObject_FastCall(__pyx_t_1, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 303, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    }
    __pyx_t_1 = PyNumber_Multiply(__pyx_t_2, __pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 303, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_14 = __pyx_PyFloat_AsDouble(__pyx_t_1); if (unlikely((__pyx_t_14 == (double)-1) && PyErr_Occurred())) __PYX_ERR(4, 303, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_rbfNormConstant = __pyx_t_14;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":302
 *     cdef uintptr_t addr_precomp_weights = precompWeights.data.ptr
 * 
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         rbfNormConstant = betaHparam * np.sqrt(2.0 / (<double>precompWeights.shape[0] - 0.5))
 *     else:
 */
    goto __pyx_L24;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":305
 *         rbfNormConstant = betaHparam * np.sqrt(2.0 / (<double>precompWeights.shape[0] - 0.5))
 *     else:
 *         rbfNormConstant = betaHparam * np.sqrt(2 / <double>precompWeights.shape[0])             # <<<<<<<<<<<<<<
 * 
 *     if inputX.dtype == "float32" and precompWeights.dtype == "float32" and \
 */
  /*else*/ {
    __pyx_t_1 = PyFloat_FromDouble(__pyx_v_betaHparam); if (unlikely(!__pyx_t_1)) __PYX_ERR(4, 305, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_np); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 305, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_sqrt); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 305, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_precompWeights, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 305, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(4, 305, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_14 = __pyx_PyFloat_AsDouble(__pyx_t_3); if (unlikely((__pyx_t_14 == (double)-1) && PyErr_Occurred())) __PYX_ERR(4, 305, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(((double)__pyx_t_14) == 0)) {
      PyErr_SetString(PyExc_ZeroDivisionError, "float division");
      __PYX_ERR(4, 305, __pyx_L1_error)
    }
    __pyx_t_3 = PyFloat_FromDouble((2.0 / ((double)__pyx_t_14))); if (unlikely(!__pyx_t_3)) __PYX_ERR(4, 305, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_2 = NULL;
    __pyx_t_4 = 0;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_6))) {
      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_6);
      if (likely(__pyx_t_2)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_6, function);
        __pyx_t_4 = 1;
      }
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_t_3};
      __pyx_t_7 = __Pyx_PyObject_FastCall(__pyx_t_6, __pyx_callargs+1-__pyx_t_4, 1+__pyx_t_4);
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 305, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    }
    __pyx_t_6 = PyNumber_Multiply(__pyx_t_1, __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 305, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_14 = __pyx_PyFloat_AsDouble(__pyx_t_6); if (unlikely((__pyx_t_14 == (double)-1) && PyErr_Occurred())) __PYX_ERR(4, 305, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_v_rbfNormConstant = __pyx_t_14;
  }
  __pyx_L24:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":307
 *         rbfNormConstant = betaHparam * np.sqrt(2 / <double>precompWeights.shape[0])
 * 
 *     if inputX.dtype == "float32" and precompWeights.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             outputArray.dtype == "float64" and sigmaMap.dtype == "int32" and \
 *             sigmaVals.dtype == "float64":
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputX, __pyx_n_s_dtype); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 307, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_11 = (__Pyx_PyUnicode_Equals(__pyx_t_6, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_11 < 0))) __PYX_ERR(4, 307, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (__pyx_t_11) {
  } else {
    __pyx_t_8 = __pyx_t_11;
    goto __pyx_L26_bool_binop_done;
  }
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_precompWeights, __pyx_n_s_dtype); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 307, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_11 = (__Pyx_PyUnicode_Equals(__pyx_t_6, __pyx_n_u_float32, Py_EQ)); if (unlikely((__pyx_t_11 < 0))) __PYX_ERR(4, 307, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (__pyx_t_11) {
  } else {
    __pyx_t_8 = __pyx_t_11;
    goto __pyx_L26_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":308
 * 
 *     if inputX.dtype == "float32" and precompWeights.dtype == "float32" and \
 *             outputArray.dtype == "float64" and sigmaMap.dtype == "int32" and \             # <<<<<<<<<<<<<<
 *             sigmaVals.dtype == "float64":
 *         errCode = ardCudaGrad[float](<float*>addr_input, <double*>addr_random_feats,
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 308, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_11 = (__Pyx_PyUnicode_Equals(__pyx_t_6, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_11 < 0))) __PYX_ERR(4, 308, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (__pyx_t_11) {
  } else {
    __pyx_t_8 = __pyx_t_11;
    goto __pyx_L26_bool_binop_done;
  }
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_sigmaMap, __pyx_n_s_dtype); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 308, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_11 = (__Pyx_PyUnicode_Equals(__pyx_t_6, __pyx_n_u_int32, Py_EQ)); if (unlikely((__pyx_t_11 < 0))) __PYX_ERR(4, 308, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (__pyx_t_11) {
  } else {
    __pyx_t_8 = __pyx_t_11;
    goto __pyx_L26_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":309
 *     if inputX.dtype == "float32" and precompWeights.dtype == "float32" and \
 *             outputArray.dtype == "float64" and sigmaMap.dtype == "int32" and \
 *             sigmaVals.dtype == "float64":             # <<<<<<<<<<<<<<
 *         errCode = ardCudaGrad[float](<float*>addr_input, <double*>addr_random_feats,
 *                 <float*>addr_precomp_weights, <int32_t*>addr_sigma_map,
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_sigmaVals, __pyx_n_s_dtype); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 309, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_11 = (__Pyx_PyUnicode_Equals(__pyx_t_6, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_11 < 0))) __PYX_ERR(4, 309, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_8 = __pyx_t_11;
  __pyx_L26_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":307
 *         rbfNormConstant = betaHparam * np.sqrt(2 / <double>precompWeights.shape[0])
 * 
 *     if inputX.dtype == "float32" and precompWeights.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             outputArray.dtype == "float64" and sigmaMap.dtype == "int32" and \
 *             sigmaVals.dtype == "float64":
 */
  if (__pyx_t_8) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":313
 *                 <float*>addr_precomp_weights, <int32_t*>addr_sigma_map,
 *                 <double*>addr_sigma_vals,
 *                 <double*>addr_grad, inputX.shape[0], inputX.shape[1],             # <<<<<<<<<<<<<<
 *                 gradient.shape[2], precompWeights.shape[0],
 *                 rbfNormConstant)
 */
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputX, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 313, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_6, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 313, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_7); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 313, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputX, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 313, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_7, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 313, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_15 = __Pyx_PyInt_As_int(__pyx_t_6); if (unlikely((__pyx_t_15 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 313, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":314
 *                 <double*>addr_sigma_vals,
 *                 <double*>addr_grad, inputX.shape[0], inputX.shape[1],
 *                 gradient.shape[2], precompWeights.shape[0],             # <<<<<<<<<<<<<<
 *                 rbfNormConstant)
 * 
 */
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_gradient, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 314, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_6, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 314, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_16 = __Pyx_PyInt_As_int(__pyx_t_7); if (unlikely((__pyx_t_16 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 314, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_precompWeights, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 314, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_7, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 314, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_17 = __Pyx_PyInt_As_int(__pyx_t_6); if (unlikely((__pyx_t_17 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 314, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":310
 *             outputArray.dtype == "float64" and sigmaMap.dtype == "int32" and \
 *             sigmaVals.dtype == "float64":
 *         errCode = ardCudaGrad[float](<float*>addr_input, <double*>addr_random_feats,             # <<<<<<<<<<<<<<
 *                 <float*>addr_precomp_weights, <int32_t*>addr_sigma_map,
 *                 <double*>addr_sigma_vals,
 */
    __pyx_v_errCode = ardCudaGrad<float>(((float *)__pyx_v_addr_input), ((double *)__pyx_v_addr_random_feats), ((float *)__pyx_v_addr_precomp_weights), ((int32_t *)__pyx_v_addr_sigma_map), ((double *)__pyx_v_addr_sigma_vals), ((double *)__pyx_v_addr_grad), __pyx_t_4, __pyx_t_15, __pyx_t_16, __pyx_t_17, __pyx_v_rbfNormConstant);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":307
 *         rbfNormConstant = betaHparam * np.sqrt(2 / <double>precompWeights.shape[0])
 * 
 *     if inputX.dtype == "float32" and precompWeights.dtype == "float32" and \             # <<<<<<<<<<<<<<
 *             outputArray.dtype == "float64" and sigmaMap.dtype == "int32" and \
 *             sigmaVals.dtype == "float64":
 */
    goto __pyx_L25;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":317
 *                 rbfNormConstant)
 * 
 *     elif inputX.dtype == "float64" and precompWeights.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             outputArray.dtype == "float64" and sigmaMap.dtype == "int32" and \
 *             sigmaVals.dtype == "float64":
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputX, __pyx_n_s_dtype); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 317, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_11 = (__Pyx_PyUnicode_Equals(__pyx_t_6, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_11 < 0))) __PYX_ERR(4, 317, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (__pyx_t_11) {
  } else {
    __pyx_t_8 = __pyx_t_11;
    goto __pyx_L31_bool_binop_done;
  }
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_precompWeights, __pyx_n_s_dtype); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 317, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_11 = (__Pyx_PyUnicode_Equals(__pyx_t_6, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_11 < 0))) __PYX_ERR(4, 317, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (__pyx_t_11) {
  } else {
    __pyx_t_8 = __pyx_t_11;
    goto __pyx_L31_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":318
 * 
 *     elif inputX.dtype == "float64" and precompWeights.dtype == "float64" and \
 *             outputArray.dtype == "float64" and sigmaMap.dtype == "int32" and \             # <<<<<<<<<<<<<<
 *             sigmaVals.dtype == "float64":
 *         errCode = ardCudaGrad[double](<double*>addr_input, <double*>addr_random_feats,
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_outputArray, __pyx_n_s_dtype); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 318, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_11 = (__Pyx_PyUnicode_Equals(__pyx_t_6, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_11 < 0))) __PYX_ERR(4, 318, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (__pyx_t_11) {
  } else {
    __pyx_t_8 = __pyx_t_11;
    goto __pyx_L31_bool_binop_done;
  }
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_sigmaMap, __pyx_n_s_dtype); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 318, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_11 = (__Pyx_PyUnicode_Equals(__pyx_t_6, __pyx_n_u_int32, Py_EQ)); if (unlikely((__pyx_t_11 < 0))) __PYX_ERR(4, 318, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (__pyx_t_11) {
  } else {
    __pyx_t_8 = __pyx_t_11;
    goto __pyx_L31_bool_binop_done;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":319
 *     elif inputX.dtype == "float64" and precompWeights.dtype == "float64" and \
 *             outputArray.dtype == "float64" and sigmaMap.dtype == "int32" and \
 *             sigmaVals.dtype == "float64":             # <<<<<<<<<<<<<<
 *         errCode = ardCudaGrad[double](<double*>addr_input, <double*>addr_random_feats,
 *                 <double*>addr_precomp_weights, <int32_t*>addr_sigma_map,
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_sigmaVals, __pyx_n_s_dtype); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_11 = (__Pyx_PyUnicode_Equals(__pyx_t_6, __pyx_n_u_float64, Py_EQ)); if (unlikely((__pyx_t_11 < 0))) __PYX_ERR(4, 319, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_8 = __pyx_t_11;
  __pyx_L31_bool_binop_done:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":317
 *                 rbfNormConstant)
 * 
 *     elif inputX.dtype == "float64" and precompWeights.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             outputArray.dtype == "float64" and sigmaMap.dtype == "int32" and \
 *             sigmaVals.dtype == "float64":
 */
  if (likely(__pyx_t_8)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":323
 *                 <double*>addr_precomp_weights, <int32_t*>addr_sigma_map,
 *                 <double*>addr_sigma_vals,
 *                 <double*>addr_grad, inputX.shape[0], inputX.shape[1],             # <<<<<<<<<<<<<<
 *                 gradient.shape[2], precompWeights.shape[0],
 *                 rbfNormConstant)
 */
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputX, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 323, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_6, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 323, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_17 = __Pyx_PyInt_As_int(__pyx_t_7); if (unlikely((__pyx_t_17 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 323, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_inputX, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 323, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_7, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 323, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_16 = __Pyx_PyInt_As_int(__pyx_t_6); if (unlikely((__pyx_t_16 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 323, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":324
 *                 <double*>addr_sigma_vals,
 *                 <double*>addr_grad, inputX.shape[0], inputX.shape[1],
 *                 gradient.shape[2], precompWeights.shape[0],             # <<<<<<<<<<<<<<
 *                 rbfNormConstant)
 *     else:
 */
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_gradient, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 324, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_6, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 324, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_15 = __Pyx_PyInt_As_int(__pyx_t_7); if (unlikely((__pyx_t_15 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 324, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_precompWeights, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(4, 324, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_7, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 324, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_6); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(4, 324, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":320
 *             outputArray.dtype == "float64" and sigmaMap.dtype == "int32" and \
 *             sigmaVals.dtype == "float64":
 *         errCode = ardCudaGrad[double](<double*>addr_input, <double*>addr_random_feats,             # <<<<<<<<<<<<<<
 *                 <double*>addr_precomp_weights, <int32_t*>addr_sigma_map,
 *                 <double*>addr_sigma_vals,
 */
    __pyx_v_errCode = ardCudaGrad<double>(((double *)__pyx_v_addr_input), ((double *)__pyx_v_addr_random_feats), ((double *)__pyx_v_addr_precomp_weights), ((int32_t *)__pyx_v_addr_sigma_map), ((double *)__pyx_v_addr_sigma_vals), ((double *)__pyx_v_addr_grad), __pyx_t_17, __pyx_t_16, __pyx_t_15, __pyx_t_4, __pyx_v_rbfNormConstant);

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":317
 *                 rbfNormConstant)
 * 
 *     elif inputX.dtype == "float64" and precompWeights.dtype == "float64" and \             # <<<<<<<<<<<<<<
 *             outputArray.dtype == "float64" and sigmaMap.dtype == "int32" and \
 *             sigmaVals.dtype == "float64":
 */
    goto __pyx_L25;
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":327
 *                 rbfNormConstant)
 *     else:
 *         raise ValueError("The input arrays to a wrapped RBF feature gen function have incorrect "             # <<<<<<<<<<<<<<
 *                 "types.")
 * 
 */
  /*else*/ {
    __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__67, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 327, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_Raise(__pyx_t_6, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __PYX_ERR(4, 327, __pyx_L1_error)
  }
  __pyx_L25:;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":330
 *                 "types.")
 * 
 *     if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *         raise Exception("Fatal error encountered in RBF feature gen.")
 *     if fitIntercept:
 */
  __pyx_t_9 = __Pyx_ssize_strlen(__pyx_v_errCode); if (unlikely(__pyx_t_9 == ((Py_ssize_t)-1))) __PYX_ERR(4, 330, __pyx_L1_error)
  __pyx_t_6 = __Pyx_decode_c_string(__pyx_v_errCode, 0, __pyx_t_9, NULL, NULL, PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 330, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_8 = (__Pyx_PyUnicode_Equals(__pyx_t_6, __pyx_n_u_no_error, Py_NE)); if (unlikely((__pyx_t_8 < 0))) __PYX_ERR(4, 330, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (unlikely(__pyx_t_8)) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":331
 * 
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered in RBF feature gen.")             # <<<<<<<<<<<<<<
 *     if fitIntercept:
 *         outputArray[:,0] = betaHparam
 */
    __pyx_t_6 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__68, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 331, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_Raise(__pyx_t_6, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __PYX_ERR(4, 331, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":330
 *                 "types.")
 * 
 *     if errCode.decode("UTF-8") != "no_error":             # <<<<<<<<<<<<<<
 *         raise Exception("Fatal error encountered in RBF feature gen.")
 *     if fitIntercept:
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":332
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered in RBF feature gen.")
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         outputArray[:,0] = betaHparam
 *         gradient[:,0,:] = 0
 */
  __pyx_t_8 = (__pyx_v_fitIntercept != 0);
  if (__pyx_t_8) {

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":333
 *         raise Exception("Fatal error encountered in RBF feature gen.")
 *     if fitIntercept:
 *         outputArray[:,0] = betaHparam             # <<<<<<<<<<<<<<
 *         gradient[:,0,:] = 0
 *     return gradient
 */
    __pyx_t_6 = PyFloat_FromDouble(__pyx_v_betaHparam); if (unlikely(!__pyx_t_6)) __PYX_ERR(4, 333, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (unlikely((PyObject_SetItem(__pyx_v_outputArray, __pyx_tuple__38, __pyx_t_6) < 0))) __PYX_ERR(4, 333, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":334
 *     if fitIntercept:
 *         outputArray[:,0] = betaHparam
 *         gradient[:,0,:] = 0             # <<<<<<<<<<<<<<
 *     return gradient
 */
    if (unlikely((PyObject_SetItem(__pyx_v_gradient, __pyx_tuple__69, __pyx_int_0) < 0))) __PYX_ERR(4, 334, __pyx_L1_error)

    /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":332
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered in RBF feature gen.")
 *     if fitIntercept:             # <<<<<<<<<<<<<<
 *         outputArray[:,0] = betaHparam
 *         gradient[:,0,:] = 0
 */
  }

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":335
 *         outputArray[:,0] = betaHparam
 *         gradient[:,0,:] = 0
 *     return gradient             # <<<<<<<<<<<<<<
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_gradient);
  __pyx_r = __pyx_v_gradient;
  goto __pyx_L0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":232
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaMiniARDGrad(inputX, outputArray, precompWeights,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("cuda_rf_gen_module.cudaMiniARDGrad", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_gradient);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyMethodDef __pyx_methods[] = {
  {0, 0, 0, 0}
};
#ifndef CYTHON_SMALL_CODE
#if defined(__clang__)
    #define CYTHON_SMALL_CODE
#elif defined(__GNUC__) && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 3))
    #define CYTHON_SMALL_CODE __attribute__((cold))
#else
    #define CYTHON_SMALL_CODE
#endif
#endif
/* #### Code section: pystring_table ### */

static int __Pyx_CreateStringTabAndInitStrings(void) {
  __Pyx_StringTabEntry __pyx_string_tab[] = {
    {&__pyx_kp_u_Both_inputArray_and_outputArray, __pyx_k_Both_inputArray_and_outputArray, sizeof(__pyx_k_Both_inputArray_and_outputArray), 0, 1, 0, 0},
    {&__pyx_n_u_C_CONTIGUOUS, __pyx_k_C_CONTIGUOUS, sizeof(__pyx_k_C_CONTIGUOUS), 0, 1, 0, 1},
    {&__pyx_kp_u_Compression_size_must_be_num_rff, __pyx_k_Compression_size_must_be_num_rff, sizeof(__pyx_k_Compression_size_must_be_num_rff), 0, 1, 0, 0},
    {&__pyx_kp_u_Fatal_error_encountered, __pyx_k_Fatal_error_encountered, sizeof(__pyx_k_Fatal_error_encountered), 0, 1, 0, 0},
    {&__pyx_kp_u_Fatal_error_encountered_in_CudaR, __pyx_k_Fatal_error_encountered_in_CudaR, sizeof(__pyx_k_Fatal_error_encountered_in_CudaR), 0, 1, 0, 0},
    {&__pyx_kp_u_Fatal_error_encountered_in_RBF_f, __pyx_k_Fatal_error_encountered_in_RBF_f, sizeof(__pyx_k_Fatal_error_encountered_in_RBF_f), 0, 1, 0, 0},
    {&__pyx_kp_u_Fatal_error_encountered_in_doubl, __pyx_k_Fatal_error_encountered_in_doubl, sizeof(__pyx_k_Fatal_error_encountered_in_doubl), 0, 1, 0, 0},
    {&__pyx_kp_u_Fatal_error_encountered_in_float, __pyx_k_Fatal_error_encountered_in_float, sizeof(__pyx_k_Fatal_error_encountered_in_float), 0, 1, 0, 0},
    {&__pyx_kp_u_Fatal_error_encountered_in_float_2, __pyx_k_Fatal_error_encountered_in_float_2, sizeof(__pyx_k_Fatal_error_encountered_in_float_2), 0, 1, 0, 0},
    {&__pyx_kp_u_Fatal_error_encountered_while_pe, __pyx_k_Fatal_error_encountered_while_pe, sizeof(__pyx_k_Fatal_error_encountered_while_pe), 0, 1, 0, 0},
    {&__pyx_kp_u_Fatal_error_encountered_while_pe_2, __pyx_k_Fatal_error_encountered_while_pe_2, sizeof(__pyx_k_Fatal_error_encountered_while_pe_2), 0, 1, 0, 0},
    {&__pyx_n_s_ImportError, __pyx_k_ImportError, sizeof(__pyx_k_ImportError), 0, 0, 1, 1},
    {&__pyx_kp_u_Inconsistent_array_types_passed, __pyx_k_Inconsistent_array_types_passed, sizeof(__pyx_k_Inconsistent_array_types_passed), 0, 1, 0, 0},
    {&__pyx_kp_u_Inconsistent_types_passed_to_a_w, __pyx_k_Inconsistent_types_passed_to_a_w, sizeof(__pyx_k_Inconsistent_types_passed_to_a_w), 0, 1, 0, 0},
    {&__pyx_kp_u_Incorrect_array_dims_passed, __pyx_k_Incorrect_array_dims_passed, sizeof(__pyx_k_Incorrect_array_dims_passed), 0, 1, 0, 0},
    {&__pyx_kp_u_Incorrect_array_dims_passed_to_a, __pyx_k_Incorrect_array_dims_passed_to_a, sizeof(__pyx_k_Incorrect_array_dims_passed_to_a), 0, 1, 0, 0},
    {&__pyx_kp_u_Incorrect_array_dims_passed_to_f, __pyx_k_Incorrect_array_dims_passed_to_f, sizeof(__pyx_k_Incorrect_array_dims_passed_to_f), 0, 1, 0, 0},
    {&__pyx_kp_u_Incorrect_data_types_passed, __pyx_k_Incorrect_data_types_passed, sizeof(__pyx_k_Incorrect_data_types_passed), 0, 1, 0, 0},
    {&__pyx_kp_u_Incorrect_data_types_supplied, __pyx_k_Incorrect_data_types_supplied, sizeof(__pyx_k_Incorrect_data_types_supplied), 0, 1, 0, 0},
    {&__pyx_kp_u_One_or_more_arguments_is_not_C_c, __pyx_k_One_or_more_arguments_is_not_C_c, sizeof(__pyx_k_One_or_more_arguments_is_not_C_c), 0, 1, 0, 0},
    {&__pyx_kp_u_One_or_more_arguments_to_a_wrapp, __pyx_k_One_or_more_arguments_to_a_wrapp, sizeof(__pyx_k_One_or_more_arguments_to_a_wrapp), 0, 1, 0, 0},
    {&__pyx_kp_u_One_or_more_arguments_to_cpuSORF, __pyx_k_One_or_more_arguments_to_cpuSORF, sizeof(__pyx_k_One_or_more_arguments_to_cpuSORF), 0, 1, 0, 0},
    {&__pyx_kp_u_One_or_more_arguments_to_floatCu, __pyx_k_One_or_more_arguments_to_floatCu, sizeof(__pyx_k_One_or_more_arguments_to_floatCu), 0, 1, 0, 0},
    {&__pyx_kp_u_Shape_of_output_array_and_or_chi, __pyx_k_Shape_of_output_array_and_or_chi, sizeof(__pyx_k_Shape_of_output_array_and_or_chi), 0, 1, 0, 0},
    {&__pyx_kp_u_Shape_of_output_array_is_not_app, __pyx_k_Shape_of_output_array_is_not_app, sizeof(__pyx_k_Shape_of_output_array_is_not_app), 0, 1, 0, 0},
    {&__pyx_kp_u_Sizes_on_input_and_output_arrays, __pyx_k_Sizes_on_input_and_output_arrays, sizeof(__pyx_k_Sizes_on_input_and_output_arrays), 0, 1, 0, 0},
    {&__pyx_kp_u_The_input_and_chiArr_arrays_are, __pyx_k_The_input_and_chiArr_arrays_are, sizeof(__pyx_k_The_input_and_chiArr_arrays_are), 0, 1, 0, 0},
    {&__pyx_kp_u_The_input_arrays_to_a_wrapped_RB, __pyx_k_The_input_arrays_to_a_wrapped_RB, sizeof(__pyx_k_The_input_arrays_to_a_wrapped_RB), 0, 1, 0, 0},
    {&__pyx_kp_u_The_input_arrays_to_a_wrapped_RB_2, __pyx_k_The_input_arrays_to_a_wrapped_RB_2, sizeof(__pyx_k_The_input_arrays_to_a_wrapped_RB_2), 0, 1, 0, 0},
    {&__pyx_kp_u_The_number_of_datapoints_in_the, __pyx_k_The_number_of_datapoints_in_the, sizeof(__pyx_k_The_number_of_datapoints_in_the), 0, 1, 0, 0},
    {&__pyx_kp_u_The_number_of_input_and_output_d, __pyx_k_The_number_of_input_and_output_d, sizeof(__pyx_k_The_number_of_input_and_output_d), 0, 1, 0, 0},
    {&__pyx_kp_u_The_number_of_sampled_frequencie, __pyx_k_The_number_of_sampled_frequencie, sizeof(__pyx_k_The_number_of_sampled_frequencie), 0, 1, 0, 0},
    {&__pyx_kp_u_The_shape_of_the_output_array_is, __pyx_k_The_shape_of_the_output_array_is, sizeof(__pyx_k_The_shape_of_the_output_array_is), 0, 1, 0, 0},
    {&__pyx_kp_u_There_must_be_at_least_one_datap, __pyx_k_There_must_be_at_least_one_datap, sizeof(__pyx_k_There_must_be_at_least_one_datap), 0, 1, 0, 0},
    {&__pyx_kp_u_Unexpected_array_type_passed_to, __pyx_k_Unexpected_array_type_passed_to, sizeof(__pyx_k_Unexpected_array_type_passed_to), 0, 1, 0, 0},
    {&__pyx_kp_u_Unexpected_kernel_order_supplied, __pyx_k_Unexpected_kernel_order_supplied, sizeof(__pyx_k_Unexpected_kernel_order_supplied), 0, 1, 0, 0},
    {&__pyx_kp_u_Unexpected_types_passed_to_wrapp, __pyx_k_Unexpected_types_passed_to_wrapp, sizeof(__pyx_k_Unexpected_types_passed_to_wrapp), 0, 1, 0, 0},
    {&__pyx_n_s_ValueError, __pyx_k_ValueError, sizeof(__pyx_k_ValueError), 0, 0, 1, 1},
    {&__pyx_kp_u_X_must_be_a_3d_array, __pyx_k_X_must_be_a_3d_array, sizeof(__pyx_k_X_must_be_a_3d_array), 0, 1, 0, 0},
    {&__pyx_n_s_Z, __pyx_k_Z, sizeof(__pyx_k_Z), 0, 0, 1, 1},
    {&__pyx_n_s__70, __pyx_k__70, sizeof(__pyx_k__70), 0, 0, 1, 1},
    {&__pyx_n_s__96, __pyx_k__96, sizeof(__pyx_k__96), 0, 0, 1, 1},
    {&__pyx_n_s_addr, __pyx_k_addr, sizeof(__pyx_k_addr), 0, 0, 1, 1},
    {&__pyx_n_s_addr_chi, __pyx_k_addr_chi, sizeof(__pyx_k_addr_chi), 0, 0, 1, 1},
    {&__pyx_n_s_addr_featureArray, __pyx_k_addr_featureArray, sizeof(__pyx_k_addr_featureArray), 0, 0, 1, 1},
    {&__pyx_n_s_addr_grad, __pyx_k_addr_grad, sizeof(__pyx_k_addr_grad), 0, 0, 1, 1},
    {&__pyx_n_s_addr_gradient, __pyx_k_addr_gradient, sizeof(__pyx_k_addr_gradient), 0, 0, 1, 1},
    {&__pyx_n_s_addr_input, __pyx_k_addr_input, sizeof(__pyx_k_addr_input), 0, 0, 1, 1},
    {&__pyx_n_s_addr_output, __pyx_k_addr_output, sizeof(__pyx_k_addr_output), 0, 0, 1, 1},
    {&__pyx_n_s_addr_preSumFeats, __pyx_k_addr_preSumFeats, sizeof(__pyx_k_addr_preSumFeats), 0, 0, 1, 1},
    {&__pyx_n_s_addr_precomp_weights, __pyx_k_addr_precomp_weights, sizeof(__pyx_k_addr_precomp_weights), 0, 0, 1, 1},
    {&__pyx_n_s_addr_radem, __pyx_k_addr_radem, sizeof(__pyx_k_addr_radem), 0, 0, 1, 1},
    {&__pyx_n_s_addr_random_feats, __pyx_k_addr_random_feats, sizeof(__pyx_k_addr_random_feats), 0, 0, 1, 1},
    {&__pyx_n_s_addr_reshapedCopy, __pyx_k_addr_reshapedCopy, sizeof(__pyx_k_addr_reshapedCopy), 0, 0, 1, 1},
    {&__pyx_n_s_addr_reshapedX, __pyx_k_addr_reshapedX, sizeof(__pyx_k_addr_reshapedX), 0, 0, 1, 1},
    {&__pyx_n_s_addr_sigma_map, __pyx_k_addr_sigma_map, sizeof(__pyx_k_addr_sigma_map), 0, 0, 1, 1},
    {&__pyx_n_s_addr_sigma_vals, __pyx_k_addr_sigma_vals, sizeof(__pyx_k_addr_sigma_vals), 0, 0, 1, 1},
    {&__pyx_n_s_asyncio_coroutines, __pyx_k_asyncio_coroutines, sizeof(__pyx_k_asyncio_coroutines), 0, 0, 1, 1},
    {&__pyx_n_s_axis, __pyx_k_axis, sizeof(__pyx_k_axis), 0, 0, 1, 1},
    {&__pyx_n_s_beta, __pyx_k_beta, sizeof(__pyx_k_beta), 0, 0, 1, 1},
    {&__pyx_n_s_betaHparam, __pyx_k_betaHparam, sizeof(__pyx_k_betaHparam), 0, 0, 1, 1},
    {&__pyx_n_s_ceil, __pyx_k_ceil, sizeof(__pyx_k_ceil), 0, 0, 1, 1},
    {&__pyx_n_s_chiArr, __pyx_k_chiArr, sizeof(__pyx_k_chiArr), 0, 0, 1, 1},
    {&__pyx_kp_u_chiArr_input_to_RBF_feature_gen, __pyx_k_chiArr_input_to_RBF_feature_gen, sizeof(__pyx_k_chiArr_input_to_RBF_feature_gen), 0, 1, 0, 0},
    {&__pyx_kp_u_chiArr_must_be_a_1d_array_output, __pyx_k_chiArr_must_be_a_1d_array_output, sizeof(__pyx_k_chiArr_must_be_a_1d_array_output), 0, 1, 0, 0},
    {&__pyx_kp_u_chiArr_must_have_same_shape_1_an, __pyx_k_chiArr_must_have_same_shape_1_an, sizeof(__pyx_k_chiArr_must_have_same_shape_1_an), 0, 1, 0, 0},
    {&__pyx_kp_u_chiArr_radem_and_reshapedX_shoul, __pyx_k_chiArr_radem_and_reshapedX_shoul, sizeof(__pyx_k_chiArr_radem_and_reshapedX_shoul), 0, 1, 0, 0},
    {&__pyx_kp_u_chiArr_shape_0_must_polydegree, __pyx_k_chiArr_shape_0_must_polydegree, sizeof(__pyx_k_chiArr_shape_0_must_polydegree), 0, 1, 0, 0},
    {&__pyx_kp_u_chiArr_shape_0_must_radem_shape, __pyx_k_chiArr_shape_0_must_radem_shape, sizeof(__pyx_k_chiArr_shape_0_must_radem_shape), 0, 1, 0, 0},
    {&__pyx_kp_u_chiArr_shape_1_must_radem_shape, __pyx_k_chiArr_shape_1_must_radem_shape, sizeof(__pyx_k_chiArr_shape_1_must_radem_shape), 0, 1, 0, 0},
    {&__pyx_kp_u_chiArr_should_be_a_1d_array_rade, __pyx_k_chiArr_should_be_a_1d_array_rade, sizeof(__pyx_k_chiArr_should_be_a_1d_array_rade), 0, 1, 0, 0},
    {&__pyx_kp_u_chiArr_should_be_a_2d_array_rade, __pyx_k_chiArr_should_be_a_2d_array_rade, sizeof(__pyx_k_chiArr_should_be_a_2d_array_rade), 0, 1, 0, 0},
    {&__pyx_n_s_class_getitem, __pyx_k_class_getitem, sizeof(__pyx_k_class_getitem), 0, 0, 1, 1},
    {&__pyx_n_s_cline_in_traceback, __pyx_k_cline_in_traceback, sizeof(__pyx_k_cline_in_traceback), 0, 0, 1, 1},
    {&__pyx_n_s_compression_size, __pyx_k_compression_size, sizeof(__pyx_k_compression_size), 0, 0, 1, 1},
    {&__pyx_n_s_copy, __pyx_k_copy, sizeof(__pyx_k_copy), 0, 0, 1, 1},
    {&__pyx_n_s_cp, __pyx_k_cp, sizeof(__pyx_k_cp), 0, 0, 1, 1},
    {&__pyx_n_s_cpArray, __pyx_k_cpArray, sizeof(__pyx_k_cpArray), 0, 0, 1, 1},
    {&__pyx_n_s_cudaExactQuadratic, __pyx_k_cudaExactQuadratic, sizeof(__pyx_k_cudaExactQuadratic), 0, 0, 1, 1},
    {&__pyx_n_s_cudaMiniARDGrad, __pyx_k_cudaMiniARDGrad, sizeof(__pyx_k_cudaMiniARDGrad), 0, 0, 1, 1},
    {&__pyx_n_s_cudaPySORFTransform, __pyx_k_cudaPySORFTransform, sizeof(__pyx_k_cudaPySORFTransform), 0, 0, 1, 1},
    {&__pyx_n_s_cudaRBFFeatureGen, __pyx_k_cudaRBFFeatureGen, sizeof(__pyx_k_cudaRBFFeatureGen), 0, 0, 1, 1},
    {&__pyx_n_s_cudaRBFGrad, __pyx_k_cudaRBFGrad, sizeof(__pyx_k_cudaRBFGrad), 0, 0, 1, 1},
    {&__pyx_n_s_cudaSRHT, __pyx_k_cudaSRHT, sizeof(__pyx_k_cudaSRHT), 0, 0, 1, 1},
    {&__pyx_n_s_cuda_rf_gen_module, __pyx_k_cuda_rf_gen_module, sizeof(__pyx_k_cuda_rf_gen_module), 0, 0, 1, 1},
    {&__pyx_n_s_cupy, __pyx_k_cupy, sizeof(__pyx_k_cupy), 0, 0, 1, 1},
    {&__pyx_n_s_cutoff, __pyx_k_cutoff, sizeof(__pyx_k_cutoff), 0, 0, 1, 1},
    {&__pyx_n_s_cutoff2, __pyx_k_cutoff2, sizeof(__pyx_k_cutoff2), 0, 0, 1, 1},
    {&__pyx_n_s_data, __pyx_k_data, sizeof(__pyx_k_data), 0, 0, 1, 1},
    {&__pyx_kp_u_dim1_of_the_input_array_must_be, __pyx_k_dim1_of_the_input_array_must_be, sizeof(__pyx_k_dim1_of_the_input_array_must_be), 0, 1, 0, 0},
    {&__pyx_kp_u_dim2_of_the_input_array_to_RBF_f, __pyx_k_dim2_of_the_input_array_to_RBF_f, sizeof(__pyx_k_dim2_of_the_input_array_to_RBF_f), 0, 1, 0, 0},
    {&__pyx_kp_u_dim2_of_the_input_array_to_float, __pyx_k_dim2_of_the_input_array_to_float, sizeof(__pyx_k_dim2_of_the_input_array_to_float), 0, 1, 0, 0},
    {&__pyx_kp_u_dim2_of_the_reshapedX_array_must, __pyx_k_dim2_of_the_reshapedX_array_must, sizeof(__pyx_k_dim2_of_the_reshapedX_array_must), 0, 1, 0, 0},
    {&__pyx_n_s_dtype, __pyx_k_dtype, sizeof(__pyx_k_dtype), 0, 0, 1, 1},
    {&__pyx_n_s_errCode, __pyx_k_errCode, sizeof(__pyx_k_errCode), 0, 0, 1, 1},
    {&__pyx_n_s_featureArray, __pyx_k_featureArray, sizeof(__pyx_k_featureArray), 0, 0, 1, 1},
    {&__pyx_n_s_fitIntercept, __pyx_k_fitIntercept, sizeof(__pyx_k_fitIntercept), 0, 0, 1, 1},
    {&__pyx_n_s_flags, __pyx_k_flags, sizeof(__pyx_k_flags), 0, 0, 1, 1},
    {&__pyx_n_s_float32, __pyx_k_float32, sizeof(__pyx_k_float32), 0, 0, 1, 1},
    {&__pyx_n_u_float32, __pyx_k_float32, sizeof(__pyx_k_float32), 0, 1, 0, 1},
    {&__pyx_n_s_float64, __pyx_k_float64, sizeof(__pyx_k_float64), 0, 0, 1, 1},
    {&__pyx_n_u_float64, __pyx_k_float64, sizeof(__pyx_k_float64), 0, 1, 0, 1},
    {&__pyx_n_s_floor, __pyx_k_floor, sizeof(__pyx_k_floor), 0, 0, 1, 1},
    {&__pyx_n_s_gpuConv1dArcCosFGen, __pyx_k_gpuConv1dArcCosFGen, sizeof(__pyx_k_gpuConv1dArcCosFGen), 0, 0, 1, 1},
    {&__pyx_n_s_gpuConv1dFGen, __pyx_k_gpuConv1dFGen, sizeof(__pyx_k_gpuConv1dFGen), 0, 0, 1, 1},
    {&__pyx_n_s_gpuConv1dMaxpool, __pyx_k_gpuConv1dMaxpool, sizeof(__pyx_k_gpuConv1dMaxpool), 0, 0, 1, 1},
    {&__pyx_n_s_gpuConvGrad, __pyx_k_gpuConvGrad, sizeof(__pyx_k_gpuConvGrad), 0, 0, 1, 1},
    {&__pyx_n_s_gpuGraphPolyFHT, __pyx_k_gpuGraphPolyFHT, sizeof(__pyx_k_gpuGraphPolyFHT), 0, 0, 1, 1},
    {&__pyx_n_s_gpuPolyFHT, __pyx_k_gpuPolyFHT, sizeof(__pyx_k_gpuPolyFHT), 0, 0, 1, 1},
    {&__pyx_n_s_gradient, __pyx_k_gradient, sizeof(__pyx_k_gradient), 0, 0, 1, 1},
    {&__pyx_n_s_i, __pyx_k_i, sizeof(__pyx_k_i), 0, 0, 1, 1},
    {&__pyx_n_s_import, __pyx_k_import, sizeof(__pyx_k_import), 0, 0, 1, 1},
    {&__pyx_n_s_initializing, __pyx_k_initializing, sizeof(__pyx_k_initializing), 0, 0, 1, 1},
    {&__pyx_n_s_inputArray, __pyx_k_inputArray, sizeof(__pyx_k_inputArray), 0, 0, 1, 1},
    {&__pyx_kp_u_inputArray_and_outputArray_to_RB, __pyx_k_inputArray_and_outputArray_to_RB, sizeof(__pyx_k_inputArray_and_outputArray_to_RB), 0, 1, 0, 0},
    {&__pyx_n_s_inputX, __pyx_k_inputX, sizeof(__pyx_k_inputX), 0, 0, 1, 1},
    {&__pyx_n_u_int32, __pyx_k_int32, sizeof(__pyx_k_int32), 0, 1, 0, 1},
    {&__pyx_n_u_int8, __pyx_k_int8, sizeof(__pyx_k_int8), 0, 1, 0, 1},
    {&__pyx_n_s_is_coroutine, __pyx_k_is_coroutine, sizeof(__pyx_k_is_coroutine), 0, 0, 1, 1},
    {&__pyx_n_s_j, __pyx_k_j, sizeof(__pyx_k_j), 0, 0, 1, 1},
    {&__pyx_n_s_k, __pyx_k_k, sizeof(__pyx_k_k), 0, 0, 1, 1},
    {&__pyx_n_s_kernelOrder, __pyx_k_kernelOrder, sizeof(__pyx_k_kernelOrder), 0, 0, 1, 1},
    {&__pyx_n_s_log2, __pyx_k_log2, sizeof(__pyx_k_log2), 0, 0, 1, 1},
    {&__pyx_n_s_logdim, __pyx_k_logdim, sizeof(__pyx_k_logdim), 0, 0, 1, 1},
    {&__pyx_n_s_main, __pyx_k_main, sizeof(__pyx_k_main), 0, 0, 1, 1},
    {&__pyx_n_s_math, __pyx_k_math, sizeof(__pyx_k_math), 0, 0, 1, 1},
    {&__pyx_n_s_max, __pyx_k_max, sizeof(__pyx_k_max), 0, 0, 1, 1},
    {&__pyx_n_s_name, __pyx_k_name, sizeof(__pyx_k_name), 0, 0, 1, 1},
    {&__pyx_n_u_no_error, __pyx_k_no_error, sizeof(__pyx_k_no_error), 0, 1, 0, 1},
    {&__pyx_n_s_np, __pyx_k_np, sizeof(__pyx_k_np), 0, 0, 1, 1},
    {&__pyx_n_s_numExpectedFeats, __pyx_k_numExpectedFeats, sizeof(__pyx_k_numExpectedFeats), 0, 0, 1, 1},
    {&__pyx_n_s_numLengthscales, __pyx_k_numLengthscales, sizeof(__pyx_k_numLengthscales), 0, 0, 1, 1},
    {&__pyx_n_s_numThreads, __pyx_k_numThreads, sizeof(__pyx_k_numThreads), 0, 0, 1, 1},
    {&__pyx_n_s_num_repeats, __pyx_k_num_repeats, sizeof(__pyx_k_num_repeats), 0, 0, 1, 1},
    {&__pyx_n_s_numpy, __pyx_k_numpy, sizeof(__pyx_k_numpy), 0, 0, 1, 1},
    {&__pyx_kp_u_numpy_core_multiarray_failed_to, __pyx_k_numpy_core_multiarray_failed_to, sizeof(__pyx_k_numpy_core_multiarray_failed_to), 0, 1, 0, 0},
    {&__pyx_kp_u_numpy_core_umath_failed_to_impor, __pyx_k_numpy_core_umath_failed_to_impor, sizeof(__pyx_k_numpy_core_umath_failed_to_impor), 0, 1, 0, 0},
    {&__pyx_n_s_os, __pyx_k_os, sizeof(__pyx_k_os), 0, 0, 1, 1},
    {&__pyx_n_s_outputArray, __pyx_k_outputArray, sizeof(__pyx_k_outputArray), 0, 0, 1, 1},
    {&__pyx_kp_u_outputArray_shape_1_must_be_an_i, __pyx_k_outputArray_shape_1_must_be_an_i, sizeof(__pyx_k_outputArray_shape_1_must_be_an_i), 0, 1, 0, 0},
    {&__pyx_kp_u_outputArray_shape_1_must_be_rade, __pyx_k_outputArray_shape_1_must_be_rade, sizeof(__pyx_k_outputArray_shape_1_must_be_rade), 0, 1, 0, 0},
    {&__pyx_kp_u_outputArray_should_be_a_2d_array, __pyx_k_outputArray_should_be_a_2d_array, sizeof(__pyx_k_outputArray_should_be_a_2d_array), 0, 1, 0, 0},
    {&__pyx_kp_u_outputArray_should_be_a_3d_array, __pyx_k_outputArray_should_be_a_3d_array, sizeof(__pyx_k_outputArray_should_be_a_3d_array), 0, 1, 0, 0},
    {&__pyx_n_s_polydegree, __pyx_k_polydegree, sizeof(__pyx_k_polydegree), 0, 0, 1, 1},
    {&__pyx_n_s_preSumFeats, __pyx_k_preSumFeats, sizeof(__pyx_k_preSumFeats), 0, 0, 1, 1},
    {&__pyx_n_s_precompWeights, __pyx_k_precompWeights, sizeof(__pyx_k_precompWeights), 0, 0, 1, 1},
    {&__pyx_n_s_ptr, __pyx_k_ptr, sizeof(__pyx_k_ptr), 0, 0, 1, 1},
    {&__pyx_n_s_radem, __pyx_k_radem, sizeof(__pyx_k_radem), 0, 0, 1, 1},
    {&__pyx_kp_u_radem_chiArr_must_have_length_po, __pyx_k_radem_chiArr_must_have_length_po, sizeof(__pyx_k_radem_chiArr_must_have_length_po), 0, 1, 0, 0},
    {&__pyx_kp_u_radem_must_be_a_3d_array, __pyx_k_radem_must_be_a_3d_array, sizeof(__pyx_k_radem_must_be_a_3d_array), 0, 1, 0, 0},
    {&__pyx_kp_u_radem_must_be_int8, __pyx_k_radem_must_be_int8, sizeof(__pyx_k_radem_must_be_int8), 0, 1, 0, 0},
    {&__pyx_kp_u_radem_must_be_of_type_int8, __pyx_k_radem_must_be_of_type_int8, sizeof(__pyx_k_radem_must_be_of_type_int8), 0, 1, 0, 0},
    {&__pyx_kp_u_radem_must_have_length_3_for_dim, __pyx_k_radem_must_have_length_3_for_dim, sizeof(__pyx_k_radem_must_have_length_3_for_dim), 0, 1, 0, 0},
    {&__pyx_kp_u_radem_must_have_length_3_for_dim_2, __pyx_k_radem_must_have_length_3_for_dim_2, sizeof(__pyx_k_radem_must_have_length_3_for_dim_2), 0, 1, 0, 0},
    {&__pyx_kp_u_radem_must_have_length_polydegre, __pyx_k_radem_must_have_length_polydegre, sizeof(__pyx_k_radem_must_have_length_polydegre), 0, 1, 0, 0},
    {&__pyx_n_s_radem_ptr, __pyx_k_radem_ptr, sizeof(__pyx_k_radem_ptr), 0, 0, 1, 1},
    {&__pyx_n_s_range, __pyx_k_range, sizeof(__pyx_k_range), 0, 0, 1, 1},
    {&__pyx_n_s_rbfNormConstant, __pyx_k_rbfNormConstant, sizeof(__pyx_k_rbfNormConstant), 0, 0, 1, 1},
    {&__pyx_n_s_reshapedX, __pyx_k_reshapedX, sizeof(__pyx_k_reshapedX), 0, 0, 1, 1},
    {&__pyx_n_s_reshapedXCopy, __pyx_k_reshapedXCopy, sizeof(__pyx_k_reshapedXCopy), 0, 0, 1, 1},
    {&__pyx_kp_u_reshapedX_shape_1_and_shape_2_mu, __pyx_k_reshapedX_shape_1_and_shape_2_mu, sizeof(__pyx_k_reshapedX_shape_1_and_shape_2_mu), 0, 1, 0, 0},
    {&__pyx_n_s_sampler, __pyx_k_sampler, sizeof(__pyx_k_sampler), 0, 0, 1, 1},
    {&__pyx_n_s_scalingTerm, __pyx_k_scalingTerm, sizeof(__pyx_k_scalingTerm), 0, 0, 1, 1},
    {&__pyx_n_s_scaling_factor, __pyx_k_scaling_factor, sizeof(__pyx_k_scaling_factor), 0, 0, 1, 1},
    {&__pyx_n_s_shape, __pyx_k_shape, sizeof(__pyx_k_shape), 0, 0, 1, 1},
    {&__pyx_n_s_sigma, __pyx_k_sigma, sizeof(__pyx_k_sigma), 0, 0, 1, 1},
    {&__pyx_n_s_sigmaHparam, __pyx_k_sigmaHparam, sizeof(__pyx_k_sigmaHparam), 0, 0, 1, 1},
    {&__pyx_n_s_sigmaMap, __pyx_k_sigmaMap, sizeof(__pyx_k_sigmaMap), 0, 0, 1, 1},
    {&__pyx_n_s_sigmaMap_ptr, __pyx_k_sigmaMap_ptr, sizeof(__pyx_k_sigmaMap_ptr), 0, 0, 1, 1},
    {&__pyx_n_s_sigmaVals, __pyx_k_sigmaVals, sizeof(__pyx_k_sigmaVals), 0, 0, 1, 1},
    {&__pyx_n_s_spec, __pyx_k_spec, sizeof(__pyx_k_spec), 0, 0, 1, 1},
    {&__pyx_n_s_sqrt, __pyx_k_sqrt, sizeof(__pyx_k_sqrt), 0, 0, 1, 1},
    {&__pyx_n_s_startPos2, __pyx_k_startPos2, sizeof(__pyx_k_startPos2), 0, 0, 1, 1},
    {&__pyx_n_s_startPosition, __pyx_k_startPosition, sizeof(__pyx_k_startPosition), 0, 0, 1, 1},
    {&__pyx_n_s_sum, __pyx_k_sum, sizeof(__pyx_k_sum), 0, 0, 1, 1},
    {&__pyx_n_s_test, __pyx_k_test, sizeof(__pyx_k_test), 0, 0, 1, 1},
    {&__pyx_kp_s_xGPR_random_feature_generation_g, __pyx_k_xGPR_random_feature_generation_g, sizeof(__pyx_k_xGPR_random_feature_generation_g), 0, 0, 1, 0},
    {&__pyx_kp_s_xGPR_random_feature_generation_g_2, __pyx_k_xGPR_random_feature_generation_g_2, sizeof(__pyx_k_xGPR_random_feature_generation_g_2), 0, 0, 1, 0},
    {&__pyx_kp_s_xGPR_random_feature_generation_g_3, __pyx_k_xGPR_random_feature_generation_g_3, sizeof(__pyx_k_xGPR_random_feature_generation_g_3), 0, 0, 1, 0},
    {&__pyx_kp_s_xGPR_random_feature_generation_g_4, __pyx_k_xGPR_random_feature_generation_g_4, sizeof(__pyx_k_xGPR_random_feature_generation_g_4), 0, 0, 1, 0},
    {&__pyx_n_s_zeros, __pyx_k_zeros, sizeof(__pyx_k_zeros), 0, 0, 1, 1},
    {0, 0, 0, 0, 0, 0, 0}
  };
  return __Pyx_InitStrings(__pyx_string_tab);
}
/* #### Code section: cached_builtins ### */
static CYTHON_SMALL_CODE int __Pyx_InitCachedBuiltins(void) {
  __pyx_builtin_ValueError = __Pyx_GetBuiltinName(__pyx_n_s_ValueError); if (!__pyx_builtin_ValueError) __PYX_ERR(0, 57, __pyx_L1_error)
  __pyx_builtin_range = __Pyx_GetBuiltinName(__pyx_n_s_range); if (!__pyx_builtin_range) __PYX_ERR(1, 123, __pyx_L1_error)
  __pyx_builtin_ImportError = __Pyx_GetBuiltinName(__pyx_n_s_ImportError); if (!__pyx_builtin_ImportError) __PYX_ERR(2, 983, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}
/* #### Code section: cached_constants ### */

static CYTHON_SMALL_CODE int __Pyx_InitCachedConstants(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_InitCachedConstants", 0);

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":983
 *         __pyx_import_array()
 *     except Exception:
 *         raise ImportError("numpy.core.multiarray failed to import")             # <<<<<<<<<<<<<<
 * 
 * cdef inline int import_umath() except -1:
 */
  __pyx_tuple_ = PyTuple_Pack(1, __pyx_kp_u_numpy_core_multiarray_failed_to); if (unlikely(!__pyx_tuple_)) __PYX_ERR(2, 983, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple_);
  __Pyx_GIVEREF(__pyx_tuple_);

  /* "../venv_testing/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd":989
 *         _import_umath()
 *     except Exception:
 *         raise ImportError("numpy.core.umath failed to import")             # <<<<<<<<<<<<<<
 * 
 * cdef inline int import_ufunc() except -1:
 */
  __pyx_tuple__2 = PyTuple_Pack(1, __pyx_kp_u_numpy_core_umath_failed_to_impor); if (unlikely(!__pyx_tuple__2)) __PYX_ERR(2, 989, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__2);
  __Pyx_GIVEREF(__pyx_tuple__2);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":57
 *     #of two, which is a requirement for the transform.
 *     if cpArray.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")             # <<<<<<<<<<<<<<
 *     if cpArray.shape[1] != radem.shape[1] or cpArray.shape[2] != radem.shape[2]:
 *         raise ValueError("Incorrect array dims passed to floatCudaPySORFTransform.")
 */
  __pyx_tuple__3 = PyTuple_Pack(1, __pyx_kp_u_There_must_be_at_least_one_datap); if (unlikely(!__pyx_tuple__3)) __PYX_ERR(0, 57, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__3);
  __Pyx_GIVEREF(__pyx_tuple__3);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":59
 *         raise ValueError("There must be at least one datapoint.")
 *     if cpArray.shape[1] != radem.shape[1] or cpArray.shape[2] != radem.shape[2]:
 *         raise ValueError("Incorrect array dims passed to floatCudaPySORFTransform.")             # <<<<<<<<<<<<<<
 *     if radem.shape[0] != 3:
 *         raise ValueError("radem must have length 3 for dim 0.")
 */
  __pyx_tuple__4 = PyTuple_Pack(1, __pyx_kp_u_Incorrect_array_dims_passed_to_f); if (unlikely(!__pyx_tuple__4)) __PYX_ERR(0, 59, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__4);
  __Pyx_GIVEREF(__pyx_tuple__4);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":61
 *         raise ValueError("Incorrect array dims passed to floatCudaPySORFTransform.")
 *     if radem.shape[0] != 3:
 *         raise ValueError("radem must have length 3 for dim 0.")             # <<<<<<<<<<<<<<
 * 
 *     if not cpArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"]:
 */
  __pyx_tuple__5 = PyTuple_Pack(1, __pyx_kp_u_radem_must_have_length_3_for_dim); if (unlikely(!__pyx_tuple__5)) __PYX_ERR(0, 61, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__5);
  __Pyx_GIVEREF(__pyx_tuple__5);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":64
 * 
 *     if not cpArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments to floatCudaPySORFTransform is not "             # <<<<<<<<<<<<<<
 *                 "C contiguous.")
 *     if not radem.dtype == "int8":
 */
  __pyx_tuple__6 = PyTuple_Pack(1, __pyx_kp_u_One_or_more_arguments_to_floatCu); if (unlikely(!__pyx_tuple__6)) __PYX_ERR(0, 64, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__6);
  __Pyx_GIVEREF(__pyx_tuple__6);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":67
 *                 "C contiguous.")
 *     if not radem.dtype == "int8":
 *         raise ValueError("radem must be of type int8.")             # <<<<<<<<<<<<<<
 *     logdim = np.log2(cpArray.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or cpArray.shape[2] < 2:
 */
  __pyx_tuple__7 = PyTuple_Pack(1, __pyx_kp_u_radem_must_be_of_type_int8); if (unlikely(!__pyx_tuple__7)) __PYX_ERR(0, 67, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__7);
  __Pyx_GIVEREF(__pyx_tuple__7);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":70
 *     logdim = np.log2(cpArray.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or cpArray.shape[2] < 2:
 *         raise ValueError("dim2 of the input array to floatCudaPySORFTransform "             # <<<<<<<<<<<<<<
 *                             "must be a power of 2 >= 2.")
 * 
 */
  __pyx_tuple__8 = PyTuple_Pack(1, __pyx_kp_u_dim2_of_the_input_array_to_float); if (unlikely(!__pyx_tuple__8)) __PYX_ERR(0, 70, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__8);
  __Pyx_GIVEREF(__pyx_tuple__8);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":83
 *                 cpArray.shape[2])
 *     else:
 *         raise ValueError("Unexpected array type passed to a wrapped C++ function.")             # <<<<<<<<<<<<<<
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered in floatCudaSORF3d.")
 */
  __pyx_tuple__9 = PyTuple_Pack(1, __pyx_kp_u_Unexpected_array_type_passed_to); if (unlikely(!__pyx_tuple__9)) __PYX_ERR(0, 83, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__9);
  __Pyx_GIVEREF(__pyx_tuple__9);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":85
 *         raise ValueError("Unexpected array type passed to a wrapped C++ function.")
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered in floatCudaSORF3d.")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_tuple__10 = PyTuple_Pack(1, __pyx_kp_u_Fatal_error_encountered_in_float); if (unlikely(!__pyx_tuple__10)) __PYX_ERR(0, 85, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__10);
  __Pyx_GIVEREF(__pyx_tuple__10);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":120
 * 
 *     if radem.dtype != "int8":
 *         raise ValueError("Incorrect data types passed.")             # <<<<<<<<<<<<<<
 *     if len(Z.shape) != 2 or len(radem.shape) != 1:
 *         raise ValueError("Incorrect array dims passed.")
 */
  __pyx_tuple__11 = PyTuple_Pack(1, __pyx_kp_u_Incorrect_data_types_passed); if (unlikely(!__pyx_tuple__11)) __PYX_ERR(0, 120, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__11);
  __Pyx_GIVEREF(__pyx_tuple__11);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":122
 *         raise ValueError("Incorrect data types passed.")
 *     if len(Z.shape) != 2 or len(radem.shape) != 1:
 *         raise ValueError("Incorrect array dims passed.")             # <<<<<<<<<<<<<<
 *     if Z.shape[0] == 0:
 *         raise ValueError("There must be at least one datapoint.")
 */
  __pyx_tuple__12 = PyTuple_Pack(1, __pyx_kp_u_Incorrect_array_dims_passed); if (unlikely(!__pyx_tuple__12)) __PYX_ERR(0, 122, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__12);
  __Pyx_GIVEREF(__pyx_tuple__12);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":130
 *         raise ValueError("Incorrect array dims passed.")
 *     if compression_size > Z.shape[1] or compression_size < 2:
 *         raise ValueError("Compression size must be <= num rffs but >= 2.")             # <<<<<<<<<<<<<<
 * 
 *     if not Z.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"]:
 */
  __pyx_tuple__13 = PyTuple_Pack(1, __pyx_kp_u_Compression_size_must_be_num_rff); if (unlikely(!__pyx_tuple__13)) __PYX_ERR(0, 130, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__13);
  __Pyx_GIVEREF(__pyx_tuple__13);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":133
 * 
 *     if not Z.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments to cpuSORFTransform is not "             # <<<<<<<<<<<<<<
 *                 "C contiguous.")
 *     logdim = np.log2(Z.shape[1])
 */
  __pyx_tuple__14 = PyTuple_Pack(1, __pyx_kp_u_One_or_more_arguments_to_cpuSORF); if (unlikely(!__pyx_tuple__14)) __PYX_ERR(0, 133, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__14);
  __Pyx_GIVEREF(__pyx_tuple__14);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":137
 *     logdim = np.log2(Z.shape[1])
 *     if np.ceil(logdim) != np.floor(logdim) or Z.shape[1] < 2:
 *         raise ValueError("dim1 of the input array must be a power of 2 >= 2.")             # <<<<<<<<<<<<<<
 * 
 *     if Z.dtype == "float32":
 */
  __pyx_tuple__15 = PyTuple_Pack(1, __pyx_kp_u_dim1_of_the_input_array_must_be); if (unlikely(!__pyx_tuple__15)) __PYX_ERR(0, 137, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__15);
  __Pyx_GIVEREF(__pyx_tuple__15);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":147
 * 
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered.")             # <<<<<<<<<<<<<<
 * 
 *     Z[:,:compression_size] = Z[:,sampler]
 */
  __pyx_tuple__16 = PyTuple_Pack(1, __pyx_kp_u_Fatal_error_encountered); if (unlikely(!__pyx_tuple__16)) __PYX_ERR(0, 147, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__16);
  __Pyx_GIVEREF(__pyx_tuple__16);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":149
 *         raise Exception("Fatal error encountered.")
 * 
 *     Z[:,:compression_size] = Z[:,sampler]             # <<<<<<<<<<<<<<
 *     scaling_factor = np.sqrt( <double>radem.shape[0] / <double>compression_size )
 *     Z[:,:compression_size] *= scaling_factor
 */
  __pyx_slice__17 = PySlice_New(Py_None, Py_None, Py_None); if (unlikely(!__pyx_slice__17)) __PYX_ERR(0, 149, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_slice__17);
  __Pyx_GIVEREF(__pyx_slice__17);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":82
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 *         raise ValueError("The number of input and output datapoints do not "             # <<<<<<<<<<<<<<
 *                 "agree.")
 *     if not len(radem.shape) == 3:
 */
  __pyx_tuple__18 = PyTuple_Pack(1, __pyx_kp_u_The_number_of_input_and_output_d); if (unlikely(!__pyx_tuple__18)) __PYX_ERR(1, 82, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__18);
  __Pyx_GIVEREF(__pyx_tuple__18);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":85
 *                 "agree.")
 *     if not len(radem.shape) == 3:
 *         raise ValueError("radem must be a 3d array.")             # <<<<<<<<<<<<<<
 *     if not len(chiArr.shape) == 1 or not len(outputArray.shape) == 2:
 *         raise ValueError("chiArr must be a 1d array; outputArray must be 2d.")
 */
  __pyx_tuple__19 = PyTuple_Pack(1, __pyx_kp_u_radem_must_be_a_3d_array); if (unlikely(!__pyx_tuple__19)) __PYX_ERR(1, 85, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__19);
  __Pyx_GIVEREF(__pyx_tuple__19);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":87
 *         raise ValueError("radem must be a 3d array.")
 *     if not len(chiArr.shape) == 1 or not len(outputArray.shape) == 2:
 *         raise ValueError("chiArr must be a 1d array; outputArray must be 2d.")             # <<<<<<<<<<<<<<
 *     if not len(reshapedX.shape) == 3:
 *         raise ValueError("X must be a 3d array.")
 */
  __pyx_tuple__20 = PyTuple_Pack(1, __pyx_kp_u_chiArr_must_be_a_1d_array_output); if (unlikely(!__pyx_tuple__20)) __PYX_ERR(1, 87, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__20);
  __Pyx_GIVEREF(__pyx_tuple__20);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":89
 *         raise ValueError("chiArr must be a 1d array; outputArray must be 2d.")
 *     if not len(reshapedX.shape) == 3:
 *         raise ValueError("X must be a 3d array.")             # <<<<<<<<<<<<<<
 *     if not radem.dtype == "int8":
 *         raise ValueError("radem must be int8.")
 */
  __pyx_tuple__21 = PyTuple_Pack(1, __pyx_kp_u_X_must_be_a_3d_array); if (unlikely(!__pyx_tuple__21)) __PYX_ERR(1, 89, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__21);
  __Pyx_GIVEREF(__pyx_tuple__21);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":91
 *         raise ValueError("X must be a 3d array.")
 *     if not radem.dtype == "int8":
 *         raise ValueError("radem must be int8.")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_tuple__22 = PyTuple_Pack(1, __pyx_kp_u_radem_must_be_int8); if (unlikely(!__pyx_tuple__22)) __PYX_ERR(1, 91, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__22);
  __Pyx_GIVEREF(__pyx_tuple__22);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":96
 *     #Check that shapes of radem, outputArray are correct.
 *     if radem.shape[0] != 3 or radem.shape[1] != 1:
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")             # <<<<<<<<<<<<<<
 *     if outputArray.shape[1] != radem.shape[2]:
 *         raise ValueError("outputArray.shape[1] must be an integer multiple of the next largest "
 */
  __pyx_tuple__23 = PyTuple_Pack(1, __pyx_kp_u_radem_must_have_length_3_for_dim_2); if (unlikely(!__pyx_tuple__23)) __PYX_ERR(1, 96, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__23);
  __Pyx_GIVEREF(__pyx_tuple__23);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":98
 *         raise ValueError("radem must have length 3 for dim 0 and length 1 for dim1.")
 *     if outputArray.shape[1] != radem.shape[2]:
 *         raise ValueError("outputArray.shape[1] must be an integer multiple of the next largest "             # <<<<<<<<<<<<<<
 *                 "power of 2 greater than the kernel width * X.shape[2].")
 * 
 */
  __pyx_tuple__24 = PyTuple_Pack(1, __pyx_kp_u_outputArray_shape_1_must_be_an_i); if (unlikely(!__pyx_tuple__24)) __PYX_ERR(1, 98, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__24);
  __Pyx_GIVEREF(__pyx_tuple__24);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":103
 *     #Next, make sure that reshapedX and chiArr make sense.
 *     if chiArr.shape[0] != radem.shape[2]:
 *         raise ValueError("chiArr.shape[0] must == radem.shape[2].")             # <<<<<<<<<<<<<<
 * 
 *     logdim = np.log2(reshapedX.shape[2])
 */
  __pyx_tuple__25 = PyTuple_Pack(1, __pyx_kp_u_chiArr_shape_0_must_radem_shape); if (unlikely(!__pyx_tuple__25)) __PYX_ERR(1, 103, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__25);
  __Pyx_GIVEREF(__pyx_tuple__25);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":107
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")             # <<<<<<<<<<<<<<
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "
 */
  __pyx_tuple__26 = PyTuple_Pack(1, __pyx_kp_u_dim2_of_the_reshapedX_array_must); if (unlikely(!__pyx_tuple__26)) __PYX_ERR(1, 107, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__26);
  __Pyx_GIVEREF(__pyx_tuple__26);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":109
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if not radem.shape[2] % reshapedX.shape[2] == 0:
 *         raise ValueError("The number of sampled frequencies should be an integer multiple of "             # <<<<<<<<<<<<<<
 *                 "reshapedX.shape[2].")
 * 
 */
  __pyx_tuple__27 = PyTuple_Pack(1, __pyx_kp_u_The_number_of_sampled_frequencie); if (unlikely(!__pyx_tuple__27)) __PYX_ERR(1, 109, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__27);
  __Pyx_GIVEREF(__pyx_tuple__27);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":115
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] \
 *             or not radem.flags["C_CONTIGUOUS"] or not chiArr.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments is not C contiguous.")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_tuple__28 = PyTuple_Pack(1, __pyx_kp_u_One_or_more_arguments_is_not_C_c); if (unlikely(!__pyx_tuple__28)) __PYX_ERR(1, 115, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__28);
  __Pyx_GIVEREF(__pyx_tuple__28);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":130
 *                     radem.shape[2])
 *             if errCode.decode("UTF-8") != "no_error":
 *                 raise Exception("Fatal error encountered in floatGpuConv1dTransform_.")             # <<<<<<<<<<<<<<
 * 
 *             reshapedXCopy *= chiArr[None,None,(i * reshapedX.shape[2]):((i+1) * reshapedX.shape[2])]
 */
  __pyx_tuple__29 = PyTuple_Pack(1, __pyx_kp_u_Fatal_error_encountered_in_float_2); if (unlikely(!__pyx_tuple__29)) __PYX_ERR(1, 130, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__29);
  __Pyx_GIVEREF(__pyx_tuple__29);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":154
 *             startPosition += reshapedX.shape[2]
 *     else:
 *         raise ValueError("Inconsistent types passed to a wrapped C++ function.")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_tuple__30 = PyTuple_Pack(1, __pyx_kp_u_Inconsistent_types_passed_to_a_w); if (unlikely(!__pyx_tuple__30)) __PYX_ERR(1, 154, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__30);
  __Pyx_GIVEREF(__pyx_tuple__30);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":192
 * 
 *     if len(chiArr.shape) != 1 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")             # <<<<<<<<<<<<<<
 *     if len(outputArray.shape) != 2:
 *         raise ValueError("outputArray should be a 2d array.")
 */
  __pyx_tuple__31 = PyTuple_Pack(1, __pyx_kp_u_chiArr_should_be_a_1d_array_rade); if (unlikely(!__pyx_tuple__31)) __PYX_ERR(1, 192, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__31);
  __Pyx_GIVEREF(__pyx_tuple__31);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":194
 *         raise ValueError("chiArr should be a 1d array. radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 2:
 *         raise ValueError("outputArray should be a 2d array.")             # <<<<<<<<<<<<<<
 * 
 *     if reshapedX.shape[0] == 0:
 */
  __pyx_tuple__32 = PyTuple_Pack(1, __pyx_kp_u_outputArray_should_be_a_2d_array); if (unlikely(!__pyx_tuple__32)) __PYX_ERR(1, 194, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__32);
  __Pyx_GIVEREF(__pyx_tuple__32);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":199
 *         raise ValueError("There must be at least one datapoint.")
 *     if reshapedX.shape[0] != outputArray.shape[0]:
 *         raise ValueError("The number of datapoints in the outputs and the inputs do "             # <<<<<<<<<<<<<<
 *                 "not agree.")
 *     if radem.shape[0] != 3 or radem.shape[1] != 1:
 */
  __pyx_tuple__33 = PyTuple_Pack(1, __pyx_kp_u_The_number_of_datapoints_in_the); if (unlikely(!__pyx_tuple__33)) __PYX_ERR(1, 199, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__33);
  __Pyx_GIVEREF(__pyx_tuple__33);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":205
 * 
 *     if outputArray.shape[1] % 2 != 0 or outputArray.shape[1] < 2:
 *         raise ValueError("Shape of output array is not appropriate.")             # <<<<<<<<<<<<<<
 * 
 *     if 2 * chiArr.shape[0] != outputArray.shape[1] or chiArr.shape[0] > radem.shape[2]:
 */
  __pyx_tuple__34 = PyTuple_Pack(1, __pyx_kp_u_Shape_of_output_array_is_not_app); if (unlikely(!__pyx_tuple__34)) __PYX_ERR(1, 205, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__34);
  __Pyx_GIVEREF(__pyx_tuple__34);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":208
 * 
 *     if 2 * chiArr.shape[0] != outputArray.shape[1] or chiArr.shape[0] > radem.shape[2]:
 *         raise ValueError("Shape of output array and / or chiArr is inappropriate.")             # <<<<<<<<<<<<<<
 * 
 *     logdim = np.log2(reshapedX.shape[2])
 */
  __pyx_tuple__35 = PyTuple_Pack(1, __pyx_kp_u_Shape_of_output_array_and_or_chi); if (unlikely(!__pyx_tuple__35)) __PYX_ERR(1, 208, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__35);
  __Pyx_GIVEREF(__pyx_tuple__35);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":257
 *                     reshapedX.shape[2], chiArr.shape[0], radem.shape[2], scalingTerm)
 *     else:
 *         raise ValueError("Incorrect data types supplied.")             # <<<<<<<<<<<<<<
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")
 */
  __pyx_tuple__36 = PyTuple_Pack(1, __pyx_kp_u_Incorrect_data_types_supplied); if (unlikely(!__pyx_tuple__36)) __PYX_ERR(1, 257, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__36);
  __Pyx_GIVEREF(__pyx_tuple__36);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":259
 *         raise ValueError("Incorrect data types supplied.")
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered while performing FHT RF generation.")             # <<<<<<<<<<<<<<
 * 
 *     if fitIntercept:
 */
  __pyx_tuple__37 = PyTuple_Pack(1, __pyx_kp_u_Fatal_error_encountered_while_pe); if (unlikely(!__pyx_tuple__37)) __PYX_ERR(1, 259, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__37);
  __Pyx_GIVEREF(__pyx_tuple__37);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":262
 * 
 *     if fitIntercept:
 *         outputArray[:,0] = beta_             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_tuple__38 = PyTuple_Pack(2, __pyx_slice__17, __pyx_int_0); if (unlikely(!__pyx_tuple__38)) __PYX_ERR(1, 262, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__38);
  __Pyx_GIVEREF(__pyx_tuple__38);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":419
 * 
 *     if kernelOrder not in [1,2]:
 *         raise ValueError("Unexpected kernel order supplied.")             # <<<<<<<<<<<<<<
 * 
 *     if len(chiArr.shape) != 1 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 */
  __pyx_tuple__39 = PyTuple_Pack(1, __pyx_kp_u_Unexpected_kernel_order_supplied); if (unlikely(!__pyx_tuple__39)) __PYX_ERR(1, 419, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__39);
  __Pyx_GIVEREF(__pyx_tuple__39);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":69
 * 
 *     if len(chiArr.shape) != 2 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 *         raise ValueError("chiArr should be a 2d array. radem and reshapedX should be 3d arrays.")             # <<<<<<<<<<<<<<
 *     if len(outputArray.shape) != 2:
 *         raise ValueError("outputArray should be a 2d array.")
 */
  __pyx_tuple__40 = PyTuple_Pack(1, __pyx_kp_u_chiArr_should_be_a_2d_array_rade); if (unlikely(!__pyx_tuple__40)) __PYX_ERR(3, 69, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__40);
  __Pyx_GIVEREF(__pyx_tuple__40);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":79
 *                 "not agree.")
 *     if radem.shape[0] != 3 * polydegree or radem.shape[1] != 1:
 *         raise ValueError("radem must have length polydegree for dim 0 and length 1 for dim1.")             # <<<<<<<<<<<<<<
 *     if outputArray.shape[1] != radem.shape[2]:
 *         raise ValueError("outputArray.shape[1] must be radem.shape[2], which must be an integer multiple of "
 */
  __pyx_tuple__41 = PyTuple_Pack(1, __pyx_kp_u_radem_must_have_length_polydegre); if (unlikely(!__pyx_tuple__41)) __PYX_ERR(3, 79, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__41);
  __Pyx_GIVEREF(__pyx_tuple__41);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":81
 *         raise ValueError("radem must have length polydegree for dim 0 and length 1 for dim1.")
 *     if outputArray.shape[1] != radem.shape[2]:
 *         raise ValueError("outputArray.shape[1] must be radem.shape[2], which must be an integer multiple of "             # <<<<<<<<<<<<<<
 *                     "the next power of 2 greater than the kernel width * X.shape[2].")
 * 
 */
  __pyx_tuple__42 = PyTuple_Pack(1, __pyx_kp_u_outputArray_shape_1_must_be_rade); if (unlikely(!__pyx_tuple__42)) __PYX_ERR(3, 81, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__42);
  __Pyx_GIVEREF(__pyx_tuple__42);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":85
 * 
 *     if chiArr.shape[1] != radem.shape[2]:
 *         raise ValueError("chiArr.shape[1] must == radem.shape[2].")             # <<<<<<<<<<<<<<
 *     if chiArr.shape[0] != polydegree:
 *         raise ValueError("chiArr.shape[0] must == polydegree.")
 */
  __pyx_tuple__43 = PyTuple_Pack(1, __pyx_kp_u_chiArr_shape_1_must_radem_shape); if (unlikely(!__pyx_tuple__43)) __PYX_ERR(3, 85, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__43);
  __Pyx_GIVEREF(__pyx_tuple__43);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":87
 *         raise ValueError("chiArr.shape[1] must == radem.shape[2].")
 *     if chiArr.shape[0] != polydegree:
 *         raise ValueError("chiArr.shape[0] must == polydegree.")             # <<<<<<<<<<<<<<
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 */
  __pyx_tuple__44 = PyTuple_Pack(1, __pyx_kp_u_chiArr_shape_0_must_polydegree); if (unlikely(!__pyx_tuple__44)) __PYX_ERR(3, 87, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__44);
  __Pyx_GIVEREF(__pyx_tuple__44);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":119
 *             if errCode.decode("UTF-8") != "no_error":
 *                 raise Exception("Fatal error encountered while performing FHT RF generation.")
 *             preSumFeats *= chiArr[0:1, None, startPosition:cutoff]             # <<<<<<<<<<<<<<
 * 
 *             for j in range(1, polydegree):
 */
  __pyx_slice__45 = PySlice_New(__pyx_int_0, __pyx_int_1, Py_None); if (unlikely(!__pyx_slice__45)) __PYX_ERR(3, 119, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_slice__45);
  __Pyx_GIVEREF(__pyx_slice__45);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":160
 *             startPosition += reshapedX.shape[2]
 *     else:
 *         raise ValueError("Inconsistent array types passed to wrapped C++ function.")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_tuple__46 = PyTuple_Pack(1, __pyx_kp_u_Inconsistent_array_types_passed); if (unlikely(!__pyx_tuple__46)) __PYX_ERR(3, 160, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__46);
  __Pyx_GIVEREF(__pyx_tuple__46);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":196
 * 
 *     if len(chiArr.shape) != 3 or len(radem.shape) != 3 or len(reshapedX.shape) != 3:
 *         raise ValueError("chiArr, radem and reshapedX should be 3d arrays.")             # <<<<<<<<<<<<<<
 *     if len(outputArray.shape) != 3:
 *         raise ValueError("outputArray should be a 3d array.")
 */
  __pyx_tuple__47 = PyTuple_Pack(1, __pyx_kp_u_chiArr_radem_and_reshapedX_shoul); if (unlikely(!__pyx_tuple__47)) __PYX_ERR(3, 196, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__47);
  __Pyx_GIVEREF(__pyx_tuple__47);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":198
 *         raise ValueError("chiArr, radem and reshapedX should be 3d arrays.")
 *     if len(outputArray.shape) != 3:
 *         raise ValueError("outputArray should be a 3d array.")             # <<<<<<<<<<<<<<
 * 
 *     if reshapedX.shape[0] == 0:
 */
  __pyx_tuple__48 = PyTuple_Pack(1, __pyx_kp_u_outputArray_should_be_a_3d_array); if (unlikely(!__pyx_tuple__48)) __PYX_ERR(3, 198, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__48);
  __Pyx_GIVEREF(__pyx_tuple__48);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":207
 *                 "not agree.")
 *     if radem.shape[0] != 3 * polydegree or chiArr.shape[0] != polydegree:
 *         raise ValueError("radem & chiArr must have length polydegree for dim 0.")             # <<<<<<<<<<<<<<
 * 
 *     if chiArr.shape[2] != radem.shape[2] or chiArr.shape[1] != radem.shape[1]:
 */
  __pyx_tuple__49 = PyTuple_Pack(1, __pyx_kp_u_radem_chiArr_must_have_length_po); if (unlikely(!__pyx_tuple__49)) __PYX_ERR(3, 207, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__49);
  __Pyx_GIVEREF(__pyx_tuple__49);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":210
 * 
 *     if chiArr.shape[2] != radem.shape[2] or chiArr.shape[1] != radem.shape[1]:
 *         raise ValueError("chiArr must have same shape[1] and shape[2] as radem.")             # <<<<<<<<<<<<<<
 *     logdim = np.log2(reshapedX.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or reshapedX.shape[2] < 2:
 */
  __pyx_tuple__50 = PyTuple_Pack(1, __pyx_kp_u_chiArr_must_have_same_shape_1_an); if (unlikely(!__pyx_tuple__50)) __PYX_ERR(3, 210, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__50);
  __Pyx_GIVEREF(__pyx_tuple__50);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":215
 *         raise ValueError("dim2 of the reshapedX array must be a power of 2 >= 2.")
 *     if radem.shape[2] != reshapedX.shape[2] or radem.shape[1] != reshapedX.shape[1]:
 *         raise ValueError("reshapedX shape[1] and shape[2] must == radem shape[1] and shape[2].")             # <<<<<<<<<<<<<<
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not reshapedX.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] \
 */
  __pyx_tuple__51 = PyTuple_Pack(1, __pyx_kp_u_reshapedX_shape_1_and_shape_2_mu); if (unlikely(!__pyx_tuple__51)) __PYX_ERR(3, 215, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__51);
  __Pyx_GIVEREF(__pyx_tuple__51);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":237
 *                 outputArray.shape[0], outputArray.shape[1], outputArray.shape[2])
 *         if errCode.decode("UTF-8") != "no_error":
 *             raise Exception("Fatal error encountered while performing graph convolution.")             # <<<<<<<<<<<<<<
 *         outputArray *= chiArr[0:1, :, :]
 * 
 */
  __pyx_tuple__52 = PyTuple_Pack(1, __pyx_kp_u_Fatal_error_encountered_while_pe_2); if (unlikely(!__pyx_tuple__52)) __PYX_ERR(3, 237, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__52);
  __Pyx_GIVEREF(__pyx_tuple__52);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":238
 *         if errCode.decode("UTF-8") != "no_error":
 *             raise Exception("Fatal error encountered while performing graph convolution.")
 *         outputArray *= chiArr[0:1, :, :]             # <<<<<<<<<<<<<<
 * 
 *         for j in range(1, polydegree):
 */
  __pyx_tuple__53 = PyTuple_Pack(3, __pyx_slice__45, __pyx_slice__17, __pyx_slice__17); if (unlikely(!__pyx_tuple__53)) __PYX_ERR(3, 238, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__53);
  __Pyx_GIVEREF(__pyx_tuple__53);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":299
 * 
 *     if len(inputArray.shape) != 2 or len(outputArray.shape) != 2:
 *         raise ValueError("Both inputArray and outputArray for the exact quadratic "             # <<<<<<<<<<<<<<
 *                 "must be 2d arrays.")
 * 
 */
  __pyx_tuple__54 = PyTuple_Pack(1, __pyx_kp_u_Both_inputArray_and_outputArray); if (unlikely(!__pyx_tuple__54)) __PYX_ERR(3, 299, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__54);
  __Pyx_GIVEREF(__pyx_tuple__54);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":308
 *                 "not agree.")
 *     if outputArray.shape[1] != numExpectedFeats:
 *         raise ValueError("The shape of the output array is incorrect for a quadratic.")             # <<<<<<<<<<<<<<
 * 
 *     if not outputArray.flags["C_CONTIGUOUS"] or not inputArray.flags["C_CONTIGUOUS"]:
 */
  __pyx_tuple__55 = PyTuple_Pack(1, __pyx_kp_u_The_shape_of_the_output_array_is); if (unlikely(!__pyx_tuple__55)) __PYX_ERR(3, 308, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__55);
  __Pyx_GIVEREF(__pyx_tuple__55);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":322
 * 
 *     else:
 *         raise ValueError("Unexpected types passed to wrapped C++ function.")             # <<<<<<<<<<<<<<
 * 
 *     if errCode.decode("UTF-8") != "no_error":
 */
  __pyx_tuple__56 = PyTuple_Pack(1, __pyx_kp_u_Unexpected_types_passed_to_wrapp); if (unlikely(!__pyx_tuple__56)) __PYX_ERR(3, 322, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__56);
  __Pyx_GIVEREF(__pyx_tuple__56);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":81
 *     if not inputArray.flags["C_CONTIGUOUS"] or not radem.flags["C_CONTIGUOUS"] or not \
 *             chiArr.flags["C_CONTIGUOUS"] or not outputArray.flags["C_CONTIGUOUS"]:
 *         raise ValueError("One or more arguments to a wrapped RBF feature gen function is not "             # <<<<<<<<<<<<<<
 *                 "C contiguous.")
 * 
 */
  __pyx_tuple__57 = PyTuple_Pack(1, __pyx_kp_u_One_or_more_arguments_to_a_wrapp); if (unlikely(!__pyx_tuple__57)) __PYX_ERR(4, 81, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__57);
  __Pyx_GIVEREF(__pyx_tuple__57);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":87
 *         raise ValueError("There must be at least one datapoint.")
 *     if inputArray.shape[1] != radem.shape[1] or inputArray.shape[2] != radem.shape[2]:
 *         raise ValueError("Incorrect array dims passed to a wrapped RBF feature gen function.")             # <<<<<<<<<<<<<<
 *     if radem.shape[0] != 3:
 *         raise ValueError("radem must have length 3 for dim 0.")
 */
  __pyx_tuple__58 = PyTuple_Pack(1, __pyx_kp_u_Incorrect_array_dims_passed_to_a); if (unlikely(!__pyx_tuple__58)) __PYX_ERR(4, 87, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__58);
  __Pyx_GIVEREF(__pyx_tuple__58);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":91
 *         raise ValueError("radem must have length 3 for dim 0.")
 *     if inputArray.shape[0] != outputArray.shape[0]:
 *         raise ValueError("inputArray and outputArray to RBF feature gen must have same number "             # <<<<<<<<<<<<<<
 *                     "of datapoints.")
 *     if outputArray.shape[1] != 2 * chiArr.shape[0]:
 */
  __pyx_tuple__59 = PyTuple_Pack(1, __pyx_kp_u_inputArray_and_outputArray_to_RB); if (unlikely(!__pyx_tuple__59)) __PYX_ERR(4, 91, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__59);
  __Pyx_GIVEREF(__pyx_tuple__59);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":94
 *                     "of datapoints.")
 *     if outputArray.shape[1] != 2 * chiArr.shape[0]:
 *         raise ValueError("chiArr input to RBF feature gen is of incorrect size.")             # <<<<<<<<<<<<<<
 *     if 2 * inputArray.shape[1] * inputArray.shape[2] < outputArray.shape[1]:
 *         raise ValueError("Sizes on input and output arrays to RBF feature gen are inappropriate.")
 */
  __pyx_tuple__60 = PyTuple_Pack(1, __pyx_kp_u_chiArr_input_to_RBF_feature_gen); if (unlikely(!__pyx_tuple__60)) __PYX_ERR(4, 94, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__60);
  __Pyx_GIVEREF(__pyx_tuple__60);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":96
 *         raise ValueError("chiArr input to RBF feature gen is of incorrect size.")
 *     if 2 * inputArray.shape[1] * inputArray.shape[2] < outputArray.shape[1]:
 *         raise ValueError("Sizes on input and output arrays to RBF feature gen are inappropriate.")             # <<<<<<<<<<<<<<
 * 
 *     logdim = np.log2(inputArray.shape[2])
 */
  __pyx_tuple__61 = PyTuple_Pack(1, __pyx_kp_u_Sizes_on_input_and_output_arrays); if (unlikely(!__pyx_tuple__61)) __PYX_ERR(4, 96, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__61);
  __Pyx_GIVEREF(__pyx_tuple__61);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":100
 *     logdim = np.log2(inputArray.shape[2])
 *     if np.ceil(logdim) != np.floor(logdim) or inputArray.shape[2] < 2:
 *         raise ValueError("dim2 of the input array to RBF feature gen functions "             # <<<<<<<<<<<<<<
 *                             "must be a power of 2 >= 2.")
 * 
 */
  __pyx_tuple__62 = PyTuple_Pack(1, __pyx_kp_u_dim2_of_the_input_array_to_RBF_f); if (unlikely(!__pyx_tuple__62)) __PYX_ERR(4, 100, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__62);
  __Pyx_GIVEREF(__pyx_tuple__62);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":121
 *                 inputArray.shape[2], chiArr.shape[0]);
 *     else:
 *         raise ValueError("The input and chiArr arrays are of inconsistent types.")             # <<<<<<<<<<<<<<
 * 
 *     if errCode.decode("UTF-8") != "no_error":
 */
  __pyx_tuple__63 = PyTuple_Pack(1, __pyx_kp_u_The_input_and_chiArr_arrays_are); if (unlikely(!__pyx_tuple__63)) __PYX_ERR(4, 121, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__63);
  __Pyx_GIVEREF(__pyx_tuple__63);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":124
 * 
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered in CudaRBFFeatureGen.")             # <<<<<<<<<<<<<<
 *     if fitIntercept:
 *         outputArray[:,0] = betaHparam
 */
  __pyx_tuple__64 = PyTuple_Pack(1, __pyx_kp_u_Fatal_error_encountered_in_CudaR); if (unlikely(!__pyx_tuple__64)) __PYX_ERR(4, 124, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__64);
  __Pyx_GIVEREF(__pyx_tuple__64);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":222
 *         raise ValueError("The input and chiArr arrays are of inconsistent types.")
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered in doubleCudaRBFFeatureGen.")             # <<<<<<<<<<<<<<
 *     if fitIntercept:
 *         outputArray[:,0] = betaHparam
 */
  __pyx_tuple__65 = PyTuple_Pack(1, __pyx_kp_u_Fatal_error_encountered_in_doubl); if (unlikely(!__pyx_tuple__65)) __PYX_ERR(4, 222, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__65);
  __Pyx_GIVEREF(__pyx_tuple__65);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":272
 *     if len(inputX.shape) != 2 or len(outputArray.shape) != 2 or \
 *             len(precompWeights.shape) != 2 or len(sigmaMap.shape) != 1:
 *         raise ValueError("The input arrays to a wrapped RBF feature gen function have incorrect "             # <<<<<<<<<<<<<<
 *                 "shapes.")
 * 
 */
  __pyx_tuple__66 = PyTuple_Pack(1, __pyx_kp_u_The_input_arrays_to_a_wrapped_RB); if (unlikely(!__pyx_tuple__66)) __PYX_ERR(4, 272, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__66);
  __Pyx_GIVEREF(__pyx_tuple__66);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":327
 *                 rbfNormConstant)
 *     else:
 *         raise ValueError("The input arrays to a wrapped RBF feature gen function have incorrect "             # <<<<<<<<<<<<<<
 *                 "types.")
 * 
 */
  __pyx_tuple__67 = PyTuple_Pack(1, __pyx_kp_u_The_input_arrays_to_a_wrapped_RB_2); if (unlikely(!__pyx_tuple__67)) __PYX_ERR(4, 327, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__67);
  __Pyx_GIVEREF(__pyx_tuple__67);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":331
 * 
 *     if errCode.decode("UTF-8") != "no_error":
 *         raise Exception("Fatal error encountered in RBF feature gen.")             # <<<<<<<<<<<<<<
 *     if fitIntercept:
 *         outputArray[:,0] = betaHparam
 */
  __pyx_tuple__68 = PyTuple_Pack(1, __pyx_kp_u_Fatal_error_encountered_in_RBF_f); if (unlikely(!__pyx_tuple__68)) __PYX_ERR(4, 331, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__68);
  __Pyx_GIVEREF(__pyx_tuple__68);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":334
 *     if fitIntercept:
 *         outputArray[:,0] = betaHparam
 *         gradient[:,0,:] = 0             # <<<<<<<<<<<<<<
 *     return gradient
 */
  __pyx_tuple__69 = PyTuple_Pack(3, __pyx_slice__17, __pyx_int_0, __pyx_slice__17); if (unlikely(!__pyx_tuple__69)) __PYX_ERR(4, 334, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__69);
  __Pyx_GIVEREF(__pyx_tuple__69);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":26
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaPySORFTransform(cpArray, radem, int numThreads):
 */
  __pyx_tuple__71 = PyTuple_Pack(7, __pyx_n_s_cpArray, __pyx_n_s_radem, __pyx_n_s_numThreads, __pyx_n_s_errCode, __pyx_n_s_logdim, __pyx_n_s_addr, __pyx_n_s_addr_radem); if (unlikely(!__pyx_tuple__71)) __PYX_ERR(0, 26, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__71);
  __Pyx_GIVEREF(__pyx_tuple__71);
  __pyx_codeobj__72 = (PyObject*)__Pyx_PyCode_New(3, 0, 0, 7, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__71, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_xGPR_random_feature_generation_g, __pyx_n_s_cudaPySORFTransform, 26, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__72)) __PYX_ERR(0, 26, __pyx_L1_error)

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":91
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaSRHT(Z, radem,
 */
  __pyx_tuple__73 = PyTuple_Pack(10, __pyx_n_s_Z, __pyx_n_s_radem, __pyx_n_s_sampler, __pyx_n_s_compression_size, __pyx_n_s_numThreads, __pyx_n_s_errCode, __pyx_n_s_scaling_factor, __pyx_n_s_addr, __pyx_n_s_addr_radem, __pyx_n_s_logdim); if (unlikely(!__pyx_tuple__73)) __PYX_ERR(0, 91, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__73);
  __Pyx_GIVEREF(__pyx_tuple__73);
  __pyx_codeobj__74 = (PyObject*)__Pyx_PyCode_New(5, 0, 0, 10, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__73, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_xGPR_random_feature_generation_g, __pyx_n_s_cudaSRHT, 91, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__74)) __PYX_ERR(0, 91, __pyx_L1_error)

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":46
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuConv1dMaxpool(reshapedX, radem, outputArray, chiArr,
 */
  __pyx_tuple__75 = PyTuple_Pack(14, __pyx_n_s_reshapedX, __pyx_n_s_radem, __pyx_n_s_outputArray, __pyx_n_s_chiArr, __pyx_n_s_numThreads, __pyx_n_s_errCode, __pyx_n_s_i, __pyx_n_s_startPosition, __pyx_n_s_cutoff, __pyx_n_s_num_repeats, __pyx_n_s_reshapedXCopy, __pyx_n_s_addr_reshapedCopy, __pyx_n_s_addr_radem, __pyx_n_s_logdim); if (unlikely(!__pyx_tuple__75)) __PYX_ERR(1, 46, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__75);
  __Pyx_GIVEREF(__pyx_tuple__75);
  __pyx_codeobj__76 = (PyObject*)__Pyx_PyCode_New(5, 0, 0, 14, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__75, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_xGPR_random_feature_generation_g_2, __pyx_n_s_gpuConv1dMaxpool, 46, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__76)) __PYX_ERR(1, 46, __pyx_L1_error)

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":159
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuConv1dFGen(reshapedX, radem, outputArray, chiArr,
 */
  __pyx_tuple__77 = PyTuple_Pack(16, __pyx_n_s_reshapedX, __pyx_n_s_radem, __pyx_n_s_outputArray, __pyx_n_s_chiArr, __pyx_n_s_numThreads, __pyx_n_s_beta, __pyx_n_s_fitIntercept, __pyx_n_s_errCode, __pyx_n_s_scalingTerm, __pyx_n_s_logdim, __pyx_n_s_featureArray, __pyx_n_s_addr_reshapedX, __pyx_n_s_addr_featureArray, __pyx_n_s_addr_radem, __pyx_n_s_addr_chi, __pyx_n_s_addr_output); if (unlikely(!__pyx_tuple__77)) __PYX_ERR(1, 159, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__77);
  __Pyx_GIVEREF(__pyx_tuple__77);
  __pyx_codeobj__78 = (PyObject*)__Pyx_PyCode_New(7, 0, 0, 16, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__77, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_xGPR_random_feature_generation_g_2, __pyx_n_s_gpuConv1dFGen, 159, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__78)) __PYX_ERR(1, 159, __pyx_L1_error)

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":266
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuConvGrad(reshapedX, radem, outputArray, chiArr,
 */
  __pyx_tuple__79 = PyTuple_Pack(27, __pyx_n_s_reshapedX, __pyx_n_s_radem, __pyx_n_s_outputArray, __pyx_n_s_chiArr, __pyx_n_s_numThreads, __pyx_n_s_sigma, __pyx_n_s_beta, __pyx_n_s_fitIntercept, __pyx_n_s_errCode, __pyx_n_s_reshapedXCopy, __pyx_n_s_scalingTerm, __pyx_n_s_num_repeats, __pyx_n_s_startPosition, __pyx_n_s_cutoff, __pyx_n_s_startPos2, __pyx_n_s_cutoff2, __pyx_n_s_i, __pyx_n_s_j, __pyx_n_s_logdim, __pyx_n_s_gradient, __pyx_n_s_featureArray, __pyx_n_s_addr_reshapedX, __pyx_n_s_addr_featureArray, __pyx_n_s_addr_radem, __pyx_n_s_addr_chi, __pyx_n_s_addr_output, __pyx_n_s_addr_gradient); if (unlikely(!__pyx_tuple__79)) __PYX_ERR(1, 266, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__79);
  __Pyx_GIVEREF(__pyx_tuple__79);
  __pyx_codeobj__80 = (PyObject*)__Pyx_PyCode_New(8, 0, 0, 27, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__79, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_xGPR_random_feature_generation_g_2, __pyx_n_s_gpuConvGrad, 266, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__80)) __PYX_ERR(1, 266, __pyx_L1_error)

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":386
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuConv1dArcCosFGen(reshapedX, radem, outputArray, chiArr,
 */
  __pyx_tuple__81 = PyTuple_Pack(17, __pyx_n_s_reshapedX, __pyx_n_s_radem, __pyx_n_s_outputArray, __pyx_n_s_chiArr, __pyx_n_s_numThreads, __pyx_n_s_beta, __pyx_n_s_kernelOrder, __pyx_n_s_fitIntercept, __pyx_n_s_errCode, __pyx_n_s_scalingTerm, __pyx_n_s_logdim, __pyx_n_s_featureArray, __pyx_n_s_addr_reshapedX, __pyx_n_s_addr_featureArray, __pyx_n_s_addr_radem, __pyx_n_s_addr_chi, __pyx_n_s_addr_output); if (unlikely(!__pyx_tuple__81)) __PYX_ERR(1, 386, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__81);
  __Pyx_GIVEREF(__pyx_tuple__81);
  __pyx_codeobj__82 = (PyObject*)__Pyx_PyCode_New(8, 0, 0, 17, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__81, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_xGPR_random_feature_generation_g_2, __pyx_n_s_gpuConv1dArcCosFGen, 386, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__82)) __PYX_ERR(1, 386, __pyx_L1_error)

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":35
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuGraphPolyFHT(reshapedX, radem, chiArr, outputArray, int polydegree,
 */
  __pyx_tuple__83 = PyTuple_Pack(18, __pyx_n_s_reshapedX, __pyx_n_s_radem, __pyx_n_s_chiArr, __pyx_n_s_outputArray, __pyx_n_s_polydegree, __pyx_n_s_numThreads, __pyx_n_s_errCode, __pyx_n_s_reshapedXCopy, __pyx_n_s_preSumFeats, __pyx_n_s_num_repeats, __pyx_n_s_startPosition, __pyx_n_s_cutoff, __pyx_n_s_i, __pyx_n_s_j, __pyx_n_s_logdim, __pyx_n_s_addr_reshapedCopy, __pyx_n_s_addr_preSumFeats, __pyx_n_s_addr_radem); if (unlikely(!__pyx_tuple__83)) __PYX_ERR(3, 35, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__83);
  __Pyx_GIVEREF(__pyx_tuple__83);
  __pyx_codeobj__84 = (PyObject*)__Pyx_PyCode_New(6, 0, 0, 18, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__83, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_xGPR_random_feature_generation_g_3, __pyx_n_s_gpuGraphPolyFHT, 35, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__84)) __PYX_ERR(3, 35, __pyx_L1_error)

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":165
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuPolyFHT(reshapedX, radem, chiArr, outputArray, int polydegree,
 */
  __pyx_tuple__85 = PyTuple_Pack(15, __pyx_n_s_reshapedX, __pyx_n_s_radem, __pyx_n_s_chiArr, __pyx_n_s_outputArray, __pyx_n_s_polydegree, __pyx_n_s_numThreads, __pyx_n_s_errCode, __pyx_n_s_reshapedXCopy, __pyx_n_s_j, __pyx_n_s_k, __pyx_n_s_logdim, __pyx_n_s_addr_reshapedCopy, __pyx_n_s_addr_output, __pyx_n_s_addr_radem, __pyx_n_s_radem_ptr); if (unlikely(!__pyx_tuple__85)) __PYX_ERR(3, 165, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__85);
  __Pyx_GIVEREF(__pyx_tuple__85);
  __pyx_codeobj__86 = (PyObject*)__Pyx_PyCode_New(6, 0, 0, 15, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__85, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_xGPR_random_feature_generation_g_3, __pyx_n_s_gpuPolyFHT, 165, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__86)) __PYX_ERR(3, 165, __pyx_L1_error)

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":273
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaExactQuadratic(inputArray, outputArray,
 */
  __pyx_tuple__87 = PyTuple_Pack(7, __pyx_n_s_inputArray, __pyx_n_s_outputArray, __pyx_n_s_numThreads, __pyx_n_s_errCode, __pyx_n_s_addr_output, __pyx_n_s_addr_input, __pyx_n_s_numExpectedFeats); if (unlikely(!__pyx_tuple__87)) __PYX_ERR(3, 273, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__87);
  __Pyx_GIVEREF(__pyx_tuple__87);
  __pyx_codeobj__88 = (PyObject*)__Pyx_PyCode_New(3, 0, 0, 7, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__87, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_xGPR_random_feature_generation_g_3, __pyx_n_s_cudaExactQuadratic, 273, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__88)) __PYX_ERR(3, 273, __pyx_L1_error)

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":39
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaRBFFeatureGen(inputArray, outputArray, radem,
 */
  __pyx_tuple__89 = PyTuple_Pack(14, __pyx_n_s_inputArray, __pyx_n_s_outputArray, __pyx_n_s_radem, __pyx_n_s_chiArr, __pyx_n_s_betaHparam, __pyx_n_s_numThreads, __pyx_n_s_fitIntercept, __pyx_n_s_errCode, __pyx_n_s_logdim, __pyx_n_s_rbfNormConstant, __pyx_n_s_addr_input, __pyx_n_s_addr_output, __pyx_n_s_addr_chi, __pyx_n_s_addr_radem); if (unlikely(!__pyx_tuple__89)) __PYX_ERR(4, 39, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__89);
  __Pyx_GIVEREF(__pyx_tuple__89);
  __pyx_codeobj__90 = (PyObject*)__Pyx_PyCode_New(7, 0, 0, 14, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__89, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_xGPR_random_feature_generation_g_4, __pyx_n_s_cudaRBFFeatureGen, 39, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__90)) __PYX_ERR(4, 39, __pyx_L1_error)
  __pyx_tuple__91 = PyTuple_Pack(1, ((PyObject *)Py_False)); if (unlikely(!__pyx_tuple__91)) __PYX_ERR(4, 39, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__91);
  __Pyx_GIVEREF(__pyx_tuple__91);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":130
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaRBFGrad(inputArray, outputArray, radem,
 */
  __pyx_tuple__92 = PyTuple_Pack(17, __pyx_n_s_inputArray, __pyx_n_s_outputArray, __pyx_n_s_radem, __pyx_n_s_chiArr, __pyx_n_s_betaHparam, __pyx_n_s_sigmaHparam, __pyx_n_s_numThreads, __pyx_n_s_fitIntercept, __pyx_n_s_errCode, __pyx_n_s_logdim, __pyx_n_s_rbfNormConstant, __pyx_n_s_addr_input, __pyx_n_s_addr_output, __pyx_n_s_addr_chi, __pyx_n_s_addr_radem, __pyx_n_s_gradient, __pyx_n_s_addr_gradient); if (unlikely(!__pyx_tuple__92)) __PYX_ERR(4, 130, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__92);
  __Pyx_GIVEREF(__pyx_tuple__92);
  __pyx_codeobj__93 = (PyObject*)__Pyx_PyCode_New(8, 0, 0, 17, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__92, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_xGPR_random_feature_generation_g_4, __pyx_n_s_cudaRBFGrad, 130, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__93)) __PYX_ERR(4, 130, __pyx_L1_error)

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":232
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaMiniARDGrad(inputX, outputArray, precompWeights,
 */
  __pyx_tuple__94 = PyTuple_Pack(20, __pyx_n_s_inputX, __pyx_n_s_outputArray, __pyx_n_s_precompWeights, __pyx_n_s_sigmaMap, __pyx_n_s_sigmaVals, __pyx_n_s_betaHparam, __pyx_n_s_numThreads, __pyx_n_s_fitIntercept, __pyx_n_s_errCode, __pyx_n_s_logdim, __pyx_n_s_rbfNormConstant, __pyx_n_s_numLengthscales, __pyx_n_s_gradient, __pyx_n_s_addr_input, __pyx_n_s_addr_random_feats, __pyx_n_s_addr_sigma_map, __pyx_n_s_sigmaMap_ptr, __pyx_n_s_addr_sigma_vals, __pyx_n_s_addr_grad, __pyx_n_s_addr_precomp_weights); if (unlikely(!__pyx_tuple__94)) __PYX_ERR(4, 232, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__94);
  __Pyx_GIVEREF(__pyx_tuple__94);
  __pyx_codeobj__95 = (PyObject*)__Pyx_PyCode_New(8, 0, 0, 20, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__94, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_xGPR_random_feature_generation_g_4, __pyx_n_s_cudaMiniARDGrad, 232, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__95)) __PYX_ERR(4, 232, __pyx_L1_error)
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_RefNannyFinishContext();
  return -1;
}
/* #### Code section: init_constants ### */

static CYTHON_SMALL_CODE int __Pyx_InitConstants(void) {
  if (__Pyx_CreateStringTabAndInitStrings() < 0) __PYX_ERR(5, 1, __pyx_L1_error);
  __pyx_int_0 = PyInt_FromLong(0); if (unlikely(!__pyx_int_0)) __PYX_ERR(5, 1, __pyx_L1_error)
  __pyx_int_1 = PyInt_FromLong(1); if (unlikely(!__pyx_int_1)) __PYX_ERR(5, 1, __pyx_L1_error)
  __pyx_int_2 = PyInt_FromLong(2); if (unlikely(!__pyx_int_2)) __PYX_ERR(5, 1, __pyx_L1_error)
  __pyx_int_3 = PyInt_FromLong(3); if (unlikely(!__pyx_int_3)) __PYX_ERR(5, 1, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}
/* #### Code section: init_globals ### */

static CYTHON_SMALL_CODE int __Pyx_InitGlobals(void) {
  /* NumpyImportArray.init */
  /*
 * Cython has automatically inserted a call to _import_array since
 * you didn't include one when you cimported numpy. To disable this
 * add the line
 *   <void>numpy._import_array
 */
#ifdef NPY_FEATURE_VERSION
#ifndef NO_IMPORT_ARRAY
if (unlikely(_import_array() == -1)) {
    PyErr_SetString(PyExc_ImportError, "numpy.core.multiarray failed to import "
    "(auto-generated because you didn't call 'numpy.import_array()' after cimporting numpy; "
    "use '<void>numpy._import_array' to disable if you are certain you don't need it).");
}
#endif
#endif

if (unlikely(PyErr_Occurred())) __PYX_ERR(5, 1, __pyx_L1_error)

  return 0;
  __pyx_L1_error:;
  return -1;
}
/* #### Code section: init_module ### */

static CYTHON_SMALL_CODE int __Pyx_modinit_global_init_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_variable_export_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_function_export_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_type_init_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_type_import_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_variable_import_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_function_import_code(void); /*proto*/

static int __Pyx_modinit_global_init_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_global_init_code", 0);
  /*--- Global init code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_variable_export_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_variable_export_code", 0);
  /*--- Variable export code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_function_export_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_function_export_code", 0);
  /*--- Function export code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_type_init_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_type_init_code", 0);
  /*--- Type init code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_type_import_code(void) {
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__Pyx_modinit_type_import_code", 0);
  /*--- Type import code ---*/
  __pyx_t_1 = PyImport_ImportModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_t_1)) __PYX_ERR(6, 9, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_ptype_7cpython_4type_type = __Pyx_ImportType_3_0_3(__pyx_t_1, __Pyx_BUILTIN_MODULE_NAME, "type", 
  #if defined(PYPY_VERSION_NUM) && PYPY_VERSION_NUM < 0x050B0000
  sizeof(PyTypeObject), __PYX_GET_STRUCT_ALIGNMENT_3_0_3(PyTypeObject),
  #elif CYTHON_COMPILING_IN_LIMITED_API
  sizeof(PyTypeObject), __PYX_GET_STRUCT_ALIGNMENT_3_0_3(PyTypeObject),
  #else
  sizeof(PyHeapTypeObject), __PYX_GET_STRUCT_ALIGNMENT_3_0_3(PyHeapTypeObject),
  #endif
  __Pyx_ImportType_CheckSize_Warn_3_0_3); if (!__pyx_ptype_7cpython_4type_type) __PYX_ERR(6, 9, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyImport_ImportModule("numpy"); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 202, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_ptype_5numpy_dtype = __Pyx_ImportType_3_0_3(__pyx_t_1, "numpy", "dtype", sizeof(PyArray_Descr), __PYX_GET_STRUCT_ALIGNMENT_3_0_3(PyArray_Descr),__Pyx_ImportType_CheckSize_Ignore_3_0_3); if (!__pyx_ptype_5numpy_dtype) __PYX_ERR(2, 202, __pyx_L1_error)
  __pyx_ptype_5numpy_flatiter = __Pyx_ImportType_3_0_3(__pyx_t_1, "numpy", "flatiter", sizeof(PyArrayIterObject), __PYX_GET_STRUCT_ALIGNMENT_3_0_3(PyArrayIterObject),__Pyx_ImportType_CheckSize_Ignore_3_0_3); if (!__pyx_ptype_5numpy_flatiter) __PYX_ERR(2, 225, __pyx_L1_error)
  __pyx_ptype_5numpy_broadcast = __Pyx_ImportType_3_0_3(__pyx_t_1, "numpy", "broadcast", sizeof(PyArrayMultiIterObject), __PYX_GET_STRUCT_ALIGNMENT_3_0_3(PyArrayMultiIterObject),__Pyx_ImportType_CheckSize_Ignore_3_0_3); if (!__pyx_ptype_5numpy_broadcast) __PYX_ERR(2, 229, __pyx_L1_error)
  __pyx_ptype_5numpy_ndarray = __Pyx_ImportType_3_0_3(__pyx_t_1, "numpy", "ndarray", sizeof(PyArrayObject), __PYX_GET_STRUCT_ALIGNMENT_3_0_3(PyArrayObject),__Pyx_ImportType_CheckSize_Ignore_3_0_3); if (!__pyx_ptype_5numpy_ndarray) __PYX_ERR(2, 238, __pyx_L1_error)
  __pyx_ptype_5numpy_generic = __Pyx_ImportType_3_0_3(__pyx_t_1, "numpy", "generic", sizeof(PyObject), __PYX_GET_STRUCT_ALIGNMENT_3_0_3(PyObject),__Pyx_ImportType_CheckSize_Warn_3_0_3); if (!__pyx_ptype_5numpy_generic) __PYX_ERR(2, 809, __pyx_L1_error)
  __pyx_ptype_5numpy_number = __Pyx_ImportType_3_0_3(__pyx_t_1, "numpy", "number", sizeof(PyObject), __PYX_GET_STRUCT_ALIGNMENT_3_0_3(PyObject),__Pyx_ImportType_CheckSize_Warn_3_0_3); if (!__pyx_ptype_5numpy_number) __PYX_ERR(2, 811, __pyx_L1_error)
  __pyx_ptype_5numpy_integer = __Pyx_ImportType_3_0_3(__pyx_t_1, "numpy", "integer", sizeof(PyObject), __PYX_GET_STRUCT_ALIGNMENT_3_0_3(PyObject),__Pyx_ImportType_CheckSize_Warn_3_0_3); if (!__pyx_ptype_5numpy_integer) __PYX_ERR(2, 813, __pyx_L1_error)
  __pyx_ptype_5numpy_signedinteger = __Pyx_ImportType_3_0_3(__pyx_t_1, "numpy", "signedinteger", sizeof(PyObject), __PYX_GET_STRUCT_ALIGNMENT_3_0_3(PyObject),__Pyx_ImportType_CheckSize_Warn_3_0_3); if (!__pyx_ptype_5numpy_signedinteger) __PYX_ERR(2, 815, __pyx_L1_error)
  __pyx_ptype_5numpy_unsignedinteger = __Pyx_ImportType_3_0_3(__pyx_t_1, "numpy", "unsignedinteger", sizeof(PyObject), __PYX_GET_STRUCT_ALIGNMENT_3_0_3(PyObject),__Pyx_ImportType_CheckSize_Warn_3_0_3); if (!__pyx_ptype_5numpy_unsignedinteger) __PYX_ERR(2, 817, __pyx_L1_error)
  __pyx_ptype_5numpy_inexact = __Pyx_ImportType_3_0_3(__pyx_t_1, "numpy", "inexact", sizeof(PyObject), __PYX_GET_STRUCT_ALIGNMENT_3_0_3(PyObject),__Pyx_ImportType_CheckSize_Warn_3_0_3); if (!__pyx_ptype_5numpy_inexact) __PYX_ERR(2, 819, __pyx_L1_error)
  __pyx_ptype_5numpy_floating = __Pyx_ImportType_3_0_3(__pyx_t_1, "numpy", "floating", sizeof(PyObject), __PYX_GET_STRUCT_ALIGNMENT_3_0_3(PyObject),__Pyx_ImportType_CheckSize_Warn_3_0_3); if (!__pyx_ptype_5numpy_floating) __PYX_ERR(2, 821, __pyx_L1_error)
  __pyx_ptype_5numpy_complexfloating = __Pyx_ImportType_3_0_3(__pyx_t_1, "numpy", "complexfloating", sizeof(PyObject), __PYX_GET_STRUCT_ALIGNMENT_3_0_3(PyObject),__Pyx_ImportType_CheckSize_Warn_3_0_3); if (!__pyx_ptype_5numpy_complexfloating) __PYX_ERR(2, 823, __pyx_L1_error)
  __pyx_ptype_5numpy_flexible = __Pyx_ImportType_3_0_3(__pyx_t_1, "numpy", "flexible", sizeof(PyObject), __PYX_GET_STRUCT_ALIGNMENT_3_0_3(PyObject),__Pyx_ImportType_CheckSize_Warn_3_0_3); if (!__pyx_ptype_5numpy_flexible) __PYX_ERR(2, 825, __pyx_L1_error)
  __pyx_ptype_5numpy_character = __Pyx_ImportType_3_0_3(__pyx_t_1, "numpy", "character", sizeof(PyObject), __PYX_GET_STRUCT_ALIGNMENT_3_0_3(PyObject),__Pyx_ImportType_CheckSize_Warn_3_0_3); if (!__pyx_ptype_5numpy_character) __PYX_ERR(2, 827, __pyx_L1_error)
  __pyx_ptype_5numpy_ufunc = __Pyx_ImportType_3_0_3(__pyx_t_1, "numpy", "ufunc", sizeof(PyUFuncObject), __PYX_GET_STRUCT_ALIGNMENT_3_0_3(PyUFuncObject),__Pyx_ImportType_CheckSize_Ignore_3_0_3); if (!__pyx_ptype_5numpy_ufunc) __PYX_ERR(2, 865, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_RefNannyFinishContext();
  return -1;
}

static int __Pyx_modinit_variable_import_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_variable_import_code", 0);
  /*--- Variable import code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_function_import_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_function_import_code", 0);
  /*--- Function import code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}


#if PY_MAJOR_VERSION >= 3
#if CYTHON_PEP489_MULTI_PHASE_INIT
static PyObject* __pyx_pymod_create(PyObject *spec, PyModuleDef *def); /*proto*/
static int __pyx_pymod_exec_cuda_rf_gen_module(PyObject* module); /*proto*/
static PyModuleDef_Slot __pyx_moduledef_slots[] = {
  {Py_mod_create, (void*)__pyx_pymod_create},
  {Py_mod_exec, (void*)__pyx_pymod_exec_cuda_rf_gen_module},
  {0, NULL}
};
#endif

#ifdef __cplusplus
namespace {
  struct PyModuleDef __pyx_moduledef =
  #else
  static struct PyModuleDef __pyx_moduledef =
  #endif
  {
      PyModuleDef_HEAD_INIT,
      "cuda_rf_gen_module",
      __pyx_k_This_main_Cython_extension_combi, /* m_doc */
    #if CYTHON_PEP489_MULTI_PHASE_INIT
      0, /* m_size */
    #elif CYTHON_USE_MODULE_STATE
      sizeof(__pyx_mstate), /* m_size */
    #else
      -1, /* m_size */
    #endif
      __pyx_methods /* m_methods */,
    #if CYTHON_PEP489_MULTI_PHASE_INIT
      __pyx_moduledef_slots, /* m_slots */
    #else
      NULL, /* m_reload */
    #endif
    #if CYTHON_USE_MODULE_STATE
      __pyx_m_traverse, /* m_traverse */
      __pyx_m_clear, /* m_clear */
      NULL /* m_free */
    #else
      NULL, /* m_traverse */
      NULL, /* m_clear */
      NULL /* m_free */
    #endif
  };
  #ifdef __cplusplus
} /* anonymous namespace */
#endif
#endif

#ifndef CYTHON_NO_PYINIT_EXPORT
#define __Pyx_PyMODINIT_FUNC PyMODINIT_FUNC
#elif PY_MAJOR_VERSION < 3
#ifdef __cplusplus
#define __Pyx_PyMODINIT_FUNC extern "C" void
#else
#define __Pyx_PyMODINIT_FUNC void
#endif
#else
#ifdef __cplusplus
#define __Pyx_PyMODINIT_FUNC extern "C" PyObject *
#else
#define __Pyx_PyMODINIT_FUNC PyObject *
#endif
#endif


#if PY_MAJOR_VERSION < 3
__Pyx_PyMODINIT_FUNC initcuda_rf_gen_module(void) CYTHON_SMALL_CODE; /*proto*/
__Pyx_PyMODINIT_FUNC initcuda_rf_gen_module(void)
#else
__Pyx_PyMODINIT_FUNC PyInit_cuda_rf_gen_module(void) CYTHON_SMALL_CODE; /*proto*/
__Pyx_PyMODINIT_FUNC PyInit_cuda_rf_gen_module(void)
#if CYTHON_PEP489_MULTI_PHASE_INIT
{
  return PyModuleDef_Init(&__pyx_moduledef);
}
static CYTHON_SMALL_CODE int __Pyx_check_single_interpreter(void) {
    #if PY_VERSION_HEX >= 0x030700A1
    static PY_INT64_T main_interpreter_id = -1;
    PY_INT64_T current_id = PyInterpreterState_GetID(PyThreadState_Get()->interp);
    if (main_interpreter_id == -1) {
        main_interpreter_id = current_id;
        return (unlikely(current_id == -1)) ? -1 : 0;
    } else if (unlikely(main_interpreter_id != current_id))
    #else
    static PyInterpreterState *main_interpreter = NULL;
    PyInterpreterState *current_interpreter = PyThreadState_Get()->interp;
    if (!main_interpreter) {
        main_interpreter = current_interpreter;
    } else if (unlikely(main_interpreter != current_interpreter))
    #endif
    {
        PyErr_SetString(
            PyExc_ImportError,
            "Interpreter change detected - this module can only be loaded into one interpreter per process.");
        return -1;
    }
    return 0;
}
#if CYTHON_COMPILING_IN_LIMITED_API
static CYTHON_SMALL_CODE int __Pyx_copy_spec_to_module(PyObject *spec, PyObject *module, const char* from_name, const char* to_name, int allow_none)
#else
static CYTHON_SMALL_CODE int __Pyx_copy_spec_to_module(PyObject *spec, PyObject *moddict, const char* from_name, const char* to_name, int allow_none)
#endif
{
    PyObject *value = PyObject_GetAttrString(spec, from_name);
    int result = 0;
    if (likely(value)) {
        if (allow_none || value != Py_None) {
#if CYTHON_COMPILING_IN_LIMITED_API
            result = PyModule_AddObject(module, to_name, value);
#else
            result = PyDict_SetItemString(moddict, to_name, value);
#endif
        }
        Py_DECREF(value);
    } else if (PyErr_ExceptionMatches(PyExc_AttributeError)) {
        PyErr_Clear();
    } else {
        result = -1;
    }
    return result;
}
static CYTHON_SMALL_CODE PyObject* __pyx_pymod_create(PyObject *spec, PyModuleDef *def) {
    PyObject *module = NULL, *moddict, *modname;
    CYTHON_UNUSED_VAR(def);
    if (__Pyx_check_single_interpreter())
        return NULL;
    if (__pyx_m)
        return __Pyx_NewRef(__pyx_m);
    modname = PyObject_GetAttrString(spec, "name");
    if (unlikely(!modname)) goto bad;
    module = PyModule_NewObject(modname);
    Py_DECREF(modname);
    if (unlikely(!module)) goto bad;
#if CYTHON_COMPILING_IN_LIMITED_API
    moddict = module;
#else
    moddict = PyModule_GetDict(module);
    if (unlikely(!moddict)) goto bad;
#endif
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "loader", "__loader__", 1) < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "origin", "__file__", 1) < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "parent", "__package__", 1) < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "submodule_search_locations", "__path__", 0) < 0)) goto bad;
    return module;
bad:
    Py_XDECREF(module);
    return NULL;
}


static CYTHON_SMALL_CODE int __pyx_pymod_exec_cuda_rf_gen_module(PyObject *__pyx_pyinit_module)
#endif
#endif
{
  int stringtab_initialized = 0;
  #if CYTHON_USE_MODULE_STATE
  int pystate_addmodule_run = 0;
  #endif
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannyDeclarations
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  if (__pyx_m) {
    if (__pyx_m == __pyx_pyinit_module) return 0;
    PyErr_SetString(PyExc_RuntimeError, "Module 'cuda_rf_gen_module' has already been imported. Re-initialisation is not supported.");
    return -1;
  }
  #elif PY_MAJOR_VERSION >= 3
  if (__pyx_m) return __Pyx_NewRef(__pyx_m);
  #endif
  /*--- Module creation code ---*/
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  __pyx_m = __pyx_pyinit_module;
  Py_INCREF(__pyx_m);
  #else
  #if PY_MAJOR_VERSION < 3
  __pyx_m = Py_InitModule4("cuda_rf_gen_module", __pyx_methods, __pyx_k_This_main_Cython_extension_combi, 0, PYTHON_API_VERSION); Py_XINCREF(__pyx_m);
  if (unlikely(!__pyx_m)) __PYX_ERR(5, 1, __pyx_L1_error)
  #elif CYTHON_USE_MODULE_STATE
  __pyx_t_1 = PyModule_Create(&__pyx_moduledef); if (unlikely(!__pyx_t_1)) __PYX_ERR(5, 1, __pyx_L1_error)
  {
    int add_module_result = PyState_AddModule(__pyx_t_1, &__pyx_moduledef);
    __pyx_t_1 = 0; /* transfer ownership from __pyx_t_1 to cuda_rf_gen_module pseudovariable */
    if (unlikely((add_module_result < 0))) __PYX_ERR(5, 1, __pyx_L1_error)
    pystate_addmodule_run = 1;
  }
  #else
  __pyx_m = PyModule_Create(&__pyx_moduledef);
  if (unlikely(!__pyx_m)) __PYX_ERR(5, 1, __pyx_L1_error)
  #endif
  #endif
  CYTHON_UNUSED_VAR(__pyx_t_1);
  __pyx_d = PyModule_GetDict(__pyx_m); if (unlikely(!__pyx_d)) __PYX_ERR(5, 1, __pyx_L1_error)
  Py_INCREF(__pyx_d);
  __pyx_b = PyImport_AddModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_b)) __PYX_ERR(5, 1, __pyx_L1_error)
  Py_INCREF(__pyx_b);
  __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(5, 1, __pyx_L1_error)
  Py_INCREF(__pyx_cython_runtime);
  if (PyObject_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) __PYX_ERR(5, 1, __pyx_L1_error)
  #if CYTHON_REFNANNY
__Pyx_RefNanny = __Pyx_RefNannyImportAPI("refnanny");
if (!__Pyx_RefNanny) {
  PyErr_Clear();
  __Pyx_RefNanny = __Pyx_RefNannyImportAPI("Cython.Runtime.refnanny");
  if (!__Pyx_RefNanny)
      Py_FatalError("failed to import 'refnanny' module");
}
#endif
  __Pyx_RefNannySetupContext("__Pyx_PyMODINIT_FUNC PyInit_cuda_rf_gen_module(void)", 0);
  if (__Pyx_check_binary_version(__PYX_LIMITED_VERSION_HEX, __Pyx_get_runtime_version(), CYTHON_COMPILING_IN_LIMITED_API) < 0) __PYX_ERR(5, 1, __pyx_L1_error)
  #ifdef __Pxy_PyFrame_Initialize_Offsets
  __Pxy_PyFrame_Initialize_Offsets();
  #endif
  __pyx_empty_tuple = PyTuple_New(0); if (unlikely(!__pyx_empty_tuple)) __PYX_ERR(5, 1, __pyx_L1_error)
  __pyx_empty_bytes = PyBytes_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_bytes)) __PYX_ERR(5, 1, __pyx_L1_error)
  __pyx_empty_unicode = PyUnicode_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_unicode)) __PYX_ERR(5, 1, __pyx_L1_error)
  #ifdef __Pyx_CyFunction_USED
  if (__pyx_CyFunction_init(__pyx_m) < 0) __PYX_ERR(5, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_FusedFunction_USED
  if (__pyx_FusedFunction_init(__pyx_m) < 0) __PYX_ERR(5, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Coroutine_USED
  if (__pyx_Coroutine_init(__pyx_m) < 0) __PYX_ERR(5, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Generator_USED
  if (__pyx_Generator_init(__pyx_m) < 0) __PYX_ERR(5, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_AsyncGen_USED
  if (__pyx_AsyncGen_init(__pyx_m) < 0) __PYX_ERR(5, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_StopAsyncIteration_USED
  if (__pyx_StopAsyncIteration_init(__pyx_m) < 0) __PYX_ERR(5, 1, __pyx_L1_error)
  #endif
  /*--- Library function declarations ---*/
  /*--- Threads initialization code ---*/
  #if defined(WITH_THREAD) && PY_VERSION_HEX < 0x030700F0 && defined(__PYX_FORCE_INIT_THREADS) && __PYX_FORCE_INIT_THREADS
  PyEval_InitThreads();
  #endif
  /*--- Initialize various global constants etc. ---*/
  if (__Pyx_InitConstants() < 0) __PYX_ERR(5, 1, __pyx_L1_error)
  stringtab_initialized = 1;
  if (__Pyx_InitGlobals() < 0) __PYX_ERR(5, 1, __pyx_L1_error)
  #if PY_MAJOR_VERSION < 3 && (__PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT)
  if (__Pyx_init_sys_getdefaultencoding_params() < 0) __PYX_ERR(5, 1, __pyx_L1_error)
  #endif
  if (__pyx_module_is_main_cuda_rf_gen_module) {
    if (PyObject_SetAttr(__pyx_m, __pyx_n_s_name, __pyx_n_s_main) < 0) __PYX_ERR(5, 1, __pyx_L1_error)
  }
  #if PY_MAJOR_VERSION >= 3
  {
    PyObject *modules = PyImport_GetModuleDict(); if (unlikely(!modules)) __PYX_ERR(5, 1, __pyx_L1_error)
    if (!PyDict_GetItemString(modules, "cuda_rf_gen_module")) {
      if (unlikely((PyDict_SetItemString(modules, "cuda_rf_gen_module", __pyx_m) < 0))) __PYX_ERR(5, 1, __pyx_L1_error)
    }
  }
  #endif
  /*--- Builtin init code ---*/
  if (__Pyx_InitCachedBuiltins() < 0) __PYX_ERR(5, 1, __pyx_L1_error)
  /*--- Constants init code ---*/
  if (__Pyx_InitCachedConstants() < 0) __PYX_ERR(5, 1, __pyx_L1_error)
  /*--- Global type/function init code ---*/
  (void)__Pyx_modinit_global_init_code();
  (void)__Pyx_modinit_variable_export_code();
  (void)__Pyx_modinit_function_export_code();
  (void)__Pyx_modinit_type_init_code();
  if (unlikely((__Pyx_modinit_type_import_code() < 0))) __PYX_ERR(5, 1, __pyx_L1_error)
  (void)__Pyx_modinit_variable_import_code();
  (void)__Pyx_modinit_function_import_code();
  /*--- Execution code ---*/
  #if defined(__Pyx_Generator_USED) || defined(__Pyx_Coroutine_USED)
  if (__Pyx_patch_abc() < 0) __PYX_ERR(5, 1, __pyx_L1_error)
  #endif

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":9
 * reason -- it double checks all of the array dimensions, types,
 * is data contiguous etc. before calling the wrapped C functions."""
 * import numpy as np             # <<<<<<<<<<<<<<
 * cimport numpy as np
 * cimport cython
 */
  __pyx_t_2 = __Pyx_ImportDottedModule(__pyx_n_s_numpy, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 9, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_np, __pyx_t_2) < 0) __PYX_ERR(0, 9, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":13
 * cimport cython
 * from libc cimport stdint
 * import cupy as cp             # <<<<<<<<<<<<<<
 * from libc.stdint cimport uintptr_t
 * import math
 */
  __pyx_t_2 = __Pyx_ImportDottedModule(__pyx_n_s_cupy, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 13, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cp, __pyx_t_2) < 0) __PYX_ERR(0, 13, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":15
 * import cupy as cp
 * from libc.stdint cimport uintptr_t
 * import math             # <<<<<<<<<<<<<<
 * from libc.stdint cimport int8_t
 * 
 */
  __pyx_t_2 = __Pyx_ImportDottedModule(__pyx_n_s_math, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 15, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_math, __pyx_t_2) < 0) __PYX_ERR(0, 15, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":26
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaPySORFTransform(cpArray, radem, int numThreads):
 */
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_18cuda_rf_gen_module_1cudaPySORFTransform, 0, __pyx_n_s_cudaPySORFTransform, NULL, __pyx_n_s_cuda_rf_gen_module, __pyx_d, ((PyObject *)__pyx_codeobj__72)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 26, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cudaPySORFTransform, __pyx_t_2) < 0) __PYX_ERR(0, 26, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_basic_operations.pyx":91
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaSRHT(Z, radem,
 */
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_18cuda_rf_gen_module_3cudaSRHT, 0, __pyx_n_s_cudaSRHT, NULL, __pyx_n_s_cuda_rf_gen_module, __pyx_d, ((PyObject *)__pyx_codeobj__74)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 91, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cudaSRHT, __pyx_t_2) < 0) __PYX_ERR(0, 91, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":9
 * reason -- it double checks all of the array dimensions, types,
 * is data contiguous etc. before calling the wrapped C functions."""
 * import numpy as np             # <<<<<<<<<<<<<<
 * cimport numpy as np
 * cimport cython
 */
  __pyx_t_2 = __Pyx_ImportDottedModule(__pyx_n_s_numpy, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 9, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_np, __pyx_t_2) < 0) __PYX_ERR(1, 9, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":13
 * cimport cython
 * from libc cimport stdint
 * import cupy as cp             # <<<<<<<<<<<<<<
 * from libc.stdint cimport uintptr_t
 * import math
 */
  __pyx_t_2 = __Pyx_ImportDottedModule(__pyx_n_s_cupy, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 13, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cp, __pyx_t_2) < 0) __PYX_ERR(1, 13, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":15
 * import cupy as cp
 * from libc.stdint cimport uintptr_t
 * import math             # <<<<<<<<<<<<<<
 * from libc.stdint cimport int8_t, int32_t
 * from libcpp cimport bool
 */
  __pyx_t_2 = __Pyx_ImportDottedModule(__pyx_n_s_math, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 15, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_math, __pyx_t_2) < 0) __PYX_ERR(1, 15, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":46
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuConv1dMaxpool(reshapedX, radem, outputArray, chiArr,
 */
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_18cuda_rf_gen_module_5gpuConv1dMaxpool, 0, __pyx_n_s_gpuConv1dMaxpool, NULL, __pyx_n_s_cuda_rf_gen_module, __pyx_d, ((PyObject *)__pyx_codeobj__76)); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 46, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_gpuConv1dMaxpool, __pyx_t_2) < 0) __PYX_ERR(1, 46, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":162
 * @cython.wraparound(False)
 * def gpuConv1dFGen(reshapedX, radem, outputArray, chiArr,
 *                 int numThreads, float beta_, bool fitIntercept = False):             # <<<<<<<<<<<<<<
 *     """Uses wrapped C functions to generate random features for FHTConv1d, GraphConv1d,
 *     and related kernels. This function cannot be used to calculate the gradient
 */
  __pyx_t_2 = __Pyx_PyBool_FromLong(((int)0)); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 162, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":159
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuConv1dFGen(reshapedX, radem, outputArray, chiArr,
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 159, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_2);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_2)) __PYX_ERR(1, 159, __pyx_L1_error);
  __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_18cuda_rf_gen_module_7gpuConv1dFGen, 0, __pyx_n_s_gpuConv1dFGen, NULL, __pyx_n_s_cuda_rf_gen_module, __pyx_d, ((PyObject *)__pyx_codeobj__78)); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 159, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_CyFunction_SetDefaultsTuple(__pyx_t_2, __pyx_t_3);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_gpuConv1dFGen, __pyx_t_2) < 0) __PYX_ERR(1, 159, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":270
 * def gpuConvGrad(reshapedX, radem, outputArray, chiArr,
 *                 int numThreads, float sigma, float beta_,
 *                 bool fitIntercept = False):             # <<<<<<<<<<<<<<
 *     """Performs feature generation for the GraphRBF kernel while also performing
 *     gradient calculations.
 */
  __pyx_t_2 = __Pyx_PyBool_FromLong(((int)0)); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 270, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":266
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuConvGrad(reshapedX, radem, outputArray, chiArr,
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 266, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_2);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_2)) __PYX_ERR(1, 266, __pyx_L1_error);
  __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_18cuda_rf_gen_module_9gpuConvGrad, 0, __pyx_n_s_gpuConvGrad, NULL, __pyx_n_s_cuda_rf_gen_module, __pyx_d, ((PyObject *)__pyx_codeobj__80)); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 266, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_CyFunction_SetDefaultsTuple(__pyx_t_2, __pyx_t_3);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_gpuConvGrad, __pyx_t_2) < 0) __PYX_ERR(1, 266, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":390
 * def gpuConv1dArcCosFGen(reshapedX, radem, outputArray, chiArr,
 *                 int numThreads, float beta_, int kernelOrder,
 *                 bool fitIntercept = False):             # <<<<<<<<<<<<<<
 *     """Uses wrapped C functions to generate random features for arccosine kernels
 *     for sequences and graphs.
 */
  __pyx_t_2 = __Pyx_PyBool_FromLong(((int)0)); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 390, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_convolution.pyx":386
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuConv1dArcCosFGen(reshapedX, radem, outputArray, chiArr,
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 386, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_2);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_2)) __PYX_ERR(1, 386, __pyx_L1_error);
  __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_18cuda_rf_gen_module_11gpuConv1dArcCosFGen, 0, __pyx_n_s_gpuConv1dArcCosFGen, NULL, __pyx_n_s_cuda_rf_gen_module, __pyx_d, ((PyObject *)__pyx_codeobj__82)); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 386, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_CyFunction_SetDefaultsTuple(__pyx_t_2, __pyx_t_3);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_gpuConv1dArcCosFGen, __pyx_t_2) < 0) __PYX_ERR(1, 386, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":9
 * reason -- it double checks all of the array dimensions, types,
 * is data contiguous etc. before calling the wrapped C functions."""
 * import numpy as np             # <<<<<<<<<<<<<<
 * cimport numpy as np
 * cimport cython
 */
  __pyx_t_2 = __Pyx_ImportDottedModule(__pyx_n_s_numpy, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 9, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_np, __pyx_t_2) < 0) __PYX_ERR(3, 9, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":13
 * cimport cython
 * from libc cimport stdint
 * import cupy as cp             # <<<<<<<<<<<<<<
 * from libc.stdint cimport uintptr_t
 * import math
 */
  __pyx_t_2 = __Pyx_ImportDottedModule(__pyx_n_s_cupy, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 13, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cp, __pyx_t_2) < 0) __PYX_ERR(3, 13, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":15
 * import cupy as cp
 * from libc.stdint cimport uintptr_t
 * import math             # <<<<<<<<<<<<<<
 * from libc.stdint cimport int8_t
 * 
 */
  __pyx_t_2 = __Pyx_ImportDottedModule(__pyx_n_s_math, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 15, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_math, __pyx_t_2) < 0) __PYX_ERR(3, 15, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":35
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuGraphPolyFHT(reshapedX, radem, chiArr, outputArray, int polydegree,
 */
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_18cuda_rf_gen_module_13gpuGraphPolyFHT, 0, __pyx_n_s_gpuGraphPolyFHT, NULL, __pyx_n_s_cuda_rf_gen_module, __pyx_d, ((PyObject *)__pyx_codeobj__84)); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 35, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_gpuGraphPolyFHT, __pyx_t_2) < 0) __PYX_ERR(3, 35, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":165
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def gpuPolyFHT(reshapedX, radem, chiArr, outputArray, int polydegree,
 */
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_18cuda_rf_gen_module_15gpuPolyFHT, 0, __pyx_n_s_gpuPolyFHT, NULL, __pyx_n_s_cuda_rf_gen_module, __pyx_d, ((PyObject *)__pyx_codeobj__86)); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 165, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_gpuPolyFHT, __pyx_t_2) < 0) __PYX_ERR(3, 165, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_polynomial.pyx":273
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaExactQuadratic(inputArray, outputArray,
 */
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_18cuda_rf_gen_module_17cudaExactQuadratic, 0, __pyx_n_s_cudaExactQuadratic, NULL, __pyx_n_s_cuda_rf_gen_module, __pyx_d, ((PyObject *)__pyx_codeobj__88)); if (unlikely(!__pyx_t_2)) __PYX_ERR(3, 273, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cudaExactQuadratic, __pyx_t_2) < 0) __PYX_ERR(3, 273, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":8
 * reason -- it double checks all of the array dimensions, types,
 * is data contiguous etc. before calling the wrapped C functions."""
 * import os             # <<<<<<<<<<<<<<
 * import numpy as np
 * cimport numpy as np
 */
  __pyx_t_2 = __Pyx_ImportDottedModule(__pyx_n_s_os, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 8, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_os, __pyx_t_2) < 0) __PYX_ERR(4, 8, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":9
 * is data contiguous etc. before calling the wrapped C functions."""
 * import os
 * import numpy as np             # <<<<<<<<<<<<<<
 * cimport numpy as np
 * cimport cython
 */
  __pyx_t_2 = __Pyx_ImportDottedModule(__pyx_n_s_numpy, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 9, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_np, __pyx_t_2) < 0) __PYX_ERR(4, 9, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":13
 * cimport cython
 * from libc cimport stdint
 * import cupy as cp             # <<<<<<<<<<<<<<
 * from libc.stdint cimport uintptr_t
 * import math
 */
  __pyx_t_2 = __Pyx_ImportDottedModule(__pyx_n_s_cupy, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 13, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cp, __pyx_t_2) < 0) __PYX_ERR(4, 13, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":15
 * import cupy as cp
 * from libc.stdint cimport uintptr_t
 * import math             # <<<<<<<<<<<<<<
 * from libc.stdint cimport int8_t, int32_t
 * from libcpp cimport bool
 */
  __pyx_t_2 = __Pyx_ImportDottedModule(__pyx_n_s_math, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 15, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_math, __pyx_t_2) < 0) __PYX_ERR(4, 15, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":39
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaRBFFeatureGen(inputArray, outputArray, radem,
 */
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_18cuda_rf_gen_module_19cudaRBFFeatureGen, 0, __pyx_n_s_cudaRBFFeatureGen, NULL, __pyx_n_s_cuda_rf_gen_module, __pyx_d, ((PyObject *)__pyx_codeobj__90)); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 39, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_CyFunction_SetDefaultsTuple(__pyx_t_2, __pyx_tuple__91);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cudaRBFFeatureGen, __pyx_t_2) < 0) __PYX_ERR(4, 39, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":134
 * def cudaRBFGrad(inputArray, outputArray, radem,
 *                 chiArr, double betaHparam, double sigmaHparam,
 *                 int numThreads, bool fitIntercept = False):             # <<<<<<<<<<<<<<
 *     """Wraps RBFFeatureGen and uses
 *     it to to generate random features for an RBF kernel
 */
  __pyx_t_2 = __Pyx_PyBool_FromLong(((int)0)); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 134, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":130
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaRBFGrad(inputArray, outputArray, radem,
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(4, 130, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_2);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_2)) __PYX_ERR(4, 130, __pyx_L1_error);
  __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_18cuda_rf_gen_module_21cudaRBFGrad, 0, __pyx_n_s_cudaRBFGrad, NULL, __pyx_n_s_cuda_rf_gen_module, __pyx_d, ((PyObject *)__pyx_codeobj__93)); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 130, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_CyFunction_SetDefaultsTuple(__pyx_t_2, __pyx_t_3);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cudaRBFGrad, __pyx_t_2) < 0) __PYX_ERR(4, 130, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":236
 * def cudaMiniARDGrad(inputX, outputArray, precompWeights,
 *                 sigmaMap, sigmaVals, double betaHparam, int numThreads,
 *                 bool fitIntercept = False):             # <<<<<<<<<<<<<<
 *     """Performs gradient calculations for the MiniARD kernel, using
 *     pregenerated features and precomputed weights.
 */
  __pyx_t_2 = __Pyx_PyBool_FromLong(((int)0)); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 236, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);

  /* "xGPR/random_feature_generation/gpu_rf_gen/cuda_rbf_operations.pyx":232
 * 
 * 
 * @cython.boundscheck(False)             # <<<<<<<<<<<<<<
 * @cython.wraparound(False)
 * def cudaMiniARDGrad(inputX, outputArray, precompWeights,
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(4, 232, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_2);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_2)) __PYX_ERR(4, 232, __pyx_L1_error);
  __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_18cuda_rf_gen_module_23cudaMiniARDGrad, 0, __pyx_n_s_cudaMiniARDGrad, NULL, __pyx_n_s_cuda_rf_gen_module, __pyx_d, ((PyObject *)__pyx_codeobj__95)); if (unlikely(!__pyx_t_2)) __PYX_ERR(4, 232, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_CyFunction_SetDefaultsTuple(__pyx_t_2, __pyx_t_3);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cudaMiniARDGrad, __pyx_t_2) < 0) __PYX_ERR(4, 232, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "cuda_rf_gen_module.pyx":1
 * """This 'main' Cython extension combines all the other             # <<<<<<<<<<<<<<
 * Cuda Cython extensions so that all of them are built as
 * a single .so. This is slightly clunky, but at this time
 */
  __pyx_t_2 = __Pyx_PyDict_NewPresized(0); if (unlikely(!__pyx_t_2)) __PYX_ERR(5, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_test, __pyx_t_2) < 0) __PYX_ERR(5, 1, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /*--- Wrapped vars code ---*/

  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  if (__pyx_m) {
    if (__pyx_d && stringtab_initialized) {
      __Pyx_AddTraceback("init cuda_rf_gen_module", __pyx_clineno, __pyx_lineno, __pyx_filename);
    }
    #if !CYTHON_USE_MODULE_STATE
    Py_CLEAR(__pyx_m);
    #else
    Py_DECREF(__pyx_m);
    if (pystate_addmodule_run) {
      PyObject *tp, *value, *tb;
      PyErr_Fetch(&tp, &value, &tb);
      PyState_RemoveModule(&__pyx_moduledef);
      PyErr_Restore(tp, value, tb);
    }
    #endif
  } else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_ImportError, "init cuda_rf_gen_module");
  }
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  return (__pyx_m != NULL) ? 0 : -1;
  #elif PY_MAJOR_VERSION >= 3
  return __pyx_m;
  #else
  return;
  #endif
}
/* #### Code section: cleanup_globals ### */
/* #### Code section: cleanup_module ### */
/* #### Code section: main_method ### */
/* #### Code section: utility_code_pragmas ### */
#ifdef _MSC_VER
#pragma warning( push )
/* Warning 4127: conditional expression is constant
 * Cython uses constant conditional expressions to allow in inline functions to be optimized at
 * compile-time, so this warning is not useful
 */
#pragma warning( disable : 4127 )
#endif



/* #### Code section: utility_code_def ### */

/* --- Runtime support code --- */
/* Refnanny */
#if CYTHON_REFNANNY
static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname) {
    PyObject *m = NULL, *p = NULL;
    void *r = NULL;
    m = PyImport_ImportModule(modname);
    if (!m) goto end;
    p = PyObject_GetAttrString(m, "RefNannyAPI");
    if (!p) goto end;
    r = PyLong_AsVoidPtr(p);
end:
    Py_XDECREF(p);
    Py_XDECREF(m);
    return (__Pyx_RefNannyAPIStruct *)r;
}
#endif

/* PyErrExceptionMatches */
#if CYTHON_FAST_THREAD_STATE
static int __Pyx_PyErr_ExceptionMatchesTuple(PyObject *exc_type, PyObject *tuple) {
    Py_ssize_t i, n;
    n = PyTuple_GET_SIZE(tuple);
#if PY_MAJOR_VERSION >= 3
    for (i=0; i<n; i++) {
        if (exc_type == PyTuple_GET_ITEM(tuple, i)) return 1;
    }
#endif
    for (i=0; i<n; i++) {
        if (__Pyx_PyErr_GivenExceptionMatches(exc_type, PyTuple_GET_ITEM(tuple, i))) return 1;
    }
    return 0;
}
static CYTHON_INLINE int __Pyx_PyErr_ExceptionMatchesInState(PyThreadState* tstate, PyObject* err) {
    int result;
    PyObject *exc_type;
#if PY_VERSION_HEX >= 0x030C00A6
    PyObject *current_exception = tstate->current_exception;
    if (unlikely(!current_exception)) return 0;
    exc_type = (PyObject*) Py_TYPE(current_exception);
    if (exc_type == err) return 1;
#else
    exc_type = tstate->curexc_type;
    if (exc_type == err) return 1;
    if (unlikely(!exc_type)) return 0;
#endif
    #if CYTHON_AVOID_BORROWED_REFS
    Py_INCREF(exc_type);
    #endif
    if (unlikely(PyTuple_Check(err))) {
        result = __Pyx_PyErr_ExceptionMatchesTuple(exc_type, err);
    } else {
        result = __Pyx_PyErr_GivenExceptionMatches(exc_type, err);
    }
    #if CYTHON_AVOID_BORROWED_REFS
    Py_DECREF(exc_type);
    #endif
    return result;
}
#endif

/* PyErrFetchRestore */
#if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
#if PY_VERSION_HEX >= 0x030C00A6
    PyObject *tmp_value;
    assert(type == NULL || (value != NULL && type == (PyObject*) Py_TYPE(value)));
    if (value) {
        #if CYTHON_COMPILING_IN_CPYTHON
        if (unlikely(((PyBaseExceptionObject*) value)->traceback != tb))
        #endif
            PyException_SetTraceback(value, tb);
    }
    tmp_value = tstate->current_exception;
    tstate->current_exception = value;
    Py_XDECREF(tmp_value);
    Py_XDECREF(type);
    Py_XDECREF(tb);
#else
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    tmp_type = tstate->curexc_type;
    tmp_value = tstate->curexc_value;
    tmp_tb = tstate->curexc_traceback;
    tstate->curexc_type = type;
    tstate->curexc_value = value;
    tstate->curexc_traceback = tb;
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
#endif
}
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
#if PY_VERSION_HEX >= 0x030C00A6
    PyObject* exc_value;
    exc_value = tstate->current_exception;
    tstate->current_exception = 0;
    *value = exc_value;
    *type = NULL;
    *tb = NULL;
    if (exc_value) {
        *type = (PyObject*) Py_TYPE(exc_value);
        Py_INCREF(*type);
        #if CYTHON_COMPILING_IN_CPYTHON
        *tb = ((PyBaseExceptionObject*) exc_value)->traceback;
        Py_XINCREF(*tb);
        #else
        *tb = PyException_GetTraceback(exc_value);
        #endif
    }
#else
    *type = tstate->curexc_type;
    *value = tstate->curexc_value;
    *tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
#endif
}
#endif

/* PyObjectGetAttrStr */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStr(PyObject* obj, PyObject* attr_name) {
    PyTypeObject* tp = Py_TYPE(obj);
    if (likely(tp->tp_getattro))
        return tp->tp_getattro(obj, attr_name);
#if PY_MAJOR_VERSION < 3
    if (likely(tp->tp_getattr))
        return tp->tp_getattr(obj, PyString_AS_STRING(attr_name));
#endif
    return PyObject_GetAttr(obj, attr_name);
}
#endif

/* PyObjectGetAttrStrNoError */
static void __Pyx_PyObject_GetAttrStr_ClearAttributeError(void) {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    if (likely(__Pyx_PyErr_ExceptionMatches(PyExc_AttributeError)))
        __Pyx_PyErr_Clear();
}
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStrNoError(PyObject* obj, PyObject* attr_name) {
    PyObject *result;
#if CYTHON_COMPILING_IN_CPYTHON && CYTHON_USE_TYPE_SLOTS && PY_VERSION_HEX >= 0x030700B1
    PyTypeObject* tp = Py_TYPE(obj);
    if (likely(tp->tp_getattro == PyObject_GenericGetAttr)) {
        return _PyObject_GenericGetAttrWithDict(obj, attr_name, NULL, 1);
    }
#endif
    result = __Pyx_PyObject_GetAttrStr(obj, attr_name);
    if (unlikely(!result)) {
        __Pyx_PyObject_GetAttrStr_ClearAttributeError();
    }
    return result;
}

/* GetBuiltinName */
static PyObject *__Pyx_GetBuiltinName(PyObject *name) {
    PyObject* result = __Pyx_PyObject_GetAttrStrNoError(__pyx_b, name);
    if (unlikely(!result) && !PyErr_Occurred()) {
        PyErr_Format(PyExc_NameError,
#if PY_MAJOR_VERSION >= 3
            "name '%U' is not defined", name);
#else
            "name '%.200s' is not defined", PyString_AS_STRING(name));
#endif
    }
    return result;
}

/* GetTopmostException */
#if CYTHON_USE_EXC_INFO_STACK && CYTHON_FAST_THREAD_STATE
static _PyErr_StackItem *
__Pyx_PyErr_GetTopmostException(PyThreadState *tstate)
{
    _PyErr_StackItem *exc_info = tstate->exc_info;
    while ((exc_info->exc_value == NULL || exc_info->exc_value == Py_None) &&
           exc_info->previous_item != NULL)
    {
        exc_info = exc_info->previous_item;
    }
    return exc_info;
}
#endif

/* SaveResetException */
#if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx__ExceptionSave(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
  #if CYTHON_USE_EXC_INFO_STACK && PY_VERSION_HEX >= 0x030B00a4
    _PyErr_StackItem *exc_info = __Pyx_PyErr_GetTopmostException(tstate);
    PyObject *exc_value = exc_info->exc_value;
    if (exc_value == NULL || exc_value == Py_None) {
        *value = NULL;
        *type = NULL;
        *tb = NULL;
    } else {
        *value = exc_value;
        Py_INCREF(*value);
        *type = (PyObject*) Py_TYPE(exc_value);
        Py_INCREF(*type);
        *tb = PyException_GetTraceback(exc_value);
    }
  #elif CYTHON_USE_EXC_INFO_STACK
    _PyErr_StackItem *exc_info = __Pyx_PyErr_GetTopmostException(tstate);
    *type = exc_info->exc_type;
    *value = exc_info->exc_value;
    *tb = exc_info->exc_traceback;
    Py_XINCREF(*type);
    Py_XINCREF(*value);
    Py_XINCREF(*tb);
  #else
    *type = tstate->exc_type;
    *value = tstate->exc_value;
    *tb = tstate->exc_traceback;
    Py_XINCREF(*type);
    Py_XINCREF(*value);
    Py_XINCREF(*tb);
  #endif
}
static CYTHON_INLINE void __Pyx__ExceptionReset(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
  #if CYTHON_USE_EXC_INFO_STACK && PY_VERSION_HEX >= 0x030B00a4
    _PyErr_StackItem *exc_info = tstate->exc_info;
    PyObject *tmp_value = exc_info->exc_value;
    exc_info->exc_value = value;
    Py_XDECREF(tmp_value);
    Py_XDECREF(type);
    Py_XDECREF(tb);
  #else
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    #if CYTHON_USE_EXC_INFO_STACK
    _PyErr_StackItem *exc_info = tstate->exc_info;
    tmp_type = exc_info->exc_type;
    tmp_value = exc_info->exc_value;
    tmp_tb = exc_info->exc_traceback;
    exc_info->exc_type = type;
    exc_info->exc_value = value;
    exc_info->exc_traceback = tb;
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = type;
    tstate->exc_value = value;
    tstate->exc_traceback = tb;
    #endif
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
  #endif
}
#endif

/* GetException */
#if CYTHON_FAST_THREAD_STATE
static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb)
#else
static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb)
#endif
{
    PyObject *local_type = NULL, *local_value, *local_tb = NULL;
#if CYTHON_FAST_THREAD_STATE
    PyObject *tmp_type, *tmp_value, *tmp_tb;
  #if PY_VERSION_HEX >= 0x030C00A6
    local_value = tstate->current_exception;
    tstate->current_exception = 0;
    if (likely(local_value)) {
        local_type = (PyObject*) Py_TYPE(local_value);
        Py_INCREF(local_type);
        local_tb = PyException_GetTraceback(local_value);
    }
  #else
    local_type = tstate->curexc_type;
    local_value = tstate->curexc_value;
    local_tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
  #endif
#else
    PyErr_Fetch(&local_type, &local_value, &local_tb);
#endif
    PyErr_NormalizeException(&local_type, &local_value, &local_tb);
#if CYTHON_FAST_THREAD_STATE && PY_VERSION_HEX >= 0x030C00A6
    if (unlikely(tstate->current_exception))
#elif CYTHON_FAST_THREAD_STATE
    if (unlikely(tstate->curexc_type))
#else
    if (unlikely(PyErr_Occurred()))
#endif
        goto bad;
    #if PY_MAJOR_VERSION >= 3
    if (local_tb) {
        if (unlikely(PyException_SetTraceback(local_value, local_tb) < 0))
            goto bad;
    }
    #endif
    Py_XINCREF(local_tb);
    Py_XINCREF(local_type);
    Py_XINCREF(local_value);
    *type = local_type;
    *value = local_value;
    *tb = local_tb;
#if CYTHON_FAST_THREAD_STATE
    #if CYTHON_USE_EXC_INFO_STACK
    {
        _PyErr_StackItem *exc_info = tstate->exc_info;
      #if PY_VERSION_HEX >= 0x030B00a4
        tmp_value = exc_info->exc_value;
        exc_info->exc_value = local_value;
        tmp_type = NULL;
        tmp_tb = NULL;
        Py_XDECREF(local_type);
        Py_XDECREF(local_tb);
      #else
        tmp_type = exc_info->exc_type;
        tmp_value = exc_info->exc_value;
        tmp_tb = exc_info->exc_traceback;
        exc_info->exc_type = local_type;
        exc_info->exc_value = local_value;
        exc_info->exc_traceback = local_tb;
      #endif
    }
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = local_type;
    tstate->exc_value = local_value;
    tstate->exc_traceback = local_tb;
    #endif
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
#else
    PyErr_SetExcInfo(local_type, local_value, local_tb);
#endif
    return 0;
bad:
    *type = 0;
    *value = 0;
    *tb = 0;
    Py_XDECREF(local_type);
    Py_XDECREF(local_value);
    Py_XDECREF(local_tb);
    return -1;
}

/* PyObjectCall */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw) {
    PyObject *result;
    ternaryfunc call = Py_TYPE(func)->tp_call;
    if (unlikely(!call))
        return PyObject_Call(func, arg, kw);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = (*call)(func, arg, kw);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* RaiseException */
#if PY_MAJOR_VERSION < 3
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause) {
    __Pyx_PyThreadState_declare
    CYTHON_UNUSED_VAR(cause);
    Py_XINCREF(type);
    if (!value || value == Py_None)
        value = NULL;
    else
        Py_INCREF(value);
    if (!tb || tb == Py_None)
        tb = NULL;
    else {
        Py_INCREF(tb);
        if (!PyTraceBack_Check(tb)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: arg 3 must be a traceback or None");
            goto raise_error;
        }
    }
    if (PyType_Check(type)) {
#if CYTHON_COMPILING_IN_PYPY
        if (!value) {
            Py_INCREF(Py_None);
            value = Py_None;
        }
#endif
        PyErr_NormalizeException(&type, &value, &tb);
    } else {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto raise_error;
        }
        value = type;
        type = (PyObject*) Py_TYPE(type);
        Py_INCREF(type);
        if (!PyType_IsSubtype((PyTypeObject *)type, (PyTypeObject *)PyExc_BaseException)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: exception class must be a subclass of BaseException");
            goto raise_error;
        }
    }
    __Pyx_PyThreadState_assign
    __Pyx_ErrRestore(type, value, tb);
    return;
raise_error:
    Py_XDECREF(value);
    Py_XDECREF(type);
    Py_XDECREF(tb);
    return;
}
#else
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause) {
    PyObject* owned_instance = NULL;
    if (tb == Py_None) {
        tb = 0;
    } else if (tb && !PyTraceBack_Check(tb)) {
        PyErr_SetString(PyExc_TypeError,
            "raise: arg 3 must be a traceback or None");
        goto bad;
    }
    if (value == Py_None)
        value = 0;
    if (PyExceptionInstance_Check(type)) {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto bad;
        }
        value = type;
        type = (PyObject*) Py_TYPE(value);
    } else if (PyExceptionClass_Check(type)) {
        PyObject *instance_class = NULL;
        if (value && PyExceptionInstance_Check(value)) {
            instance_class = (PyObject*) Py_TYPE(value);
            if (instance_class != type) {
                int is_subclass = PyObject_IsSubclass(instance_class, type);
                if (!is_subclass) {
                    instance_class = NULL;
                } else if (unlikely(is_subclass == -1)) {
                    goto bad;
                } else {
                    type = instance_class;
                }
            }
        }
        if (!instance_class) {
            PyObject *args;
            if (!value)
                args = PyTuple_New(0);
            else if (PyTuple_Check(value)) {
                Py_INCREF(value);
                args = value;
            } else
                args = PyTuple_Pack(1, value);
            if (!args)
                goto bad;
            owned_instance = PyObject_Call(type, args, NULL);
            Py_DECREF(args);
            if (!owned_instance)
                goto bad;
            value = owned_instance;
            if (!PyExceptionInstance_Check(value)) {
                PyErr_Format(PyExc_TypeError,
                             "calling %R should have returned an instance of "
                             "BaseException, not %R",
                             type, Py_TYPE(value));
                goto bad;
            }
        }
    } else {
        PyErr_SetString(PyExc_TypeError,
            "raise: exception class must be a subclass of BaseException");
        goto bad;
    }
    if (cause) {
        PyObject *fixed_cause;
        if (cause == Py_None) {
            fixed_cause = NULL;
        } else if (PyExceptionClass_Check(cause)) {
            fixed_cause = PyObject_CallObject(cause, NULL);
            if (fixed_cause == NULL)
                goto bad;
        } else if (PyExceptionInstance_Check(cause)) {
            fixed_cause = cause;
            Py_INCREF(fixed_cause);
        } else {
            PyErr_SetString(PyExc_TypeError,
                            "exception causes must derive from "
                            "BaseException");
            goto bad;
        }
        PyException_SetCause(value, fixed_cause);
    }
    PyErr_SetObject(type, value);
    if (tb) {
      #if PY_VERSION_HEX >= 0x030C00A6
        PyException_SetTraceback(value, tb);
      #elif CYTHON_FAST_THREAD_STATE
        PyThreadState *tstate = __Pyx_PyThreadState_Current;
        PyObject* tmp_tb = tstate->curexc_traceback;
        if (tb != tmp_tb) {
            Py_INCREF(tb);
            tstate->curexc_traceback = tb;
            Py_XDECREF(tmp_tb);
        }
#else
        PyObject *tmp_type, *tmp_value, *tmp_tb;
        PyErr_Fetch(&tmp_type, &tmp_value, &tmp_tb);
        Py_INCREF(tb);
        PyErr_Restore(tmp_type, tmp_value, tb);
        Py_XDECREF(tmp_tb);
#endif
    }
bad:
    Py_XDECREF(owned_instance);
    return;
}
#endif

/* TupleAndListFromArray */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE void __Pyx_copy_object_array(PyObject *const *CYTHON_RESTRICT src, PyObject** CYTHON_RESTRICT dest, Py_ssize_t length) {
    PyObject *v;
    Py_ssize_t i;
    for (i = 0; i < length; i++) {
        v = dest[i] = src[i];
        Py_INCREF(v);
    }
}
static CYTHON_INLINE PyObject *
__Pyx_PyTuple_FromArray(PyObject *const *src, Py_ssize_t n)
{
    PyObject *res;
    if (n <= 0) {
        Py_INCREF(__pyx_empty_tuple);
        return __pyx_empty_tuple;
    }
    res = PyTuple_New(n);
    if (unlikely(res == NULL)) return NULL;
    __Pyx_copy_object_array(src, ((PyTupleObject*)res)->ob_item, n);
    return res;
}
static CYTHON_INLINE PyObject *
__Pyx_PyList_FromArray(PyObject *const *src, Py_ssize_t n)
{
    PyObject *res;
    if (n <= 0) {
        return PyList_New(0);
    }
    res = PyList_New(n);
    if (unlikely(res == NULL)) return NULL;
    __Pyx_copy_object_array(src, ((PyListObject*)res)->ob_item, n);
    return res;
}
#endif

/* BytesEquals */
static CYTHON_INLINE int __Pyx_PyBytes_Equals(PyObject* s1, PyObject* s2, int equals) {
#if CYTHON_COMPILING_IN_PYPY || CYTHON_COMPILING_IN_LIMITED_API
    return PyObject_RichCompareBool(s1, s2, equals);
#else
    if (s1 == s2) {
        return (equals == Py_EQ);
    } else if (PyBytes_CheckExact(s1) & PyBytes_CheckExact(s2)) {
        const char *ps1, *ps2;
        Py_ssize_t length = PyBytes_GET_SIZE(s1);
        if (length != PyBytes_GET_SIZE(s2))
            return (equals == Py_NE);
        ps1 = PyBytes_AS_STRING(s1);
        ps2 = PyBytes_AS_STRING(s2);
        if (ps1[0] != ps2[0]) {
            return (equals == Py_NE);
        } else if (length == 1) {
            return (equals == Py_EQ);
        } else {
            int result;
#if CYTHON_USE_UNICODE_INTERNALS && (PY_VERSION_HEX < 0x030B0000)
            Py_hash_t hash1, hash2;
            hash1 = ((PyBytesObject*)s1)->ob_shash;
            hash2 = ((PyBytesObject*)s2)->ob_shash;
            if (hash1 != hash2 && hash1 != -1 && hash2 != -1) {
                return (equals == Py_NE);
            }
#endif
            result = memcmp(ps1, ps2, (size_t)length);
            return (equals == Py_EQ) ? (result == 0) : (result != 0);
        }
    } else if ((s1 == Py_None) & PyBytes_CheckExact(s2)) {
        return (equals == Py_NE);
    } else if ((s2 == Py_None) & PyBytes_CheckExact(s1)) {
        return (equals == Py_NE);
    } else {
        int result;
        PyObject* py_result = PyObject_RichCompare(s1, s2, equals);
        if (!py_result)
            return -1;
        result = __Pyx_PyObject_IsTrue(py_result);
        Py_DECREF(py_result);
        return result;
    }
#endif
}

/* UnicodeEquals */
static CYTHON_INLINE int __Pyx_PyUnicode_Equals(PyObject* s1, PyObject* s2, int equals) {
#if CYTHON_COMPILING_IN_PYPY || CYTHON_COMPILING_IN_LIMITED_API
    return PyObject_RichCompareBool(s1, s2, equals);
#else
#if PY_MAJOR_VERSION < 3
    PyObject* owned_ref = NULL;
#endif
    int s1_is_unicode, s2_is_unicode;
    if (s1 == s2) {
        goto return_eq;
    }
    s1_is_unicode = PyUnicode_CheckExact(s1);
    s2_is_unicode = PyUnicode_CheckExact(s2);
#if PY_MAJOR_VERSION < 3
    if ((s1_is_unicode & (!s2_is_unicode)) && PyString_CheckExact(s2)) {
        owned_ref = PyUnicode_FromObject(s2);
        if (unlikely(!owned_ref))
            return -1;
        s2 = owned_ref;
        s2_is_unicode = 1;
    } else if ((s2_is_unicode & (!s1_is_unicode)) && PyString_CheckExact(s1)) {
        owned_ref = PyUnicode_FromObject(s1);
        if (unlikely(!owned_ref))
            return -1;
        s1 = owned_ref;
        s1_is_unicode = 1;
    } else if (((!s2_is_unicode) & (!s1_is_unicode))) {
        return __Pyx_PyBytes_Equals(s1, s2, equals);
    }
#endif
    if (s1_is_unicode & s2_is_unicode) {
        Py_ssize_t length;
        int kind;
        void *data1, *data2;
        if (unlikely(__Pyx_PyUnicode_READY(s1) < 0) || unlikely(__Pyx_PyUnicode_READY(s2) < 0))
            return -1;
        length = __Pyx_PyUnicode_GET_LENGTH(s1);
        if (length != __Pyx_PyUnicode_GET_LENGTH(s2)) {
            goto return_ne;
        }
#if CYTHON_USE_UNICODE_INTERNALS
        {
            Py_hash_t hash1, hash2;
        #if CYTHON_PEP393_ENABLED
            hash1 = ((PyASCIIObject*)s1)->hash;
            hash2 = ((PyASCIIObject*)s2)->hash;
        #else
            hash1 = ((PyUnicodeObject*)s1)->hash;
            hash2 = ((PyUnicodeObject*)s2)->hash;
        #endif
            if (hash1 != hash2 && hash1 != -1 && hash2 != -1) {
                goto return_ne;
            }
        }
#endif
        kind = __Pyx_PyUnicode_KIND(s1);
        if (kind != __Pyx_PyUnicode_KIND(s2)) {
            goto return_ne;
        }
        data1 = __Pyx_PyUnicode_DATA(s1);
        data2 = __Pyx_PyUnicode_DATA(s2);
        if (__Pyx_PyUnicode_READ(kind, data1, 0) != __Pyx_PyUnicode_READ(kind, data2, 0)) {
            goto return_ne;
        } else if (length == 1) {
            goto return_eq;
        } else {
            int result = memcmp(data1, data2, (size_t)(length * kind));
            #if PY_MAJOR_VERSION < 3
            Py_XDECREF(owned_ref);
            #endif
            return (equals == Py_EQ) ? (result == 0) : (result != 0);
        }
    } else if ((s1 == Py_None) & s2_is_unicode) {
        goto return_ne;
    } else if ((s2 == Py_None) & s1_is_unicode) {
        goto return_ne;
    } else {
        int result;
        PyObject* py_result = PyObject_RichCompare(s1, s2, equals);
        #if PY_MAJOR_VERSION < 3
        Py_XDECREF(owned_ref);
        #endif
        if (!py_result)
            return -1;
        result = __Pyx_PyObject_IsTrue(py_result);
        Py_DECREF(py_result);
        return result;
    }
return_eq:
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(owned_ref);
    #endif
    return (equals == Py_EQ);
return_ne:
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(owned_ref);
    #endif
    return (equals == Py_NE);
#endif
}

/* fastcall */
#if CYTHON_METH_FASTCALL
static CYTHON_INLINE PyObject * __Pyx_GetKwValue_FASTCALL(PyObject *kwnames, PyObject *const *kwvalues, PyObject *s)
{
    Py_ssize_t i, n = PyTuple_GET_SIZE(kwnames);
    for (i = 0; i < n; i++)
    {
        if (s == PyTuple_GET_ITEM(kwnames, i)) return kwvalues[i];
    }
    for (i = 0; i < n; i++)
    {
        int eq = __Pyx_PyUnicode_Equals(s, PyTuple_GET_ITEM(kwnames, i), Py_EQ);
        if (unlikely(eq != 0)) {
            if (unlikely(eq < 0)) return NULL;  // error
            return kwvalues[i];
        }
    }
    return NULL;  // not found (no exception set)
}
#endif

/* RaiseArgTupleInvalid */
static void __Pyx_RaiseArgtupleInvalid(
    const char* func_name,
    int exact,
    Py_ssize_t num_min,
    Py_ssize_t num_max,
    Py_ssize_t num_found)
{
    Py_ssize_t num_expected;
    const char *more_or_less;
    if (num_found < num_min) {
        num_expected = num_min;
        more_or_less = "at least";
    } else {
        num_expected = num_max;
        more_or_less = "at most";
    }
    if (exact) {
        more_or_less = "exactly";
    }
    PyErr_Format(PyExc_TypeError,
                 "%.200s() takes %.8s %" CYTHON_FORMAT_SSIZE_T "d positional argument%.1s (%" CYTHON_FORMAT_SSIZE_T "d given)",
                 func_name, more_or_less, num_expected,
                 (num_expected == 1) ? "" : "s", num_found);
}

/* RaiseDoubleKeywords */
static void __Pyx_RaiseDoubleKeywordsError(
    const char* func_name,
    PyObject* kw_name)
{
    PyErr_Format(PyExc_TypeError,
        #if PY_MAJOR_VERSION >= 3
        "%s() got multiple values for keyword argument '%U'", func_name, kw_name);
        #else
        "%s() got multiple values for keyword argument '%s'", func_name,
        PyString_AsString(kw_name));
        #endif
}

/* ParseKeywords */
static int __Pyx_ParseOptionalKeywords(
    PyObject *kwds,
    PyObject *const *kwvalues,
    PyObject **argnames[],
    PyObject *kwds2,
    PyObject *values[],
    Py_ssize_t num_pos_args,
    const char* function_name)
{
    PyObject *key = 0, *value = 0;
    Py_ssize_t pos = 0;
    PyObject*** name;
    PyObject*** first_kw_arg = argnames + num_pos_args;
    int kwds_is_tuple = CYTHON_METH_FASTCALL && likely(PyTuple_Check(kwds));
    while (1) {
        Py_XDECREF(key); key = NULL;
        Py_XDECREF(value); value = NULL;
        if (kwds_is_tuple) {
            Py_ssize_t size;
#if CYTHON_ASSUME_SAFE_MACROS
            size = PyTuple_GET_SIZE(kwds);
#else
            size = PyTuple_Size(kwds);
            if (size < 0) goto bad;
#endif
            if (pos >= size) break;
#if CYTHON_AVOID_BORROWED_REFS
            key = __Pyx_PySequence_ITEM(kwds, pos);
            if (!key) goto bad;
#elif CYTHON_ASSUME_SAFE_MACROS
            key = PyTuple_GET_ITEM(kwds, pos);
#else
            key = PyTuple_GetItem(kwds, pos);
            if (!key) goto bad;
#endif
            value = kwvalues[pos];
            pos++;
        }
        else
        {
            if (!PyDict_Next(kwds, &pos, &key, &value)) break;
#if CYTHON_AVOID_BORROWED_REFS
            Py_INCREF(key);
#endif
        }
        name = first_kw_arg;
        while (*name && (**name != key)) name++;
        if (*name) {
            values[name-argnames] = value;
#if CYTHON_AVOID_BORROWED_REFS
            Py_INCREF(value); // transfer ownership of value to values
            Py_DECREF(key);
#endif
            key = NULL;
            value = NULL;
            continue;
        }
#if !CYTHON_AVOID_BORROWED_REFS
        Py_INCREF(key);
#endif
        Py_INCREF(value);
        name = first_kw_arg;
        #if PY_MAJOR_VERSION < 3
        if (likely(PyString_Check(key))) {
            while (*name) {
                if ((CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**name) == PyString_GET_SIZE(key))
                        && _PyString_Eq(**name, key)) {
                    values[name-argnames] = value;
#if CYTHON_AVOID_BORROWED_REFS
                    value = NULL;  // ownership transferred to values
#endif
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    if ((**argname == key) || (
                            (CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**argname) == PyString_GET_SIZE(key))
                             && _PyString_Eq(**argname, key))) {
                        goto arg_passed_twice;
                    }
                    argname++;
                }
            }
        } else
        #endif
        if (likely(PyUnicode_Check(key))) {
            while (*name) {
                int cmp = (
                #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                    (__Pyx_PyUnicode_GET_LENGTH(**name) != __Pyx_PyUnicode_GET_LENGTH(key)) ? 1 :
                #endif
                    PyUnicode_Compare(**name, key)
                );
                if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                if (cmp == 0) {
                    values[name-argnames] = value;
#if CYTHON_AVOID_BORROWED_REFS
                    value = NULL; // ownership transferred to values
#endif
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    int cmp = (**argname == key) ? 0 :
                    #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                        (__Pyx_PyUnicode_GET_LENGTH(**argname) != __Pyx_PyUnicode_GET_LENGTH(key)) ? 1 :
                    #endif
                        PyUnicode_Compare(**argname, key);
                    if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                    if (cmp == 0) goto arg_passed_twice;
                    argname++;
                }
            }
        } else
            goto invalid_keyword_type;
        if (kwds2) {
            if (unlikely(PyDict_SetItem(kwds2, key, value))) goto bad;
        } else {
            goto invalid_keyword;
        }
    }
    Py_XDECREF(key);
    Py_XDECREF(value);
    return 0;
arg_passed_twice:
    __Pyx_RaiseDoubleKeywordsError(function_name, key);
    goto bad;
invalid_keyword_type:
    PyErr_Format(PyExc_TypeError,
        "%.200s() keywords must be strings", function_name);
    goto bad;
invalid_keyword:
    #if PY_MAJOR_VERSION < 3
    PyErr_Format(PyExc_TypeError,
        "%.200s() got an unexpected keyword argument '%.200s'",
        function_name, PyString_AsString(key));
    #else
    PyErr_Format(PyExc_TypeError,
        "%s() got an unexpected keyword argument '%U'",
        function_name, key);
    #endif
bad:
    Py_XDECREF(key);
    Py_XDECREF(value);
    return -1;
}

/* GetItemInt */
static PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j) {
    PyObject *r;
    if (unlikely(!j)) return NULL;
    r = PyObject_GetItem(o, j);
    Py_DECREF(j);
    return r;
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    Py_ssize_t wrapped_i = i;
    if (wraparound & unlikely(i < 0)) {
        wrapped_i += PyList_GET_SIZE(o);
    }
    if ((!boundscheck) || likely(__Pyx_is_valid_index(wrapped_i, PyList_GET_SIZE(o)))) {
        PyObject *r = PyList_GET_ITEM(o, wrapped_i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    Py_ssize_t wrapped_i = i;
    if (wraparound & unlikely(i < 0)) {
        wrapped_i += PyTuple_GET_SIZE(o);
    }
    if ((!boundscheck) || likely(__Pyx_is_valid_index(wrapped_i, PyTuple_GET_SIZE(o)))) {
        PyObject *r = PyTuple_GET_ITEM(o, wrapped_i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i, int is_list,
                                                     CYTHON_NCP_UNUSED int wraparound,
                                                     CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS && CYTHON_USE_TYPE_SLOTS
    if (is_list || PyList_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyList_GET_SIZE(o);
        if ((!boundscheck) || (likely(__Pyx_is_valid_index(n, PyList_GET_SIZE(o))))) {
            PyObject *r = PyList_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    }
    else if (PyTuple_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyTuple_GET_SIZE(o);
        if ((!boundscheck) || likely(__Pyx_is_valid_index(n, PyTuple_GET_SIZE(o)))) {
            PyObject *r = PyTuple_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    } else {
        PyMappingMethods *mm = Py_TYPE(o)->tp_as_mapping;
        PySequenceMethods *sm = Py_TYPE(o)->tp_as_sequence;
        if (mm && mm->mp_subscript) {
            PyObject *r, *key = PyInt_FromSsize_t(i);
            if (unlikely(!key)) return NULL;
            r = mm->mp_subscript(o, key);
            Py_DECREF(key);
            return r;
        }
        if (likely(sm && sm->sq_item)) {
            if (wraparound && unlikely(i < 0) && likely(sm->sq_length)) {
                Py_ssize_t l = sm->sq_length(o);
                if (likely(l >= 0)) {
                    i += l;
                } else {
                    if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                        return NULL;
                    PyErr_Clear();
                }
            }
            return sm->sq_item(o, i);
        }
    }
#else
    if (is_list || PySequence_Check(o)) {
        return PySequence_GetItem(o, i);
    }
#endif
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
}

/* PyIntCompare */
static CYTHON_INLINE int __Pyx_PyInt_BoolEqObjC(PyObject *op1, PyObject *op2, long intval, long inplace) {
    CYTHON_MAYBE_UNUSED_VAR(intval);
    CYTHON_UNUSED_VAR(inplace);
    if (op1 == op2) {
        return 1;
    }
    #if PY_MAJOR_VERSION < 3
    if (likely(PyInt_CheckExact(op1))) {
        const long b = intval;
        long a = PyInt_AS_LONG(op1);
        return (a == b);
    }
    #endif
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        int unequal;
        unsigned long uintval;
        Py_ssize_t size = __Pyx_PyLong_DigitCount(op1);
        const digit* digits = __Pyx_PyLong_Digits(op1);
        if (intval == 0) {
            return (__Pyx_PyLong_IsZero(op1) == 1);
        } else if (intval < 0) {
            if (__Pyx_PyLong_IsNonNeg(op1))
                return 0;
            intval = -intval;
        } else {
            if (__Pyx_PyLong_IsNeg(op1))
                return 0;
        }
        uintval = (unsigned long) intval;
#if PyLong_SHIFT * 4 < SIZEOF_LONG*8
        if (uintval >> (PyLong_SHIFT * 4)) {
            unequal = (size != 5) || (digits[0] != (uintval & (unsigned long) PyLong_MASK))
                 | (digits[1] != ((uintval >> (1 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK)) | (digits[2] != ((uintval >> (2 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK)) | (digits[3] != ((uintval >> (3 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK)) | (digits[4] != ((uintval >> (4 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK));
        } else
#endif
#if PyLong_SHIFT * 3 < SIZEOF_LONG*8
        if (uintval >> (PyLong_SHIFT * 3)) {
            unequal = (size != 4) || (digits[0] != (uintval & (unsigned long) PyLong_MASK))
                 | (digits[1] != ((uintval >> (1 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK)) | (digits[2] != ((uintval >> (2 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK)) | (digits[3] != ((uintval >> (3 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK));
        } else
#endif
#if PyLong_SHIFT * 2 < SIZEOF_LONG*8
        if (uintval >> (PyLong_SHIFT * 2)) {
            unequal = (size != 3) || (digits[0] != (uintval & (unsigned long) PyLong_MASK))
                 | (digits[1] != ((uintval >> (1 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK)) | (digits[2] != ((uintval >> (2 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK));
        } else
#endif
#if PyLong_SHIFT * 1 < SIZEOF_LONG*8
        if (uintval >> (PyLong_SHIFT * 1)) {
            unequal = (size != 2) || (digits[0] != (uintval & (unsigned long) PyLong_MASK))
                 | (digits[1] != ((uintval >> (1 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK));
        } else
#endif
            unequal = (size != 1) || (((unsigned long) digits[0]) != (uintval & (unsigned long) PyLong_MASK));
        return (unequal == 0);
    }
    #endif
    if (PyFloat_CheckExact(op1)) {
        const long b = intval;
#if CYTHON_COMPILING_IN_LIMITED_API
        double a = __pyx_PyFloat_AsDouble(op1);
#else
        double a = PyFloat_AS_DOUBLE(op1);
#endif
        return ((double)a == (double)b);
    }
    return __Pyx_PyObject_IsTrueAndDecref(
        PyObject_RichCompare(op1, op2, Py_EQ));
}

/* PyIntCompare */
static CYTHON_INLINE int __Pyx_PyInt_BoolNeObjC(PyObject *op1, PyObject *op2, long intval, long inplace) {
    CYTHON_MAYBE_UNUSED_VAR(intval);
    CYTHON_UNUSED_VAR(inplace);
    if (op1 == op2) {
        return 0;
    }
    #if PY_MAJOR_VERSION < 3
    if (likely(PyInt_CheckExact(op1))) {
        const long b = intval;
        long a = PyInt_AS_LONG(op1);
        return (a != b);
    }
    #endif
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        int unequal;
        unsigned long uintval;
        Py_ssize_t size = __Pyx_PyLong_DigitCount(op1);
        const digit* digits = __Pyx_PyLong_Digits(op1);
        if (intval == 0) {
            return (__Pyx_PyLong_IsZero(op1) != 1);
        } else if (intval < 0) {
            if (__Pyx_PyLong_IsNonNeg(op1))
                return 1;
            intval = -intval;
        } else {
            if (__Pyx_PyLong_IsNeg(op1))
                return 1;
        }
        uintval = (unsigned long) intval;
#if PyLong_SHIFT * 4 < SIZEOF_LONG*8
        if (uintval >> (PyLong_SHIFT * 4)) {
            unequal = (size != 5) || (digits[0] != (uintval & (unsigned long) PyLong_MASK))
                 | (digits[1] != ((uintval >> (1 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK)) | (digits[2] != ((uintval >> (2 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK)) | (digits[3] != ((uintval >> (3 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK)) | (digits[4] != ((uintval >> (4 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK));
        } else
#endif
#if PyLong_SHIFT * 3 < SIZEOF_LONG*8
        if (uintval >> (PyLong_SHIFT * 3)) {
            unequal = (size != 4) || (digits[0] != (uintval & (unsigned long) PyLong_MASK))
                 | (digits[1] != ((uintval >> (1 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK)) | (digits[2] != ((uintval >> (2 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK)) | (digits[3] != ((uintval >> (3 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK));
        } else
#endif
#if PyLong_SHIFT * 2 < SIZEOF_LONG*8
        if (uintval >> (PyLong_SHIFT * 2)) {
            unequal = (size != 3) || (digits[0] != (uintval & (unsigned long) PyLong_MASK))
                 | (digits[1] != ((uintval >> (1 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK)) | (digits[2] != ((uintval >> (2 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK));
        } else
#endif
#if PyLong_SHIFT * 1 < SIZEOF_LONG*8
        if (uintval >> (PyLong_SHIFT * 1)) {
            unequal = (size != 2) || (digits[0] != (uintval & (unsigned long) PyLong_MASK))
                 | (digits[1] != ((uintval >> (1 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK));
        } else
#endif
            unequal = (size != 1) || (((unsigned long) digits[0]) != (uintval & (unsigned long) PyLong_MASK));
        return (unequal != 0);
    }
    #endif
    if (PyFloat_CheckExact(op1)) {
        const long b = intval;
#if CYTHON_COMPILING_IN_LIMITED_API
        double a = __pyx_PyFloat_AsDouble(op1);
#else
        double a = PyFloat_AS_DOUBLE(op1);
#endif
        return ((double)a != (double)b);
    }
    return __Pyx_PyObject_IsTrueAndDecref(
        PyObject_RichCompare(op1, op2, Py_NE));
}

/* DictGetItem */
#if PY_MAJOR_VERSION >= 3 && !CYTHON_COMPILING_IN_PYPY
static PyObject *__Pyx_PyDict_GetItem(PyObject *d, PyObject* key) {
    PyObject *value;
    value = PyDict_GetItemWithError(d, key);
    if (unlikely(!value)) {
        if (!PyErr_Occurred()) {
            if (unlikely(PyTuple_Check(key))) {
                PyObject* args = PyTuple_Pack(1, key);
                if (likely(args)) {
                    PyErr_SetObject(PyExc_KeyError, args);
                    Py_DECREF(args);
                }
            } else {
                PyErr_SetObject(PyExc_KeyError, key);
            }
        }
        return NULL;
    }
    Py_INCREF(value);
    return value;
}
#endif

/* PyDictVersioning */
#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj) {
    PyObject *dict = Py_TYPE(obj)->tp_dict;
    return likely(dict) ? __PYX_GET_DICT_VERSION(dict) : 0;
}
static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj) {
    PyObject **dictptr = NULL;
    Py_ssize_t offset = Py_TYPE(obj)->tp_dictoffset;
    if (offset) {
#if CYTHON_COMPILING_IN_CPYTHON
        dictptr = (likely(offset > 0)) ? (PyObject **) ((char *)obj + offset) : _PyObject_GetDictPtr(obj);
#else
        dictptr = _PyObject_GetDictPtr(obj);
#endif
    }
    return (dictptr && *dictptr) ? __PYX_GET_DICT_VERSION(*dictptr) : 0;
}
static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version) {
    PyObject *dict = Py_TYPE(obj)->tp_dict;
    if (unlikely(!dict) || unlikely(tp_dict_version != __PYX_GET_DICT_VERSION(dict)))
        return 0;
    return obj_dict_version == __Pyx_get_object_dict_version(obj);
}
#endif

/* GetModuleGlobalName */
#if CYTHON_USE_DICT_VERSIONS
static PyObject *__Pyx__GetModuleGlobalName(PyObject *name, PY_UINT64_T *dict_version, PyObject **dict_cached_value)
#else
static CYTHON_INLINE PyObject *__Pyx__GetModuleGlobalName(PyObject *name)
#endif
{
    PyObject *result;
#if !CYTHON_AVOID_BORROWED_REFS
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030500A1
    result = _PyDict_GetItem_KnownHash(__pyx_d, name, ((PyASCIIObject *) name)->hash);
    __PYX_UPDATE_DICT_CACHE(__pyx_d, result, *dict_cached_value, *dict_version)
    if (likely(result)) {
        return __Pyx_NewRef(result);
    } else if (unlikely(PyErr_Occurred())) {
        return NULL;
    }
#elif CYTHON_COMPILING_IN_LIMITED_API
    if (unlikely(!__pyx_m)) {
        return NULL;
    }
    result = PyObject_GetAttr(__pyx_m, name);
    if (likely(result)) {
        return result;
    }
#else
    result = PyDict_GetItem(__pyx_d, name);
    __PYX_UPDATE_DICT_CACHE(__pyx_d, result, *dict_cached_value, *dict_version)
    if (likely(result)) {
        return __Pyx_NewRef(result);
    }
#endif
#else
    result = PyObject_GetItem(__pyx_d, name);
    __PYX_UPDATE_DICT_CACHE(__pyx_d, result, *dict_cached_value, *dict_version)
    if (likely(result)) {
        return __Pyx_NewRef(result);
    }
    PyErr_Clear();
#endif
    return __Pyx_GetBuiltinName(name);
}

/* PyFunctionFastCall */
#if CYTHON_FAST_PYCALL && !CYTHON_VECTORCALL
static PyObject* __Pyx_PyFunction_FastCallNoKw(PyCodeObject *co, PyObject **args, Py_ssize_t na,
                                               PyObject *globals) {
    PyFrameObject *f;
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    PyObject **fastlocals;
    Py_ssize_t i;
    PyObject *result;
    assert(globals != NULL);
    /* XXX Perhaps we should create a specialized
       PyFrame_New() that doesn't take locals, but does
       take builtins without sanity checking them.
       */
    assert(tstate != NULL);
    f = PyFrame_New(tstate, co, globals, NULL);
    if (f == NULL) {
        return NULL;
    }
    fastlocals = __Pyx_PyFrame_GetLocalsplus(f);
    for (i = 0; i < na; i++) {
        Py_INCREF(*args);
        fastlocals[i] = *args++;
    }
    result = PyEval_EvalFrameEx(f,0);
    ++tstate->recursion_depth;
    Py_DECREF(f);
    --tstate->recursion_depth;
    return result;
}
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs) {
    PyCodeObject *co = (PyCodeObject *)PyFunction_GET_CODE(func);
    PyObject *globals = PyFunction_GET_GLOBALS(func);
    PyObject *argdefs = PyFunction_GET_DEFAULTS(func);
    PyObject *closure;
#if PY_MAJOR_VERSION >= 3
    PyObject *kwdefs;
#endif
    PyObject *kwtuple, **k;
    PyObject **d;
    Py_ssize_t nd;
    Py_ssize_t nk;
    PyObject *result;
    assert(kwargs == NULL || PyDict_Check(kwargs));
    nk = kwargs ? PyDict_Size(kwargs) : 0;
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object"))) {
        return NULL;
    }
    if (
#if PY_MAJOR_VERSION >= 3
            co->co_kwonlyargcount == 0 &&
#endif
            likely(kwargs == NULL || nk == 0) &&
            co->co_flags == (CO_OPTIMIZED | CO_NEWLOCALS | CO_NOFREE)) {
        if (argdefs == NULL && co->co_argcount == nargs) {
            result = __Pyx_PyFunction_FastCallNoKw(co, args, nargs, globals);
            goto done;
        }
        else if (nargs == 0 && argdefs != NULL
                 && co->co_argcount == Py_SIZE(argdefs)) {
            /* function called with no arguments, but all parameters have
               a default value: use default values as arguments .*/
            args = &PyTuple_GET_ITEM(argdefs, 0);
            result =__Pyx_PyFunction_FastCallNoKw(co, args, Py_SIZE(argdefs), globals);
            goto done;
        }
    }
    if (kwargs != NULL) {
        Py_ssize_t pos, i;
        kwtuple = PyTuple_New(2 * nk);
        if (kwtuple == NULL) {
            result = NULL;
            goto done;
        }
        k = &PyTuple_GET_ITEM(kwtuple, 0);
        pos = i = 0;
        while (PyDict_Next(kwargs, &pos, &k[i], &k[i+1])) {
            Py_INCREF(k[i]);
            Py_INCREF(k[i+1]);
            i += 2;
        }
        nk = i / 2;
    }
    else {
        kwtuple = NULL;
        k = NULL;
    }
    closure = PyFunction_GET_CLOSURE(func);
#if PY_MAJOR_VERSION >= 3
    kwdefs = PyFunction_GET_KW_DEFAULTS(func);
#endif
    if (argdefs != NULL) {
        d = &PyTuple_GET_ITEM(argdefs, 0);
        nd = Py_SIZE(argdefs);
    }
    else {
        d = NULL;
        nd = 0;
    }
#if PY_MAJOR_VERSION >= 3
    result = PyEval_EvalCodeEx((PyObject*)co, globals, (PyObject *)NULL,
                               args, (int)nargs,
                               k, (int)nk,
                               d, (int)nd, kwdefs, closure);
#else
    result = PyEval_EvalCodeEx(co, globals, (PyObject *)NULL,
                               args, (int)nargs,
                               k, (int)nk,
                               d, (int)nd, closure);
#endif
    Py_XDECREF(kwtuple);
done:
    Py_LeaveRecursiveCall();
    return result;
}
#endif

/* PyObjectCallMethO */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg) {
    PyObject *self, *result;
    PyCFunction cfunc;
    cfunc = __Pyx_CyOrPyCFunction_GET_FUNCTION(func);
    self = __Pyx_CyOrPyCFunction_GET_SELF(func);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = cfunc(self, arg);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* PyObjectFastCall */
#if PY_VERSION_HEX < 0x03090000 || CYTHON_COMPILING_IN_LIMITED_API
static PyObject* __Pyx_PyObject_FastCall_fallback(PyObject *func, PyObject **args, size_t nargs, PyObject *kwargs) {
    PyObject *argstuple;
    PyObject *result = 0;
    size_t i;
    argstuple = PyTuple_New((Py_ssize_t)nargs);
    if (unlikely(!argstuple)) return NULL;
    for (i = 0; i < nargs; i++) {
        Py_INCREF(args[i]);
        if (__Pyx_PyTuple_SET_ITEM(argstuple, (Py_ssize_t)i, args[i]) < 0) goto bad;
    }
    result = __Pyx_PyObject_Call(func, argstuple, kwargs);
  bad:
    Py_DECREF(argstuple);
    return result;
}
#endif
static CYTHON_INLINE PyObject* __Pyx_PyObject_FastCallDict(PyObject *func, PyObject **args, size_t _nargs, PyObject *kwargs) {
    Py_ssize_t nargs = __Pyx_PyVectorcall_NARGS(_nargs);
#if CYTHON_COMPILING_IN_CPYTHON
    if (nargs == 0 && kwargs == NULL) {
        if (__Pyx_CyOrPyCFunction_Check(func) && likely( __Pyx_CyOrPyCFunction_GET_FLAGS(func) & METH_NOARGS))
            return __Pyx_PyObject_CallMethO(func, NULL);
    }
    else if (nargs == 1 && kwargs == NULL) {
        if (__Pyx_CyOrPyCFunction_Check(func) && likely( __Pyx_CyOrPyCFunction_GET_FLAGS(func) & METH_O))
            return __Pyx_PyObject_CallMethO(func, args[0]);
    }
#endif
    #if PY_VERSION_HEX < 0x030800B1
    #if CYTHON_FAST_PYCCALL
    if (PyCFunction_Check(func)) {
        if (kwargs) {
            return _PyCFunction_FastCallDict(func, args, nargs, kwargs);
        } else {
            return _PyCFunction_FastCallKeywords(func, args, nargs, NULL);
        }
    }
    #if PY_VERSION_HEX >= 0x030700A1
    if (!kwargs && __Pyx_IS_TYPE(func, &PyMethodDescr_Type)) {
        return _PyMethodDescr_FastCallKeywords(func, args, nargs, NULL);
    }
    #endif
    #endif
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(func)) {
        return __Pyx_PyFunction_FastCallDict(func, args, nargs, kwargs);
    }
    #endif
    #endif
    if (kwargs == NULL) {
        #if CYTHON_VECTORCALL
        #if Py_VERSION_HEX < 0x03090000
        vectorcallfunc f = _PyVectorcall_Function(func);
        #else
        vectorcallfunc f = PyVectorcall_Function(func);
        #endif
        if (f) {
            return f(func, args, (size_t)nargs, NULL);
        }
        #elif defined(__Pyx_CyFunction_USED) && CYTHON_BACKPORT_VECTORCALL
        if (__Pyx_CyFunction_CheckExact(func)) {
            __pyx_vectorcallfunc f = __Pyx_CyFunction_func_vectorcall(func);
            if (f) return f(func, args, (size_t)nargs, NULL);
        }
        #endif
    }
    if (nargs == 0) {
        return __Pyx_PyObject_Call(func, __pyx_empty_tuple, kwargs);
    }
    #if PY_VERSION_HEX >= 0x03090000 && !CYTHON_COMPILING_IN_LIMITED_API
    return PyObject_VectorcallDict(func, args, (size_t)nargs, kwargs);
    #else
    return __Pyx_PyObject_FastCall_fallback(func, args, (size_t)nargs, kwargs);
    #endif
}

/* decode_c_string */
static CYTHON_INLINE PyObject* __Pyx_decode_c_string(
         const char* cstring, Py_ssize_t start, Py_ssize_t stop,
         const char* encoding, const char* errors,
         PyObject* (*decode_func)(const char *s, Py_ssize_t size, const char *errors)) {
    Py_ssize_t length;
    if (unlikely((start < 0) | (stop < 0))) {
        size_t slen = strlen(cstring);
        if (unlikely(slen > (size_t) PY_SSIZE_T_MAX)) {
            PyErr_SetString(PyExc_OverflowError,
                            "c-string too long to convert to Python");
            return NULL;
        }
        length = (Py_ssize_t) slen;
        if (start < 0) {
            start += length;
            if (start < 0)
                start = 0;
        }
        if (stop < 0)
            stop += length;
    }
    if (unlikely(stop <= start))
        return __Pyx_NewRef(__pyx_empty_unicode);
    length = stop - start;
    cstring += start;
    if (decode_func) {
        return decode_func(cstring, length, errors);
    } else {
        return PyUnicode_Decode(cstring, length, encoding, errors);
    }
}

/* ArgTypeTest */
static int __Pyx__ArgTypeTest(PyObject *obj, PyTypeObject *type, const char *name, int exact)
{
    __Pyx_TypeName type_name;
    __Pyx_TypeName obj_type_name;
    if (unlikely(!type)) {
        PyErr_SetString(PyExc_SystemError, "Missing type object");
        return 0;
    }
    else if (exact) {
        #if PY_MAJOR_VERSION == 2
        if ((type == &PyBaseString_Type) && likely(__Pyx_PyBaseString_CheckExact(obj))) return 1;
        #endif
    }
    else {
        if (likely(__Pyx_TypeCheck(obj, type))) return 1;
    }
    type_name = __Pyx_PyType_GetName(type);
    obj_type_name = __Pyx_PyType_GetName(Py_TYPE(obj));
    PyErr_Format(PyExc_TypeError,
        "Argument '%.200s' has incorrect type (expected " __Pyx_FMT_TYPENAME
        ", got " __Pyx_FMT_TYPENAME ")", name, type_name, obj_type_name);
    __Pyx_DECREF_TypeName(type_name);
    __Pyx_DECREF_TypeName(obj_type_name);
    return 0;
}

/* IsLittleEndian */
static CYTHON_INLINE int __Pyx_Is_Little_Endian(void)
{
  union {
    uint32_t u32;
    uint8_t u8[4];
  } S;
  S.u32 = 0x01020304;
  return S.u8[0] == 4;
}

/* BufferFormatCheck */
static void __Pyx_BufFmt_Init(__Pyx_BufFmt_Context* ctx,
                              __Pyx_BufFmt_StackElem* stack,
                              __Pyx_TypeInfo* type) {
  stack[0].field = &ctx->root;
  stack[0].parent_offset = 0;
  ctx->root.type = type;
  ctx->root.name = "buffer dtype";
  ctx->root.offset = 0;
  ctx->head = stack;
  ctx->head->field = &ctx->root;
  ctx->fmt_offset = 0;
  ctx->head->parent_offset = 0;
  ctx->new_packmode = '@';
  ctx->enc_packmode = '@';
  ctx->new_count = 1;
  ctx->enc_count = 0;
  ctx->enc_type = 0;
  ctx->is_complex = 0;
  ctx->is_valid_array = 0;
  ctx->struct_alignment = 0;
  while (type->typegroup == 'S') {
    ++ctx->head;
    ctx->head->field = type->fields;
    ctx->head->parent_offset = 0;
    type = type->fields->type;
  }
}
static int __Pyx_BufFmt_ParseNumber(const char** ts) {
    int count;
    const char* t = *ts;
    if (*t < '0' || *t > '9') {
      return -1;
    } else {
        count = *t++ - '0';
        while (*t >= '0' && *t <= '9') {
            count *= 10;
            count += *t++ - '0';
        }
    }
    *ts = t;
    return count;
}
static int __Pyx_BufFmt_ExpectNumber(const char **ts) {
    int number = __Pyx_BufFmt_ParseNumber(ts);
    if (number == -1)
        PyErr_Format(PyExc_ValueError,\
                     "Does not understand character buffer dtype format string ('%c')", **ts);
    return number;
}
static void __Pyx_BufFmt_RaiseUnexpectedChar(char ch) {
  PyErr_Format(PyExc_ValueError,
               "Unexpected format string character: '%c'", ch);
}
static const char* __Pyx_BufFmt_DescribeTypeChar(char ch, int is_complex) {
  switch (ch) {
    case '?': return "'bool'";
    case 'c': return "'char'";
    case 'b': return "'signed char'";
    case 'B': return "'unsigned char'";
    case 'h': return "'short'";
    case 'H': return "'unsigned short'";
    case 'i': return "'int'";
    case 'I': return "'unsigned int'";
    case 'l': return "'long'";
    case 'L': return "'unsigned long'";
    case 'q': return "'long long'";
    case 'Q': return "'unsigned long long'";
    case 'f': return (is_complex ? "'complex float'" : "'float'");
    case 'd': return (is_complex ? "'complex double'" : "'double'");
    case 'g': return (is_complex ? "'complex long double'" : "'long double'");
    case 'T': return "a struct";
    case 'O': return "Python object";
    case 'P': return "a pointer";
    case 's': case 'p': return "a string";
    case 0: return "end";
    default: return "unparsable format string";
  }
}
static size_t __Pyx_BufFmt_TypeCharToStandardSize(char ch, int is_complex) {
  switch (ch) {
    case '?': case 'c': case 'b': case 'B': case 's': case 'p': return 1;
    case 'h': case 'H': return 2;
    case 'i': case 'I': case 'l': case 'L': return 4;
    case 'q': case 'Q': return 8;
    case 'f': return (is_complex ? 8 : 4);
    case 'd': return (is_complex ? 16 : 8);
    case 'g': {
      PyErr_SetString(PyExc_ValueError, "Python does not define a standard format string size for long double ('g')..");
      return 0;
    }
    case 'O': case 'P': return sizeof(void*);
    default:
      __Pyx_BufFmt_RaiseUnexpectedChar(ch);
      return 0;
    }
}
static size_t __Pyx_BufFmt_TypeCharToNativeSize(char ch, int is_complex) {
  switch (ch) {
    case '?': case 'c': case 'b': case 'B': case 's': case 'p': return 1;
    case 'h': case 'H': return sizeof(short);
    case 'i': case 'I': return sizeof(int);
    case 'l': case 'L': return sizeof(long);
    #ifdef HAVE_LONG_LONG
    case 'q': case 'Q': return sizeof(PY_LONG_LONG);
    #endif
    case 'f': return sizeof(float) * (is_complex ? 2 : 1);
    case 'd': return sizeof(double) * (is_complex ? 2 : 1);
    case 'g': return sizeof(long double) * (is_complex ? 2 : 1);
    case 'O': case 'P': return sizeof(void*);
    default: {
      __Pyx_BufFmt_RaiseUnexpectedChar(ch);
      return 0;
    }
  }
}
typedef struct { char c; short x; } __Pyx_st_short;
typedef struct { char c; int x; } __Pyx_st_int;
typedef struct { char c; long x; } __Pyx_st_long;
typedef struct { char c; float x; } __Pyx_st_float;
typedef struct { char c; double x; } __Pyx_st_double;
typedef struct { char c; long double x; } __Pyx_st_longdouble;
typedef struct { char c; void *x; } __Pyx_st_void_p;
#ifdef HAVE_LONG_LONG
typedef struct { char c; PY_LONG_LONG x; } __Pyx_st_longlong;
#endif
static size_t __Pyx_BufFmt_TypeCharToAlignment(char ch, int is_complex) {
  CYTHON_UNUSED_VAR(is_complex);
  switch (ch) {
    case '?': case 'c': case 'b': case 'B': case 's': case 'p': return 1;
    case 'h': case 'H': return sizeof(__Pyx_st_short) - sizeof(short);
    case 'i': case 'I': return sizeof(__Pyx_st_int) - sizeof(int);
    case 'l': case 'L': return sizeof(__Pyx_st_long) - sizeof(long);
#ifdef HAVE_LONG_LONG
    case 'q': case 'Q': return sizeof(__Pyx_st_longlong) - sizeof(PY_LONG_LONG);
#endif
    case 'f': return sizeof(__Pyx_st_float) - sizeof(float);
    case 'd': return sizeof(__Pyx_st_double) - sizeof(double);
    case 'g': return sizeof(__Pyx_st_longdouble) - sizeof(long double);
    case 'P': case 'O': return sizeof(__Pyx_st_void_p) - sizeof(void*);
    default:
      __Pyx_BufFmt_RaiseUnexpectedChar(ch);
      return 0;
    }
}
/* These are for computing the padding at the end of the struct to align
   on the first member of the struct. This will probably the same as above,
   but we don't have any guarantees.
 */
typedef struct { short x; char c; } __Pyx_pad_short;
typedef struct { int x; char c; } __Pyx_pad_int;
typedef struct { long x; char c; } __Pyx_pad_long;
typedef struct { float x; char c; } __Pyx_pad_float;
typedef struct { double x; char c; } __Pyx_pad_double;
typedef struct { long double x; char c; } __Pyx_pad_longdouble;
typedef struct { void *x; char c; } __Pyx_pad_void_p;
#ifdef HAVE_LONG_LONG
typedef struct { PY_LONG_LONG x; char c; } __Pyx_pad_longlong;
#endif
static size_t __Pyx_BufFmt_TypeCharToPadding(char ch, int is_complex) {
  CYTHON_UNUSED_VAR(is_complex);
  switch (ch) {
    case '?': case 'c': case 'b': case 'B': case 's': case 'p': return 1;
    case 'h': case 'H': return sizeof(__Pyx_pad_short) - sizeof(short);
    case 'i': case 'I': return sizeof(__Pyx_pad_int) - sizeof(int);
    case 'l': case 'L': return sizeof(__Pyx_pad_long) - sizeof(long);
#ifdef HAVE_LONG_LONG
    case 'q': case 'Q': return sizeof(__Pyx_pad_longlong) - sizeof(PY_LONG_LONG);
#endif
    case 'f': return sizeof(__Pyx_pad_float) - sizeof(float);
    case 'd': return sizeof(__Pyx_pad_double) - sizeof(double);
    case 'g': return sizeof(__Pyx_pad_longdouble) - sizeof(long double);
    case 'P': case 'O': return sizeof(__Pyx_pad_void_p) - sizeof(void*);
    default:
      __Pyx_BufFmt_RaiseUnexpectedChar(ch);
      return 0;
    }
}
static char __Pyx_BufFmt_TypeCharToGroup(char ch, int is_complex) {
  switch (ch) {
    case 'c':
        return 'H';
    case 'b': case 'h': case 'i':
    case 'l': case 'q': case 's': case 'p':
        return 'I';
    case '?': case 'B': case 'H': case 'I': case 'L': case 'Q':
        return 'U';
    case 'f': case 'd': case 'g':
        return (is_complex ? 'C' : 'R');
    case 'O':
        return 'O';
    case 'P':
        return 'P';
    default: {
      __Pyx_BufFmt_RaiseUnexpectedChar(ch);
      return 0;
    }
  }
}
static void __Pyx_BufFmt_RaiseExpected(__Pyx_BufFmt_Context* ctx) {
  if (ctx->head == NULL || ctx->head->field == &ctx->root) {
    const char* expected;
    const char* quote;
    if (ctx->head == NULL) {
      expected = "end";
      quote = "";
    } else {
      expected = ctx->head->field->type->name;
      quote = "'";
    }
    PyErr_Format(PyExc_ValueError,
                 "Buffer dtype mismatch, expected %s%s%s but got %s",
                 quote, expected, quote,
                 __Pyx_BufFmt_DescribeTypeChar(ctx->enc_type, ctx->is_complex));
  } else {
    __Pyx_StructField* field = ctx->head->field;
    __Pyx_StructField* parent = (ctx->head - 1)->field;
    PyErr_Format(PyExc_ValueError,
                 "Buffer dtype mismatch, expected '%s' but got %s in '%s.%s'",
                 field->type->name, __Pyx_BufFmt_DescribeTypeChar(ctx->enc_type, ctx->is_complex),
                 parent->type->name, field->name);
  }
}
static int __Pyx_BufFmt_ProcessTypeChunk(__Pyx_BufFmt_Context* ctx) {
  char group;
  size_t size, offset, arraysize = 1;
  if (ctx->enc_type == 0) return 0;
  if (ctx->head->field->type->arraysize[0]) {
    int i, ndim = 0;
    if (ctx->enc_type == 's' || ctx->enc_type == 'p') {
        ctx->is_valid_array = ctx->head->field->type->ndim == 1;
        ndim = 1;
        if (ctx->enc_count != ctx->head->field->type->arraysize[0]) {
            PyErr_Format(PyExc_ValueError,
                         "Expected a dimension of size %zu, got %zu",
                         ctx->head->field->type->arraysize[0], ctx->enc_count);
            return -1;
        }
    }
    if (!ctx->is_valid_array) {
      PyErr_Format(PyExc_ValueError, "Expected %d dimensions, got %d",
                   ctx->head->field->type->ndim, ndim);
      return -1;
    }
    for (i = 0; i < ctx->head->field->type->ndim; i++) {
      arraysize *= ctx->head->field->type->arraysize[i];
    }
    ctx->is_valid_array = 0;
    ctx->enc_count = 1;
  }
  group = __Pyx_BufFmt_TypeCharToGroup(ctx->enc_type, ctx->is_complex);
  do {
    __Pyx_StructField* field = ctx->head->field;
    __Pyx_TypeInfo* type = field->type;
    if (ctx->enc_packmode == '@' || ctx->enc_packmode == '^') {
      size = __Pyx_BufFmt_TypeCharToNativeSize(ctx->enc_type, ctx->is_complex);
    } else {
      size = __Pyx_BufFmt_TypeCharToStandardSize(ctx->enc_type, ctx->is_complex);
    }
    if (ctx->enc_packmode == '@') {
      size_t align_at = __Pyx_BufFmt_TypeCharToAlignment(ctx->enc_type, ctx->is_complex);
      size_t align_mod_offset;
      if (align_at == 0) return -1;
      align_mod_offset = ctx->fmt_offset % align_at;
      if (align_mod_offset > 0) ctx->fmt_offset += align_at - align_mod_offset;
      if (ctx->struct_alignment == 0)
          ctx->struct_alignment = __Pyx_BufFmt_TypeCharToPadding(ctx->enc_type,
                                                                 ctx->is_complex);
    }
    if (type->size != size || type->typegroup != group) {
      if (type->typegroup == 'C' && type->fields != NULL) {
        size_t parent_offset = ctx->head->parent_offset + field->offset;
        ++ctx->head;
        ctx->head->field = type->fields;
        ctx->head->parent_offset = parent_offset;
        continue;
      }
      if ((type->typegroup == 'H' || group == 'H') && type->size == size) {
      } else {
          __Pyx_BufFmt_RaiseExpected(ctx);
          return -1;
      }
    }
    offset = ctx->head->parent_offset + field->offset;
    if (ctx->fmt_offset != offset) {
      PyErr_Format(PyExc_ValueError,
                   "Buffer dtype mismatch; next field is at offset %" CYTHON_FORMAT_SSIZE_T "d but %" CYTHON_FORMAT_SSIZE_T "d expected",
                   (Py_ssize_t)ctx->fmt_offset, (Py_ssize_t)offset);
      return -1;
    }
    ctx->fmt_offset += size;
    if (arraysize)
      ctx->fmt_offset += (arraysize - 1) * size;
    --ctx->enc_count;
    while (1) {
      if (field == &ctx->root) {
        ctx->head = NULL;
        if (ctx->enc_count != 0) {
          __Pyx_BufFmt_RaiseExpected(ctx);
          return -1;
        }
        break;
      }
      ctx->head->field = ++field;
      if (field->type == NULL) {
        --ctx->head;
        field = ctx->head->field;
        continue;
      } else if (field->type->typegroup == 'S') {
        size_t parent_offset = ctx->head->parent_offset + field->offset;
        if (field->type->fields->type == NULL) continue;
        field = field->type->fields;
        ++ctx->head;
        ctx->head->field = field;
        ctx->head->parent_offset = parent_offset;
        break;
      } else {
        break;
      }
    }
  } while (ctx->enc_count);
  ctx->enc_type = 0;
  ctx->is_complex = 0;
  return 0;
}
static int
__pyx_buffmt_parse_array(__Pyx_BufFmt_Context* ctx, const char** tsp)
{
    const char *ts = *tsp;
    int i = 0, number, ndim;
    ++ts;
    if (ctx->new_count != 1) {
        PyErr_SetString(PyExc_ValueError,
                        "Cannot handle repeated arrays in format string");
        return -1;
    }
    if (__Pyx_BufFmt_ProcessTypeChunk(ctx) == -1) return -1;
    ndim = ctx->head->field->type->ndim;
    while (*ts && *ts != ')') {
        switch (*ts) {
            case ' ': case '\f': case '\r': case '\n': case '\t': case '\v':  continue;
            default:  break;
        }
        number = __Pyx_BufFmt_ExpectNumber(&ts);
        if (number == -1) return -1;
        if (i < ndim && (size_t) number != ctx->head->field->type->arraysize[i]) {
            PyErr_Format(PyExc_ValueError,
                        "Expected a dimension of size %zu, got %d",
                        ctx->head->field->type->arraysize[i], number);
            return -1;
        }
        if (*ts != ',' && *ts != ')') {
            PyErr_Format(PyExc_ValueError,
                                "Expected a comma in format string, got '%c'", *ts);
            return -1;
        }
        if (*ts == ',') ts++;
        i++;
    }
    if (i != ndim) {
        PyErr_Format(PyExc_ValueError, "Expected %d dimension(s), got %d",
                            ctx->head->field->type->ndim, i);
        return -1;
    }
    if (!*ts) {
        PyErr_SetString(PyExc_ValueError,
                        "Unexpected end of format string, expected ')'");
        return -1;
    }
    ctx->is_valid_array = 1;
    ctx->new_count = 1;
    *tsp = ++ts;
    return 0;
}
static const char* __Pyx_BufFmt_CheckString(__Pyx_BufFmt_Context* ctx, const char* ts) {
  int got_Z = 0;
  while (1) {
    switch(*ts) {
      case 0:
        if (ctx->enc_type != 0 && ctx->head == NULL) {
          __Pyx_BufFmt_RaiseExpected(ctx);
          return NULL;
        }
        if (__Pyx_BufFmt_ProcessTypeChunk(ctx) == -1) return NULL;
        if (ctx->head != NULL) {
          __Pyx_BufFmt_RaiseExpected(ctx);
          return NULL;
        }
        return ts;
      case ' ':
      case '\r':
      case '\n':
        ++ts;
        break;
      case '<':
        if (!__Pyx_Is_Little_Endian()) {
          PyErr_SetString(PyExc_ValueError, "Little-endian buffer not supported on big-endian compiler");
          return NULL;
        }
        ctx->new_packmode = '=';
        ++ts;
        break;
      case '>':
      case '!':
        if (__Pyx_Is_Little_Endian()) {
          PyErr_SetString(PyExc_ValueError, "Big-endian buffer not supported on little-endian compiler");
          return NULL;
        }
        ctx->new_packmode = '=';
        ++ts;
        break;
      case '=':
      case '@':
      case '^':
        ctx->new_packmode = *ts++;
        break;
      case 'T':
        {
          const char* ts_after_sub;
          size_t i, struct_count = ctx->new_count;
          size_t struct_alignment = ctx->struct_alignment;
          ctx->new_count = 1;
          ++ts;
          if (*ts != '{') {
            PyErr_SetString(PyExc_ValueError, "Buffer acquisition: Expected '{' after 'T'");
            return NULL;
          }
          if (__Pyx_BufFmt_ProcessTypeChunk(ctx) == -1) return NULL;
          ctx->enc_type = 0;
          ctx->enc_count = 0;
          ctx->struct_alignment = 0;
          ++ts;
          ts_after_sub = ts;
          for (i = 0; i != struct_count; ++i) {
            ts_after_sub = __Pyx_BufFmt_CheckString(ctx, ts);
            if (!ts_after_sub) return NULL;
          }
          ts = ts_after_sub;
          if (struct_alignment) ctx->struct_alignment = struct_alignment;
        }
        break;
      case '}':
        {
          size_t alignment = ctx->struct_alignment;
          ++ts;
          if (__Pyx_BufFmt_ProcessTypeChunk(ctx) == -1) return NULL;
          ctx->enc_type = 0;
          if (alignment && ctx->fmt_offset % alignment) {
            ctx->fmt_offset += alignment - (ctx->fmt_offset % alignment);
          }
        }
        return ts;
      case 'x':
        if (__Pyx_BufFmt_ProcessTypeChunk(ctx) == -1) return NULL;
        ctx->fmt_offset += ctx->new_count;
        ctx->new_count = 1;
        ctx->enc_count = 0;
        ctx->enc_type = 0;
        ctx->enc_packmode = ctx->new_packmode;
        ++ts;
        break;
      case 'Z':
        got_Z = 1;
        ++ts;
        if (*ts != 'f' && *ts != 'd' && *ts != 'g') {
          __Pyx_BufFmt_RaiseUnexpectedChar('Z');
          return NULL;
        }
        CYTHON_FALLTHROUGH;
      case '?': case 'c': case 'b': case 'B': case 'h': case 'H': case 'i': case 'I':
      case 'l': case 'L': case 'q': case 'Q':
      case 'f': case 'd': case 'g':
      case 'O': case 'p':
        if ((ctx->enc_type == *ts) && (got_Z == ctx->is_complex) &&
            (ctx->enc_packmode == ctx->new_packmode) && (!ctx->is_valid_array)) {
          ctx->enc_count += ctx->new_count;
          ctx->new_count = 1;
          got_Z = 0;
          ++ts;
          break;
        }
        CYTHON_FALLTHROUGH;
      case 's':
        if (__Pyx_BufFmt_ProcessTypeChunk(ctx) == -1) return NULL;
        ctx->enc_count = ctx->new_count;
        ctx->enc_packmode = ctx->new_packmode;
        ctx->enc_type = *ts;
        ctx->is_complex = got_Z;
        ++ts;
        ctx->new_count = 1;
        got_Z = 0;
        break;
      case ':':
        ++ts;
        while(*ts != ':') ++ts;
        ++ts;
        break;
      case '(':
        if (__pyx_buffmt_parse_array(ctx, &ts) < 0) return NULL;
        break;
      default:
        {
          int number = __Pyx_BufFmt_ExpectNumber(&ts);
          if (number == -1) return NULL;
          ctx->new_count = (size_t)number;
        }
    }
  }
}

/* BufferGetAndValidate */
  static CYTHON_INLINE void __Pyx_SafeReleaseBuffer(Py_buffer* info) {
  if (unlikely(info->buf == NULL)) return;
  if (info->suboffsets == __Pyx_minusones) info->suboffsets = NULL;
  __Pyx_ReleaseBuffer(info);
}
static void __Pyx_ZeroBuffer(Py_buffer* buf) {
  buf->buf = NULL;
  buf->obj = NULL;
  buf->strides = __Pyx_zeros;
  buf->shape = __Pyx_zeros;
  buf->suboffsets = __Pyx_minusones;
}
static int __Pyx__GetBufferAndValidate(
        Py_buffer* buf, PyObject* obj,  __Pyx_TypeInfo* dtype, int flags,
        int nd, int cast, __Pyx_BufFmt_StackElem* stack)
{
  buf->buf = NULL;
  if (unlikely(__Pyx_GetBuffer(obj, buf, flags) == -1)) {
    __Pyx_ZeroBuffer(buf);
    return -1;
  }
  if (unlikely(buf->ndim != nd)) {
    PyErr_Format(PyExc_ValueError,
                 "Buffer has wrong number of dimensions (expected %d, got %d)",
                 nd, buf->ndim);
    goto fail;
  }
  if (!cast) {
    __Pyx_BufFmt_Context ctx;
    __Pyx_BufFmt_Init(&ctx, stack, dtype);
    if (!__Pyx_BufFmt_CheckString(&ctx, buf->format)) goto fail;
  }
  if (unlikely((size_t)buf->itemsize != dtype->size)) {
    PyErr_Format(PyExc_ValueError,
      "Item size of buffer (%" CYTHON_FORMAT_SSIZE_T "d byte%s) does not match size of '%s' (%" CYTHON_FORMAT_SSIZE_T "d byte%s)",
      buf->itemsize, (buf->itemsize > 1) ? "s" : "",
      dtype->name, (Py_ssize_t)dtype->size, (dtype->size > 1) ? "s" : "");
    goto fail;
  }
  if (buf->suboffsets == NULL) buf->suboffsets = __Pyx_minusones;
  return 0;
fail:;
  __Pyx_SafeReleaseBuffer(buf);
  return -1;
}

/* PyObjectCallOneArg */
  static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *args[2] = {NULL, arg};
    return __Pyx_PyObject_FastCall(func, args+1, 1 | __Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET);
}

/* ObjectGetItem */
  #if CYTHON_USE_TYPE_SLOTS
static PyObject *__Pyx_PyObject_GetIndex(PyObject *obj, PyObject *index) {
    PyObject *runerr = NULL;
    Py_ssize_t key_value;
    key_value = __Pyx_PyIndex_AsSsize_t(index);
    if (likely(key_value != -1 || !(runerr = PyErr_Occurred()))) {
        return __Pyx_GetItemInt_Fast(obj, key_value, 0, 1, 1);
    }
    if (PyErr_GivenExceptionMatches(runerr, PyExc_OverflowError)) {
        __Pyx_TypeName index_type_name = __Pyx_PyType_GetName(Py_TYPE(index));
        PyErr_Clear();
        PyErr_Format(PyExc_IndexError,
            "cannot fit '" __Pyx_FMT_TYPENAME "' into an index-sized integer", index_type_name);
        __Pyx_DECREF_TypeName(index_type_name);
    }
    return NULL;
}
static PyObject *__Pyx_PyObject_GetItem_Slow(PyObject *obj, PyObject *key) {
    __Pyx_TypeName obj_type_name;
    if (likely(PyType_Check(obj))) {
        PyObject *meth = __Pyx_PyObject_GetAttrStrNoError(obj, __pyx_n_s_class_getitem);
        if (meth) {
            PyObject *result = __Pyx_PyObject_CallOneArg(meth, key);
            Py_DECREF(meth);
            return result;
        }
    }
    obj_type_name = __Pyx_PyType_GetName(Py_TYPE(obj));
    PyErr_Format(PyExc_TypeError,
        "'" __Pyx_FMT_TYPENAME "' object is not subscriptable", obj_type_name);
    __Pyx_DECREF_TypeName(obj_type_name);
    return NULL;
}
static PyObject *__Pyx_PyObject_GetItem(PyObject *obj, PyObject *key) {
    PyTypeObject *tp = Py_TYPE(obj);
    PyMappingMethods *mm = tp->tp_as_mapping;
    PySequenceMethods *sm = tp->tp_as_sequence;
    if (likely(mm && mm->mp_subscript)) {
        return mm->mp_subscript(obj, key);
    }
    if (likely(sm && sm->sq_item)) {
        return __Pyx_PyObject_GetIndex(obj, key);
    }
    return __Pyx_PyObject_GetItem_Slow(obj, key);
}
#endif

/* PyIntBinop */
  #if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_SubtractObjC(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check) {
    CYTHON_MAYBE_UNUSED_VAR(intval);
    CYTHON_MAYBE_UNUSED_VAR(inplace);
    CYTHON_UNUSED_VAR(zerodivision_check);
    #if PY_MAJOR_VERSION < 3
    if (likely(PyInt_CheckExact(op1))) {
        const long b = intval;
        long x;
        long a = PyInt_AS_LONG(op1);
        
            x = (long)((unsigned long)a - (unsigned long)b);
            if (likely((x^a) >= 0 || (x^~b) >= 0))
                return PyInt_FromLong(x);
            return PyLong_Type.tp_as_number->nb_subtract(op1, op2);
    }
    #endif
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        const long b = intval;
        long a, x;
#ifdef HAVE_LONG_LONG
        const PY_LONG_LONG llb = intval;
        PY_LONG_LONG lla, llx;
#endif
        if (unlikely(__Pyx_PyLong_IsZero(op1))) {
            return PyLong_FromLong(-intval);
        }
        if (likely(__Pyx_PyLong_IsCompact(op1))) {
            a = __Pyx_PyLong_CompactValue(op1);
        } else {
            const digit* digits = __Pyx_PyLong_Digits(op1);
            const Py_ssize_t size = __Pyx_PyLong_SignedDigitCount(op1);
            switch (size) {
                case -2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case 2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case -3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case 3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case -4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case 4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                default: return PyLong_Type.tp_as_number->nb_subtract(op1, op2);
            }
        }
                x = a - b;
            return PyLong_FromLong(x);
#ifdef HAVE_LONG_LONG
        long_long:
                llx = lla - llb;
            return PyLong_FromLongLong(llx);
#endif
        
        
    }
    #endif
    if (PyFloat_CheckExact(op1)) {
        const long b = intval;
#if CYTHON_COMPILING_IN_LIMITED_API
        double a = __pyx_PyFloat_AsDouble(op1);
#else
        double a = PyFloat_AS_DOUBLE(op1);
#endif
            double result;
            
            PyFPE_START_PROTECT("subtract", return NULL)
            result = ((double)a) - (double)b;
            PyFPE_END_PROTECT(result)
            return PyFloat_FromDouble(result);
    }
    return (inplace ? PyNumber_InPlaceSubtract : PyNumber_Subtract)(op1, op2);
}
#endif

/* SliceObject */
  static CYTHON_INLINE int __Pyx_PyObject_SetSlice(PyObject* obj, PyObject* value,
        Py_ssize_t cstart, Py_ssize_t cstop,
        PyObject** _py_start, PyObject** _py_stop, PyObject** _py_slice,
        int has_cstart, int has_cstop, int wraparound) {
    __Pyx_TypeName obj_type_name;
#if CYTHON_USE_TYPE_SLOTS
    PyMappingMethods* mp;
#if PY_MAJOR_VERSION < 3
    PySequenceMethods* ms = Py_TYPE(obj)->tp_as_sequence;
    if (likely(ms && ms->sq_ass_slice)) {
        if (!has_cstart) {
            if (_py_start && (*_py_start != Py_None)) {
                cstart = __Pyx_PyIndex_AsSsize_t(*_py_start);
                if ((cstart == (Py_ssize_t)-1) && PyErr_Occurred()) goto bad;
            } else
                cstart = 0;
        }
        if (!has_cstop) {
            if (_py_stop && (*_py_stop != Py_None)) {
                cstop = __Pyx_PyIndex_AsSsize_t(*_py_stop);
                if ((cstop == (Py_ssize_t)-1) && PyErr_Occurred()) goto bad;
            } else
                cstop = PY_SSIZE_T_MAX;
        }
        if (wraparound && unlikely((cstart < 0) | (cstop < 0)) && likely(ms->sq_length)) {
            Py_ssize_t l = ms->sq_length(obj);
            if (likely(l >= 0)) {
                if (cstop < 0) {
                    cstop += l;
                    if (cstop < 0) cstop = 0;
                }
                if (cstart < 0) {
                    cstart += l;
                    if (cstart < 0) cstart = 0;
                }
            } else {
                if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                    goto bad;
                PyErr_Clear();
            }
        }
        return ms->sq_ass_slice(obj, cstart, cstop, value);
    }
#else
    CYTHON_UNUSED_VAR(wraparound);
#endif
    mp = Py_TYPE(obj)->tp_as_mapping;
    if (likely(mp && mp->mp_ass_subscript))
#else
    CYTHON_UNUSED_VAR(wraparound);
#endif
    {
        int result;
        PyObject *py_slice, *py_start, *py_stop;
        if (_py_slice) {
            py_slice = *_py_slice;
        } else {
            PyObject* owned_start = NULL;
            PyObject* owned_stop = NULL;
            if (_py_start) {
                py_start = *_py_start;
            } else {
                if (has_cstart) {
                    owned_start = py_start = PyInt_FromSsize_t(cstart);
                    if (unlikely(!py_start)) goto bad;
                } else
                    py_start = Py_None;
            }
            if (_py_stop) {
                py_stop = *_py_stop;
            } else {
                if (has_cstop) {
                    owned_stop = py_stop = PyInt_FromSsize_t(cstop);
                    if (unlikely(!py_stop)) {
                        Py_XDECREF(owned_start);
                        goto bad;
                    }
                } else
                    py_stop = Py_None;
            }
            py_slice = PySlice_New(py_start, py_stop, Py_None);
            Py_XDECREF(owned_start);
            Py_XDECREF(owned_stop);
            if (unlikely(!py_slice)) goto bad;
        }
#if CYTHON_USE_TYPE_SLOTS
        result = mp->mp_ass_subscript(obj, py_slice, value);
#else
        result = value ? PyObject_SetItem(obj, py_slice, value) : PyObject_DelItem(obj, py_slice);
#endif
        if (!_py_slice) {
            Py_DECREF(py_slice);
        }
        return result;
    }
    obj_type_name = __Pyx_PyType_GetName(Py_TYPE(obj));
    PyErr_Format(PyExc_TypeError,
        "'" __Pyx_FMT_TYPENAME "' object does not support slice %.10s",
        obj_type_name, value ? "assignment" : "deletion");
    __Pyx_DECREF_TypeName(obj_type_name);
bad:
    return -1;
}

/* PyIntBinop */
  #if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_RemainderObjC(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check) {
    CYTHON_MAYBE_UNUSED_VAR(intval);
    CYTHON_MAYBE_UNUSED_VAR(inplace);
    CYTHON_UNUSED_VAR(zerodivision_check);
    #if PY_MAJOR_VERSION < 3
    if (likely(PyInt_CheckExact(op1))) {
        const long b = intval;
        long x;
        long a = PyInt_AS_LONG(op1);
        
            x = a % b;
            x += ((x != 0) & ((x ^ b) < 0)) * b;
            return PyInt_FromLong(x);
    }
    #endif
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        const long b = intval;
        long a, x;
#ifdef HAVE_LONG_LONG
        const PY_LONG_LONG llb = intval;
        PY_LONG_LONG lla, llx;
#endif
        if (unlikely(__Pyx_PyLong_IsZero(op1))) {
            return __Pyx_NewRef(op1);
        }
        if (likely(__Pyx_PyLong_IsCompact(op1))) {
            a = __Pyx_PyLong_CompactValue(op1);
        } else {
            const digit* digits = __Pyx_PyLong_Digits(op1);
            const Py_ssize_t size = __Pyx_PyLong_SignedDigitCount(op1);
            switch (size) {
                case -2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case 2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case -3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case 3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case -4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case 4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                default: return PyLong_Type.tp_as_number->nb_remainder(op1, op2);
            }
        }
                x = a % b;
                x += ((x != 0) & ((x ^ b) < 0)) * b;
            return PyLong_FromLong(x);
#ifdef HAVE_LONG_LONG
        long_long:
                llx = lla % llb;
                llx += ((llx != 0) & ((llx ^ llb) < 0)) * llb;
            return PyLong_FromLongLong(llx);
#endif
        
        
    }
    #endif
    return (inplace ? PyNumber_InPlaceRemainder : PyNumber_Remainder)(op1, op2);
}
#endif

/* PyIntBinop */
  #if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_MultiplyCObj(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check) {
    CYTHON_MAYBE_UNUSED_VAR(intval);
    CYTHON_MAYBE_UNUSED_VAR(inplace);
    CYTHON_UNUSED_VAR(zerodivision_check);
    #if PY_MAJOR_VERSION < 3
    if (likely(PyInt_CheckExact(op2))) {
        const long a = intval;
        long b = PyInt_AS_LONG(op2);
        
#ifdef HAVE_LONG_LONG
            if (sizeof(PY_LONG_LONG) > sizeof(long)) {
                PY_LONG_LONG result = (PY_LONG_LONG)a * (PY_LONG_LONG)b;
                return (result >= LONG_MIN && result <= LONG_MAX) ?
                    PyInt_FromLong((long)result) : PyLong_FromLongLong(result);
            }
#endif
#if CYTHON_USE_TYPE_SLOTS
            return PyInt_Type.tp_as_number->nb_multiply(op1, op2);
#else
            return PyNumber_Multiply(op1, op2);
#endif
    }
    #endif
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op2))) {
        const long a = intval;
        long b, x;
#ifdef HAVE_LONG_LONG
        const PY_LONG_LONG lla = intval;
        PY_LONG_LONG llb, llx;
#endif
        if (unlikely(__Pyx_PyLong_IsZero(op2))) {
            return __Pyx_NewRef(op2);
        }
        if (likely(__Pyx_PyLong_IsCompact(op2))) {
            b = __Pyx_PyLong_CompactValue(op2);
        } else {
            const digit* digits = __Pyx_PyLong_Digits(op2);
            const Py_ssize_t size = __Pyx_PyLong_SignedDigitCount(op2);
            switch (size) {
                case -2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT+30) {
                        b = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT+30) {
                        llb = -(PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case 2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT+30) {
                        b = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT+30) {
                        llb = (PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case -3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT+30) {
                        b = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT+30) {
                        llb = -(PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case 3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT+30) {
                        b = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT+30) {
                        llb = (PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case -4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT+30) {
                        b = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT+30) {
                        llb = -(PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case 4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT+30) {
                        b = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT+30) {
                        llb = (PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                default: return PyLong_Type.tp_as_number->nb_multiply(op1, op2);
            }
        }
                CYTHON_UNUSED_VAR(a);
                CYTHON_UNUSED_VAR(b);
                #ifdef HAVE_LONG_LONG
                llb = b;
                goto long_long;
                #else
                return PyLong_Type.tp_as_number->nb_multiply(op1, op2);
                #endif
            return PyLong_FromLong(x);
#ifdef HAVE_LONG_LONG
        long_long:
                llx = lla * llb;
            return PyLong_FromLongLong(llx);
#endif
        
        
    }
    #endif
    if (PyFloat_CheckExact(op2)) {
        const long a = intval;
#if CYTHON_COMPILING_IN_LIMITED_API
        double b = __pyx_PyFloat_AsDouble(op2);
#else
        double b = PyFloat_AS_DOUBLE(op2);
#endif
            double result;
            
            PyFPE_START_PROTECT("multiply", return NULL)
            result = ((double)a) * (double)b;
            PyFPE_END_PROTECT(result)
            return PyFloat_FromDouble(result);
    }
    return (inplace ? PyNumber_InPlaceMultiply : PyNumber_Multiply)(op1, op2);
}
#endif

/* PyIntBinop */
  #if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_TrueDivideObjC(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check) {
    CYTHON_MAYBE_UNUSED_VAR(intval);
    CYTHON_MAYBE_UNUSED_VAR(inplace);
    CYTHON_UNUSED_VAR(zerodivision_check);
    #if PY_MAJOR_VERSION < 3
    if (likely(PyInt_CheckExact(op1))) {
        const long b = intval;
        long a = PyInt_AS_LONG(op1);
        
            if (8 * sizeof(long) <= 53 || likely(labs(a) <= ((PY_LONG_LONG)1 << 53))) {
                return PyFloat_FromDouble((double)a / (double)b);
            }
            return PyInt_Type.tp_as_number->nb_true_divide(op1, op2);
    }
    #endif
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        const long b = intval;
        long a, x;
        if (unlikely(__Pyx_PyLong_IsZero(op1))) {
        }
        if (likely(__Pyx_PyLong_IsCompact(op1))) {
            a = __Pyx_PyLong_CompactValue(op1);
        } else {
            const digit* digits = __Pyx_PyLong_Digits(op1);
            const Py_ssize_t size = __Pyx_PyLong_SignedDigitCount(op1);
            switch (size) {
                case -2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT && 1 * PyLong_SHIFT < 53) {
                        a = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    }
                    CYTHON_FALLTHROUGH;
                case 2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT && 1 * PyLong_SHIFT < 53) {
                        a = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    }
                    CYTHON_FALLTHROUGH;
                case -3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT && 2 * PyLong_SHIFT < 53) {
                        a = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    }
                    CYTHON_FALLTHROUGH;
                case 3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT && 2 * PyLong_SHIFT < 53) {
                        a = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    }
                    CYTHON_FALLTHROUGH;
                case -4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT && 3 * PyLong_SHIFT < 53) {
                        a = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    }
                    CYTHON_FALLTHROUGH;
                case 4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT && 3 * PyLong_SHIFT < 53) {
                        a = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    }
                    CYTHON_FALLTHROUGH;
                default: return PyLong_Type.tp_as_number->nb_true_divide(op1, op2);
            }
        }
                if ((8 * sizeof(long) <= 53 || likely(labs(a) <= ((PY_LONG_LONG)1 << 53)))
                        || __Pyx_PyLong_DigitCount(op1) <= 52 / PyLong_SHIFT) {
                    return PyFloat_FromDouble((double)a / (double)b);
                }
                return PyLong_Type.tp_as_number->nb_true_divide(op1, op2);
            return PyLong_FromLong(x);
        
    }
    #endif
    if (PyFloat_CheckExact(op1)) {
        const long b = intval;
#if CYTHON_COMPILING_IN_LIMITED_API
        double a = __pyx_PyFloat_AsDouble(op1);
#else
        double a = PyFloat_AS_DOUBLE(op1);
#endif
            double result;
            
            PyFPE_START_PROTECT("divide", return NULL)
            result = ((double)a) / (double)b;
            PyFPE_END_PROTECT(result)
            return PyFloat_FromDouble(result);
    }
    return (inplace ? PyNumber_InPlaceTrueDivide : PyNumber_TrueDivide)(op1, op2);
}
#endif

/* PyIntBinop */
  #if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_AddObjC(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check) {
    CYTHON_MAYBE_UNUSED_VAR(intval);
    CYTHON_MAYBE_UNUSED_VAR(inplace);
    CYTHON_UNUSED_VAR(zerodivision_check);
    #if PY_MAJOR_VERSION < 3
    if (likely(PyInt_CheckExact(op1))) {
        const long b = intval;
        long x;
        long a = PyInt_AS_LONG(op1);
        
            x = (long)((unsigned long)a + (unsigned long)b);
            if (likely((x^a) >= 0 || (x^b) >= 0))
                return PyInt_FromLong(x);
            return PyLong_Type.tp_as_number->nb_add(op1, op2);
    }
    #endif
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        const long b = intval;
        long a, x;
#ifdef HAVE_LONG_LONG
        const PY_LONG_LONG llb = intval;
        PY_LONG_LONG lla, llx;
#endif
        if (unlikely(__Pyx_PyLong_IsZero(op1))) {
            return __Pyx_NewRef(op2);
        }
        if (likely(__Pyx_PyLong_IsCompact(op1))) {
            a = __Pyx_PyLong_CompactValue(op1);
        } else {
            const digit* digits = __Pyx_PyLong_Digits(op1);
            const Py_ssize_t size = __Pyx_PyLong_SignedDigitCount(op1);
            switch (size) {
                case -2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case 2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case -3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case 3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case -4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                case 4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    #ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
                    #endif
                    }
                    CYTHON_FALLTHROUGH;
                default: return PyLong_Type.tp_as_number->nb_add(op1, op2);
            }
        }
                x = a + b;
            return PyLong_FromLong(x);
#ifdef HAVE_LONG_LONG
        long_long:
                llx = lla + llb;
            return PyLong_FromLongLong(llx);
#endif
        
        
    }
    #endif
    if (PyFloat_CheckExact(op1)) {
        const long b = intval;
#if CYTHON_COMPILING_IN_LIMITED_API
        double a = __pyx_PyFloat_AsDouble(op1);
#else
        double a = PyFloat_AS_DOUBLE(op1);
#endif
            double result;
            
            PyFPE_START_PROTECT("add", return NULL)
            result = ((double)a) + (double)b;
            PyFPE_END_PROTECT(result)
            return PyFloat_FromDouble(result);
    }
    return (inplace ? PyNumber_InPlaceAdd : PyNumber_Add)(op1, op2);
}
#endif

/* TypeImport */
  #ifndef __PYX_HAVE_RT_ImportType_3_0_3
#define __PYX_HAVE_RT_ImportType_3_0_3
static PyTypeObject *__Pyx_ImportType_3_0_3(PyObject *module, const char *module_name, const char *class_name,
    size_t size, size_t alignment, enum __Pyx_ImportType_CheckSize_3_0_3 check_size)
{
    PyObject *result = 0;
    char warning[200];
    Py_ssize_t basicsize;
    Py_ssize_t itemsize;
#if CYTHON_COMPILING_IN_LIMITED_API
    PyObject *py_basicsize;
    PyObject *py_itemsize;
#endif
    result = PyObject_GetAttrString(module, class_name);
    if (!result)
        goto bad;
    if (!PyType_Check(result)) {
        PyErr_Format(PyExc_TypeError,
            "%.200s.%.200s is not a type object",
            module_name, class_name);
        goto bad;
    }
#if !CYTHON_COMPILING_IN_LIMITED_API
    basicsize = ((PyTypeObject *)result)->tp_basicsize;
    itemsize = ((PyTypeObject *)result)->tp_itemsize;
#else
    py_basicsize = PyObject_GetAttrString(result, "__basicsize__");
    if (!py_basicsize)
        goto bad;
    basicsize = PyLong_AsSsize_t(py_basicsize);
    Py_DECREF(py_basicsize);
    py_basicsize = 0;
    if (basicsize == (Py_ssize_t)-1 && PyErr_Occurred())
        goto bad;
    py_itemsize = PyObject_GetAttrString(result, "__itemsize__");
    if (!py_itemsize)
        goto bad;
    itemsize = PyLong_AsSsize_t(py_itemsize);
    Py_DECREF(py_itemsize);
    py_itemsize = 0;
    if (itemsize == (Py_ssize_t)-1 && PyErr_Occurred())
        goto bad;
#endif
    if (itemsize) {
        if (size % alignment) {
            alignment = size % alignment;
        }
        if (itemsize < (Py_ssize_t)alignment)
            itemsize = (Py_ssize_t)alignment;
    }
    if ((size_t)(basicsize + itemsize) < size) {
        PyErr_Format(PyExc_ValueError,
            "%.200s.%.200s size changed, may indicate binary incompatibility. "
            "Expected %zd from C header, got %zd from PyObject",
            module_name, class_name, size, basicsize+itemsize);
        goto bad;
    }
    if (check_size == __Pyx_ImportType_CheckSize_Error_3_0_3 &&
            ((size_t)basicsize > size || (size_t)(basicsize + itemsize) < size)) {
        PyErr_Format(PyExc_ValueError,
            "%.200s.%.200s size changed, may indicate binary incompatibility. "
            "Expected %zd from C header, got %zd-%zd from PyObject",
            module_name, class_name, size, basicsize, basicsize+itemsize);
        goto bad;
    }
    else if (check_size == __Pyx_ImportType_CheckSize_Warn_3_0_3 && (size_t)basicsize > size) {
        PyOS_snprintf(warning, sizeof(warning),
            "%s.%s size changed, may indicate binary incompatibility. "
            "Expected %zd from C header, got %zd from PyObject",
            module_name, class_name, size, basicsize);
        if (PyErr_WarnEx(NULL, warning, 0) < 0) goto bad;
    }
    return (PyTypeObject *)result;
bad:
    Py_XDECREF(result);
    return NULL;
}
#endif

/* Import */
  static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level) {
    PyObject *module = 0;
    PyObject *empty_dict = 0;
    PyObject *empty_list = 0;
    #if PY_MAJOR_VERSION < 3
    PyObject *py_import;
    py_import = __Pyx_PyObject_GetAttrStr(__pyx_b, __pyx_n_s_import);
    if (unlikely(!py_import))
        goto bad;
    if (!from_list) {
        empty_list = PyList_New(0);
        if (unlikely(!empty_list))
            goto bad;
        from_list = empty_list;
    }
    #endif
    empty_dict = PyDict_New();
    if (unlikely(!empty_dict))
        goto bad;
    {
        #if PY_MAJOR_VERSION >= 3
        if (level == -1) {
            if (strchr(__Pyx_MODULE_NAME, '.') != NULL) {
                module = PyImport_ImportModuleLevelObject(
                    name, __pyx_d, empty_dict, from_list, 1);
                if (unlikely(!module)) {
                    if (unlikely(!PyErr_ExceptionMatches(PyExc_ImportError)))
                        goto bad;
                    PyErr_Clear();
                }
            }
            level = 0;
        }
        #endif
        if (!module) {
            #if PY_MAJOR_VERSION < 3
            PyObject *py_level = PyInt_FromLong(level);
            if (unlikely(!py_level))
                goto bad;
            module = PyObject_CallFunctionObjArgs(py_import,
                name, __pyx_d, empty_dict, from_list, py_level, (PyObject *)NULL);
            Py_DECREF(py_level);
            #else
            module = PyImport_ImportModuleLevelObject(
                name, __pyx_d, empty_dict, from_list, level);
            #endif
        }
    }
bad:
    Py_XDECREF(empty_dict);
    Py_XDECREF(empty_list);
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(py_import);
    #endif
    return module;
}

/* ImportDottedModule */
  #if PY_MAJOR_VERSION >= 3
static PyObject *__Pyx__ImportDottedModule_Error(PyObject *name, PyObject *parts_tuple, Py_ssize_t count) {
    PyObject *partial_name = NULL, *slice = NULL, *sep = NULL;
    if (unlikely(PyErr_Occurred())) {
        PyErr_Clear();
    }
    if (likely(PyTuple_GET_SIZE(parts_tuple) == count)) {
        partial_name = name;
    } else {
        slice = PySequence_GetSlice(parts_tuple, 0, count);
        if (unlikely(!slice))
            goto bad;
        sep = PyUnicode_FromStringAndSize(".", 1);
        if (unlikely(!sep))
            goto bad;
        partial_name = PyUnicode_Join(sep, slice);
    }
    PyErr_Format(
#if PY_MAJOR_VERSION < 3
        PyExc_ImportError,
        "No module named '%s'", PyString_AS_STRING(partial_name));
#else
#if PY_VERSION_HEX >= 0x030600B1
        PyExc_ModuleNotFoundError,
#else
        PyExc_ImportError,
#endif
        "No module named '%U'", partial_name);
#endif
bad:
    Py_XDECREF(sep);
    Py_XDECREF(slice);
    Py_XDECREF(partial_name);
    return NULL;
}
#endif
#if PY_MAJOR_VERSION >= 3
static PyObject *__Pyx__ImportDottedModule_Lookup(PyObject *name) {
    PyObject *imported_module;
#if PY_VERSION_HEX < 0x030700A1 || (CYTHON_COMPILING_IN_PYPY && PYPY_VERSION_NUM  < 0x07030400)
    PyObject *modules = PyImport_GetModuleDict();
    if (unlikely(!modules))
        return NULL;
    imported_module = __Pyx_PyDict_GetItemStr(modules, name);
    Py_XINCREF(imported_module);
#else
    imported_module = PyImport_GetModule(name);
#endif
    return imported_module;
}
#endif
#if PY_MAJOR_VERSION >= 3
static PyObject *__Pyx_ImportDottedModule_WalkParts(PyObject *module, PyObject *name, PyObject *parts_tuple) {
    Py_ssize_t i, nparts;
    nparts = PyTuple_GET_SIZE(parts_tuple);
    for (i=1; i < nparts && module; i++) {
        PyObject *part, *submodule;
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        part = PyTuple_GET_ITEM(parts_tuple, i);
#else
        part = PySequence_ITEM(parts_tuple, i);
#endif
        submodule = __Pyx_PyObject_GetAttrStrNoError(module, part);
#if !(CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS)
        Py_DECREF(part);
#endif
        Py_DECREF(module);
        module = submodule;
    }
    if (unlikely(!module)) {
        return __Pyx__ImportDottedModule_Error(name, parts_tuple, i);
    }
    return module;
}
#endif
static PyObject *__Pyx__ImportDottedModule(PyObject *name, PyObject *parts_tuple) {
#if PY_MAJOR_VERSION < 3
    PyObject *module, *from_list, *star = __pyx_n_s__70;
    CYTHON_UNUSED_VAR(parts_tuple);
    from_list = PyList_New(1);
    if (unlikely(!from_list))
        return NULL;
    Py_INCREF(star);
    PyList_SET_ITEM(from_list, 0, star);
    module = __Pyx_Import(name, from_list, 0);
    Py_DECREF(from_list);
    return module;
#else
    PyObject *imported_module;
    PyObject *module = __Pyx_Import(name, NULL, 0);
    if (!parts_tuple || unlikely(!module))
        return module;
    imported_module = __Pyx__ImportDottedModule_Lookup(name);
    if (likely(imported_module)) {
        Py_DECREF(module);
        return imported_module;
    }
    PyErr_Clear();
    return __Pyx_ImportDottedModule_WalkParts(module, name, parts_tuple);
#endif
}
static PyObject *__Pyx_ImportDottedModule(PyObject *name, PyObject *parts_tuple) {
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030400B1
    PyObject *module = __Pyx__ImportDottedModule_Lookup(name);
    if (likely(module)) {
        PyObject *spec = __Pyx_PyObject_GetAttrStrNoError(module, __pyx_n_s_spec);
        if (likely(spec)) {
            PyObject *unsafe = __Pyx_PyObject_GetAttrStrNoError(spec, __pyx_n_s_initializing);
            if (likely(!unsafe || !__Pyx_PyObject_IsTrue(unsafe))) {
                Py_DECREF(spec);
                spec = NULL;
            }
            Py_XDECREF(unsafe);
        }
        if (likely(!spec)) {
            PyErr_Clear();
            return module;
        }
        Py_DECREF(spec);
        Py_DECREF(module);
    } else if (PyErr_Occurred()) {
        PyErr_Clear();
    }
#endif
    return __Pyx__ImportDottedModule(name, parts_tuple);
}

/* FixUpExtensionType */
  #if CYTHON_USE_TYPE_SPECS
static int __Pyx_fix_up_extension_type_from_spec(PyType_Spec *spec, PyTypeObject *type) {
#if PY_VERSION_HEX > 0x030900B1 || CYTHON_COMPILING_IN_LIMITED_API
    CYTHON_UNUSED_VAR(spec);
    CYTHON_UNUSED_VAR(type);
#else
    const PyType_Slot *slot = spec->slots;
    while (slot && slot->slot && slot->slot != Py_tp_members)
        slot++;
    if (slot && slot->slot == Py_tp_members) {
        int changed = 0;
#if !(PY_VERSION_HEX <= 0x030900b1 && CYTHON_COMPILING_IN_CPYTHON)
        const
#endif
            PyMemberDef *memb = (PyMemberDef*) slot->pfunc;
        while (memb && memb->name) {
            if (memb->name[0] == '_' && memb->name[1] == '_') {
#if PY_VERSION_HEX < 0x030900b1
                if (strcmp(memb->name, "__weaklistoffset__") == 0) {
                    assert(memb->type == T_PYSSIZET);
                    assert(memb->flags == READONLY);
                    type->tp_weaklistoffset = memb->offset;
                    changed = 1;
                }
                else if (strcmp(memb->name, "__dictoffset__") == 0) {
                    assert(memb->type == T_PYSSIZET);
                    assert(memb->flags == READONLY);
                    type->tp_dictoffset = memb->offset;
                    changed = 1;
                }
#if CYTHON_METH_FASTCALL
                else if (strcmp(memb->name, "__vectorcalloffset__") == 0) {
                    assert(memb->type == T_PYSSIZET);
                    assert(memb->flags == READONLY);
#if PY_VERSION_HEX >= 0x030800b4
                    type->tp_vectorcall_offset = memb->offset;
#else
                    type->tp_print = (printfunc) memb->offset;
#endif
                    changed = 1;
                }
#endif
#else
                if ((0));
#endif
#if PY_VERSION_HEX <= 0x030900b1 && CYTHON_COMPILING_IN_CPYTHON
                else if (strcmp(memb->name, "__module__") == 0) {
                    PyObject *descr;
                    assert(memb->type == T_OBJECT);
                    assert(memb->flags == 0 || memb->flags == READONLY);
                    descr = PyDescr_NewMember(type, memb);
                    if (unlikely(!descr))
                        return -1;
                    if (unlikely(PyDict_SetItem(type->tp_dict, PyDescr_NAME(descr), descr) < 0)) {
                        Py_DECREF(descr);
                        return -1;
                    }
                    Py_DECREF(descr);
                    changed = 1;
                }
#endif
            }
            memb++;
        }
        if (changed)
            PyType_Modified(type);
    }
#endif
    return 0;
}
#endif

/* FetchSharedCythonModule */
  static PyObject *__Pyx_FetchSharedCythonABIModule(void) {
    PyObject *abi_module = PyImport_AddModule((char*) __PYX_ABI_MODULE_NAME);
    if (unlikely(!abi_module)) return NULL;
    Py_INCREF(abi_module);
    return abi_module;
}

/* FetchCommonType */
  static int __Pyx_VerifyCachedType(PyObject *cached_type,
                               const char *name,
                               Py_ssize_t basicsize,
                               Py_ssize_t expected_basicsize) {
    if (!PyType_Check(cached_type)) {
        PyErr_Format(PyExc_TypeError,
            "Shared Cython type %.200s is not a type object", name);
        return -1;
    }
    if (basicsize != expected_basicsize) {
        PyErr_Format(PyExc_TypeError,
            "Shared Cython type %.200s has the wrong size, try recompiling",
            name);
        return -1;
    }
    return 0;
}
#if !CYTHON_USE_TYPE_SPECS
static PyTypeObject* __Pyx_FetchCommonType(PyTypeObject* type) {
    PyObject* abi_module;
    const char* object_name;
    PyTypeObject *cached_type = NULL;
    abi_module = __Pyx_FetchSharedCythonABIModule();
    if (!abi_module) return NULL;
    object_name = strrchr(type->tp_name, '.');
    object_name = object_name ? object_name+1 : type->tp_name;
    cached_type = (PyTypeObject*) PyObject_GetAttrString(abi_module, object_name);
    if (cached_type) {
        if (__Pyx_VerifyCachedType(
              (PyObject *)cached_type,
              object_name,
              cached_type->tp_basicsize,
              type->tp_basicsize) < 0) {
            goto bad;
        }
        goto done;
    }
    if (!PyErr_ExceptionMatches(PyExc_AttributeError)) goto bad;
    PyErr_Clear();
    if (PyType_Ready(type) < 0) goto bad;
    if (PyObject_SetAttrString(abi_module, object_name, (PyObject *)type) < 0)
        goto bad;
    Py_INCREF(type);
    cached_type = type;
done:
    Py_DECREF(abi_module);
    return cached_type;
bad:
    Py_XDECREF(cached_type);
    cached_type = NULL;
    goto done;
}
#else
static PyTypeObject *__Pyx_FetchCommonTypeFromSpec(PyObject *module, PyType_Spec *spec, PyObject *bases) {
    PyObject *abi_module, *cached_type = NULL;
    const char* object_name = strrchr(spec->name, '.');
    object_name = object_name ? object_name+1 : spec->name;
    abi_module = __Pyx_FetchSharedCythonABIModule();
    if (!abi_module) return NULL;
    cached_type = PyObject_GetAttrString(abi_module, object_name);
    if (cached_type) {
        Py_ssize_t basicsize;
#if CYTHON_COMPILING_IN_LIMITED_API
        PyObject *py_basicsize;
        py_basicsize = PyObject_GetAttrString(cached_type, "__basicsize__");
        if (unlikely(!py_basicsize)) goto bad;
        basicsize = PyLong_AsSsize_t(py_basicsize);
        Py_DECREF(py_basicsize);
        py_basicsize = 0;
        if (unlikely(basicsize == (Py_ssize_t)-1) && PyErr_Occurred()) goto bad;
#else
        basicsize = likely(PyType_Check(cached_type)) ? ((PyTypeObject*) cached_type)->tp_basicsize : -1;
#endif
        if (__Pyx_VerifyCachedType(
              cached_type,
              object_name,
              basicsize,
              spec->basicsize) < 0) {
            goto bad;
        }
        goto done;
    }
    if (!PyErr_ExceptionMatches(PyExc_AttributeError)) goto bad;
    PyErr_Clear();
    CYTHON_UNUSED_VAR(module);
    cached_type = __Pyx_PyType_FromModuleAndSpec(abi_module, spec, bases);
    if (unlikely(!cached_type)) goto bad;
    if (unlikely(__Pyx_fix_up_extension_type_from_spec(spec, (PyTypeObject *) cached_type) < 0)) goto bad;
    if (PyObject_SetAttrString(abi_module, object_name, cached_type) < 0) goto bad;
done:
    Py_DECREF(abi_module);
    assert(cached_type == NULL || PyType_Check(cached_type));
    return (PyTypeObject *) cached_type;
bad:
    Py_XDECREF(cached_type);
    cached_type = NULL;
    goto done;
}
#endif

/* PyVectorcallFastCallDict */
  #if CYTHON_METH_FASTCALL
static PyObject *__Pyx_PyVectorcall_FastCallDict_kw(PyObject *func, __pyx_vectorcallfunc vc, PyObject *const *args, size_t nargs, PyObject *kw)
{
    PyObject *res = NULL;
    PyObject *kwnames;
    PyObject **newargs;
    PyObject **kwvalues;
    Py_ssize_t i, pos;
    size_t j;
    PyObject *key, *value;
    unsigned long keys_are_strings;
    Py_ssize_t nkw = PyDict_GET_SIZE(kw);
    newargs = (PyObject **)PyMem_Malloc((nargs + (size_t)nkw) * sizeof(args[0]));
    if (unlikely(newargs == NULL)) {
        PyErr_NoMemory();
        return NULL;
    }
    for (j = 0; j < nargs; j++) newargs[j] = args[j];
    kwnames = PyTuple_New(nkw);
    if (unlikely(kwnames == NULL)) {
        PyMem_Free(newargs);
        return NULL;
    }
    kwvalues = newargs + nargs;
    pos = i = 0;
    keys_are_strings = Py_TPFLAGS_UNICODE_SUBCLASS;
    while (PyDict_Next(kw, &pos, &key, &value)) {
        keys_are_strings &= Py_TYPE(key)->tp_flags;
        Py_INCREF(key);
        Py_INCREF(value);
        PyTuple_SET_ITEM(kwnames, i, key);
        kwvalues[i] = value;
        i++;
    }
    if (unlikely(!keys_are_strings)) {
        PyErr_SetString(PyExc_TypeError, "keywords must be strings");
        goto cleanup;
    }
    res = vc(func, newargs, nargs, kwnames);
cleanup:
    Py_DECREF(kwnames);
    for (i = 0; i < nkw; i++)
        Py_DECREF(kwvalues[i]);
    PyMem_Free(newargs);
    return res;
}
static CYTHON_INLINE PyObject *__Pyx_PyVectorcall_FastCallDict(PyObject *func, __pyx_vectorcallfunc vc, PyObject *const *args, size_t nargs, PyObject *kw)
{
    if (likely(kw == NULL) || PyDict_GET_SIZE(kw) == 0) {
        return vc(func, args, nargs, NULL);
    }
    return __Pyx_PyVectorcall_FastCallDict_kw(func, vc, args, nargs, kw);
}
#endif

/* CythonFunctionShared */
  #if CYTHON_COMPILING_IN_LIMITED_API
static CYTHON_INLINE int __Pyx__IsSameCyOrCFunction(PyObject *func, void *cfunc) {
    if (__Pyx_CyFunction_Check(func)) {
        return PyCFunction_GetFunction(((__pyx_CyFunctionObject*)func)->func) == (PyCFunction) cfunc;
    } else if (PyCFunction_Check(func)) {
        return PyCFunction_GetFunction(func) == (PyCFunction) cfunc;
    }
    return 0;
}
#else
static CYTHON_INLINE int __Pyx__IsSameCyOrCFunction(PyObject *func, void *cfunc) {
    return __Pyx_CyOrPyCFunction_Check(func) && __Pyx_CyOrPyCFunction_GET_FUNCTION(func) == (PyCFunction) cfunc;
}
#endif
static CYTHON_INLINE void __Pyx__CyFunction_SetClassObj(__pyx_CyFunctionObject* f, PyObject* classobj) {
#if PY_VERSION_HEX < 0x030900B1 || CYTHON_COMPILING_IN_LIMITED_API
    __Pyx_Py_XDECREF_SET(
        __Pyx_CyFunction_GetClassObj(f),
            ((classobj) ? __Pyx_NewRef(classobj) : NULL));
#else
    __Pyx_Py_XDECREF_SET(
        ((PyCMethodObject *) (f))->mm_class,
        (PyTypeObject*)((classobj) ? __Pyx_NewRef(classobj) : NULL));
#endif
}
static PyObject *
__Pyx_CyFunction_get_doc(__pyx_CyFunctionObject *op, void *closure)
{
    CYTHON_UNUSED_VAR(closure);
    if (unlikely(op->func_doc == NULL)) {
#if CYTHON_COMPILING_IN_LIMITED_API
        op->func_doc = PyObject_GetAttrString(op->func, "__doc__");
        if (unlikely(!op->func_doc)) return NULL;
#else
        if (((PyCFunctionObject*)op)->m_ml->ml_doc) {
#if PY_MAJOR_VERSION >= 3
            op->func_doc = PyUnicode_FromString(((PyCFunctionObject*)op)->m_ml->ml_doc);
#else
            op->func_doc = PyString_FromString(((PyCFunctionObject*)op)->m_ml->ml_doc);
#endif
            if (unlikely(op->func_doc == NULL))
                return NULL;
        } else {
            Py_INCREF(Py_None);
            return Py_None;
        }
#endif
    }
    Py_INCREF(op->func_doc);
    return op->func_doc;
}
static int
__Pyx_CyFunction_set_doc(__pyx_CyFunctionObject *op, PyObject *value, void *context)
{
    CYTHON_UNUSED_VAR(context);
    if (value == NULL) {
        value = Py_None;
    }
    Py_INCREF(value);
    __Pyx_Py_XDECREF_SET(op->func_doc, value);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_name(__pyx_CyFunctionObject *op, void *context)
{
    CYTHON_UNUSED_VAR(context);
    if (unlikely(op->func_name == NULL)) {
#if CYTHON_COMPILING_IN_LIMITED_API
        op->func_name = PyObject_GetAttrString(op->func, "__name__");
#elif PY_MAJOR_VERSION >= 3
        op->func_name = PyUnicode_InternFromString(((PyCFunctionObject*)op)->m_ml->ml_name);
#else
        op->func_name = PyString_InternFromString(((PyCFunctionObject*)op)->m_ml->ml_name);
#endif
        if (unlikely(op->func_name == NULL))
            return NULL;
    }
    Py_INCREF(op->func_name);
    return op->func_name;
}
static int
__Pyx_CyFunction_set_name(__pyx_CyFunctionObject *op, PyObject *value, void *context)
{
    CYTHON_UNUSED_VAR(context);
#if PY_MAJOR_VERSION >= 3
    if (unlikely(value == NULL || !PyUnicode_Check(value)))
#else
    if (unlikely(value == NULL || !PyString_Check(value)))
#endif
    {
        PyErr_SetString(PyExc_TypeError,
                        "__name__ must be set to a string object");
        return -1;
    }
    Py_INCREF(value);
    __Pyx_Py_XDECREF_SET(op->func_name, value);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_qualname(__pyx_CyFunctionObject *op, void *context)
{
    CYTHON_UNUSED_VAR(context);
    Py_INCREF(op->func_qualname);
    return op->func_qualname;
}
static int
__Pyx_CyFunction_set_qualname(__pyx_CyFunctionObject *op, PyObject *value, void *context)
{
    CYTHON_UNUSED_VAR(context);
#if PY_MAJOR_VERSION >= 3
    if (unlikely(value == NULL || !PyUnicode_Check(value)))
#else
    if (unlikely(value == NULL || !PyString_Check(value)))
#endif
    {
        PyErr_SetString(PyExc_TypeError,
                        "__qualname__ must be set to a string object");
        return -1;
    }
    Py_INCREF(value);
    __Pyx_Py_XDECREF_SET(op->func_qualname, value);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_dict(__pyx_CyFunctionObject *op, void *context)
{
    CYTHON_UNUSED_VAR(context);
    if (unlikely(op->func_dict == NULL)) {
        op->func_dict = PyDict_New();
        if (unlikely(op->func_dict == NULL))
            return NULL;
    }
    Py_INCREF(op->func_dict);
    return op->func_dict;
}
static int
__Pyx_CyFunction_set_dict(__pyx_CyFunctionObject *op, PyObject *value, void *context)
{
    CYTHON_UNUSED_VAR(context);
    if (unlikely(value == NULL)) {
        PyErr_SetString(PyExc_TypeError,
               "function's dictionary may not be deleted");
        return -1;
    }
    if (unlikely(!PyDict_Check(value))) {
        PyErr_SetString(PyExc_TypeError,
               "setting function's dictionary to a non-dict");
        return -1;
    }
    Py_INCREF(value);
    __Pyx_Py_XDECREF_SET(op->func_dict, value);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_globals(__pyx_CyFunctionObject *op, void *context)
{
    CYTHON_UNUSED_VAR(context);
    Py_INCREF(op->func_globals);
    return op->func_globals;
}
static PyObject *
__Pyx_CyFunction_get_closure(__pyx_CyFunctionObject *op, void *context)
{
    CYTHON_UNUSED_VAR(op);
    CYTHON_UNUSED_VAR(context);
    Py_INCREF(Py_None);
    return Py_None;
}
static PyObject *
__Pyx_CyFunction_get_code(__pyx_CyFunctionObject *op, void *context)
{
    PyObject* result = (op->func_code) ? op->func_code : Py_None;
    CYTHON_UNUSED_VAR(context);
    Py_INCREF(result);
    return result;
}
static int
__Pyx_CyFunction_init_defaults(__pyx_CyFunctionObject *op) {
    int result = 0;
    PyObject *res = op->defaults_getter((PyObject *) op);
    if (unlikely(!res))
        return -1;
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    op->defaults_tuple = PyTuple_GET_ITEM(res, 0);
    Py_INCREF(op->defaults_tuple);
    op->defaults_kwdict = PyTuple_GET_ITEM(res, 1);
    Py_INCREF(op->defaults_kwdict);
    #else
    op->defaults_tuple = __Pyx_PySequence_ITEM(res, 0);
    if (unlikely(!op->defaults_tuple)) result = -1;
    else {
        op->defaults_kwdict = __Pyx_PySequence_ITEM(res, 1);
        if (unlikely(!op->defaults_kwdict)) result = -1;
    }
    #endif
    Py_DECREF(res);
    return result;
}
static int
__Pyx_CyFunction_set_defaults(__pyx_CyFunctionObject *op, PyObject* value, void *context) {
    CYTHON_UNUSED_VAR(context);
    if (!value) {
        value = Py_None;
    } else if (unlikely(value != Py_None && !PyTuple_Check(value))) {
        PyErr_SetString(PyExc_TypeError,
                        "__defaults__ must be set to a tuple object");
        return -1;
    }
    PyErr_WarnEx(PyExc_RuntimeWarning, "changes to cyfunction.__defaults__ will not "
                 "currently affect the values used in function calls", 1);
    Py_INCREF(value);
    __Pyx_Py_XDECREF_SET(op->defaults_tuple, value);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_defaults(__pyx_CyFunctionObject *op, void *context) {
    PyObject* result = op->defaults_tuple;
    CYTHON_UNUSED_VAR(context);
    if (unlikely(!result)) {
        if (op->defaults_getter) {
            if (unlikely(__Pyx_CyFunction_init_defaults(op) < 0)) return NULL;
            result = op->defaults_tuple;
        } else {
            result = Py_None;
        }
    }
    Py_INCREF(result);
    return result;
}
static int
__Pyx_CyFunction_set_kwdefaults(__pyx_CyFunctionObject *op, PyObject* value, void *context) {
    CYTHON_UNUSED_VAR(context);
    if (!value) {
        value = Py_None;
    } else if (unlikely(value != Py_None && !PyDict_Check(value))) {
        PyErr_SetString(PyExc_TypeError,
                        "__kwdefaults__ must be set to a dict object");
        return -1;
    }
    PyErr_WarnEx(PyExc_RuntimeWarning, "changes to cyfunction.__kwdefaults__ will not "
                 "currently affect the values used in function calls", 1);
    Py_INCREF(value);
    __Pyx_Py_XDECREF_SET(op->defaults_kwdict, value);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_kwdefaults(__pyx_CyFunctionObject *op, void *context) {
    PyObject* result = op->defaults_kwdict;
    CYTHON_UNUSED_VAR(context);
    if (unlikely(!result)) {
        if (op->defaults_getter) {
            if (unlikely(__Pyx_CyFunction_init_defaults(op) < 0)) return NULL;
            result = op->defaults_kwdict;
        } else {
            result = Py_None;
        }
    }
    Py_INCREF(result);
    return result;
}
static int
__Pyx_CyFunction_set_annotations(__pyx_CyFunctionObject *op, PyObject* value, void *context) {
    CYTHON_UNUSED_VAR(context);
    if (!value || value == Py_None) {
        value = NULL;
    } else if (unlikely(!PyDict_Check(value))) {
        PyErr_SetString(PyExc_TypeError,
                        "__annotations__ must be set to a dict object");
        return -1;
    }
    Py_XINCREF(value);
    __Pyx_Py_XDECREF_SET(op->func_annotations, value);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_annotations(__pyx_CyFunctionObject *op, void *context) {
    PyObject* result = op->func_annotations;
    CYTHON_UNUSED_VAR(context);
    if (unlikely(!result)) {
        result = PyDict_New();
        if (unlikely(!result)) return NULL;
        op->func_annotations = result;
    }
    Py_INCREF(result);
    return result;
}
static PyObject *
__Pyx_CyFunction_get_is_coroutine(__pyx_CyFunctionObject *op, void *context) {
    int is_coroutine;
    CYTHON_UNUSED_VAR(context);
    if (op->func_is_coroutine) {
        return __Pyx_NewRef(op->func_is_coroutine);
    }
    is_coroutine = op->flags & __Pyx_CYFUNCTION_COROUTINE;
#if PY_VERSION_HEX >= 0x03050000
    if (is_coroutine) {
        PyObject *module, *fromlist, *marker = __pyx_n_s_is_coroutine;
        fromlist = PyList_New(1);
        if (unlikely(!fromlist)) return NULL;
        Py_INCREF(marker);
#if CYTHON_ASSUME_SAFE_MACROS
        PyList_SET_ITEM(fromlist, 0, marker);
#else
        if (unlikely(PyList_SetItem(fromlist, 0, marker) < 0)) {
            Py_DECREF(marker);
            Py_DECREF(fromlist);
            return NULL;
        }
#endif
        module = PyImport_ImportModuleLevelObject(__pyx_n_s_asyncio_coroutines, NULL, NULL, fromlist, 0);
        Py_DECREF(fromlist);
        if (unlikely(!module)) goto ignore;
        op->func_is_coroutine = __Pyx_PyObject_GetAttrStr(module, marker);
        Py_DECREF(module);
        if (likely(op->func_is_coroutine)) {
            return __Pyx_NewRef(op->func_is_coroutine);
        }
ignore:
        PyErr_Clear();
    }
#endif
    op->func_is_coroutine = __Pyx_PyBool_FromLong(is_coroutine);
    return __Pyx_NewRef(op->func_is_coroutine);
}
#if CYTHON_COMPILING_IN_LIMITED_API
static PyObject *
__Pyx_CyFunction_get_module(__pyx_CyFunctionObject *op, void *context) {
    CYTHON_UNUSED_VAR(context);
    return PyObject_GetAttrString(op->func, "__module__");
}
static int
__Pyx_CyFunction_set_module(__pyx_CyFunctionObject *op, PyObject* value, void *context) {
    CYTHON_UNUSED_VAR(context);
    return PyObject_SetAttrString(op->func, "__module__", value);
}
#endif
static PyGetSetDef __pyx_CyFunction_getsets[] = {
    {(char *) "func_doc", (getter)__Pyx_CyFunction_get_doc, (setter)__Pyx_CyFunction_set_doc, 0, 0},
    {(char *) "__doc__",  (getter)__Pyx_CyFunction_get_doc, (setter)__Pyx_CyFunction_set_doc, 0, 0},
    {(char *) "func_name", (getter)__Pyx_CyFunction_get_name, (setter)__Pyx_CyFunction_set_name, 0, 0},
    {(char *) "__name__", (getter)__Pyx_CyFunction_get_name, (setter)__Pyx_CyFunction_set_name, 0, 0},
    {(char *) "__qualname__", (getter)__Pyx_CyFunction_get_qualname, (setter)__Pyx_CyFunction_set_qualname, 0, 0},
    {(char *) "func_dict", (getter)__Pyx_CyFunction_get_dict, (setter)__Pyx_CyFunction_set_dict, 0, 0},
    {(char *) "__dict__", (getter)__Pyx_CyFunction_get_dict, (setter)__Pyx_CyFunction_set_dict, 0, 0},
    {(char *) "func_globals", (getter)__Pyx_CyFunction_get_globals, 0, 0, 0},
    {(char *) "__globals__", (getter)__Pyx_CyFunction_get_globals, 0, 0, 0},
    {(char *) "func_closure", (getter)__Pyx_CyFunction_get_closure, 0, 0, 0},
    {(char *) "__closure__", (getter)__Pyx_CyFunction_get_closure, 0, 0, 0},
    {(char *) "func_code", (getter)__Pyx_CyFunction_get_code, 0, 0, 0},
    {(char *) "__code__", (getter)__Pyx_CyFunction_get_code, 0, 0, 0},
    {(char *) "func_defaults", (getter)__Pyx_CyFunction_get_defaults, (setter)__Pyx_CyFunction_set_defaults, 0, 0},
    {(char *) "__defaults__", (getter)__Pyx_CyFunction_get_defaults, (setter)__Pyx_CyFunction_set_defaults, 0, 0},
    {(char *) "__kwdefaults__", (getter)__Pyx_CyFunction_get_kwdefaults, (setter)__Pyx_CyFunction_set_kwdefaults, 0, 0},
    {(char *) "__annotations__", (getter)__Pyx_CyFunction_get_annotations, (setter)__Pyx_CyFunction_set_annotations, 0, 0},
    {(char *) "_is_coroutine", (getter)__Pyx_CyFunction_get_is_coroutine, 0, 0, 0},
#if CYTHON_COMPILING_IN_LIMITED_API
    {"__module__", (getter)__Pyx_CyFunction_get_module, (setter)__Pyx_CyFunction_set_module, 0, 0},
#endif
    {0, 0, 0, 0, 0}
};
static PyMemberDef __pyx_CyFunction_members[] = {
#if !CYTHON_COMPILING_IN_LIMITED_API
    {(char *) "__module__", T_OBJECT, offsetof(PyCFunctionObject, m_module), 0, 0},
#endif
#if CYTHON_USE_TYPE_SPECS
    {(char *) "__dictoffset__", T_PYSSIZET, offsetof(__pyx_CyFunctionObject, func_dict), READONLY, 0},
#if CYTHON_METH_FASTCALL
#if CYTHON_BACKPORT_VECTORCALL
    {(char *) "__vectorcalloffset__", T_PYSSIZET, offsetof(__pyx_CyFunctionObject, func_vectorcall), READONLY, 0},
#else
#if !CYTHON_COMPILING_IN_LIMITED_API
    {(char *) "__vectorcalloffset__", T_PYSSIZET, offsetof(PyCFunctionObject, vectorcall), READONLY, 0},
#endif
#endif
#endif
#if PY_VERSION_HEX < 0x030500A0 || CYTHON_COMPILING_IN_LIMITED_API
    {(char *) "__weaklistoffset__", T_PYSSIZET, offsetof(__pyx_CyFunctionObject, func_weakreflist), READONLY, 0},
#else
    {(char *) "__weaklistoffset__", T_PYSSIZET, offsetof(PyCFunctionObject, m_weakreflist), READONLY, 0},
#endif
#endif
    {0, 0, 0,  0, 0}
};
static PyObject *
__Pyx_CyFunction_reduce(__pyx_CyFunctionObject *m, PyObject *args)
{
    CYTHON_UNUSED_VAR(args);
#if PY_MAJOR_VERSION >= 3
    Py_INCREF(m->func_qualname);
    return m->func_qualname;
#else
    return PyString_FromString(((PyCFunctionObject*)m)->m_ml->ml_name);
#endif
}
static PyMethodDef __pyx_CyFunction_methods[] = {
    {"__reduce__", (PyCFunction)__Pyx_CyFunction_reduce, METH_VARARGS, 0},
    {0, 0, 0, 0}
};
#if PY_VERSION_HEX < 0x030500A0 || CYTHON_COMPILING_IN_LIMITED_API
#define __Pyx_CyFunction_weakreflist(cyfunc) ((cyfunc)->func_weakreflist)
#else
#define __Pyx_CyFunction_weakreflist(cyfunc) (((PyCFunctionObject*)cyfunc)->m_weakreflist)
#endif
static PyObject *__Pyx_CyFunction_Init(__pyx_CyFunctionObject *op, PyMethodDef *ml, int flags, PyObject* qualname,
                                       PyObject *closure, PyObject *module, PyObject* globals, PyObject* code) {
#if !CYTHON_COMPILING_IN_LIMITED_API
    PyCFunctionObject *cf = (PyCFunctionObject*) op;
#endif
    if (unlikely(op == NULL))
        return NULL;
#if CYTHON_COMPILING_IN_LIMITED_API
    op->func = PyCFunction_NewEx(ml, (PyObject*)op, module);
    if (unlikely(!op->func)) return NULL;
#endif
    op->flags = flags;
    __Pyx_CyFunction_weakreflist(op) = NULL;
#if !CYTHON_COMPILING_IN_LIMITED_API
    cf->m_ml = ml;
    cf->m_self = (PyObject *) op;
#endif
    Py_XINCREF(closure);
    op->func_closure = closure;
#if !CYTHON_COMPILING_IN_LIMITED_API
    Py_XINCREF(module);
    cf->m_module = module;
#endif
    op->func_dict = NULL;
    op->func_name = NULL;
    Py_INCREF(qualname);
    op->func_qualname = qualname;
    op->func_doc = NULL;
#if PY_VERSION_HEX < 0x030900B1 || CYTHON_COMPILING_IN_LIMITED_API
    op->func_classobj = NULL;
#else
    ((PyCMethodObject*)op)->mm_class = NULL;
#endif
    op->func_globals = globals;
    Py_INCREF(op->func_globals);
    Py_XINCREF(code);
    op->func_code = code;
    op->defaults_pyobjects = 0;
    op->defaults_size = 0;
    op->defaults = NULL;
    op->defaults_tuple = NULL;
    op->defaults_kwdict = NULL;
    op->defaults_getter = NULL;
    op->func_annotations = NULL;
    op->func_is_coroutine = NULL;
#if CYTHON_METH_FASTCALL
    switch (ml->ml_flags & (METH_VARARGS | METH_FASTCALL | METH_NOARGS | METH_O | METH_KEYWORDS | METH_METHOD)) {
    case METH_NOARGS:
        __Pyx_CyFunction_func_vectorcall(op) = __Pyx_CyFunction_Vectorcall_NOARGS;
        break;
    case METH_O:
        __Pyx_CyFunction_func_vectorcall(op) = __Pyx_CyFunction_Vectorcall_O;
        break;
    case METH_METHOD | METH_FASTCALL | METH_KEYWORDS:
        __Pyx_CyFunction_func_vectorcall(op) = __Pyx_CyFunction_Vectorcall_FASTCALL_KEYWORDS_METHOD;
        break;
    case METH_FASTCALL | METH_KEYWORDS:
        __Pyx_CyFunction_func_vectorcall(op) = __Pyx_CyFunction_Vectorcall_FASTCALL_KEYWORDS;
        break;
    case METH_VARARGS | METH_KEYWORDS:
        __Pyx_CyFunction_func_vectorcall(op) = NULL;
        break;
    default:
        PyErr_SetString(PyExc_SystemError, "Bad call flags for CyFunction");
        Py_DECREF(op);
        return NULL;
    }
#endif
    return (PyObject *) op;
}
static int
__Pyx_CyFunction_clear(__pyx_CyFunctionObject *m)
{
    Py_CLEAR(m->func_closure);
#if CYTHON_COMPILING_IN_LIMITED_API
    Py_CLEAR(m->func);
#else
    Py_CLEAR(((PyCFunctionObject*)m)->m_module);
#endif
    Py_CLEAR(m->func_dict);
    Py_CLEAR(m->func_name);
    Py_CLEAR(m->func_qualname);
    Py_CLEAR(m->func_doc);
    Py_CLEAR(m->func_globals);
    Py_CLEAR(m->func_code);
#if !CYTHON_COMPILING_IN_LIMITED_API
#if PY_VERSION_HEX < 0x030900B1
    Py_CLEAR(__Pyx_CyFunction_GetClassObj(m));
#else
    {
        PyObject *cls = (PyObject*) ((PyCMethodObject *) (m))->mm_class;
        ((PyCMethodObject *) (m))->mm_class = NULL;
        Py_XDECREF(cls);
    }
#endif
#endif
    Py_CLEAR(m->defaults_tuple);
    Py_CLEAR(m->defaults_kwdict);
    Py_CLEAR(m->func_annotations);
    Py_CLEAR(m->func_is_coroutine);
    if (m->defaults) {
        PyObject **pydefaults = __Pyx_CyFunction_Defaults(PyObject *, m);
        int i;
        for (i = 0; i < m->defaults_pyobjects; i++)
            Py_XDECREF(pydefaults[i]);
        PyObject_Free(m->defaults);
        m->defaults = NULL;
    }
    return 0;
}
static void __Pyx__CyFunction_dealloc(__pyx_CyFunctionObject *m)
{
    if (__Pyx_CyFunction_weakreflist(m) != NULL)
        PyObject_ClearWeakRefs((PyObject *) m);
    __Pyx_CyFunction_clear(m);
    __Pyx_PyHeapTypeObject_GC_Del(m);
}
static void __Pyx_CyFunction_dealloc(__pyx_CyFunctionObject *m)
{
    PyObject_GC_UnTrack(m);
    __Pyx__CyFunction_dealloc(m);
}
static int __Pyx_CyFunction_traverse(__pyx_CyFunctionObject *m, visitproc visit, void *arg)
{
    Py_VISIT(m->func_closure);
#if CYTHON_COMPILING_IN_LIMITED_API
    Py_VISIT(m->func);
#else
    Py_VISIT(((PyCFunctionObject*)m)->m_module);
#endif
    Py_VISIT(m->func_dict);
    Py_VISIT(m->func_name);
    Py_VISIT(m->func_qualname);
    Py_VISIT(m->func_doc);
    Py_VISIT(m->func_globals);
    Py_VISIT(m->func_code);
#if !CYTHON_COMPILING_IN_LIMITED_API
    Py_VISIT(__Pyx_CyFunction_GetClassObj(m));
#endif
    Py_VISIT(m->defaults_tuple);
    Py_VISIT(m->defaults_kwdict);
    Py_VISIT(m->func_is_coroutine);
    if (m->defaults) {
        PyObject **pydefaults = __Pyx_CyFunction_Defaults(PyObject *, m);
        int i;
        for (i = 0; i < m->defaults_pyobjects; i++)
            Py_VISIT(pydefaults[i]);
    }
    return 0;
}
static PyObject*
__Pyx_CyFunction_repr(__pyx_CyFunctionObject *op)
{
#if PY_MAJOR_VERSION >= 3
    return PyUnicode_FromFormat("<cyfunction %U at %p>",
                                op->func_qualname, (void *)op);
#else
    return PyString_FromFormat("<cyfunction %s at %p>",
                               PyString_AsString(op->func_qualname), (void *)op);
#endif
}
static PyObject * __Pyx_CyFunction_CallMethod(PyObject *func, PyObject *self, PyObject *arg, PyObject *kw) {
#if CYTHON_COMPILING_IN_LIMITED_API
    PyObject *f = ((__pyx_CyFunctionObject*)func)->func;
    PyObject *py_name = NULL;
    PyCFunction meth;
    int flags;
    meth = PyCFunction_GetFunction(f);
    if (unlikely(!meth)) return NULL;
    flags = PyCFunction_GetFlags(f);
    if (unlikely(flags < 0)) return NULL;
#else
    PyCFunctionObject* f = (PyCFunctionObject*)func;
    PyCFunction meth = f->m_ml->ml_meth;
    int flags = f->m_ml->ml_flags;
#endif
    Py_ssize_t size;
    switch (flags & (METH_VARARGS | METH_KEYWORDS | METH_NOARGS | METH_O)) {
    case METH_VARARGS:
        if (likely(kw == NULL || PyDict_Size(kw) == 0))
            return (*meth)(self, arg);
        break;
    case METH_VARARGS | METH_KEYWORDS:
        return (*(PyCFunctionWithKeywords)(void*)meth)(self, arg, kw);
    case METH_NOARGS:
        if (likely(kw == NULL || PyDict_Size(kw) == 0)) {
#if CYTHON_ASSUME_SAFE_MACROS
            size = PyTuple_GET_SIZE(arg);
#else
            size = PyTuple_Size(arg);
            if (unlikely(size < 0)) return NULL;
#endif
            if (likely(size == 0))
                return (*meth)(self, NULL);
#if CYTHON_COMPILING_IN_LIMITED_API
            py_name = __Pyx_CyFunction_get_name((__pyx_CyFunctionObject*)func, NULL);
            if (!py_name) return NULL;
            PyErr_Format(PyExc_TypeError,
                "%.200S() takes no arguments (%" CYTHON_FORMAT_SSIZE_T "d given)",
                py_name, size);
            Py_DECREF(py_name);
#else
            PyErr_Format(PyExc_TypeError,
                "%.200s() takes no arguments (%" CYTHON_FORMAT_SSIZE_T "d given)",
                f->m_ml->ml_name, size);
#endif
            return NULL;
        }
        break;
    case METH_O:
        if (likely(kw == NULL || PyDict_Size(kw) == 0)) {
#if CYTHON_ASSUME_SAFE_MACROS
            size = PyTuple_GET_SIZE(arg);
#else
            size = PyTuple_Size(arg);
            if (unlikely(size < 0)) return NULL;
#endif
            if (likely(size == 1)) {
                PyObject *result, *arg0;
                #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
                arg0 = PyTuple_GET_ITEM(arg, 0);
                #else
                arg0 = __Pyx_PySequence_ITEM(arg, 0); if (unlikely(!arg0)) return NULL;
                #endif
                result = (*meth)(self, arg0);
                #if !(CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS)
                Py_DECREF(arg0);
                #endif
                return result;
            }
#if CYTHON_COMPILING_IN_LIMITED_API
            py_name = __Pyx_CyFunction_get_name((__pyx_CyFunctionObject*)func, NULL);
            if (!py_name) return NULL;
            PyErr_Format(PyExc_TypeError,
                "%.200S() takes exactly one argument (%" CYTHON_FORMAT_SSIZE_T "d given)",
                py_name, size);
            Py_DECREF(py_name);
#else
            PyErr_Format(PyExc_TypeError,
                "%.200s() takes exactly one argument (%" CYTHON_FORMAT_SSIZE_T "d given)",
                f->m_ml->ml_name, size);
#endif
            return NULL;
        }
        break;
    default:
        PyErr_SetString(PyExc_SystemError, "Bad call flags for CyFunction");
        return NULL;
    }
#if CYTHON_COMPILING_IN_LIMITED_API
    py_name = __Pyx_CyFunction_get_name((__pyx_CyFunctionObject*)func, NULL);
    if (!py_name) return NULL;
    PyErr_Format(PyExc_TypeError, "%.200S() takes no keyword arguments",
                 py_name);
    Py_DECREF(py_name);
#else
    PyErr_Format(PyExc_TypeError, "%.200s() takes no keyword arguments",
                 f->m_ml->ml_name);
#endif
    return NULL;
}
static CYTHON_INLINE PyObject *__Pyx_CyFunction_Call(PyObject *func, PyObject *arg, PyObject *kw) {
    PyObject *self, *result;
#if CYTHON_COMPILING_IN_LIMITED_API
    self = PyCFunction_GetSelf(((__pyx_CyFunctionObject*)func)->func);
    if (unlikely(!self) && PyErr_Occurred()) return NULL;
#else
    self = ((PyCFunctionObject*)func)->m_self;
#endif
    result = __Pyx_CyFunction_CallMethod(func, self, arg, kw);
    return result;
}
static PyObject *__Pyx_CyFunction_CallAsMethod(PyObject *func, PyObject *args, PyObject *kw) {
    PyObject *result;
    __pyx_CyFunctionObject *cyfunc = (__pyx_CyFunctionObject *) func;
#if CYTHON_METH_FASTCALL
     __pyx_vectorcallfunc vc = __Pyx_CyFunction_func_vectorcall(cyfunc);
    if (vc) {
#if CYTHON_ASSUME_SAFE_MACROS
        return __Pyx_PyVectorcall_FastCallDict(func, vc, &PyTuple_GET_ITEM(args, 0), (size_t)PyTuple_GET_SIZE(args), kw);
#else
        (void) &__Pyx_PyVectorcall_FastCallDict;
        return PyVectorcall_Call(func, args, kw);
#endif
    }
#endif
    if ((cyfunc->flags & __Pyx_CYFUNCTION_CCLASS) && !(cyfunc->flags & __Pyx_CYFUNCTION_STATICMETHOD)) {
        Py_ssize_t argc;
        PyObject *new_args;
        PyObject *self;
#if CYTHON_ASSUME_SAFE_MACROS
        argc = PyTuple_GET_SIZE(args);
#else
        argc = PyTuple_Size(args);
        if (unlikely(!argc) < 0) return NULL;
#endif
        new_args = PyTuple_GetSlice(args, 1, argc);
        if (unlikely(!new_args))
            return NULL;
        self = PyTuple_GetItem(args, 0);
        if (unlikely(!self)) {
            Py_DECREF(new_args);
#if PY_MAJOR_VERSION > 2
            PyErr_Format(PyExc_TypeError,
                         "unbound method %.200S() needs an argument",
                         cyfunc->func_qualname);
#else
            PyErr_SetString(PyExc_TypeError,
                            "unbound method needs an argument");
#endif
            return NULL;
        }
        result = __Pyx_CyFunction_CallMethod(func, self, new_args, kw);
        Py_DECREF(new_args);
    } else {
        result = __Pyx_CyFunction_Call(func, args, kw);
    }
    return result;
}
#if CYTHON_METH_FASTCALL
static CYTHON_INLINE int __Pyx_CyFunction_Vectorcall_CheckArgs(__pyx_CyFunctionObject *cyfunc, Py_ssize_t nargs, PyObject *kwnames)
{
    int ret = 0;
    if ((cyfunc->flags & __Pyx_CYFUNCTION_CCLASS) && !(cyfunc->flags & __Pyx_CYFUNCTION_STATICMETHOD)) {
        if (unlikely(nargs < 1)) {
            PyErr_Format(PyExc_TypeError, "%.200s() needs an argument",
                         ((PyCFunctionObject*)cyfunc)->m_ml->ml_name);
            return -1;
        }
        ret = 1;
    }
    if (unlikely(kwnames) && unlikely(PyTuple_GET_SIZE(kwnames))) {
        PyErr_Format(PyExc_TypeError,
                     "%.200s() takes no keyword arguments", ((PyCFunctionObject*)cyfunc)->m_ml->ml_name);
        return -1;
    }
    return ret;
}
static PyObject * __Pyx_CyFunction_Vectorcall_NOARGS(PyObject *func, PyObject *const *args, size_t nargsf, PyObject *kwnames)
{
    __pyx_CyFunctionObject *cyfunc = (__pyx_CyFunctionObject *)func;
    PyMethodDef* def = ((PyCFunctionObject*)cyfunc)->m_ml;
#if CYTHON_BACKPORT_VECTORCALL
    Py_ssize_t nargs = (Py_ssize_t)nargsf;
#else
    Py_ssize_t nargs = PyVectorcall_NARGS(nargsf);
#endif
    PyObject *self;
    switch (__Pyx_CyFunction_Vectorcall_CheckArgs(cyfunc, nargs, kwnames)) {
    case 1:
        self = args[0];
        args += 1;
        nargs -= 1;
        break;
    case 0:
        self = ((PyCFunctionObject*)cyfunc)->m_self;
        break;
    default:
        return NULL;
    }
    if (unlikely(nargs != 0)) {
        PyErr_Format(PyExc_TypeError,
            "%.200s() takes no arguments (%" CYTHON_FORMAT_SSIZE_T "d given)",
            def->ml_name, nargs);
        return NULL;
    }
    return def->ml_meth(self, NULL);
}
static PyObject * __Pyx_CyFunction_Vectorcall_O(PyObject *func, PyObject *const *args, size_t nargsf, PyObject *kwnames)
{
    __pyx_CyFunctionObject *cyfunc = (__pyx_CyFunctionObject *)func;
    PyMethodDef* def = ((PyCFunctionObject*)cyfunc)->m_ml;
#if CYTHON_BACKPORT_VECTORCALL
    Py_ssize_t nargs = (Py_ssize_t)nargsf;
#else
    Py_ssize_t nargs = PyVectorcall_NARGS(nargsf);
#endif
    PyObject *self;
    switch (__Pyx_CyFunction_Vectorcall_CheckArgs(cyfunc, nargs, kwnames)) {
    case 1:
        self = args[0];
        args += 1;
        nargs -= 1;
        break;
    case 0:
        self = ((PyCFunctionObject*)cyfunc)->m_self;
        break;
    default:
        return NULL;
    }
    if (unlikely(nargs != 1)) {
        PyErr_Format(PyExc_TypeError,
            "%.200s() takes exactly one argument (%" CYTHON_FORMAT_SSIZE_T "d given)",
            def->ml_name, nargs);
        return NULL;
    }
    return def->ml_meth(self, args[0]);
}
static PyObject * __Pyx_CyFunction_Vectorcall_FASTCALL_KEYWORDS(PyObject *func, PyObject *const *args, size_t nargsf, PyObject *kwnames)
{
    __pyx_CyFunctionObject *cyfunc = (__pyx_CyFunctionObject *)func;
    PyMethodDef* def = ((PyCFunctionObject*)cyfunc)->m_ml;
#if CYTHON_BACKPORT_VECTORCALL
    Py_ssize_t nargs = (Py_ssize_t)nargsf;
#else
    Py_ssize_t nargs = PyVectorcall_NARGS(nargsf);
#endif
    PyObject *self;
    switch (__Pyx_CyFunction_Vectorcall_CheckArgs(cyfunc, nargs, NULL)) {
    case 1:
        self = args[0];
        args += 1;
        nargs -= 1;
        break;
    case 0:
        self = ((PyCFunctionObject*)cyfunc)->m_self;
        break;
    default:
        return NULL;
    }
    return ((_PyCFunctionFastWithKeywords)(void(*)(void))def->ml_meth)(self, args, nargs, kwnames);
}
static PyObject * __Pyx_CyFunction_Vectorcall_FASTCALL_KEYWORDS_METHOD(PyObject *func, PyObject *const *args, size_t nargsf, PyObject *kwnames)
{
    __pyx_CyFunctionObject *cyfunc = (__pyx_CyFunctionObject *)func;
    PyMethodDef* def = ((PyCFunctionObject*)cyfunc)->m_ml;
    PyTypeObject *cls = (PyTypeObject *) __Pyx_CyFunction_GetClassObj(cyfunc);
#if CYTHON_BACKPORT_VECTORCALL
    Py_ssize_t nargs = (Py_ssize_t)nargsf;
#else
    Py_ssize_t nargs = PyVectorcall_NARGS(nargsf);
#endif
    PyObject *self;
    switch (__Pyx_CyFunction_Vectorcall_CheckArgs(cyfunc, nargs, NULL)) {
    case 1:
        self = args[0];
        args += 1;
        nargs -= 1;
        break;
    case 0:
        self = ((PyCFunctionObject*)cyfunc)->m_self;
        break;
    default:
        return NULL;
    }
    return ((__Pyx_PyCMethod)(void(*)(void))def->ml_meth)(self, cls, args, (size_t)nargs, kwnames);
}
#endif
#if CYTHON_USE_TYPE_SPECS
static PyType_Slot __pyx_CyFunctionType_slots[] = {
    {Py_tp_dealloc, (void *)__Pyx_CyFunction_dealloc},
    {Py_tp_repr, (void *)__Pyx_CyFunction_repr},
    {Py_tp_call, (void *)__Pyx_CyFunction_CallAsMethod},
    {Py_tp_traverse, (void *)__Pyx_CyFunction_traverse},
    {Py_tp_clear, (void *)__Pyx_CyFunction_clear},
    {Py_tp_methods, (void *)__pyx_CyFunction_methods},
    {Py_tp_members, (void *)__pyx_CyFunction_members},
    {Py_tp_getset, (void *)__pyx_CyFunction_getsets},
    {Py_tp_descr_get, (void *)__Pyx_PyMethod_New},
    {0, 0},
};
static PyType_Spec __pyx_CyFunctionType_spec = {
    __PYX_TYPE_MODULE_PREFIX "cython_function_or_method",
    sizeof(__pyx_CyFunctionObject),
    0,
#ifdef Py_TPFLAGS_METHOD_DESCRIPTOR
    Py_TPFLAGS_METHOD_DESCRIPTOR |
#endif
#if (defined(_Py_TPFLAGS_HAVE_VECTORCALL) && CYTHON_METH_FASTCALL)
    _Py_TPFLAGS_HAVE_VECTORCALL |
#endif
    Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HAVE_GC | Py_TPFLAGS_BASETYPE,
    __pyx_CyFunctionType_slots
};
#else
static PyTypeObject __pyx_CyFunctionType_type = {
    PyVarObject_HEAD_INIT(0, 0)
    __PYX_TYPE_MODULE_PREFIX "cython_function_or_method",
    sizeof(__pyx_CyFunctionObject),
    0,
    (destructor) __Pyx_CyFunction_dealloc,
#if !CYTHON_METH_FASTCALL
    0,
#elif CYTHON_BACKPORT_VECTORCALL
    (printfunc)offsetof(__pyx_CyFunctionObject, func_vectorcall),
#else
    offsetof(PyCFunctionObject, vectorcall),
#endif
    0,
    0,
#if PY_MAJOR_VERSION < 3
    0,
#else
    0,
#endif
    (reprfunc) __Pyx_CyFunction_repr,
    0,
    0,
    0,
    0,
    __Pyx_CyFunction_CallAsMethod,
    0,
    0,
    0,
    0,
#ifdef Py_TPFLAGS_METHOD_DESCRIPTOR
    Py_TPFLAGS_METHOD_DESCRIPTOR |
#endif
#if defined(_Py_TPFLAGS_HAVE_VECTORCALL) && CYTHON_METH_FASTCALL
    _Py_TPFLAGS_HAVE_VECTORCALL |
#endif
    Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HAVE_GC | Py_TPFLAGS_BASETYPE,
    0,
    (traverseproc) __Pyx_CyFunction_traverse,
    (inquiry) __Pyx_CyFunction_clear,
    0,
#if PY_VERSION_HEX < 0x030500A0
    offsetof(__pyx_CyFunctionObject, func_weakreflist),
#else
    offsetof(PyCFunctionObject, m_weakreflist),
#endif
    0,
    0,
    __pyx_CyFunction_methods,
    __pyx_CyFunction_members,
    __pyx_CyFunction_getsets,
    0,
    0,
    __Pyx_PyMethod_New,
    0,
    offsetof(__pyx_CyFunctionObject, func_dict),
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
#if PY_VERSION_HEX >= 0x030400a1
    0,
#endif
#if PY_VERSION_HEX >= 0x030800b1 && (!CYTHON_COMPILING_IN_PYPY || PYPY_VERSION_NUM >= 0x07030800)
    0,
#endif
#if __PYX_NEED_TP_PRINT_SLOT
    0,
#endif
#if PY_VERSION_HEX >= 0x030C0000
    0,
#endif
#if CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX >= 0x03090000 && PY_VERSION_HEX < 0x030a0000
    0,
#endif
};
#endif
static int __pyx_CyFunction_init(PyObject *module) {
#if CYTHON_USE_TYPE_SPECS
    __pyx_CyFunctionType = __Pyx_FetchCommonTypeFromSpec(module, &__pyx_CyFunctionType_spec, NULL);
#else
    CYTHON_UNUSED_VAR(module);
    __pyx_CyFunctionType = __Pyx_FetchCommonType(&__pyx_CyFunctionType_type);
#endif
    if (unlikely(__pyx_CyFunctionType == NULL)) {
        return -1;
    }
    return 0;
}
static CYTHON_INLINE void *__Pyx_CyFunction_InitDefaults(PyObject *func, size_t size, int pyobjects) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->defaults = PyObject_Malloc(size);
    if (unlikely(!m->defaults))
        return PyErr_NoMemory();
    memset(m->defaults, 0, size);
    m->defaults_pyobjects = pyobjects;
    m->defaults_size = size;
    return m->defaults;
}
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsTuple(PyObject *func, PyObject *tuple) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->defaults_tuple = tuple;
    Py_INCREF(tuple);
}
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsKwDict(PyObject *func, PyObject *dict) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->defaults_kwdict = dict;
    Py_INCREF(dict);
}
static CYTHON_INLINE void __Pyx_CyFunction_SetAnnotationsDict(PyObject *func, PyObject *dict) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->func_annotations = dict;
    Py_INCREF(dict);
}

/* CythonFunction */
  static PyObject *__Pyx_CyFunction_New(PyMethodDef *ml, int flags, PyObject* qualname,
                                      PyObject *closure, PyObject *module, PyObject* globals, PyObject* code) {
    PyObject *op = __Pyx_CyFunction_Init(
        PyObject_GC_New(__pyx_CyFunctionObject, __pyx_CyFunctionType),
        ml, flags, qualname, closure, module, globals, code
    );
    if (likely(op)) {
        PyObject_GC_Track(op);
    }
    return op;
}

/* CLineInTraceback */
  #ifndef CYTHON_CLINE_IN_TRACEBACK
static int __Pyx_CLineForTraceback(PyThreadState *tstate, int c_line) {
    PyObject *use_cline;
    PyObject *ptype, *pvalue, *ptraceback;
#if CYTHON_COMPILING_IN_CPYTHON
    PyObject **cython_runtime_dict;
#endif
    CYTHON_MAYBE_UNUSED_VAR(tstate);
    if (unlikely(!__pyx_cython_runtime)) {
        return c_line;
    }
    __Pyx_ErrFetchInState(tstate, &ptype, &pvalue, &ptraceback);
#if CYTHON_COMPILING_IN_CPYTHON
    cython_runtime_dict = _PyObject_GetDictPtr(__pyx_cython_runtime);
    if (likely(cython_runtime_dict)) {
        __PYX_PY_DICT_LOOKUP_IF_MODIFIED(
            use_cline, *cython_runtime_dict,
            __Pyx_PyDict_GetItemStr(*cython_runtime_dict, __pyx_n_s_cline_in_traceback))
    } else
#endif
    {
      PyObject *use_cline_obj = __Pyx_PyObject_GetAttrStrNoError(__pyx_cython_runtime, __pyx_n_s_cline_in_traceback);
      if (use_cline_obj) {
        use_cline = PyObject_Not(use_cline_obj) ? Py_False : Py_True;
        Py_DECREF(use_cline_obj);
      } else {
        PyErr_Clear();
        use_cline = NULL;
      }
    }
    if (!use_cline) {
        c_line = 0;
        (void) PyObject_SetAttr(__pyx_cython_runtime, __pyx_n_s_cline_in_traceback, Py_False);
    }
    else if (use_cline == Py_False || (use_cline != Py_True && PyObject_Not(use_cline) != 0)) {
        c_line = 0;
    }
    __Pyx_ErrRestoreInState(tstate, ptype, pvalue, ptraceback);
    return c_line;
}
#endif

/* CodeObjectCache */
  #if !CYTHON_COMPILING_IN_LIMITED_API
static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line) {
    int start = 0, mid = 0, end = count - 1;
    if (end >= 0 && code_line > entries[end].code_line) {
        return count;
    }
    while (start < end) {
        mid = start + (end - start) / 2;
        if (code_line < entries[mid].code_line) {
            end = mid;
        } else if (code_line > entries[mid].code_line) {
             start = mid + 1;
        } else {
            return mid;
        }
    }
    if (code_line <= entries[mid].code_line) {
        return mid;
    } else {
        return mid + 1;
    }
}
static PyCodeObject *__pyx_find_code_object(int code_line) {
    PyCodeObject* code_object;
    int pos;
    if (unlikely(!code_line) || unlikely(!__pyx_code_cache.entries)) {
        return NULL;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if (unlikely(pos >= __pyx_code_cache.count) || unlikely(__pyx_code_cache.entries[pos].code_line != code_line)) {
        return NULL;
    }
    code_object = __pyx_code_cache.entries[pos].code_object;
    Py_INCREF(code_object);
    return code_object;
}
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object) {
    int pos, i;
    __Pyx_CodeObjectCacheEntry* entries = __pyx_code_cache.entries;
    if (unlikely(!code_line)) {
        return;
    }
    if (unlikely(!entries)) {
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Malloc(64*sizeof(__Pyx_CodeObjectCacheEntry));
        if (likely(entries)) {
            __pyx_code_cache.entries = entries;
            __pyx_code_cache.max_count = 64;
            __pyx_code_cache.count = 1;
            entries[0].code_line = code_line;
            entries[0].code_object = code_object;
            Py_INCREF(code_object);
        }
        return;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if ((pos < __pyx_code_cache.count) && unlikely(__pyx_code_cache.entries[pos].code_line == code_line)) {
        PyCodeObject* tmp = entries[pos].code_object;
        entries[pos].code_object = code_object;
        Py_DECREF(tmp);
        return;
    }
    if (__pyx_code_cache.count == __pyx_code_cache.max_count) {
        int new_max = __pyx_code_cache.max_count + 64;
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Realloc(
            __pyx_code_cache.entries, ((size_t)new_max) * sizeof(__Pyx_CodeObjectCacheEntry));
        if (unlikely(!entries)) {
            return;
        }
        __pyx_code_cache.entries = entries;
        __pyx_code_cache.max_count = new_max;
    }
    for (i=__pyx_code_cache.count; i>pos; i--) {
        entries[i] = entries[i-1];
    }
    entries[pos].code_line = code_line;
    entries[pos].code_object = code_object;
    __pyx_code_cache.count++;
    Py_INCREF(code_object);
}
#endif

/* AddTraceback */
  #include "compile.h"
#include "frameobject.h"
#include "traceback.h"
#if PY_VERSION_HEX >= 0x030b00a6 && !CYTHON_COMPILING_IN_LIMITED_API
  #ifndef Py_BUILD_CORE
    #define Py_BUILD_CORE 1
  #endif
  #include "internal/pycore_frame.h"
#endif
#if CYTHON_COMPILING_IN_LIMITED_API
static PyObject *__Pyx_PyCode_Replace_For_AddTraceback(PyObject *code, PyObject *scratch_dict,
                                                       PyObject *firstlineno, PyObject *name) {
    PyObject *replace = NULL;
    if (unlikely(PyDict_SetItemString(scratch_dict, "co_firstlineno", firstlineno))) return NULL;
    if (unlikely(PyDict_SetItemString(scratch_dict, "co_name", name))) return NULL;
    replace = PyObject_GetAttrString(code, "replace");
    if (likely(replace)) {
        PyObject *result;
        result = PyObject_Call(replace, __pyx_empty_tuple, scratch_dict);
        Py_DECREF(replace);
        return result;
    }
    #if __PYX_LIMITED_VERSION_HEX < 0x030780000
    PyErr_Clear();
    {
        PyObject *compiled = NULL, *result = NULL;
        if (unlikely(PyDict_SetItemString(scratch_dict, "code", code))) return NULL;
        if (unlikely(PyDict_SetItemString(scratch_dict, "type", (PyObject*)(&PyType_Type)))) return NULL;
        compiled = Py_CompileString(
            "out = type(code)(\n"
            "  code.co_argcount, code.co_kwonlyargcount, code.co_nlocals, code.co_stacksize,\n"
            "  code.co_flags, code.co_code, code.co_consts, code.co_names,\n"
            "  code.co_varnames, code.co_filename, co_name, co_firstlineno,\n"
            "  code.co_lnotab)\n", "<dummy>", Py_file_input);
        if (!compiled) return NULL;
        result = PyEval_EvalCode(compiled, scratch_dict, scratch_dict);
        Py_DECREF(compiled);
        if (!result) PyErr_Print();
        Py_DECREF(result);
        result = PyDict_GetItemString(scratch_dict, "out");
        if (result) Py_INCREF(result);
        return result;
    }
    #endif
}
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename) {
    PyObject *code_object = NULL, *py_py_line = NULL, *py_funcname = NULL, *dict = NULL;
    PyObject *replace = NULL, *getframe = NULL, *frame = NULL;
    PyObject *exc_type, *exc_value, *exc_traceback;
    int success = 0;
    if (c_line) {
        (void) __pyx_cfilenm;
        (void) __Pyx_CLineForTraceback(__Pyx_PyThreadState_Current, c_line);
    }
    PyErr_Fetch(&exc_type, &exc_value, &exc_traceback);
    code_object = Py_CompileString("_getframe()", filename, Py_eval_input);
    if (unlikely(!code_object)) goto bad;
    py_py_line = PyLong_FromLong(py_line);
    if (unlikely(!py_py_line)) goto bad;
    py_funcname = PyUnicode_FromString(funcname);
    if (unlikely(!py_funcname)) goto bad;
    dict = PyDict_New();
    if (unlikely(!dict)) goto bad;
    {
        PyObject *old_code_object = code_object;
        code_object = __Pyx_PyCode_Replace_For_AddTraceback(code_object, dict, py_py_line, py_funcname);
        Py_DECREF(old_code_object);
    }
    if (unlikely(!code_object)) goto bad;
    getframe = PySys_GetObject("_getframe");
    if (unlikely(!getframe)) goto bad;
    if (unlikely(PyDict_SetItemString(dict, "_getframe", getframe))) goto bad;
    frame = PyEval_EvalCode(code_object, dict, dict);
    if (unlikely(!frame) || frame == Py_None) goto bad;
    success = 1;
  bad:
    PyErr_Restore(exc_type, exc_value, exc_traceback);
    Py_XDECREF(code_object);
    Py_XDECREF(py_py_line);
    Py_XDECREF(py_funcname);
    Py_XDECREF(dict);
    Py_XDECREF(replace);
    if (success) {
        PyTraceBack_Here(
            (struct _frame*)frame);
    }
    Py_XDECREF(frame);
}
#else
static PyCodeObject* __Pyx_CreateCodeObjectForTraceback(
            const char *funcname, int c_line,
            int py_line, const char *filename) {
    PyCodeObject *py_code = NULL;
    PyObject *py_funcname = NULL;
    #if PY_MAJOR_VERSION < 3
    PyObject *py_srcfile = NULL;
    py_srcfile = PyString_FromString(filename);
    if (!py_srcfile) goto bad;
    #endif
    if (c_line) {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        if (!py_funcname) goto bad;
        #else
        py_funcname = PyUnicode_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        if (!py_funcname) goto bad;
        funcname = PyUnicode_AsUTF8(py_funcname);
        if (!funcname) goto bad;
        #endif
    }
    else {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromString(funcname);
        if (!py_funcname) goto bad;
        #endif
    }
    #if PY_MAJOR_VERSION < 3
    py_code = __Pyx_PyCode_New(
        0,
        0,
        0,
        0,
        0,
        0,
        __pyx_empty_bytes, /*PyObject *code,*/
        __pyx_empty_tuple, /*PyObject *consts,*/
        __pyx_empty_tuple, /*PyObject *names,*/
        __pyx_empty_tuple, /*PyObject *varnames,*/
        __pyx_empty_tuple, /*PyObject *freevars,*/
        __pyx_empty_tuple, /*PyObject *cellvars,*/
        py_srcfile,   /*PyObject *filename,*/
        py_funcname,  /*PyObject *name,*/
        py_line,
        __pyx_empty_bytes  /*PyObject *lnotab*/
    );
    Py_DECREF(py_srcfile);
    #else
    py_code = PyCode_NewEmpty(filename, funcname, py_line);
    #endif
    Py_XDECREF(py_funcname);  // XDECREF since it's only set on Py3 if cline
    return py_code;
bad:
    Py_XDECREF(py_funcname);
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(py_srcfile);
    #endif
    return NULL;
}
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyFrameObject *py_frame = 0;
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    PyObject *ptype, *pvalue, *ptraceback;
    if (c_line) {
        c_line = __Pyx_CLineForTraceback(tstate, c_line);
    }
    py_code = __pyx_find_code_object(c_line ? -c_line : py_line);
    if (!py_code) {
        __Pyx_ErrFetchInState(tstate, &ptype, &pvalue, &ptraceback);
        py_code = __Pyx_CreateCodeObjectForTraceback(
            funcname, c_line, py_line, filename);
        if (!py_code) {
            /* If the code object creation fails, then we should clear the
               fetched exception references and propagate the new exception */
            Py_XDECREF(ptype);
            Py_XDECREF(pvalue);
            Py_XDECREF(ptraceback);
            goto bad;
        }
        __Pyx_ErrRestoreInState(tstate, ptype, pvalue, ptraceback);
        __pyx_insert_code_object(c_line ? -c_line : py_line, py_code);
    }
    py_frame = PyFrame_New(
        tstate,            /*PyThreadState *tstate,*/
        py_code,           /*PyCodeObject *code,*/
        __pyx_d,    /*PyObject *globals,*/
        0                  /*PyObject *locals*/
    );
    if (!py_frame) goto bad;
    __Pyx_PyFrame_SetLineNumber(py_frame, py_line);
    PyTraceBack_Here(py_frame);
bad:
    Py_XDECREF(py_code);
    Py_XDECREF(py_frame);
}
#endif

#if PY_MAJOR_VERSION < 3
static int __Pyx_GetBuffer(PyObject *obj, Py_buffer *view, int flags) {
    __Pyx_TypeName obj_type_name;
    if (PyObject_CheckBuffer(obj)) return PyObject_GetBuffer(obj, view, flags);
    obj_type_name = __Pyx_PyType_GetName(Py_TYPE(obj));
    PyErr_Format(PyExc_TypeError,
                 "'" __Pyx_FMT_TYPENAME "' does not have the buffer interface",
                 obj_type_name);
    __Pyx_DECREF_TypeName(obj_type_name);
    return -1;
}
static void __Pyx_ReleaseBuffer(Py_buffer *view) {
    PyObject *obj = view->obj;
    if (!obj) return;
    if (PyObject_CheckBuffer(obj)) {
        PyBuffer_Release(view);
        return;
    }
    if ((0)) {}
    view->obj = NULL;
    Py_DECREF(obj);
}
#endif


  /* CIntFromPyVerify */
  #define __PYX_VERIFY_RETURN_INT(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 0)
#define __PYX_VERIFY_RETURN_INT_EXC(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 1)
#define __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, exc)\
    {\
        func_type value = func_value;\
        if (sizeof(target_type) < sizeof(func_type)) {\
            if (unlikely(value != (func_type) (target_type) value)) {\
                func_type zero = 0;\
                if (exc && unlikely(value == (func_type)-1 && PyErr_Occurred()))\
                    return (target_type) -1;\
                if (is_unsigned && unlikely(value < zero))\
                    goto raise_neg_overflow;\
                else\
                    goto raise_overflow;\
            }\
        }\
        return (target_type) value;\
    }

/* Declarations */
  #if CYTHON_CCOMPLEX && (1) && (!0 || __cplusplus)
  #ifdef __cplusplus
    static CYTHON_INLINE __pyx_t_float_complex __pyx_t_float_complex_from_parts(float x, float y) {
      return ::std::complex< float >(x, y);
    }
  #else
    static CYTHON_INLINE __pyx_t_float_complex __pyx_t_float_complex_from_parts(float x, float y) {
      return x + y*(__pyx_t_float_complex)_Complex_I;
    }
  #endif
#else
    static CYTHON_INLINE __pyx_t_float_complex __pyx_t_float_complex_from_parts(float x, float y) {
      __pyx_t_float_complex z;
      z.real = x;
      z.imag = y;
      return z;
    }
#endif

/* Arithmetic */
  #if CYTHON_CCOMPLEX && (1) && (!0 || __cplusplus)
#else
    static CYTHON_INLINE int __Pyx_c_eq_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
       return (a.real == b.real) && (a.imag == b.imag);
    }
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_sum_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
        __pyx_t_float_complex z;
        z.real = a.real + b.real;
        z.imag = a.imag + b.imag;
        return z;
    }
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_diff_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
        __pyx_t_float_complex z;
        z.real = a.real - b.real;
        z.imag = a.imag - b.imag;
        return z;
    }
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_prod_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
        __pyx_t_float_complex z;
        z.real = a.real * b.real - a.imag * b.imag;
        z.imag = a.real * b.imag + a.imag * b.real;
        return z;
    }
    #if 1
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_quot_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
        if (b.imag == 0) {
            return __pyx_t_float_complex_from_parts(a.real / b.real, a.imag / b.real);
        } else if (fabsf(b.real) >= fabsf(b.imag)) {
            if (b.real == 0 && b.imag == 0) {
                return __pyx_t_float_complex_from_parts(a.real / b.real, a.imag / b.imag);
            } else {
                float r = b.imag / b.real;
                float s = (float)(1.0) / (b.real + b.imag * r);
                return __pyx_t_float_complex_from_parts(
                    (a.real + a.imag * r) * s, (a.imag - a.real * r) * s);
            }
        } else {
            float r = b.real / b.imag;
            float s = (float)(1.0) / (b.imag + b.real * r);
            return __pyx_t_float_complex_from_parts(
                (a.real * r + a.imag) * s, (a.imag * r - a.real) * s);
        }
    }
    #else
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_quot_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
        if (b.imag == 0) {
            return __pyx_t_float_complex_from_parts(a.real / b.real, a.imag / b.real);
        } else {
            float denom = b.real * b.real + b.imag * b.imag;
            return __pyx_t_float_complex_from_parts(
                (a.real * b.real + a.imag * b.imag) / denom,
                (a.imag * b.real - a.real * b.imag) / denom);
        }
    }
    #endif
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_neg_float(__pyx_t_float_complex a) {
        __pyx_t_float_complex z;
        z.real = -a.real;
        z.imag = -a.imag;
        return z;
    }
    static CYTHON_INLINE int __Pyx_c_is_zero_float(__pyx_t_float_complex a) {
       return (a.real == 0) && (a.imag == 0);
    }
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_conj_float(__pyx_t_float_complex a) {
        __pyx_t_float_complex z;
        z.real =  a.real;
        z.imag = -a.imag;
        return z;
    }
    #if 1
        static CYTHON_INLINE float __Pyx_c_abs_float(__pyx_t_float_complex z) {
          #if !defined(HAVE_HYPOT) || defined(_MSC_VER)
            return sqrtf(z.real*z.real + z.imag*z.imag);
          #else
            return hypotf(z.real, z.imag);
          #endif
        }
        static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_pow_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
            __pyx_t_float_complex z;
            float r, lnr, theta, z_r, z_theta;
            if (b.imag == 0 && b.real == (int)b.real) {
                if (b.real < 0) {
                    float denom = a.real * a.real + a.imag * a.imag;
                    a.real = a.real / denom;
                    a.imag = -a.imag / denom;
                    b.real = -b.real;
                }
                switch ((int)b.real) {
                    case 0:
                        z.real = 1;
                        z.imag = 0;
                        return z;
                    case 1:
                        return a;
                    case 2:
                        return __Pyx_c_prod_float(a, a);
                    case 3:
                        z = __Pyx_c_prod_float(a, a);
                        return __Pyx_c_prod_float(z, a);
                    case 4:
                        z = __Pyx_c_prod_float(a, a);
                        return __Pyx_c_prod_float(z, z);
                }
            }
            if (a.imag == 0) {
                if (a.real == 0) {
                    return a;
                } else if ((b.imag == 0) && (a.real >= 0)) {
                    z.real = powf(a.real, b.real);
                    z.imag = 0;
                    return z;
                } else if (a.real > 0) {
                    r = a.real;
                    theta = 0;
                } else {
                    r = -a.real;
                    theta = atan2f(0.0, -1.0);
                }
            } else {
                r = __Pyx_c_abs_float(a);
                theta = atan2f(a.imag, a.real);
            }
            lnr = logf(r);
            z_r = expf(lnr * b.real - theta * b.imag);
            z_theta = theta * b.real + lnr * b.imag;
            z.real = z_r * cosf(z_theta);
            z.imag = z_r * sinf(z_theta);
            return z;
        }
    #endif
#endif

/* Declarations */
  #if CYTHON_CCOMPLEX && (1) && (!0 || __cplusplus)
  #ifdef __cplusplus
    static CYTHON_INLINE __pyx_t_double_complex __pyx_t_double_complex_from_parts(double x, double y) {
      return ::std::complex< double >(x, y);
    }
  #else
    static CYTHON_INLINE __pyx_t_double_complex __pyx_t_double_complex_from_parts(double x, double y) {
      return x + y*(__pyx_t_double_complex)_Complex_I;
    }
  #endif
#else
    static CYTHON_INLINE __pyx_t_double_complex __pyx_t_double_complex_from_parts(double x, double y) {
      __pyx_t_double_complex z;
      z.real = x;
      z.imag = y;
      return z;
    }
#endif

/* Arithmetic */
  #if CYTHON_CCOMPLEX && (1) && (!0 || __cplusplus)
#else
    static CYTHON_INLINE int __Pyx_c_eq_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
       return (a.real == b.real) && (a.imag == b.imag);
    }
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_sum_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
        __pyx_t_double_complex z;
        z.real = a.real + b.real;
        z.imag = a.imag + b.imag;
        return z;
    }
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_diff_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
        __pyx_t_double_complex z;
        z.real = a.real - b.real;
        z.imag = a.imag - b.imag;
        return z;
    }
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_prod_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
        __pyx_t_double_complex z;
        z.real = a.real * b.real - a.imag * b.imag;
        z.imag = a.real * b.imag + a.imag * b.real;
        return z;
    }
    #if 1
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_quot_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
        if (b.imag == 0) {
            return __pyx_t_double_complex_from_parts(a.real / b.real, a.imag / b.real);
        } else if (fabs(b.real) >= fabs(b.imag)) {
            if (b.real == 0 && b.imag == 0) {
                return __pyx_t_double_complex_from_parts(a.real / b.real, a.imag / b.imag);
            } else {
                double r = b.imag / b.real;
                double s = (double)(1.0) / (b.real + b.imag * r);
                return __pyx_t_double_complex_from_parts(
                    (a.real + a.imag * r) * s, (a.imag - a.real * r) * s);
            }
        } else {
            double r = b.real / b.imag;
            double s = (double)(1.0) / (b.imag + b.real * r);
            return __pyx_t_double_complex_from_parts(
                (a.real * r + a.imag) * s, (a.imag * r - a.real) * s);
        }
    }
    #else
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_quot_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
        if (b.imag == 0) {
            return __pyx_t_double_complex_from_parts(a.real / b.real, a.imag / b.real);
        } else {
            double denom = b.real * b.real + b.imag * b.imag;
            return __pyx_t_double_complex_from_parts(
                (a.real * b.real + a.imag * b.imag) / denom,
                (a.imag * b.real - a.real * b.imag) / denom);
        }
    }
    #endif
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_neg_double(__pyx_t_double_complex a) {
        __pyx_t_double_complex z;
        z.real = -a.real;
        z.imag = -a.imag;
        return z;
    }
    static CYTHON_INLINE int __Pyx_c_is_zero_double(__pyx_t_double_complex a) {
       return (a.real == 0) && (a.imag == 0);
    }
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_conj_double(__pyx_t_double_complex a) {
        __pyx_t_double_complex z;
        z.real =  a.real;
        z.imag = -a.imag;
        return z;
    }
    #if 1
        static CYTHON_INLINE double __Pyx_c_abs_double(__pyx_t_double_complex z) {
          #if !defined(HAVE_HYPOT) || defined(_MSC_VER)
            return sqrt(z.real*z.real + z.imag*z.imag);
          #else
            return hypot(z.real, z.imag);
          #endif
        }
        static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_pow_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
            __pyx_t_double_complex z;
            double r, lnr, theta, z_r, z_theta;
            if (b.imag == 0 && b.real == (int)b.real) {
                if (b.real < 0) {
                    double denom = a.real * a.real + a.imag * a.imag;
                    a.real = a.real / denom;
                    a.imag = -a.imag / denom;
                    b.real = -b.real;
                }
                switch ((int)b.real) {
                    case 0:
                        z.real = 1;
                        z.imag = 0;
                        return z;
                    case 1:
                        return a;
                    case 2:
                        return __Pyx_c_prod_double(a, a);
                    case 3:
                        z = __Pyx_c_prod_double(a, a);
                        return __Pyx_c_prod_double(z, a);
                    case 4:
                        z = __Pyx_c_prod_double(a, a);
                        return __Pyx_c_prod_double(z, z);
                }
            }
            if (a.imag == 0) {
                if (a.real == 0) {
                    return a;
                } else if ((b.imag == 0) && (a.real >= 0)) {
                    z.real = pow(a.real, b.real);
                    z.imag = 0;
                    return z;
                } else if (a.real > 0) {
                    r = a.real;
                    theta = 0;
                } else {
                    r = -a.real;
                    theta = atan2(0.0, -1.0);
                }
            } else {
                r = __Pyx_c_abs_double(a);
                theta = atan2(a.imag, a.real);
            }
            lnr = log(r);
            z_r = exp(lnr * b.real - theta * b.imag);
            z_theta = theta * b.real + lnr * b.imag;
            z.real = z_r * cos(z_theta);
            z.imag = z_r * sin(z_theta);
            return z;
        }
    #endif
#endif

/* CIntFromPy */
  static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *x) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const int neg_one = (int) -1, const_zero = (int) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if ((sizeof(int) < sizeof(long))) {
            __PYX_VERIFY_RETURN_INT(int, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (int) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            if (unlikely(__Pyx_PyLong_IsNeg(x))) {
                goto raise_neg_overflow;
            } else if (__Pyx_PyLong_IsCompact(x)) {
                __PYX_VERIFY_RETURN_INT(int, __Pyx_compact_upylong, __Pyx_PyLong_CompactValueUnsigned(x))
            } else {
                const digit* digits = __Pyx_PyLong_Digits(x);
                assert(__Pyx_PyLong_DigitCount(x) > 1);
                switch (__Pyx_PyLong_DigitCount(x)) {
                    case 2:
                        if ((8 * sizeof(int) > 1 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(int) >= 2 * PyLong_SHIFT)) {
                                return (int) (((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                            }
                        }
                        break;
                    case 3:
                        if ((8 * sizeof(int) > 2 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(int) >= 3 * PyLong_SHIFT)) {
                                return (int) (((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                            }
                        }
                        break;
                    case 4:
                        if ((8 * sizeof(int) > 3 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(int) >= 4 * PyLong_SHIFT)) {
                                return (int) (((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                            }
                        }
                        break;
                }
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030C00A7
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (int) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if ((sizeof(int) <= sizeof(unsigned long))) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if ((sizeof(int) <= sizeof(unsigned PY_LONG_LONG))) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            if (__Pyx_PyLong_IsCompact(x)) {
                __PYX_VERIFY_RETURN_INT(int, __Pyx_compact_pylong, __Pyx_PyLong_CompactValue(x))
            } else {
                const digit* digits = __Pyx_PyLong_Digits(x);
                assert(__Pyx_PyLong_DigitCount(x) > 1);
                switch (__Pyx_PyLong_SignedDigitCount(x)) {
                    case -2:
                        if ((8 * sizeof(int) - 1 > 1 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(int) - 1 > 2 * PyLong_SHIFT)) {
                                return (int) (((int)-1)*(((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                            }
                        }
                        break;
                    case 2:
                        if ((8 * sizeof(int) > 1 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(int) - 1 > 2 * PyLong_SHIFT)) {
                                return (int) ((((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                            }
                        }
                        break;
                    case -3:
                        if ((8 * sizeof(int) - 1 > 2 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(int) - 1 > 3 * PyLong_SHIFT)) {
                                return (int) (((int)-1)*(((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                            }
                        }
                        break;
                    case 3:
                        if ((8 * sizeof(int) > 2 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(int) - 1 > 3 * PyLong_SHIFT)) {
                                return (int) ((((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                            }
                        }
                        break;
                    case -4:
                        if ((8 * sizeof(int) - 1 > 3 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(int) - 1 > 4 * PyLong_SHIFT)) {
                                return (int) (((int)-1)*(((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                            }
                        }
                        break;
                    case 4:
                        if ((8 * sizeof(int) > 3 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(int) - 1 > 4 * PyLong_SHIFT)) {
                                return (int) ((((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                            }
                        }
                        break;
                }
            }
#endif
            if ((sizeof(int) <= sizeof(long))) {
                __PYX_VERIFY_RETURN_INT_EXC(int, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if ((sizeof(int) <= sizeof(PY_LONG_LONG))) {
                __PYX_VERIFY_RETURN_INT_EXC(int, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
            int val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
#if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
#endif
            if (likely(v)) {
                int ret = -1;
#if !(CYTHON_COMPILING_IN_PYPY || CYTHON_COMPILING_IN_LIMITED_API) || defined(_PyLong_AsByteArray)
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                ret = _PyLong_AsByteArray((PyLongObject *)v,
                                           bytes, sizeof(val),
                                           is_little, !is_unsigned);
#else
                PyObject *stepval = NULL, *mask = NULL, *shift = NULL;
                int bits, remaining_bits, is_negative = 0;
                long idigit;
                int chunk_size = (sizeof(long) < 8) ? 30 : 62;
                if (unlikely(!PyLong_CheckExact(v))) {
                    PyObject *tmp = v;
                    v = PyNumber_Long(v);
                    assert(PyLong_CheckExact(v));
                    Py_DECREF(tmp);
                    if (unlikely(!v)) return (int) -1;
                }
#if CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX < 0x030B0000
                if (Py_SIZE(x) == 0)
                    return (int) 0;
                is_negative = Py_SIZE(x) < 0;
#else
                {
                    int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                    if (unlikely(result < 0))
                        return (int) -1;
                    is_negative = result == 1;
                }
#endif
                if (is_unsigned && unlikely(is_negative)) {
                    goto raise_neg_overflow;
                } else if (is_negative) {
                    stepval = PyNumber_Invert(v);
                    if (unlikely(!stepval))
                        return (int) -1;
                } else {
                    stepval = __Pyx_NewRef(v);
                }
                val = (int) 0;
                mask = PyLong_FromLong((1L << chunk_size) - 1); if (unlikely(!mask)) goto done;
                shift = PyLong_FromLong(chunk_size); if (unlikely(!shift)) goto done;
                for (bits = 0; bits < (int) sizeof(int) * 8 - chunk_size; bits += chunk_size) {
                    PyObject *tmp, *digit;
                    digit = PyNumber_And(stepval, mask);
                    if (unlikely(!digit)) goto done;
                    idigit = PyLong_AsLong(digit);
                    Py_DECREF(digit);
                    if (unlikely(idigit < 0)) goto done;
                    tmp = PyNumber_Rshift(stepval, shift);
                    if (unlikely(!tmp)) goto done;
                    Py_DECREF(stepval); stepval = tmp;
                    val |= ((int) idigit) << bits;
                    #if CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX < 0x030B0000
                    if (Py_SIZE(stepval) == 0)
                        goto unpacking_done;
                    #endif
                }
                idigit = PyLong_AsLong(stepval);
                if (unlikely(idigit < 0)) goto done;
                remaining_bits = ((int) sizeof(int) * 8) - bits - (is_unsigned ? 0 : 1);
                if (unlikely(idigit >= (1L << remaining_bits)))
                    goto raise_overflow;
                val |= ((int) idigit) << bits;
            #if CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX < 0x030B0000
            unpacking_done:
            #endif
                if (!is_unsigned) {
                    if (unlikely(val & (((int) 1) << (sizeof(int) * 8 - 1))))
                        goto raise_overflow;
                    if (is_negative)
                        val = ~val;
                }
                ret = 0;
            done:
                Py_XDECREF(shift);
                Py_XDECREF(mask);
                Py_XDECREF(stepval);
#endif
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
            return (int) -1;
        }
    } else {
        int val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (int) -1;
        val = __Pyx_PyInt_As_int(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to int");
    return (int) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to int");
    return (int) -1;
}

/* CIntFromPy */
  static CYTHON_INLINE size_t __Pyx_PyInt_As_size_t(PyObject *x) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const size_t neg_one = (size_t) -1, const_zero = (size_t) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if ((sizeof(size_t) < sizeof(long))) {
            __PYX_VERIFY_RETURN_INT(size_t, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (size_t) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            if (unlikely(__Pyx_PyLong_IsNeg(x))) {
                goto raise_neg_overflow;
            } else if (__Pyx_PyLong_IsCompact(x)) {
                __PYX_VERIFY_RETURN_INT(size_t, __Pyx_compact_upylong, __Pyx_PyLong_CompactValueUnsigned(x))
            } else {
                const digit* digits = __Pyx_PyLong_Digits(x);
                assert(__Pyx_PyLong_DigitCount(x) > 1);
                switch (__Pyx_PyLong_DigitCount(x)) {
                    case 2:
                        if ((8 * sizeof(size_t) > 1 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(size_t) >= 2 * PyLong_SHIFT)) {
                                return (size_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
                            }
                        }
                        break;
                    case 3:
                        if ((8 * sizeof(size_t) > 2 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(size_t) >= 3 * PyLong_SHIFT)) {
                                return (size_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
                            }
                        }
                        break;
                    case 4:
                        if ((8 * sizeof(size_t) > 3 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(size_t) >= 4 * PyLong_SHIFT)) {
                                return (size_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
                            }
                        }
                        break;
                }
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030C00A7
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (size_t) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if ((sizeof(size_t) <= sizeof(unsigned long))) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if ((sizeof(size_t) <= sizeof(unsigned PY_LONG_LONG))) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            if (__Pyx_PyLong_IsCompact(x)) {
                __PYX_VERIFY_RETURN_INT(size_t, __Pyx_compact_pylong, __Pyx_PyLong_CompactValue(x))
            } else {
                const digit* digits = __Pyx_PyLong_Digits(x);
                assert(__Pyx_PyLong_DigitCount(x) > 1);
                switch (__Pyx_PyLong_SignedDigitCount(x)) {
                    case -2:
                        if ((8 * sizeof(size_t) - 1 > 1 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(size_t, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(size_t) - 1 > 2 * PyLong_SHIFT)) {
                                return (size_t) (((size_t)-1)*(((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                            }
                        }
                        break;
                    case 2:
                        if ((8 * sizeof(size_t) > 1 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(size_t) - 1 > 2 * PyLong_SHIFT)) {
                                return (size_t) ((((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                            }
                        }
                        break;
                    case -3:
                        if ((8 * sizeof(size_t) - 1 > 2 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(size_t, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(size_t) - 1 > 3 * PyLong_SHIFT)) {
                                return (size_t) (((size_t)-1)*(((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                            }
                        }
                        break;
                    case 3:
                        if ((8 * sizeof(size_t) > 2 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(size_t) - 1 > 3 * PyLong_SHIFT)) {
                                return (size_t) ((((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                            }
                        }
                        break;
                    case -4:
                        if ((8 * sizeof(size_t) - 1 > 3 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(size_t, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(size_t) - 1 > 4 * PyLong_SHIFT)) {
                                return (size_t) (((size_t)-1)*(((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                            }
                        }
                        break;
                    case 4:
                        if ((8 * sizeof(size_t) > 3 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(size_t) - 1 > 4 * PyLong_SHIFT)) {
                                return (size_t) ((((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                            }
                        }
                        break;
                }
            }
#endif
            if ((sizeof(size_t) <= sizeof(long))) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if ((sizeof(size_t) <= sizeof(PY_LONG_LONG))) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
            size_t val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
#if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
#endif
            if (likely(v)) {
                int ret = -1;
#if !(CYTHON_COMPILING_IN_PYPY || CYTHON_COMPILING_IN_LIMITED_API) || defined(_PyLong_AsByteArray)
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                ret = _PyLong_AsByteArray((PyLongObject *)v,
                                           bytes, sizeof(val),
                                           is_little, !is_unsigned);
#else
                PyObject *stepval = NULL, *mask = NULL, *shift = NULL;
                int bits, remaining_bits, is_negative = 0;
                long idigit;
                int chunk_size = (sizeof(long) < 8) ? 30 : 62;
                if (unlikely(!PyLong_CheckExact(v))) {
                    PyObject *tmp = v;
                    v = PyNumber_Long(v);
                    assert(PyLong_CheckExact(v));
                    Py_DECREF(tmp);
                    if (unlikely(!v)) return (size_t) -1;
                }
#if CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX < 0x030B0000
                if (Py_SIZE(x) == 0)
                    return (size_t) 0;
                is_negative = Py_SIZE(x) < 0;
#else
                {
                    int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                    if (unlikely(result < 0))
                        return (size_t) -1;
                    is_negative = result == 1;
                }
#endif
                if (is_unsigned && unlikely(is_negative)) {
                    goto raise_neg_overflow;
                } else if (is_negative) {
                    stepval = PyNumber_Invert(v);
                    if (unlikely(!stepval))
                        return (size_t) -1;
                } else {
                    stepval = __Pyx_NewRef(v);
                }
                val = (size_t) 0;
                mask = PyLong_FromLong((1L << chunk_size) - 1); if (unlikely(!mask)) goto done;
                shift = PyLong_FromLong(chunk_size); if (unlikely(!shift)) goto done;
                for (bits = 0; bits < (int) sizeof(size_t) * 8 - chunk_size; bits += chunk_size) {
                    PyObject *tmp, *digit;
                    digit = PyNumber_And(stepval, mask);
                    if (unlikely(!digit)) goto done;
                    idigit = PyLong_AsLong(digit);
                    Py_DECREF(digit);
                    if (unlikely(idigit < 0)) goto done;
                    tmp = PyNumber_Rshift(stepval, shift);
                    if (unlikely(!tmp)) goto done;
                    Py_DECREF(stepval); stepval = tmp;
                    val |= ((size_t) idigit) << bits;
                    #if CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX < 0x030B0000
                    if (Py_SIZE(stepval) == 0)
                        goto unpacking_done;
                    #endif
                }
                idigit = PyLong_AsLong(stepval);
                if (unlikely(idigit < 0)) goto done;
                remaining_bits = ((int) sizeof(size_t) * 8) - bits - (is_unsigned ? 0 : 1);
                if (unlikely(idigit >= (1L << remaining_bits)))
                    goto raise_overflow;
                val |= ((size_t) idigit) << bits;
            #if CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX < 0x030B0000
            unpacking_done:
            #endif
                if (!is_unsigned) {
                    if (unlikely(val & (((size_t) 1) << (sizeof(size_t) * 8 - 1))))
                        goto raise_overflow;
                    if (is_negative)
                        val = ~val;
                }
                ret = 0;
            done:
                Py_XDECREF(shift);
                Py_XDECREF(mask);
                Py_XDECREF(stepval);
#endif
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
            return (size_t) -1;
        }
    } else {
        size_t val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (size_t) -1;
        val = __Pyx_PyInt_As_size_t(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to size_t");
    return (size_t) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to size_t");
    return (size_t) -1;
}

/* CIntToPy */
  static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const long neg_one = (long) -1, const_zero = (long) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(long) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(long) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(long) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
#if !CYTHON_COMPILING_IN_LIMITED_API
        return _PyLong_FromByteArray(bytes, sizeof(long),
                                     little, !is_unsigned);
#else
        PyObject *from_bytes, *result = NULL;
        PyObject *py_bytes = NULL, *arg_tuple = NULL, *kwds = NULL, *order_str = NULL;
        from_bytes = PyObject_GetAttrString((PyObject*)&PyInt_Type, "from_bytes");
        if (!from_bytes) return NULL;
        py_bytes = PyBytes_FromStringAndSize((char*)bytes, sizeof(long));
        if (!py_bytes) goto limited_bad;
        order_str = PyUnicode_FromString(little ? "little" : "big");
        if (!order_str) goto limited_bad;
        arg_tuple = PyTuple_Pack(2, py_bytes, order_str);
        if (!arg_tuple) goto limited_bad;
        kwds = PyDict_New();
        if (!kwds) goto limited_bad;
        if (PyDict_SetItemString(kwds, "signed", __Pyx_NewRef(!is_unsigned ? Py_True : Py_False))) goto limited_bad;
        result = PyObject_Call(from_bytes, arg_tuple, kwds);
        limited_bad:
        Py_XDECREF(from_bytes);
        Py_XDECREF(py_bytes);
        Py_XDECREF(order_str);
        Py_XDECREF(arg_tuple);
        Py_XDECREF(kwds);
        return result;
#endif
    }
}

/* CIntToPy */
  static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const int neg_one = (int) -1, const_zero = (int) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(int) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(int) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(int) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
#if !CYTHON_COMPILING_IN_LIMITED_API
        return _PyLong_FromByteArray(bytes, sizeof(int),
                                     little, !is_unsigned);
#else
        PyObject *from_bytes, *result = NULL;
        PyObject *py_bytes = NULL, *arg_tuple = NULL, *kwds = NULL, *order_str = NULL;
        from_bytes = PyObject_GetAttrString((PyObject*)&PyInt_Type, "from_bytes");
        if (!from_bytes) return NULL;
        py_bytes = PyBytes_FromStringAndSize((char*)bytes, sizeof(int));
        if (!py_bytes) goto limited_bad;
        order_str = PyUnicode_FromString(little ? "little" : "big");
        if (!order_str) goto limited_bad;
        arg_tuple = PyTuple_Pack(2, py_bytes, order_str);
        if (!arg_tuple) goto limited_bad;
        kwds = PyDict_New();
        if (!kwds) goto limited_bad;
        if (PyDict_SetItemString(kwds, "signed", __Pyx_NewRef(!is_unsigned ? Py_True : Py_False))) goto limited_bad;
        result = PyObject_Call(from_bytes, arg_tuple, kwds);
        limited_bad:
        Py_XDECREF(from_bytes);
        Py_XDECREF(py_bytes);
        Py_XDECREF(order_str);
        Py_XDECREF(arg_tuple);
        Py_XDECREF(kwds);
        return result;
#endif
    }
}

/* FormatTypeName */
  #if CYTHON_COMPILING_IN_LIMITED_API
static __Pyx_TypeName
__Pyx_PyType_GetName(PyTypeObject* tp)
{
    PyObject *name = __Pyx_PyObject_GetAttrStr((PyObject *)tp,
                                               __pyx_n_s_name);
    if (unlikely(name == NULL) || unlikely(!PyUnicode_Check(name))) {
        PyErr_Clear();
        Py_XDECREF(name);
        name = __Pyx_NewRef(__pyx_n_s__96);
    }
    return name;
}
#endif

/* CIntFromPy */
  static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *x) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const long neg_one = (long) -1, const_zero = (long) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if ((sizeof(long) < sizeof(long))) {
            __PYX_VERIFY_RETURN_INT(long, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (long) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            if (unlikely(__Pyx_PyLong_IsNeg(x))) {
                goto raise_neg_overflow;
            } else if (__Pyx_PyLong_IsCompact(x)) {
                __PYX_VERIFY_RETURN_INT(long, __Pyx_compact_upylong, __Pyx_PyLong_CompactValueUnsigned(x))
            } else {
                const digit* digits = __Pyx_PyLong_Digits(x);
                assert(__Pyx_PyLong_DigitCount(x) > 1);
                switch (__Pyx_PyLong_DigitCount(x)) {
                    case 2:
                        if ((8 * sizeof(long) > 1 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(long) >= 2 * PyLong_SHIFT)) {
                                return (long) (((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                            }
                        }
                        break;
                    case 3:
                        if ((8 * sizeof(long) > 2 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(long) >= 3 * PyLong_SHIFT)) {
                                return (long) (((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                            }
                        }
                        break;
                    case 4:
                        if ((8 * sizeof(long) > 3 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(long) >= 4 * PyLong_SHIFT)) {
                                return (long) (((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                            }
                        }
                        break;
                }
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030C00A7
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (long) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if ((sizeof(long) <= sizeof(unsigned long))) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if ((sizeof(long) <= sizeof(unsigned PY_LONG_LONG))) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            if (__Pyx_PyLong_IsCompact(x)) {
                __PYX_VERIFY_RETURN_INT(long, __Pyx_compact_pylong, __Pyx_PyLong_CompactValue(x))
            } else {
                const digit* digits = __Pyx_PyLong_Digits(x);
                assert(__Pyx_PyLong_DigitCount(x) > 1);
                switch (__Pyx_PyLong_SignedDigitCount(x)) {
                    case -2:
                        if ((8 * sizeof(long) - 1 > 1 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(long) - 1 > 2 * PyLong_SHIFT)) {
                                return (long) (((long)-1)*(((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                            }
                        }
                        break;
                    case 2:
                        if ((8 * sizeof(long) > 1 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(long) - 1 > 2 * PyLong_SHIFT)) {
                                return (long) ((((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                            }
                        }
                        break;
                    case -3:
                        if ((8 * sizeof(long) - 1 > 2 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(long) - 1 > 3 * PyLong_SHIFT)) {
                                return (long) (((long)-1)*(((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                            }
                        }
                        break;
                    case 3:
                        if ((8 * sizeof(long) > 2 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(long) - 1 > 3 * PyLong_SHIFT)) {
                                return (long) ((((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                            }
                        }
                        break;
                    case -4:
                        if ((8 * sizeof(long) - 1 > 3 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(long) - 1 > 4 * PyLong_SHIFT)) {
                                return (long) (((long)-1)*(((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                            }
                        }
                        break;
                    case 4:
                        if ((8 * sizeof(long) > 3 * PyLong_SHIFT)) {
                            if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                                __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                            } else if ((8 * sizeof(long) - 1 > 4 * PyLong_SHIFT)) {
                                return (long) ((((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                            }
                        }
                        break;
                }
            }
#endif
            if ((sizeof(long) <= sizeof(long))) {
                __PYX_VERIFY_RETURN_INT_EXC(long, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if ((sizeof(long) <= sizeof(PY_LONG_LONG))) {
                __PYX_VERIFY_RETURN_INT_EXC(long, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
            long val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
#if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
#endif
            if (likely(v)) {
                int ret = -1;
#if !(CYTHON_COMPILING_IN_PYPY || CYTHON_COMPILING_IN_LIMITED_API) || defined(_PyLong_AsByteArray)
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                ret = _PyLong_AsByteArray((PyLongObject *)v,
                                           bytes, sizeof(val),
                                           is_little, !is_unsigned);
#else
                PyObject *stepval = NULL, *mask = NULL, *shift = NULL;
                int bits, remaining_bits, is_negative = 0;
                long idigit;
                int chunk_size = (sizeof(long) < 8) ? 30 : 62;
                if (unlikely(!PyLong_CheckExact(v))) {
                    PyObject *tmp = v;
                    v = PyNumber_Long(v);
                    assert(PyLong_CheckExact(v));
                    Py_DECREF(tmp);
                    if (unlikely(!v)) return (long) -1;
                }
#if CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX < 0x030B0000
                if (Py_SIZE(x) == 0)
                    return (long) 0;
                is_negative = Py_SIZE(x) < 0;
#else
                {
                    int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                    if (unlikely(result < 0))
                        return (long) -1;
                    is_negative = result == 1;
                }
#endif
                if (is_unsigned && unlikely(is_negative)) {
                    goto raise_neg_overflow;
                } else if (is_negative) {
                    stepval = PyNumber_Invert(v);
                    if (unlikely(!stepval))
                        return (long) -1;
                } else {
                    stepval = __Pyx_NewRef(v);
                }
                val = (long) 0;
                mask = PyLong_FromLong((1L << chunk_size) - 1); if (unlikely(!mask)) goto done;
                shift = PyLong_FromLong(chunk_size); if (unlikely(!shift)) goto done;
                for (bits = 0; bits < (int) sizeof(long) * 8 - chunk_size; bits += chunk_size) {
                    PyObject *tmp, *digit;
                    digit = PyNumber_And(stepval, mask);
                    if (unlikely(!digit)) goto done;
                    idigit = PyLong_AsLong(digit);
                    Py_DECREF(digit);
                    if (unlikely(idigit < 0)) goto done;
                    tmp = PyNumber_Rshift(stepval, shift);
                    if (unlikely(!tmp)) goto done;
                    Py_DECREF(stepval); stepval = tmp;
                    val |= ((long) idigit) << bits;
                    #if CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX < 0x030B0000
                    if (Py_SIZE(stepval) == 0)
                        goto unpacking_done;
                    #endif
                }
                idigit = PyLong_AsLong(stepval);
                if (unlikely(idigit < 0)) goto done;
                remaining_bits = ((int) sizeof(long) * 8) - bits - (is_unsigned ? 0 : 1);
                if (unlikely(idigit >= (1L << remaining_bits)))
                    goto raise_overflow;
                val |= ((long) idigit) << bits;
            #if CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX < 0x030B0000
            unpacking_done:
            #endif
                if (!is_unsigned) {
                    if (unlikely(val & (((long) 1) << (sizeof(long) * 8 - 1))))
                        goto raise_overflow;
                    if (is_negative)
                        val = ~val;
                }
                ret = 0;
            done:
                Py_XDECREF(shift);
                Py_XDECREF(mask);
                Py_XDECREF(stepval);
#endif
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
            return (long) -1;
        }
    } else {
        long val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (long) -1;
        val = __Pyx_PyInt_As_long(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to long");
    return (long) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to long");
    return (long) -1;
}

/* FastTypeChecks */
  #if CYTHON_COMPILING_IN_CPYTHON
static int __Pyx_InBases(PyTypeObject *a, PyTypeObject *b) {
    while (a) {
        a = __Pyx_PyType_GetSlot(a, tp_base, PyTypeObject*);
        if (a == b)
            return 1;
    }
    return b == &PyBaseObject_Type;
}
static CYTHON_INLINE int __Pyx_IsSubtype(PyTypeObject *a, PyTypeObject *b) {
    PyObject *mro;
    if (a == b) return 1;
    mro = a->tp_mro;
    if (likely(mro)) {
        Py_ssize_t i, n;
        n = PyTuple_GET_SIZE(mro);
        for (i = 0; i < n; i++) {
            if (PyTuple_GET_ITEM(mro, i) == (PyObject *)b)
                return 1;
        }
        return 0;
    }
    return __Pyx_InBases(a, b);
}
static CYTHON_INLINE int __Pyx_IsAnySubtype2(PyTypeObject *cls, PyTypeObject *a, PyTypeObject *b) {
    PyObject *mro;
    if (cls == a || cls == b) return 1;
    mro = cls->tp_mro;
    if (likely(mro)) {
        Py_ssize_t i, n;
        n = PyTuple_GET_SIZE(mro);
        for (i = 0; i < n; i++) {
            PyObject *base = PyTuple_GET_ITEM(mro, i);
            if (base == (PyObject *)a || base == (PyObject *)b)
                return 1;
        }
        return 0;
    }
    return __Pyx_InBases(cls, a) || __Pyx_InBases(cls, b);
}
#if PY_MAJOR_VERSION == 2
static int __Pyx_inner_PyErr_GivenExceptionMatches2(PyObject *err, PyObject* exc_type1, PyObject* exc_type2) {
    PyObject *exception, *value, *tb;
    int res;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&exception, &value, &tb);
    res = exc_type1 ? PyObject_IsSubclass(err, exc_type1) : 0;
    if (unlikely(res == -1)) {
        PyErr_WriteUnraisable(err);
        res = 0;
    }
    if (!res) {
        res = PyObject_IsSubclass(err, exc_type2);
        if (unlikely(res == -1)) {
            PyErr_WriteUnraisable(err);
            res = 0;
        }
    }
    __Pyx_ErrRestore(exception, value, tb);
    return res;
}
#else
static CYTHON_INLINE int __Pyx_inner_PyErr_GivenExceptionMatches2(PyObject *err, PyObject* exc_type1, PyObject *exc_type2) {
    if (exc_type1) {
        return __Pyx_IsAnySubtype2((PyTypeObject*)err, (PyTypeObject*)exc_type1, (PyTypeObject*)exc_type2);
    } else {
        return __Pyx_IsSubtype((PyTypeObject*)err, (PyTypeObject*)exc_type2);
    }
}
#endif
static int __Pyx_PyErr_GivenExceptionMatchesTuple(PyObject *exc_type, PyObject *tuple) {
    Py_ssize_t i, n;
    assert(PyExceptionClass_Check(exc_type));
    n = PyTuple_GET_SIZE(tuple);
#if PY_MAJOR_VERSION >= 3
    for (i=0; i<n; i++) {
        if (exc_type == PyTuple_GET_ITEM(tuple, i)) return 1;
    }
#endif
    for (i=0; i<n; i++) {
        PyObject *t = PyTuple_GET_ITEM(tuple, i);
        #if PY_MAJOR_VERSION < 3
        if (likely(exc_type == t)) return 1;
        #endif
        if (likely(PyExceptionClass_Check(t))) {
            if (__Pyx_inner_PyErr_GivenExceptionMatches2(exc_type, NULL, t)) return 1;
        } else {
        }
    }
    return 0;
}
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches(PyObject *err, PyObject* exc_type) {
    if (likely(err == exc_type)) return 1;
    if (likely(PyExceptionClass_Check(err))) {
        if (likely(PyExceptionClass_Check(exc_type))) {
            return __Pyx_inner_PyErr_GivenExceptionMatches2(err, NULL, exc_type);
        } else if (likely(PyTuple_Check(exc_type))) {
            return __Pyx_PyErr_GivenExceptionMatchesTuple(err, exc_type);
        } else {
        }
    }
    return PyErr_GivenExceptionMatches(err, exc_type);
}
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *exc_type1, PyObject *exc_type2) {
    assert(PyExceptionClass_Check(exc_type1));
    assert(PyExceptionClass_Check(exc_type2));
    if (likely(err == exc_type1 || err == exc_type2)) return 1;
    if (likely(PyExceptionClass_Check(err))) {
        return __Pyx_inner_PyErr_GivenExceptionMatches2(err, exc_type1, exc_type2);
    }
    return (PyErr_GivenExceptionMatches(err, exc_type1) || PyErr_GivenExceptionMatches(err, exc_type2));
}
#endif

/* CheckBinaryVersion */
  static unsigned long __Pyx_get_runtime_version() {
#if __PYX_LIMITED_VERSION_HEX >= 0x030B00A4
    return Py_Version & ~0xFFUL;
#else
    const char* rt_version = Py_GetVersion();
    unsigned long version = 0;
    unsigned long factor = 0x01000000UL;
    unsigned int digit = 0;
    int i = 0;
    while (factor) {
        while ('0' <= rt_version[i] && rt_version[i] <= '9') {
            digit = digit * 10 + (unsigned int) (rt_version[i] - '0');
            ++i;
        }
        version += factor * digit;
        if (rt_version[i] != '.')
            break;
        digit = 0;
        factor >>= 8;
        ++i;
    }
    return version;
#endif
}
static int __Pyx_check_binary_version(unsigned long ct_version, unsigned long rt_version, int allow_newer) {
    const unsigned long MAJOR_MINOR = 0xFFFF0000UL;
    if ((rt_version & MAJOR_MINOR) == (ct_version & MAJOR_MINOR))
        return 0;
    if (likely(allow_newer && (rt_version & MAJOR_MINOR) > (ct_version & MAJOR_MINOR)))
        return 1;
    {
        char message[200];
        PyOS_snprintf(message, sizeof(message),
                      "compile time Python version %d.%d "
                      "of module '%.100s' "
                      "%s "
                      "runtime version %d.%d",
                       (int) (ct_version >> 24), (int) ((ct_version >> 16) & 0xFF),
                       __Pyx_MODULE_NAME,
                       (allow_newer) ? "was newer than" : "does not match",
                       (int) (rt_version >> 24), (int) ((rt_version >> 16) & 0xFF)
       );
        return PyErr_WarnEx(NULL, message, 1);
    }
}

/* InitStrings */
  #if PY_MAJOR_VERSION >= 3
static int __Pyx_InitString(__Pyx_StringTabEntry t, PyObject **str) {
    if (t.is_unicode | t.is_str) {
        if (t.intern) {
            *str = PyUnicode_InternFromString(t.s);
        } else if (t.encoding) {
            *str = PyUnicode_Decode(t.s, t.n - 1, t.encoding, NULL);
        } else {
            *str = PyUnicode_FromStringAndSize(t.s, t.n - 1);
        }
    } else {
        *str = PyBytes_FromStringAndSize(t.s, t.n - 1);
    }
    if (!*str)
        return -1;
    if (PyObject_Hash(*str) == -1)
        return -1;
    return 0;
}
#endif
static int __Pyx_InitStrings(__Pyx_StringTabEntry *t) {
    while (t->p) {
        #if PY_MAJOR_VERSION >= 3
        __Pyx_InitString(*t, t->p);
        #else
        if (t->is_unicode) {
            *t->p = PyUnicode_DecodeUTF8(t->s, t->n - 1, NULL);
        } else if (t->intern) {
            *t->p = PyString_InternFromString(t->s);
        } else {
            *t->p = PyString_FromStringAndSize(t->s, t->n - 1);
        }
        if (!*t->p)
            return -1;
        if (PyObject_Hash(*t->p) == -1)
            return -1;
        #endif
        ++t;
    }
    return 0;
}

#include <string.h>
static CYTHON_INLINE Py_ssize_t __Pyx_ssize_strlen(const char *s) {
    size_t len = strlen(s);
    if (unlikely(len > (size_t) PY_SSIZE_T_MAX)) {
        PyErr_SetString(PyExc_OverflowError, "byte string is too long");
        return -1;
    }
    return (Py_ssize_t) len;
}
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char* c_str) {
    Py_ssize_t len = __Pyx_ssize_strlen(c_str);
    if (unlikely(len < 0)) return NULL;
    return __Pyx_PyUnicode_FromStringAndSize(c_str, len);
}
static CYTHON_INLINE PyObject* __Pyx_PyByteArray_FromString(const char* c_str) {
    Py_ssize_t len = __Pyx_ssize_strlen(c_str);
    if (unlikely(len < 0)) return NULL;
    return PyByteArray_FromStringAndSize(c_str, len);
}
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject* o) {
    Py_ssize_t ignore;
    return __Pyx_PyObject_AsStringAndSize(o, &ignore);
}
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
#if !CYTHON_PEP393_ENABLED
static const char* __Pyx_PyUnicode_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
    char* defenc_c;
    PyObject* defenc = _PyUnicode_AsDefaultEncodedString(o, NULL);
    if (!defenc) return NULL;
    defenc_c = PyBytes_AS_STRING(defenc);
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
    {
        char* end = defenc_c + PyBytes_GET_SIZE(defenc);
        char* c;
        for (c = defenc_c; c < end; c++) {
            if ((unsigned char) (*c) >= 128) {
                PyUnicode_AsASCIIString(o);
                return NULL;
            }
        }
    }
#endif
    *length = PyBytes_GET_SIZE(defenc);
    return defenc_c;
}
#else
static CYTHON_INLINE const char* __Pyx_PyUnicode_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
    if (unlikely(__Pyx_PyUnicode_READY(o) == -1)) return NULL;
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
    if (likely(PyUnicode_IS_ASCII(o))) {
        *length = PyUnicode_GET_LENGTH(o);
        return PyUnicode_AsUTF8(o);
    } else {
        PyUnicode_AsASCIIString(o);
        return NULL;
    }
#else
    return PyUnicode_AsUTF8AndSize(o, length);
#endif
}
#endif
#endif
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
    if (
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
            __Pyx_sys_getdefaultencoding_not_ascii &&
#endif
            PyUnicode_Check(o)) {
        return __Pyx_PyUnicode_AsStringAndSize(o, length);
    } else
#endif
#if (!CYTHON_COMPILING_IN_PYPY && !CYTHON_COMPILING_IN_LIMITED_API) || (defined(PyByteArray_AS_STRING) && defined(PyByteArray_GET_SIZE))
    if (PyByteArray_Check(o)) {
        *length = PyByteArray_GET_SIZE(o);
        return PyByteArray_AS_STRING(o);
    } else
#endif
    {
        char* result;
        int r = PyBytes_AsStringAndSize(o, &result, length);
        if (unlikely(r < 0)) {
            return NULL;
        } else {
            return result;
        }
    }
}
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject* x) {
   int is_true = x == Py_True;
   if (is_true | (x == Py_False) | (x == Py_None)) return is_true;
   else return PyObject_IsTrue(x);
}
static CYTHON_INLINE int __Pyx_PyObject_IsTrueAndDecref(PyObject* x) {
    int retval;
    if (unlikely(!x)) return -1;
    retval = __Pyx_PyObject_IsTrue(x);
    Py_DECREF(x);
    return retval;
}
static PyObject* __Pyx_PyNumber_IntOrLongWrongResultType(PyObject* result, const char* type_name) {
    __Pyx_TypeName result_type_name = __Pyx_PyType_GetName(Py_TYPE(result));
#if PY_MAJOR_VERSION >= 3
    if (PyLong_Check(result)) {
        if (PyErr_WarnFormat(PyExc_DeprecationWarning, 1,
                "__int__ returned non-int (type " __Pyx_FMT_TYPENAME ").  "
                "The ability to return an instance of a strict subclass of int is deprecated, "
                "and may be removed in a future version of Python.",
                result_type_name)) {
            __Pyx_DECREF_TypeName(result_type_name);
            Py_DECREF(result);
            return NULL;
        }
        __Pyx_DECREF_TypeName(result_type_name);
        return result;
    }
#endif
    PyErr_Format(PyExc_TypeError,
                 "__%.4s__ returned non-%.4s (type " __Pyx_FMT_TYPENAME ")",
                 type_name, type_name, result_type_name);
    __Pyx_DECREF_TypeName(result_type_name);
    Py_DECREF(result);
    return NULL;
}
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x) {
#if CYTHON_USE_TYPE_SLOTS
  PyNumberMethods *m;
#endif
  const char *name = NULL;
  PyObject *res = NULL;
#if PY_MAJOR_VERSION < 3
  if (likely(PyInt_Check(x) || PyLong_Check(x)))
#else
  if (likely(PyLong_Check(x)))
#endif
    return __Pyx_NewRef(x);
#if CYTHON_USE_TYPE_SLOTS
  m = Py_TYPE(x)->tp_as_number;
  #if PY_MAJOR_VERSION < 3
  if (m && m->nb_int) {
    name = "int";
    res = m->nb_int(x);
  }
  else if (m && m->nb_long) {
    name = "long";
    res = m->nb_long(x);
  }
  #else
  if (likely(m && m->nb_int)) {
    name = "int";
    res = m->nb_int(x);
  }
  #endif
#else
  if (!PyBytes_CheckExact(x) && !PyUnicode_CheckExact(x)) {
    res = PyNumber_Int(x);
  }
#endif
  if (likely(res)) {
#if PY_MAJOR_VERSION < 3
    if (unlikely(!PyInt_Check(res) && !PyLong_Check(res))) {
#else
    if (unlikely(!PyLong_CheckExact(res))) {
#endif
        return __Pyx_PyNumber_IntOrLongWrongResultType(res, name);
    }
  }
  else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_TypeError,
                    "an integer is required");
  }
  return res;
}
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject* b) {
  Py_ssize_t ival;
  PyObject *x;
#if PY_MAJOR_VERSION < 3
  if (likely(PyInt_CheckExact(b))) {
    if (sizeof(Py_ssize_t) >= sizeof(long))
        return PyInt_AS_LONG(b);
    else
        return PyInt_AsSsize_t(b);
  }
#endif
  if (likely(PyLong_CheckExact(b))) {
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(__Pyx_PyLong_IsCompact(b))) {
        return __Pyx_PyLong_CompactValue(b);
    } else {
      const digit* digits = __Pyx_PyLong_Digits(b);
      const Py_ssize_t size = __Pyx_PyLong_SignedDigitCount(b);
      switch (size) {
         case 2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
      }
    }
    #endif
    return PyLong_AsSsize_t(b);
  }
  x = PyNumber_Index(b);
  if (!x) return -1;
  ival = PyInt_AsSsize_t(x);
  Py_DECREF(x);
  return ival;
}
static CYTHON_INLINE Py_hash_t __Pyx_PyIndex_AsHash_t(PyObject* o) {
  if (sizeof(Py_hash_t) == sizeof(Py_ssize_t)) {
    return (Py_hash_t) __Pyx_PyIndex_AsSsize_t(o);
#if PY_MAJOR_VERSION < 3
  } else if (likely(PyInt_CheckExact(o))) {
    return PyInt_AS_LONG(o);
#endif
  } else {
    Py_ssize_t ival;
    PyObject *x;
    x = PyNumber_Index(o);
    if (!x) return -1;
    ival = PyInt_AsLong(x);
    Py_DECREF(x);
    return ival;
  }
}
static CYTHON_INLINE PyObject * __Pyx_PyBool_FromLong(long b) {
  return b ? __Pyx_NewRef(Py_True) : __Pyx_NewRef(Py_False);
}
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t ival) {
    return PyInt_FromSize_t(ival);
}


/* #### Code section: utility_code_pragmas_end ### */
#ifdef _MSC_VER
#pragma warning( pop )
#endif



/* #### Code section: end ### */
#endif /* Py_PYTHON_H */
